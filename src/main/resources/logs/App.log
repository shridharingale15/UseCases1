2022-02-14 10:56:19 INFO  SparkContext:57 - Running Spark version 3.0.3
2022-02-14 10:56:19 DEBUG MutableMetricsFactory:42 - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about="", sampleName="Ops", always=false, type=DEFAULT, value={"Rate of successful kerberos logins and latency (milliseconds)"}, valueName="Time")
2022-02-14 10:56:19 DEBUG MutableMetricsFactory:42 - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about="", sampleName="Ops", always=false, type=DEFAULT, value={"Rate of failed kerberos logins and latency (milliseconds)"}, valueName="Time")
2022-02-14 10:56:19 DEBUG MutableMetricsFactory:42 - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about="", sampleName="Ops", always=false, type=DEFAULT, value={"GetGroups"}, valueName="Time")
2022-02-14 10:56:19 DEBUG MetricsSystemImpl:232 - UgiMetrics, User and group related metrics
2022-02-14 10:56:20 DEBUG KerberosName:89 - Kerberos krb5 configuration not found, setting default realm to empty
2022-02-14 10:56:20 DEBUG Groups:301 -  Creating new Groups object
2022-02-14 10:56:20 DEBUG NativeCodeLoader:46 - Trying to load the custom-built native-hadoop library...
2022-02-14 10:56:20 DEBUG NativeCodeLoader:50 - Loaded the native-hadoop library
2022-02-14 10:56:20 DEBUG JniBasedUnixGroupsMapping:50 - Using JniBasedUnixGroupsMapping for Group resolution
2022-02-14 10:56:20 DEBUG JniBasedUnixGroupsMappingWithFallback:45 - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
2022-02-14 10:56:20 DEBUG Groups:112 - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2022-02-14 10:56:20 DEBUG UserGroupInformation:223 - hadoop login
2022-02-14 10:56:20 DEBUG UserGroupInformation:158 - hadoop login commit
2022-02-14 10:56:20 DEBUG UserGroupInformation:188 - using local user:NTUserPrincipal: Shridhar Ingale
2022-02-14 10:56:20 DEBUG UserGroupInformation:194 - Using user: "NTUserPrincipal: Shridhar Ingale" with name Shridhar Ingale
2022-02-14 10:56:20 DEBUG UserGroupInformation:204 - User entry: "Shridhar Ingale"
2022-02-14 10:56:20 DEBUG UserGroupInformation:816 - Assuming keytab is managed externally since logged in from subject.
2022-02-14 10:56:20 DEBUG UserGroupInformation:844 - UGI loginUser:Shridhar Ingale (auth:SIMPLE)
2022-02-14 10:56:20 INFO  ResourceUtils:57 - ==============================================================
2022-02-14 10:56:20 INFO  ResourceUtils:57 - Resources for spark.driver:

2022-02-14 10:56:20 INFO  ResourceUtils:57 - ==============================================================
2022-02-14 10:56:20 INFO  SparkContext:57 - Submitted application: 03d9c621-b5a4-46d2-9121-e6774afc4cb7
2022-02-14 10:56:20 INFO  SecurityManager:57 - Changing view acls to: Shridhar Ingale
2022-02-14 10:56:20 INFO  SecurityManager:57 - Changing modify acls to: Shridhar Ingale
2022-02-14 10:56:20 INFO  SecurityManager:57 - Changing view acls groups to: 
2022-02-14 10:56:20 INFO  SecurityManager:57 - Changing modify acls groups to: 
2022-02-14 10:56:20 INFO  SecurityManager:57 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Shridhar Ingale); groups with view permissions: Set(); users  with modify permissions: Set(Shridhar Ingale); groups with modify permissions: Set()
2022-02-14 10:56:20 DEBUG InternalLoggerFactory:45 - Using SLF4J as the default logging framework
2022-02-14 10:56:20 DEBUG InternalThreadLocalMap:56 - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2022-02-14 10:56:20 DEBUG InternalThreadLocalMap:59 - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2022-02-14 10:56:20 DEBUG MultithreadEventLoopGroup:44 - -Dio.netty.eventLoopThreads: 16
2022-02-14 10:56:20 DEBUG NioEventLoop:106 - -Dio.netty.noKeySetOptimization: false
2022-02-14 10:56:20 DEBUG NioEventLoop:107 - -Dio.netty.selectorAutoRebuildThreshold: 512
2022-02-14 10:56:20 DEBUG PlatformDependent:1003 - Platform: Windows
2022-02-14 10:56:20 DEBUG PlatformDependent0:396 - -Dio.netty.noUnsafe: false
2022-02-14 10:56:20 DEBUG PlatformDependent0:852 - Java version: 11
2022-02-14 10:56:20 DEBUG PlatformDependent0:121 - sun.misc.Unsafe.theUnsafe: available
2022-02-14 10:56:20 DEBUG PlatformDependent0:145 - sun.misc.Unsafe.copyMemory: available
2022-02-14 10:56:20 DEBUG PlatformDependent0:183 - java.nio.Buffer.address: available
2022-02-14 10:56:20 DEBUG PlatformDependent0:253 - direct buffer constructor: unavailable
java.lang.UnsupportedOperationException: Reflective setAccessible(true) disabled
	at io.netty.util.internal.ReflectionUtil.trySetAccessible(ReflectionUtil.java:31)
	at io.netty.util.internal.PlatformDependent0$4.run(PlatformDependent0.java:225)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:219)
	at io.netty.util.internal.PlatformDependent.isAndroid(PlatformDependent.java:289)
	at io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:92)
	at io.netty.channel.nio.NioEventLoop.newTaskQueue0(NioEventLoop.java:279)
	at io.netty.channel.nio.NioEventLoop.newTaskQueue(NioEventLoop.java:150)
	at io.netty.channel.nio.NioEventLoop.<init>(NioEventLoop.java:138)
	at io.netty.channel.nio.NioEventLoopGroup.newChild(NioEventLoopGroup.java:146)
	at io.netty.channel.nio.NioEventLoopGroup.newChild(NioEventLoopGroup.java:37)
	at io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:84)
	at io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:58)
	at io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:47)
	at io.netty.channel.MultithreadEventLoopGroup.<init>(MultithreadEventLoopGroup.java:59)
	at io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:86)
	at io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:81)
	at io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:68)
	at org.apache.spark.network.util.NettyUtils.createEventLoop(NettyUtils.java:66)
	at org.apache.spark.network.client.TransportClientFactory.<init>(TransportClientFactory.java:102)
	at org.apache.spark.network.TransportContext.createClientFactory(TransportContext.java:142)
	at org.apache.spark.rpc.netty.NettyRpcEnv.<init>(NettyRpcEnv.scala:77)
	at org.apache.spark.rpc.netty.NettyRpcEnvFactory.create(NettyRpcEnv.scala:486)
	at org.apache.spark.rpc.RpcEnv$.create(RpcEnv.scala:57)
	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:266)
	at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:189)
	at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:272)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2589)
	at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:937)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:931)
	at My_UsedCases.UsedCase5.My_func_swap6(UsedCase5.java:11)
	at MyTEsts.UseCaseTest5.My_func4(UseCaseTest5.java:9)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:220)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:53)
2022-02-14 10:56:20 DEBUG PlatformDependent0:314 - java.nio.Bits.unaligned: available, true
2022-02-14 10:56:20 DEBUG PlatformDependent0:373 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable
java.lang.IllegalAccessException: class io.netty.util.internal.PlatformDependent0$6 cannot access class jdk.internal.misc.Unsafe (in module java.base) because module java.base does not export jdk.internal.misc to unnamed module @7331196b
	at java.base/jdk.internal.reflect.Reflection.newIllegalAccessException(Reflection.java:361)
	at java.base/java.lang.reflect.AccessibleObject.checkAccess(AccessibleObject.java:591)
	at java.base/java.lang.reflect.Method.invoke(Method.java:558)
	at io.netty.util.internal.PlatformDependent0$6.run(PlatformDependent0.java:335)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:326)
	at io.netty.util.internal.PlatformDependent.isAndroid(PlatformDependent.java:289)
	at io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:92)
	at io.netty.channel.nio.NioEventLoop.newTaskQueue0(NioEventLoop.java:279)
	at io.netty.channel.nio.NioEventLoop.newTaskQueue(NioEventLoop.java:150)
	at io.netty.channel.nio.NioEventLoop.<init>(NioEventLoop.java:138)
	at io.netty.channel.nio.NioEventLoopGroup.newChild(NioEventLoopGroup.java:146)
	at io.netty.channel.nio.NioEventLoopGroup.newChild(NioEventLoopGroup.java:37)
	at io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:84)
	at io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:58)
	at io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:47)
	at io.netty.channel.MultithreadEventLoopGroup.<init>(MultithreadEventLoopGroup.java:59)
	at io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:86)
	at io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:81)
	at io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:68)
	at org.apache.spark.network.util.NettyUtils.createEventLoop(NettyUtils.java:66)
	at org.apache.spark.network.client.TransportClientFactory.<init>(TransportClientFactory.java:102)
	at org.apache.spark.network.TransportContext.createClientFactory(TransportContext.java:142)
	at org.apache.spark.rpc.netty.NettyRpcEnv.<init>(NettyRpcEnv.scala:77)
	at org.apache.spark.rpc.netty.NettyRpcEnvFactory.create(NettyRpcEnv.scala:486)
	at org.apache.spark.rpc.RpcEnv$.create(RpcEnv.scala:57)
	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:266)
	at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:189)
	at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:272)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2589)
	at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:937)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:931)
	at My_UsedCases.UsedCase5.My_func_swap6(UsedCase5.java:11)
	at MyTEsts.UseCaseTest5.My_func4(UseCaseTest5.java:9)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:220)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:53)
2022-02-14 10:56:20 DEBUG PlatformDependent0:386 - java.nio.DirectByteBuffer.<init>(long, int): unavailable
2022-02-14 10:56:20 DEBUG PlatformDependent:1046 - sun.misc.Unsafe: available
2022-02-14 10:56:20 DEBUG PlatformDependent:1146 - maxDirectMemory: 4227858432 bytes (maybe)
2022-02-14 10:56:20 DEBUG PlatformDependent:1165 - -Dio.netty.tmpdir: C:\Users\SHRIDH~1\AppData\Local\Temp (java.io.tmpdir)
2022-02-14 10:56:20 DEBUG PlatformDependent:1244 - -Dio.netty.bitMode: 64 (sun.arch.data.model)
2022-02-14 10:56:20 DEBUG PlatformDependent:177 - -Dio.netty.maxDirectMemory: -1 bytes
2022-02-14 10:56:20 DEBUG PlatformDependent:184 - -Dio.netty.uninitializedArrayAllocationThreshold: -1
2022-02-14 10:56:20 DEBUG CleanerJava9:71 - java.nio.ByteBuffer.cleaner(): available
2022-02-14 10:56:20 DEBUG PlatformDependent:204 - -Dio.netty.noPreferDirect: false
2022-02-14 10:56:20 DEBUG PlatformDependent:907 - org.jctools-core.MpscChunkedArrayQueue: available
2022-02-14 10:56:20 DEBUG ResourceLeakDetector:130 - -Dio.netty.leakDetection.level: simple
2022-02-14 10:56:20 DEBUG ResourceLeakDetector:131 - -Dio.netty.leakDetection.targetRecords: 4
2022-02-14 10:56:20 DEBUG PooledByteBufAllocator:156 - -Dio.netty.allocator.numHeapArenas: 16
2022-02-14 10:56:20 DEBUG PooledByteBufAllocator:157 - -Dio.netty.allocator.numDirectArenas: 16
2022-02-14 10:56:20 DEBUG PooledByteBufAllocator:159 - -Dio.netty.allocator.pageSize: 8192
2022-02-14 10:56:20 DEBUG PooledByteBufAllocator:164 - -Dio.netty.allocator.maxOrder: 11
2022-02-14 10:56:20 DEBUG PooledByteBufAllocator:168 - -Dio.netty.allocator.chunkSize: 16777216
2022-02-14 10:56:20 DEBUG PooledByteBufAllocator:169 - -Dio.netty.allocator.tinyCacheSize: 512
2022-02-14 10:56:20 DEBUG PooledByteBufAllocator:170 - -Dio.netty.allocator.smallCacheSize: 256
2022-02-14 10:56:20 DEBUG PooledByteBufAllocator:171 - -Dio.netty.allocator.normalCacheSize: 64
2022-02-14 10:56:20 DEBUG PooledByteBufAllocator:172 - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2022-02-14 10:56:20 DEBUG PooledByteBufAllocator:173 - -Dio.netty.allocator.cacheTrimInterval: 8192
2022-02-14 10:56:20 DEBUG PooledByteBufAllocator:174 - -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2022-02-14 10:56:20 DEBUG PooledByteBufAllocator:175 - -Dio.netty.allocator.useCacheForAllThreads: true
2022-02-14 10:56:20 DEBUG PooledByteBufAllocator:176 - -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2022-02-14 10:56:20 DEBUG DefaultChannelId:79 - -Dio.netty.processId: 17884 (auto-detected)
2022-02-14 10:56:20 DEBUG NetUtil:139 - -Djava.net.preferIPv4Stack: false
2022-02-14 10:56:20 DEBUG NetUtil:140 - -Djava.net.preferIPv6Addresses: false
2022-02-14 10:56:21 DEBUG NetUtil:224 - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
2022-02-14 10:56:21 DEBUG NetUtil:289 - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
2022-02-14 10:56:21 DEBUG DefaultChannelId:101 - -Dio.netty.machineId: 00:50:56:ff:fe:c0:00:01 (auto-detected)
2022-02-14 10:56:21 DEBUG ByteBufUtil:86 - -Dio.netty.allocator.type: pooled
2022-02-14 10:56:21 DEBUG ByteBufUtil:95 - -Dio.netty.threadLocalDirectBufferSize: 0
2022-02-14 10:56:21 DEBUG ByteBufUtil:98 - -Dio.netty.maxThreadLocalCharBufferSize: 16384
2022-02-14 10:56:21 DEBUG TransportServer:153 - Shuffle server started on port: 60354
2022-02-14 10:56:21 INFO  Utils:57 - Successfully started service 'sparkDriver' on port 60354.
2022-02-14 10:56:21 DEBUG SparkEnv:61 - Using serializer: class org.apache.spark.serializer.JavaSerializer
2022-02-14 10:56:21 INFO  SparkEnv:57 - Registering MapOutputTracker
2022-02-14 10:56:21 DEBUG MapOutputTrackerMasterEndpoint:61 - init
2022-02-14 10:56:21 INFO  SparkEnv:57 - Registering BlockManagerMaster
2022-02-14 10:56:21 INFO  BlockManagerMasterEndpoint:57 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022-02-14 10:56:21 INFO  BlockManagerMasterEndpoint:57 - BlockManagerMasterEndpoint up
2022-02-14 10:56:21 INFO  SparkEnv:57 - Registering BlockManagerMasterHeartbeat
2022-02-14 10:56:21 INFO  DiskBlockManager:57 - Created local directory at C:\Users\Shridhar Ingale\AppData\Local\Temp\blockmgr-f1a2ed1c-369b-43fd-a3bb-e259c6a136d6
2022-02-14 10:56:21 DEBUG DiskBlockManager:61 - Adding shutdown hook
2022-02-14 10:56:21 DEBUG ShutdownHookManager:61 - Adding shutdown hook
2022-02-14 10:56:21 INFO  MemoryStore:57 - MemoryStore started with capacity 2.2 GiB
2022-02-14 10:56:21 INFO  SparkEnv:57 - Registering OutputCommitCoordinator
2022-02-14 10:56:21 DEBUG OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:61 - init
2022-02-14 10:56:21 DEBUG SecurityManager:61 - Created SSL options for ui: SSLOptions{enabled=false, port=None, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2022-02-14 10:56:21 DEBUG log:159 - Logging to org.slf4j.impl.Log4jLoggerAdapter(org.sparkproject.jetty.util.log) via org.sparkproject.jetty.util.log.Slf4jLog
2022-02-14 10:56:21 INFO  log:169 - Logging initialized @9641ms to org.sparkproject.jetty.util.log.Slf4jLog
2022-02-14 10:56:21 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@2cec704c
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@6ec65b5e{/,null,STOPPED} added {ServletHandler@74db12c2{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@74db12c2{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-1a28b346==org.apache.spark.ui.JettyUtils$$anon$1@de461b97{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@74db12c2{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-1a28b346,POJO}
2022-02-14 10:56:22 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@77e7246b
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@3d7b1f1c{/,null,STOPPED} added {ServletHandler@51ce6f85{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@51ce6f85{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-5017e1==org.apache.spark.ui.JettyUtils$$anon$1@39a2c15b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@51ce6f85{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-5017e1,POJO}
2022-02-14 10:56:22 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@10acd6
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@b25b095{/,null,STOPPED} added {ServletHandler@5cb042da{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@5cb042da{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-571a9686==org.apache.spark.ui.JettyUtils$$anon$1@d07f69fb{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@5cb042da{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-571a9686,POJO}
2022-02-14 10:56:22 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@6ffa56fa
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@747d1932{/,null,STOPPED} added {ServletHandler@736309a9{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@736309a9{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-188b6035==org.apache.spark.ui.JettyUtils$$anon$1@71df815b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@736309a9{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-188b6035,POJO}
2022-02-14 10:56:22 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@39ad12b6
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@211febf3{/,null,STOPPED} added {ServletHandler@3bd3d05e{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@3bd3d05e{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-61d34b4==org.apache.spark.ui.JettyUtils$$anon$1@341ca94e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@3bd3d05e{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-61d34b4,POJO}
2022-02-14 10:56:22 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@459cfcca
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@6ab7ce48{/,null,STOPPED} added {ServletHandler@2c6aed22{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@2c6aed22{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-7acfb656==org.apache.spark.ui.JettyUtils$$anon$1@a3b2e3d0{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@2c6aed22{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-7acfb656,POJO}
2022-02-14 10:56:22 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@4d0753c9
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@719bb3b4{/,null,STOPPED} added {ServletHandler@52cb4f50{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@52cb4f50{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-4d27d9d==org.apache.spark.ui.JettyUtils$$anon$1@1e99442c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@52cb4f50{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-4d27d9d,POJO}
2022-02-14 10:56:22 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@2b5183ec
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@572e6fd9{/,null,STOPPED} added {ServletHandler@7f5eae0f{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@7f5eae0f{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-255e5e2e==org.apache.spark.ui.JettyUtils$$anon$1@361a0bc4{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@7f5eae0f{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-255e5e2e,POJO}
2022-02-14 10:56:22 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@3c46dcbe
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@1108adc8{/,null,STOPPED} added {ServletHandler@8a98f38{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@8a98f38{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-51d9b06c==org.apache.spark.ui.JettyUtils$$anon$1@e8000e9a{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@8a98f38{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-51d9b06c,POJO}
2022-02-14 10:56:22 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@43f0c2d1
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@38a1a26{/,null,STOPPED} added {ServletHandler@3fbcfe81{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@3fbcfe81{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-1744a475==org.apache.spark.ui.JettyUtils$$anon$1@33b145e5{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@3fbcfe81{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-1744a475,POJO}
2022-02-14 10:56:22 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@9d3c67
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@6dfcffb5{/,null,STOPPED} added {ServletHandler@184fb68d{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@184fb68d{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-1e530163==org.apache.spark.ui.JettyUtils$$anon$1@b6a05b1e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@184fb68d{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-1e530163,POJO}
2022-02-14 10:56:22 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@46d63dbb
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@16a49a5d{/,null,STOPPED} added {ServletHandler@54bca971{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@54bca971{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-205bed61==org.apache.spark.ui.JettyUtils$$anon$1@2d866b53{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@54bca971{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-205bed61,POJO}
2022-02-14 10:56:22 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@7c2b58c0
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@7bca6fac{/,null,STOPPED} added {ServletHandler@5c60b0a0{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@5c60b0a0{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-702c436b==org.apache.spark.ui.JettyUtils$$anon$1@2fc4db63{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@5c60b0a0{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-702c436b,POJO}
2022-02-14 10:56:22 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@23f3dbf0
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@760cf594{/,null,STOPPED} added {ServletHandler@aa149ed{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@aa149ed{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-31ff6309==org.apache.spark.ui.JettyUtils$$anon$1@1e0d91d2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@aa149ed{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-31ff6309,POJO}
2022-02-14 10:56:22 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@e4b6f47
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@71f0b72e{/,null,STOPPED} added {ServletHandler@7a34f66a{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@7a34f66a{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-3ed03652==org.apache.spark.ui.JettyUtils$$anon$1@d66da34c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@7a34f66a{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-3ed03652,POJO}
2022-02-14 10:56:22 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@3c35c345
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@2459319c{/,null,STOPPED} added {ServletHandler@ffaaaf0{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@ffaaaf0{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-5eed2d86==org.apache.spark.ui.JettyUtils$$anon$1@aac1d48d{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@ffaaaf0{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-5eed2d86,POJO}
2022-02-14 10:56:22 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@3db663d0
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@2de50ee4{/,null,STOPPED} added {ServletHandler@ad9e63e{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@ad9e63e{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-151ef57f==org.apache.spark.ui.JettyUtils$$anon$1@c77b0f04{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@ad9e63e{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-151ef57f,POJO}
2022-02-14 10:56:22 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@2cc03cd1
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@149c3204{/,null,STOPPED} added {ServletHandler@64f16277{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@64f16277{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-3b9632d1==org.apache.spark.ui.JettyUtils$$anon$1@eeaf1286{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@64f16277{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-3b9632d1,POJO}
2022-02-14 10:56:22 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@35e8316e
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@336880df{/,null,STOPPED} added {ServletHandler@1846579f{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@1846579f{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-2650f79==org.apache.spark.ui.JettyUtils$$anon$1@6675001b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@1846579f{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-2650f79,POJO}
2022-02-14 10:56:22 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@38af1bf6
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@7be7e15{/,null,STOPPED} added {ServletHandler@3abfe845{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@3abfe845{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-3672276e==org.apache.spark.ui.JettyUtils$$anon$1@d37a6d20{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@3abfe845{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-3672276e,POJO}
2022-02-14 10:56:22 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@2330e3e0
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@27a2a089{/,null,STOPPED} added {ServletHandler@54657dd2{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG PreEncodedHttpField:61 - HttpField encoders loaded: []
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@54657dd2{STOPPED} added {org.sparkproject.jetty.servlet.DefaultServlet-4eed2acf==org.sparkproject.jetty.servlet.DefaultServlet@7eb589aa{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@54657dd2{STOPPED} added {[/]=>org.sparkproject.jetty.servlet.DefaultServlet-4eed2acf,POJO}
2022-02-14 10:56:22 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@153cd6bb
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@2d9f64c9{/,null,STOPPED} added {ServletHandler@21ac5eb4{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@21ac5eb4{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$2-715d6168==org.apache.spark.ui.JettyUtils$$anon$2@5e220a33{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@21ac5eb4{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-715d6168,POJO}
2022-02-14 10:56:22 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@c2e3264
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@75a118e6{/,null,STOPPED} added {ServletHandler@1d540566{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@1d540566{STOPPED} added {org.glassfish.jersey.servlet.ServletContainer-7be71476==org.glassfish.jersey.servlet.ServletContainer@19f5730d{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@1d540566{STOPPED} added {[/*]=>org.glassfish.jersey.servlet.ServletContainer-7be71476,POJO}
2022-02-14 10:56:22 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@20e3c449
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@67fc2aad{/,null,STOPPED} added {ServletHandler@56f521c6{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@56f521c6{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$2-2dd8239==org.apache.spark.ui.JettyUtils$$anon$2@4bd18ba5{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@56f521c6{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-2dd8239,POJO}
2022-02-14 10:56:22 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@2e53b094
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@76ddd61a{/,null,STOPPED} added {ServletHandler@3f92a84e{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@3f92a84e{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$2-6137cf6e==org.apache.spark.ui.JettyUtils$$anon$2@f072463e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@3f92a84e{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-6137cf6e,POJO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - QueuedThreadPool[qtp262911569]@fabb651{STOPPED,8<=0<=200,i=0,r=-1,q=0}[NO_TRY] added {org.sparkproject.jetty.util.thread.ThreadPoolBudget@5bb51241,POJO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - Server@1aa6e3c0{STOPPED}[9.4.40.v20210413] added {QueuedThreadPool[SparkUI]@fabb651{STOPPED,8<=0<=200,i=0,r=-1,q=0}[NO_TRY],AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - Server@1aa6e3c0{STOPPED}[9.4.40.v20210413] added {ErrorHandler@2caa5d7c{STOPPED},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - Server@1aa6e3c0{STOPPED}[9.4.40.v20210413] added {ContextHandlerCollection@61a1ea2c{STOPPED},MANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting Server@1aa6e3c0{STOPPED}[9.4.40.v20210413]
2022-02-14 10:56:22 INFO  Server:375 - jetty-9.4.40.v20210413; built: 2021-04-13T20:42:42.668Z; git: b881a572662e1943a14ae12e7e1207989f218b74; jvm 11.0.8+10-LTS
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting Server@1aa6e3c0{STARTING}[9.4.40.v20210413]
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting QueuedThreadPool[SparkUI]@fabb651{STOPPED,8<=0<=200,i=0,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:22 DEBUG ReservedThreadExecutor:85 - ReservedThreadExecutor@43d38654{s=0/8,p=0}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - QueuedThreadPool[SparkUI]@fabb651{STARTING,8<=0<=200,i=0,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}] added {ReservedThreadExecutor@43d38654{s=0/8,p=0},AUTO}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ReservedThreadExecutor@43d38654{s=0/8,p=0}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @9823ms ReservedThreadExecutor@43d38654{s=0/8,p=0}
2022-02-14 10:56:22 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-31,5,main]
2022-02-14 10:56:22 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-32,5,main]
2022-02-14 10:56:22 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-33,5,main]
2022-02-14 10:56:22 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@fabb651{STARTING,8<=2<=200,i=2,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}]
2022-02-14 10:56:22 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-34,5,main]
2022-02-14 10:56:22 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@fabb651{STARTING,8<=3<=200,i=3,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}]
2022-02-14 10:56:22 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-35,5,main]
2022-02-14 10:56:22 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@fabb651{STARTING,8<=4<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}]
2022-02-14 10:56:22 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@fabb651{STARTING,8<=5<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}]
2022-02-14 10:56:22 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-36,5,main]
2022-02-14 10:56:22 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@fabb651{STARTING,8<=6<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}]
2022-02-14 10:56:22 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-37,5,main]
2022-02-14 10:56:22 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@fabb651{STARTING,8<=7<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}]
2022-02-14 10:56:22 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-38,5,main]
2022-02-14 10:56:22 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@fabb651{STARTING,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}]
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @9832ms QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}]
2022-02-14 10:56:22 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}]
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ErrorHandler@2caa5d7c{STOPPED}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ErrorHandler@2caa5d7c{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @9833ms ErrorHandler@2caa5d7c{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ContextHandlerCollection@61a1ea2c{STOPPED}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ContextHandlerCollection@61a1ea2c{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @9833ms ContextHandlerCollection@61a1ea2c{STARTED}
2022-02-14 10:56:22 INFO  Server:415 - Started @9833ms
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @9833ms Server@1aa6e3c0{STARTED}[9.4.40.v20210413]
2022-02-14 10:56:22 DEBUG JettyUtils:61 - Using requestHeaderSize: 8192
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - HttpConnectionFactory@3c0bbc9f[HTTP/1.1] added {HttpConfiguration@1317b708{32768/8192,8192/8192,https://:0,[]},POJO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServerConnector@78226c36{null, ()}{0.0.0.0:0} added {Server@1aa6e3c0{STARTED}[9.4.40.v20210413],UNMANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServerConnector@78226c36{null, ()}{0.0.0.0:0} added {QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}],UNMANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServerConnector@78226c36{null, ()}{0.0.0.0:0} added {ScheduledExecutorScheduler@987455b{STOPPED},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServerConnector@78226c36{null, ()}{0.0.0.0:0} added {org.sparkproject.jetty.io.ArrayByteBufferPool@1f3165e7,POJO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServerConnector@78226c36{null, (http/1.1)}{0.0.0.0:0} added {HttpConnectionFactory@3c0bbc9f[HTTP/1.1],AUTO}
2022-02-14 10:56:22 DEBUG AbstractConnector:484 - ServerConnector@78226c36{HTTP/1.1, (http/1.1)}{0.0.0.0:0} added HttpConnectionFactory@3c0bbc9f[HTTP/1.1]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServerConnector@78226c36{HTTP/1.1, (http/1.1)}{0.0.0.0:0} added {SelectorManager@ServerConnector@78226c36{HTTP/1.1, (http/1.1)}{0.0.0.0:0},MANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServerConnector@78226c36{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServerConnector@78226c36{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} added {sun.nio.ch.ServerSocketChannelImpl[/0:0:0:0:0:0:0:0:4040],POJO}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ScheduledExecutorScheduler@987455b{STOPPED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @9881ms ScheduledExecutorScheduler@987455b{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting HttpConnectionFactory@3c0bbc9f[HTTP/1.1]
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @9882ms HttpConnectionFactory@3c0bbc9f[HTTP/1.1]
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting SelectorManager@ServerConnector@78226c36{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@750ff7d3/SelectorProducer@1729ec00/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2262832+05:30 added {SelectorProducer@1729ec00,POJO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@750ff7d3/SelectorProducer@1729ec00/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2282588+05:30 added {QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}],UNMANAGED}
2022-02-14 10:56:22 DEBUG EatWhatYouKill:93 - EatWhatYouKill@750ff7d3/SelectorProducer@1729ec00/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2282588+05:30 created
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ManagedSelector@56afdf9a{STOPPED} id=0 keys=-1 selected=-1 updates=0 added {EatWhatYouKill@750ff7d3/SelectorProducer@1729ec00/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2282588+05:30,MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - SelectorManager@ServerConnector@78226c36{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} added {ManagedSelector@56afdf9a{STOPPED} id=0 keys=-1 selected=-1 updates=0,AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@5f172d4a/SelectorProducer@77ec6a3d/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2282588+05:30 added {SelectorProducer@77ec6a3d,POJO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@5f172d4a/SelectorProducer@77ec6a3d/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2328121+05:30 added {QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}],UNMANAGED}
2022-02-14 10:56:22 DEBUG EatWhatYouKill:93 - EatWhatYouKill@5f172d4a/SelectorProducer@77ec6a3d/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2328121+05:30 created
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ManagedSelector@36bf84e{STOPPED} id=1 keys=-1 selected=-1 updates=0 added {EatWhatYouKill@5f172d4a/SelectorProducer@77ec6a3d/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2328121+05:30,MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - SelectorManager@ServerConnector@78226c36{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} added {ManagedSelector@36bf84e{STOPPED} id=1 keys=-1 selected=-1 updates=0,AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@245ec1a6/SelectorProducer@782be4eb/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2353854+05:30 added {SelectorProducer@782be4eb,POJO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@245ec1a6/SelectorProducer@782be4eb/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2353854+05:30 added {QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}],UNMANAGED}
2022-02-14 10:56:22 DEBUG EatWhatYouKill:93 - EatWhatYouKill@245ec1a6/SelectorProducer@782be4eb/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2353854+05:30 created
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ManagedSelector@41fe8e5f{STOPPED} id=2 keys=-1 selected=-1 updates=0 added {EatWhatYouKill@245ec1a6/SelectorProducer@782be4eb/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2353854+05:30,MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - SelectorManager@ServerConnector@78226c36{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} added {ManagedSelector@41fe8e5f{STOPPED} id=2 keys=-1 selected=-1 updates=0,AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@6f1a80fb/SelectorProducer@5a237731/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2353854+05:30 added {SelectorProducer@5a237731,POJO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@6f1a80fb/SelectorProducer@5a237731/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2353854+05:30 added {QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}],UNMANAGED}
2022-02-14 10:56:22 DEBUG EatWhatYouKill:93 - EatWhatYouKill@6f1a80fb/SelectorProducer@5a237731/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2353854+05:30 created
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ManagedSelector@10fda3d0{STOPPED} id=3 keys=-1 selected=-1 updates=0 added {EatWhatYouKill@6f1a80fb/SelectorProducer@5a237731/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.240735+05:30,MANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - SelectorManager@ServerConnector@78226c36{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} added {ManagedSelector@10fda3d0{STOPPED} id=3 keys=-1 selected=-1 updates=0,AUTO}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ManagedSelector@56afdf9a{STOPPED} id=0 keys=-1 selected=-1 updates=0
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting EatWhatYouKill@750ff7d3/SelectorProducer@1729ec00/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2431353+05:30
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @9922ms EatWhatYouKill@750ff7d3/SelectorProducer@1729ec00/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2431353+05:30
2022-02-14 10:56:22 DEBUG QueuedThreadPool:719 - queue org.sparkproject.jetty.io.ManagedSelector$$Lambda$447/0x000000080052ac40@73fb1d7f startThread=0
2022-02-14 10:56:22 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.io.ManagedSelector$$Lambda$447/0x000000080052ac40@73fb1d7f in QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}]
2022-02-14 10:56:22 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$Start@71945bc0 on ManagedSelector@56afdf9a{STARTING} id=0 keys=0 selected=0 updates=0
2022-02-14 10:56:22 DEBUG EatWhatYouKill:141 - EatWhatYouKill@750ff7d3/SelectorProducer@1729ec00/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2476521+05:30 tryProduce false
2022-02-14 10:56:22 DEBUG ManagedSelector:558 - updateable 1
2022-02-14 10:56:22 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$Start@71945bc0
2022-02-14 10:56:22 DEBUG ManagedSelector:587 - updates 0
2022-02-14 10:56:22 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@580815ba waiting with 0 keys
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @9927ms ManagedSelector@56afdf9a{STARTED} id=0 keys=0 selected=0 updates=0
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ManagedSelector@36bf84e{STOPPED} id=1 keys=-1 selected=-1 updates=0
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting EatWhatYouKill@5f172d4a/SelectorProducer@77ec6a3d/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2476521+05:30
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @9929ms EatWhatYouKill@5f172d4a/SelectorProducer@77ec6a3d/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2476521+05:30
2022-02-14 10:56:22 DEBUG QueuedThreadPool:719 - queue org.sparkproject.jetty.io.ManagedSelector$$Lambda$447/0x000000080052ac40@3f725306 startThread=0
2022-02-14 10:56:22 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.io.ManagedSelector$$Lambda$447/0x000000080052ac40@3f725306 in QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}]
2022-02-14 10:56:22 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$Start@2412a42b on ManagedSelector@36bf84e{STARTING} id=1 keys=0 selected=0 updates=0
2022-02-14 10:56:22 DEBUG EatWhatYouKill:141 - EatWhatYouKill@5f172d4a/SelectorProducer@77ec6a3d/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2539427+05:30 tryProduce false
2022-02-14 10:56:22 DEBUG ManagedSelector:558 - updateable 1
2022-02-14 10:56:22 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$Start@2412a42b
2022-02-14 10:56:22 DEBUG ManagedSelector:587 - updates 0
2022-02-14 10:56:22 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@6c214f82 waiting with 0 keys
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @9932ms ManagedSelector@36bf84e{STARTED} id=1 keys=0 selected=0 updates=0
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ManagedSelector@41fe8e5f{STOPPED} id=2 keys=-1 selected=-1 updates=0
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting EatWhatYouKill@245ec1a6/SelectorProducer@782be4eb/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2553914+05:30
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @9934ms EatWhatYouKill@245ec1a6/SelectorProducer@782be4eb/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2568612+05:30
2022-02-14 10:56:22 DEBUG QueuedThreadPool:719 - queue org.sparkproject.jetty.io.ManagedSelector$$Lambda$447/0x000000080052ac40@7c251f90 startThread=0
2022-02-14 10:56:22 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.io.ManagedSelector$$Lambda$447/0x000000080052ac40@7c251f90 in QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}]
2022-02-14 10:56:22 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$Start@5ba26eb0 on ManagedSelector@41fe8e5f{STARTING} id=2 keys=0 selected=0 updates=0
2022-02-14 10:56:22 DEBUG EatWhatYouKill:141 - EatWhatYouKill@245ec1a6/SelectorProducer@782be4eb/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2592599+05:30 tryProduce false
2022-02-14 10:56:22 DEBUG ManagedSelector:558 - updateable 1
2022-02-14 10:56:22 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$Start@5ba26eb0
2022-02-14 10:56:22 DEBUG ManagedSelector:587 - updates 0
2022-02-14 10:56:22 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@24bf7b21 waiting with 0 keys
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @9939ms ManagedSelector@41fe8e5f{STARTED} id=2 keys=0 selected=0 updates=0
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ManagedSelector@10fda3d0{STOPPED} id=3 keys=-1 selected=-1 updates=0
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting EatWhatYouKill@6f1a80fb/SelectorProducer@5a237731/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2592599+05:30
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @9941ms EatWhatYouKill@6f1a80fb/SelectorProducer@5a237731/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2636777+05:30
2022-02-14 10:56:22 DEBUG QueuedThreadPool:719 - queue org.sparkproject.jetty.io.ManagedSelector$$Lambda$447/0x000000080052ac40@212dfd39 startThread=0
2022-02-14 10:56:22 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.io.ManagedSelector$$Lambda$447/0x000000080052ac40@212dfd39 in QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}]
2022-02-14 10:56:22 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$Start@65d57e4e on ManagedSelector@10fda3d0{STARTING} id=3 keys=0 selected=0 updates=0
2022-02-14 10:56:22 DEBUG EatWhatYouKill:141 - EatWhatYouKill@6f1a80fb/SelectorProducer@5a237731/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:22.2675439+05:30 tryProduce false
2022-02-14 10:56:22 DEBUG ManagedSelector:558 - updateable 1
2022-02-14 10:56:22 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$Start@65d57e4e
2022-02-14 10:56:22 DEBUG ManagedSelector:587 - updates 0
2022-02-14 10:56:22 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@2300575e waiting with 0 keys
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @9946ms ManagedSelector@10fda3d0{STARTED} id=3 keys=0 selected=0 updates=0
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @9946ms SelectorManager@ServerConnector@78226c36{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServerConnector@78226c36{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} added {acceptor-0@7a8406c2,POJO}
2022-02-14 10:56:22 DEBUG QueuedThreadPool:719 - queue acceptor-0@7a8406c2 startThread=0
2022-02-14 10:56:22 DEBUG QueuedThreadPool:1035 - run acceptor-0@7a8406c2 in QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=3,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}]
2022-02-14 10:56:22 INFO  AbstractConnector:331 - Started ServerConnector@78226c36{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @9948ms ServerConnector@78226c36{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-14 10:56:22 INFO  Utils:57 - Successfully started service 'SparkUI' on port 4040.
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - Server@1aa6e3c0{STARTED}[9.4.40.v20210413] added {Spark@78226c36{HTTP/1.1, (http/1.1)}{0.0.0.0:4040},UNMANAGED}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@74db12c2{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-44b18fe4==org.apache.spark.ui.HttpSecurityFilter@44b18fe4{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@74db12c2{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-44b18fe4,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@a62c7cd{STOPPED,min=32,inflate=-1} mime types IncludeExclude@7661b5a{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@a62c7cd{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@a62c7cd{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@74db12c2{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-1a28b346[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-1a28b346==org.apache.spark.ui.JettyUtils$$anon$1@de461b97{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-44b18fe4=org.apache.spark.ui.HttpSecurityFilter-44b18fe4==org.apache.spark.ui.HttpSecurityFilter@44b18fe4{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-44b18fe4]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-1a28b346=org.apache.spark.ui.JettyUtils$$anon$1-1a28b346==org.apache.spark.ui.JettyUtils$$anon$1@de461b97{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@74db12c2{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @9998ms ServletHandler@74db12c2{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-44b18fe4==org.apache.spark.ui.HttpSecurityFilter@44b18fe4{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10001ms org.apache.spark.ui.HttpSecurityFilter-44b18fe4==org.apache.spark.ui.HttpSecurityFilter@44b18fe4{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@4110765e
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-1a28b346==org.apache.spark.ui.JettyUtils$$anon$1@de461b97{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10007ms org.apache.spark.ui.JettyUtils$$anon$1-1a28b346==org.apache.spark.ui.JettyUtils$$anon$1@de461b97{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-1a28b346
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10009ms o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@a62c7cd{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@a62c7cd{STARTING,min=32,inflate=-1} added {DeflaterPool@4674d90{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@a62c7cd{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@4674d90{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10013ms DeflaterPool@4674d90{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10013ms GzipHandler@a62c7cd{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@51ce6f85{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-1e8ab90f==org.apache.spark.ui.HttpSecurityFilter@1e8ab90f{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@51ce6f85{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-1e8ab90f,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@554f0dfb{STOPPED,min=32,inflate=-1} mime types IncludeExclude@1f7076bc{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@554f0dfb{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@554f0dfb{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@51ce6f85{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-5017e1[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-5017e1==org.apache.spark.ui.JettyUtils$$anon$1@39a2c15b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-1e8ab90f=org.apache.spark.ui.HttpSecurityFilter-1e8ab90f==org.apache.spark.ui.HttpSecurityFilter@1e8ab90f{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-1e8ab90f]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-5017e1=org.apache.spark.ui.JettyUtils$$anon$1-5017e1==org.apache.spark.ui.JettyUtils$$anon$1@39a2c15b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@51ce6f85{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10021ms ServletHandler@51ce6f85{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-1e8ab90f==org.apache.spark.ui.HttpSecurityFilter@1e8ab90f{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10022ms org.apache.spark.ui.HttpSecurityFilter-1e8ab90f==org.apache.spark.ui.HttpSecurityFilter@1e8ab90f{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@6a094db2
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-5017e1==org.apache.spark.ui.JettyUtils$$anon$1@39a2c15b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10022ms org.apache.spark.ui.JettyUtils$$anon$1-5017e1==org.apache.spark.ui.JettyUtils$$anon$1@39a2c15b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-5017e1
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10023ms o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@554f0dfb{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@554f0dfb{STARTING,min=32,inflate=-1} added {DeflaterPool@2af69643{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@554f0dfb{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@2af69643{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10023ms DeflaterPool@2af69643{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10023ms GzipHandler@554f0dfb{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@5cb042da{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-146dcfe6==org.apache.spark.ui.HttpSecurityFilter@146dcfe6{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@5cb042da{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-146dcfe6,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@7a0ef219{STOPPED,min=32,inflate=-1} mime types IncludeExclude@1b1f5012{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@7a0ef219{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@7a0ef219{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@5cb042da{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-571a9686[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-571a9686==org.apache.spark.ui.JettyUtils$$anon$1@d07f69fb{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-146dcfe6=org.apache.spark.ui.HttpSecurityFilter-146dcfe6==org.apache.spark.ui.HttpSecurityFilter@146dcfe6{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-146dcfe6]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-571a9686=org.apache.spark.ui.JettyUtils$$anon$1-571a9686==org.apache.spark.ui.JettyUtils$$anon$1@d07f69fb{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@5cb042da{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10028ms ServletHandler@5cb042da{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-146dcfe6==org.apache.spark.ui.HttpSecurityFilter@146dcfe6{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10028ms org.apache.spark.ui.HttpSecurityFilter-146dcfe6==org.apache.spark.ui.HttpSecurityFilter@146dcfe6{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@6ede46f6
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-571a9686==org.apache.spark.ui.JettyUtils$$anon$1@d07f69fb{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10028ms org.apache.spark.ui.JettyUtils$$anon$1-571a9686==org.apache.spark.ui.JettyUtils$$anon$1@d07f69fb{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-571a9686
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10029ms o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@7a0ef219{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@7a0ef219{STARTING,min=32,inflate=-1} added {DeflaterPool@7b6860f9{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@7a0ef219{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@7b6860f9{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10029ms DeflaterPool@7b6860f9{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10029ms GzipHandler@7a0ef219{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@736309a9{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-6920614==org.apache.spark.ui.HttpSecurityFilter@6920614{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@736309a9{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-6920614,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@102ecc22{STOPPED,min=32,inflate=-1} mime types IncludeExclude@7ff35a3f{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@102ecc22{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@102ecc22{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@736309a9{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-188b6035[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-188b6035==org.apache.spark.ui.JettyUtils$$anon$1@71df815b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-6920614=org.apache.spark.ui.HttpSecurityFilter-6920614==org.apache.spark.ui.HttpSecurityFilter@6920614{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-6920614]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-188b6035=org.apache.spark.ui.JettyUtils$$anon$1-188b6035==org.apache.spark.ui.JettyUtils$$anon$1@71df815b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@736309a9{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10038ms ServletHandler@736309a9{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-6920614==org.apache.spark.ui.HttpSecurityFilter@6920614{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10038ms org.apache.spark.ui.HttpSecurityFilter-6920614==org.apache.spark.ui.HttpSecurityFilter@6920614{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@65b97f47
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-188b6035==org.apache.spark.ui.JettyUtils$$anon$1@71df815b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10039ms org.apache.spark.ui.JettyUtils$$anon$1-188b6035==org.apache.spark.ui.JettyUtils$$anon$1@71df815b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-188b6035
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10039ms o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@102ecc22{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@102ecc22{STARTING,min=32,inflate=-1} added {DeflaterPool@7aac8884{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@102ecc22{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@7aac8884{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10041ms DeflaterPool@7aac8884{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10041ms GzipHandler@102ecc22{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@3bd3d05e{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-5df778c3==org.apache.spark.ui.HttpSecurityFilter@5df778c3{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@3bd3d05e{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-5df778c3,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@6edcad64{STOPPED,min=32,inflate=-1} mime types IncludeExclude@4c6007fb{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@6edcad64{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@211febf3{/stages,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@6edcad64{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@211febf3{/stages,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@211febf3{/stages,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@3bd3d05e{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-61d34b4[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-61d34b4==org.apache.spark.ui.JettyUtils$$anon$1@341ca94e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-5df778c3=org.apache.spark.ui.HttpSecurityFilter-5df778c3==org.apache.spark.ui.HttpSecurityFilter@5df778c3{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-5df778c3]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-61d34b4=org.apache.spark.ui.JettyUtils$$anon$1-61d34b4==org.apache.spark.ui.JettyUtils$$anon$1@341ca94e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@3bd3d05e{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10046ms ServletHandler@3bd3d05e{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-5df778c3==org.apache.spark.ui.HttpSecurityFilter@5df778c3{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10046ms org.apache.spark.ui.HttpSecurityFilter-5df778c3==org.apache.spark.ui.HttpSecurityFilter@5df778c3{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@561b61ed
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-61d34b4==org.apache.spark.ui.JettyUtils$$anon$1@341ca94e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10047ms org.apache.spark.ui.JettyUtils$$anon$1-61d34b4==org.apache.spark.ui.JettyUtils$$anon$1@341ca94e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-61d34b4
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10048ms o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@6edcad64{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@6edcad64{STARTING,min=32,inflate=-1} added {DeflaterPool@277b8fa4{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@6edcad64{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@277b8fa4{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10049ms DeflaterPool@277b8fa4{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10049ms GzipHandler@6edcad64{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@2c6aed22{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-c27a3a2==org.apache.spark.ui.HttpSecurityFilter@c27a3a2{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@2c6aed22{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-c27a3a2,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@59dc36d4{STOPPED,min=32,inflate=-1} mime types IncludeExclude@12fcc71f{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@59dc36d4{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@59dc36d4{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@2c6aed22{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-7acfb656[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-7acfb656==org.apache.spark.ui.JettyUtils$$anon$1@a3b2e3d0{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-c27a3a2=org.apache.spark.ui.HttpSecurityFilter-c27a3a2==org.apache.spark.ui.HttpSecurityFilter@c27a3a2{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-c27a3a2]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-7acfb656=org.apache.spark.ui.JettyUtils$$anon$1-7acfb656==org.apache.spark.ui.JettyUtils$$anon$1@a3b2e3d0{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@2c6aed22{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10057ms ServletHandler@2c6aed22{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-c27a3a2==org.apache.spark.ui.HttpSecurityFilter@c27a3a2{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10057ms org.apache.spark.ui.HttpSecurityFilter-c27a3a2==org.apache.spark.ui.HttpSecurityFilter@c27a3a2{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@a92be4f
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-7acfb656==org.apache.spark.ui.JettyUtils$$anon$1@a3b2e3d0{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10058ms org.apache.spark.ui.JettyUtils$$anon$1-7acfb656==org.apache.spark.ui.JettyUtils$$anon$1@a3b2e3d0{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-7acfb656
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10058ms o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@59dc36d4{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@59dc36d4{STARTING,min=32,inflate=-1} added {DeflaterPool@524a076e{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@59dc36d4{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@524a076e{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10058ms DeflaterPool@524a076e{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10059ms GzipHandler@59dc36d4{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@52cb4f50{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-7baf1f5a==org.apache.spark.ui.HttpSecurityFilter@7baf1f5a{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@52cb4f50{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-7baf1f5a,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@7fe82967{STOPPED,min=32,inflate=-1} mime types IncludeExclude@50850539{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@7fe82967{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@7fe82967{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@52cb4f50{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-4d27d9d[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-4d27d9d==org.apache.spark.ui.JettyUtils$$anon$1@1e99442c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-7baf1f5a=org.apache.spark.ui.HttpSecurityFilter-7baf1f5a==org.apache.spark.ui.HttpSecurityFilter@7baf1f5a{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-7baf1f5a]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-4d27d9d=org.apache.spark.ui.JettyUtils$$anon$1-4d27d9d==org.apache.spark.ui.JettyUtils$$anon$1@1e99442c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@52cb4f50{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10065ms ServletHandler@52cb4f50{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-7baf1f5a==org.apache.spark.ui.HttpSecurityFilter@7baf1f5a{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10065ms org.apache.spark.ui.HttpSecurityFilter-7baf1f5a==org.apache.spark.ui.HttpSecurityFilter@7baf1f5a{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@15639440
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-4d27d9d==org.apache.spark.ui.JettyUtils$$anon$1@1e99442c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10066ms org.apache.spark.ui.JettyUtils$$anon$1-4d27d9d==org.apache.spark.ui.JettyUtils$$anon$1@1e99442c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-4d27d9d
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10067ms o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@7fe82967{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@7fe82967{STARTING,min=32,inflate=-1} added {DeflaterPool@40e37b06{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@7fe82967{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@40e37b06{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10068ms DeflaterPool@40e37b06{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10068ms GzipHandler@7fe82967{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@7f5eae0f{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-599e4d41==org.apache.spark.ui.HttpSecurityFilter@599e4d41{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@7f5eae0f{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-599e4d41,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@59cda16e{STOPPED,min=32,inflate=-1} mime types IncludeExclude@5dd903be{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@59cda16e{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@59cda16e{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@59cda16e{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@7f5eae0f{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-255e5e2e[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-255e5e2e==org.apache.spark.ui.JettyUtils$$anon$1@361a0bc4{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-599e4d41=org.apache.spark.ui.HttpSecurityFilter-599e4d41==org.apache.spark.ui.HttpSecurityFilter@599e4d41{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-599e4d41]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-255e5e2e=org.apache.spark.ui.JettyUtils$$anon$1-255e5e2e==org.apache.spark.ui.JettyUtils$$anon$1@361a0bc4{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@7f5eae0f{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10076ms ServletHandler@7f5eae0f{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-599e4d41==org.apache.spark.ui.HttpSecurityFilter@599e4d41{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10076ms org.apache.spark.ui.HttpSecurityFilter-599e4d41==org.apache.spark.ui.HttpSecurityFilter@599e4d41{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@3dfa819
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-255e5e2e==org.apache.spark.ui.JettyUtils$$anon$1@361a0bc4{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10077ms org.apache.spark.ui.JettyUtils$$anon$1-255e5e2e==org.apache.spark.ui.JettyUtils$$anon$1@361a0bc4{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-255e5e2e
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10077ms o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@59cda16e{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@59cda16e{STARTING,min=32,inflate=-1} added {DeflaterPool@53b7ce6{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@59cda16e{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@53b7ce6{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10078ms DeflaterPool@53b7ce6{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10078ms GzipHandler@59cda16e{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@8a98f38{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-97d0c06==org.apache.spark.ui.HttpSecurityFilter@97d0c06{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@8a98f38{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-97d0c06,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@72f9f27c{STOPPED,min=32,inflate=-1} mime types IncludeExclude@4c1bdcc2{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@72f9f27c{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@59cda16e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@72f9f27c{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@72f9f27c{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@8a98f38{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-51d9b06c[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-51d9b06c==org.apache.spark.ui.JettyUtils$$anon$1@e8000e9a{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-97d0c06=org.apache.spark.ui.HttpSecurityFilter-97d0c06==org.apache.spark.ui.HttpSecurityFilter@97d0c06{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-97d0c06]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-51d9b06c=org.apache.spark.ui.JettyUtils$$anon$1-51d9b06c==org.apache.spark.ui.JettyUtils$$anon$1@e8000e9a{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@8a98f38{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10083ms ServletHandler@8a98f38{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-97d0c06==org.apache.spark.ui.HttpSecurityFilter@97d0c06{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10083ms org.apache.spark.ui.HttpSecurityFilter-97d0c06==org.apache.spark.ui.HttpSecurityFilter@97d0c06{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@15b642b9
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-51d9b06c==org.apache.spark.ui.JettyUtils$$anon$1@e8000e9a{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10085ms org.apache.spark.ui.JettyUtils$$anon$1-51d9b06c==org.apache.spark.ui.JettyUtils$$anon$1@e8000e9a{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-51d9b06c
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10086ms o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@72f9f27c{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@72f9f27c{STARTING,min=32,inflate=-1} added {DeflaterPool@18b8d173{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@72f9f27c{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@18b8d173{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10087ms DeflaterPool@18b8d173{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10087ms GzipHandler@72f9f27c{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@3fbcfe81{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-411c6d44==org.apache.spark.ui.HttpSecurityFilter@411c6d44{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@3fbcfe81{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-411c6d44,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@d5d5353{STOPPED,min=32,inflate=-1} mime types IncludeExclude@242b6e1a{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@d5d5353{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@59cda16e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@d5d5353{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@72f9f27c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@d5d5353{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@3fbcfe81{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-1744a475[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-1744a475==org.apache.spark.ui.JettyUtils$$anon$1@33b145e5{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-411c6d44=org.apache.spark.ui.HttpSecurityFilter-411c6d44==org.apache.spark.ui.HttpSecurityFilter@411c6d44{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-411c6d44]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-1744a475=org.apache.spark.ui.JettyUtils$$anon$1-1744a475==org.apache.spark.ui.JettyUtils$$anon$1@33b145e5{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@3fbcfe81{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10095ms ServletHandler@3fbcfe81{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-411c6d44==org.apache.spark.ui.HttpSecurityFilter@411c6d44{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10096ms org.apache.spark.ui.HttpSecurityFilter-411c6d44==org.apache.spark.ui.HttpSecurityFilter@411c6d44{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@60c8a093
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-1744a475==org.apache.spark.ui.JettyUtils$$anon$1@33b145e5{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10096ms org.apache.spark.ui.JettyUtils$$anon$1-1744a475==org.apache.spark.ui.JettyUtils$$anon$1@33b145e5{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-1744a475
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10097ms o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@d5d5353{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@d5d5353{STARTING,min=32,inflate=-1} added {DeflaterPool@4f89331f{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@d5d5353{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@4f89331f{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10097ms DeflaterPool@4f89331f{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10098ms GzipHandler@d5d5353{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@184fb68d{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-3204e238==org.apache.spark.ui.HttpSecurityFilter@3204e238{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@184fb68d{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-3204e238,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@4dba773d{STOPPED,min=32,inflate=-1} mime types IncludeExclude@1d9bd4da{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@4dba773d{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@59cda16e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@4dba773d{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@d5d5353{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@72f9f27c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@4dba773d{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@184fb68d{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-1e530163[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-1e530163==org.apache.spark.ui.JettyUtils$$anon$1@b6a05b1e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-3204e238=org.apache.spark.ui.HttpSecurityFilter-3204e238==org.apache.spark.ui.HttpSecurityFilter@3204e238{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-3204e238]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-1e530163=org.apache.spark.ui.JettyUtils$$anon$1-1e530163==org.apache.spark.ui.JettyUtils$$anon$1@b6a05b1e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@184fb68d{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10110ms ServletHandler@184fb68d{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-3204e238==org.apache.spark.ui.HttpSecurityFilter@3204e238{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10111ms org.apache.spark.ui.HttpSecurityFilter-3204e238==org.apache.spark.ui.HttpSecurityFilter@3204e238{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@4996c99
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-1e530163==org.apache.spark.ui.JettyUtils$$anon$1@b6a05b1e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10111ms org.apache.spark.ui.JettyUtils$$anon$1-1e530163==org.apache.spark.ui.JettyUtils$$anon$1@b6a05b1e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-1e530163
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10112ms o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@4dba773d{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@4dba773d{STARTING,min=32,inflate=-1} added {DeflaterPool@51d387d3{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@4dba773d{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@51d387d3{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10112ms DeflaterPool@51d387d3{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10112ms GzipHandler@4dba773d{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@54bca971{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-58fef7f7==org.apache.spark.ui.HttpSecurityFilter@58fef7f7{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@54bca971{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-58fef7f7,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@1352434e{STOPPED,min=32,inflate=-1} mime types IncludeExclude@4f9a6c2d{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@1352434e{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@59cda16e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1352434e{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@4dba773d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@d5d5353{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@72f9f27c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@1352434e{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@54bca971{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-205bed61[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-205bed61==org.apache.spark.ui.JettyUtils$$anon$1@2d866b53{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-58fef7f7=org.apache.spark.ui.HttpSecurityFilter-58fef7f7==org.apache.spark.ui.HttpSecurityFilter@58fef7f7{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-58fef7f7]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-205bed61=org.apache.spark.ui.JettyUtils$$anon$1-205bed61==org.apache.spark.ui.JettyUtils$$anon$1@2d866b53{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@54bca971{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10123ms ServletHandler@54bca971{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-58fef7f7==org.apache.spark.ui.HttpSecurityFilter@58fef7f7{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10123ms org.apache.spark.ui.HttpSecurityFilter-58fef7f7==org.apache.spark.ui.HttpSecurityFilter@58fef7f7{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@64d4f7c7
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-205bed61==org.apache.spark.ui.JettyUtils$$anon$1@2d866b53{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10124ms org.apache.spark.ui.JettyUtils$$anon$1-205bed61==org.apache.spark.ui.JettyUtils$$anon$1@2d866b53{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-205bed61
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10125ms o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@1352434e{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@1352434e{STARTING,min=32,inflate=-1} added {DeflaterPool@2bfb6b49{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@1352434e{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@2bfb6b49{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10126ms DeflaterPool@2bfb6b49{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10126ms GzipHandler@1352434e{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@5c60b0a0{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-7afc4db9==org.apache.spark.ui.HttpSecurityFilter@7afc4db9{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@5c60b0a0{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-7afc4db9,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@4acb7ecc{STOPPED,min=32,inflate=-1} mime types IncludeExclude@2a4f5433{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@4acb7ecc{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@7bca6fac{/storage/rdd,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@59cda16e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@4acb7ecc{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7bca6fac{/storage/rdd,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1352434e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@4dba773d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@d5d5353{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@72f9f27c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@4acb7ecc{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@7bca6fac{/storage/rdd,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@7bca6fac{/storage/rdd,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@5c60b0a0{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-702c436b[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-702c436b==org.apache.spark.ui.JettyUtils$$anon$1@2fc4db63{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-7afc4db9=org.apache.spark.ui.HttpSecurityFilter-7afc4db9==org.apache.spark.ui.HttpSecurityFilter@7afc4db9{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-7afc4db9]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-702c436b=org.apache.spark.ui.JettyUtils$$anon$1-702c436b==org.apache.spark.ui.JettyUtils$$anon$1@2fc4db63{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@5c60b0a0{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10131ms ServletHandler@5c60b0a0{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-7afc4db9==org.apache.spark.ui.HttpSecurityFilter@7afc4db9{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10132ms org.apache.spark.ui.HttpSecurityFilter-7afc4db9==org.apache.spark.ui.HttpSecurityFilter@7afc4db9{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@7dbe2ebf
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-702c436b==org.apache.spark.ui.JettyUtils$$anon$1@2fc4db63{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10132ms org.apache.spark.ui.JettyUtils$$anon$1-702c436b==org.apache.spark.ui.JettyUtils$$anon$1@2fc4db63{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-702c436b
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@7bca6fac{/storage/rdd,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10133ms o.s.j.s.ServletContextHandler@7bca6fac{/storage/rdd,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@4acb7ecc{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@4acb7ecc{STARTING,min=32,inflate=-1} added {DeflaterPool@3e3315d9{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@4acb7ecc{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@3e3315d9{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10133ms DeflaterPool@3e3315d9{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10134ms GzipHandler@4acb7ecc{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@aa149ed{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-26350ea2==org.apache.spark.ui.HttpSecurityFilter@26350ea2{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@aa149ed{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-26350ea2,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@59696551{STOPPED,min=32,inflate=-1} mime types IncludeExclude@648d0e6d{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@59696551{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@760cf594{/storage/rdd/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@59cda16e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@4acb7ecc{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7bca6fac{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1352434e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@4dba773d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@59696551{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@760cf594{/storage/rdd/json,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@d5d5353{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@72f9f27c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@59696551{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@760cf594{/storage/rdd/json,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@760cf594{/storage/rdd/json,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@aa149ed{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-31ff6309[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-31ff6309==org.apache.spark.ui.JettyUtils$$anon$1@1e0d91d2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-26350ea2=org.apache.spark.ui.HttpSecurityFilter-26350ea2==org.apache.spark.ui.HttpSecurityFilter@26350ea2{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-26350ea2]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-31ff6309=org.apache.spark.ui.JettyUtils$$anon$1-31ff6309==org.apache.spark.ui.JettyUtils$$anon$1@1e0d91d2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@aa149ed{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10145ms ServletHandler@aa149ed{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-26350ea2==org.apache.spark.ui.HttpSecurityFilter@26350ea2{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10147ms org.apache.spark.ui.HttpSecurityFilter-26350ea2==org.apache.spark.ui.HttpSecurityFilter@26350ea2{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@1b1c538d
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-31ff6309==org.apache.spark.ui.JettyUtils$$anon$1@1e0d91d2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10147ms org.apache.spark.ui.JettyUtils$$anon$1-31ff6309==org.apache.spark.ui.JettyUtils$$anon$1@1e0d91d2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-31ff6309
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@760cf594{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10148ms o.s.j.s.ServletContextHandler@760cf594{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@59696551{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@59696551{STARTING,min=32,inflate=-1} added {DeflaterPool@2da3b078{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@59696551{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@2da3b078{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10149ms DeflaterPool@2da3b078{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10149ms GzipHandler@59696551{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@7a34f66a{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-46aa712c==org.apache.spark.ui.HttpSecurityFilter@46aa712c{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@7a34f66a{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-46aa712c,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@7b4a0aef{STOPPED,min=32,inflate=-1} mime types IncludeExclude@45cec376{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@7b4a0aef{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@71f0b72e{/environment,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@59cda16e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@4acb7ecc{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7bca6fac{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1352434e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@4dba773d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@59696551{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@760cf594{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7b4a0aef{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@71f0b72e{/environment,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@d5d5353{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@72f9f27c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@7b4a0aef{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@71f0b72e{/environment,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@71f0b72e{/environment,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@7a34f66a{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-3ed03652[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-3ed03652==org.apache.spark.ui.JettyUtils$$anon$1@d66da34c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-46aa712c=org.apache.spark.ui.HttpSecurityFilter-46aa712c==org.apache.spark.ui.HttpSecurityFilter@46aa712c{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-46aa712c]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-3ed03652=org.apache.spark.ui.JettyUtils$$anon$1-3ed03652==org.apache.spark.ui.JettyUtils$$anon$1@d66da34c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@7a34f66a{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10165ms ServletHandler@7a34f66a{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-46aa712c==org.apache.spark.ui.HttpSecurityFilter@46aa712c{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10166ms org.apache.spark.ui.HttpSecurityFilter-46aa712c==org.apache.spark.ui.HttpSecurityFilter@46aa712c{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@71e4b308
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-3ed03652==org.apache.spark.ui.JettyUtils$$anon$1@d66da34c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10167ms org.apache.spark.ui.JettyUtils$$anon$1-3ed03652==org.apache.spark.ui.JettyUtils$$anon$1@d66da34c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-3ed03652
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@71f0b72e{/environment,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10171ms o.s.j.s.ServletContextHandler@71f0b72e{/environment,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@7b4a0aef{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@7b4a0aef{STARTING,min=32,inflate=-1} added {DeflaterPool@4af45442{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@7b4a0aef{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@4af45442{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10173ms DeflaterPool@4af45442{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10173ms GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@ffaaaf0{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-2bc426f0==org.apache.spark.ui.HttpSecurityFilter@2bc426f0{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@ffaaaf0{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-2bc426f0,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@e4e1ef5{STOPPED,min=32,inflate=-1} mime types IncludeExclude@6d11ceef{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@e4e1ef5{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@2459319c{/environment/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@59cda16e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@4acb7ecc{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7bca6fac{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@e4e1ef5{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2459319c{/environment/json,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1352434e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@4dba773d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@59696551{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@760cf594{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@71f0b72e{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@d5d5353{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@72f9f27c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@e4e1ef5{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@2459319c{/environment/json,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@2459319c{/environment/json,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@ffaaaf0{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-5eed2d86[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-5eed2d86==org.apache.spark.ui.JettyUtils$$anon$1@aac1d48d{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-2bc426f0=org.apache.spark.ui.HttpSecurityFilter-2bc426f0==org.apache.spark.ui.HttpSecurityFilter@2bc426f0{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-2bc426f0]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-5eed2d86=org.apache.spark.ui.JettyUtils$$anon$1-5eed2d86==org.apache.spark.ui.JettyUtils$$anon$1@aac1d48d{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@ffaaaf0{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10180ms ServletHandler@ffaaaf0{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-2bc426f0==org.apache.spark.ui.HttpSecurityFilter@2bc426f0{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10181ms org.apache.spark.ui.HttpSecurityFilter-2bc426f0==org.apache.spark.ui.HttpSecurityFilter@2bc426f0{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@4993febc
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-5eed2d86==org.apache.spark.ui.JettyUtils$$anon$1@aac1d48d{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10182ms org.apache.spark.ui.JettyUtils$$anon$1-5eed2d86==org.apache.spark.ui.JettyUtils$$anon$1@aac1d48d{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-5eed2d86
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@2459319c{/environment/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10183ms o.s.j.s.ServletContextHandler@2459319c{/environment/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@e4e1ef5{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@e4e1ef5{STARTING,min=32,inflate=-1} added {DeflaterPool@57562473{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@e4e1ef5{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@57562473{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10186ms DeflaterPool@57562473{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10187ms GzipHandler@e4e1ef5{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@ad9e63e{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-4a7fd0c9==org.apache.spark.ui.HttpSecurityFilter@4a7fd0c9{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@ad9e63e{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-4a7fd0c9,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@53d13cd4{STOPPED,min=32,inflate=-1} mime types IncludeExclude@77865933{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@53d13cd4{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@2de50ee4{/executors,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@59cda16e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@4acb7ecc{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7bca6fac{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@e4e1ef5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2459319c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1352434e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@4dba773d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@59696551{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@760cf594{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@71f0b72e{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@53d13cd4{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2de50ee4{/executors,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@d5d5353{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@72f9f27c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@53d13cd4{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@2de50ee4{/executors,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@2de50ee4{/executors,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@ad9e63e{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-151ef57f[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-151ef57f==org.apache.spark.ui.JettyUtils$$anon$1@c77b0f04{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-4a7fd0c9=org.apache.spark.ui.HttpSecurityFilter-4a7fd0c9==org.apache.spark.ui.HttpSecurityFilter@4a7fd0c9{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-4a7fd0c9]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-151ef57f=org.apache.spark.ui.JettyUtils$$anon$1-151ef57f==org.apache.spark.ui.JettyUtils$$anon$1@c77b0f04{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@ad9e63e{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10199ms ServletHandler@ad9e63e{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-4a7fd0c9==org.apache.spark.ui.HttpSecurityFilter@4a7fd0c9{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10199ms org.apache.spark.ui.HttpSecurityFilter-4a7fd0c9==org.apache.spark.ui.HttpSecurityFilter@4a7fd0c9{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@4375b013
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-151ef57f==org.apache.spark.ui.JettyUtils$$anon$1@c77b0f04{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10200ms org.apache.spark.ui.JettyUtils$$anon$1-151ef57f==org.apache.spark.ui.JettyUtils$$anon$1@c77b0f04{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-151ef57f
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@2de50ee4{/executors,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10203ms o.s.j.s.ServletContextHandler@2de50ee4{/executors,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@53d13cd4{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@53d13cd4{STARTING,min=32,inflate=-1} added {DeflaterPool@3f736a16{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@53d13cd4{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@3f736a16{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10206ms DeflaterPool@3f736a16{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10206ms GzipHandler@53d13cd4{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@64f16277{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-4b039c6d==org.apache.spark.ui.HttpSecurityFilter@4b039c6d{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@64f16277{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-4b039c6d,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@60b34931{STOPPED,min=32,inflate=-1} mime types IncludeExclude@4aa21f9d{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@60b34931{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@149c3204{/executors/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@60b34931{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@149c3204{/executors/json,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@59cda16e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@4acb7ecc{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7bca6fac{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@e4e1ef5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2459319c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1352434e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@4dba773d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@59696551{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@760cf594{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@71f0b72e{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@53d13cd4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2de50ee4{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@d5d5353{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@72f9f27c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@60b34931{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@149c3204{/executors/json,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@149c3204{/executors/json,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@64f16277{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-3b9632d1[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-3b9632d1==org.apache.spark.ui.JettyUtils$$anon$1@eeaf1286{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-4b039c6d=org.apache.spark.ui.HttpSecurityFilter-4b039c6d==org.apache.spark.ui.HttpSecurityFilter@4b039c6d{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-4b039c6d]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-3b9632d1=org.apache.spark.ui.JettyUtils$$anon$1-3b9632d1==org.apache.spark.ui.JettyUtils$$anon$1@eeaf1286{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@64f16277{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10216ms ServletHandler@64f16277{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-4b039c6d==org.apache.spark.ui.HttpSecurityFilter@4b039c6d{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10218ms org.apache.spark.ui.HttpSecurityFilter-4b039c6d==org.apache.spark.ui.HttpSecurityFilter@4b039c6d{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@2c88a3e8
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-3b9632d1==org.apache.spark.ui.JettyUtils$$anon$1@eeaf1286{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10219ms org.apache.spark.ui.JettyUtils$$anon$1-3b9632d1==org.apache.spark.ui.JettyUtils$$anon$1@eeaf1286{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-3b9632d1
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@149c3204{/executors/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10220ms o.s.j.s.ServletContextHandler@149c3204{/executors/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@60b34931{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@60b34931{STARTING,min=32,inflate=-1} added {DeflaterPool@73d60e76{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@60b34931{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@73d60e76{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10221ms DeflaterPool@73d60e76{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10221ms GzipHandler@60b34931{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@1846579f{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-64aad809==org.apache.spark.ui.HttpSecurityFilter@64aad809{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@1846579f{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-64aad809,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@9679750{STOPPED,min=32,inflate=-1} mime types IncludeExclude@9b9a327{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@9679750{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@336880df{/executors/threadDump,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@60b34931{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@149c3204{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@59cda16e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@4acb7ecc{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7bca6fac{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@e4e1ef5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2459319c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1352434e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@4dba773d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@59696551{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@760cf594{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@71f0b72e{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@53d13cd4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2de50ee4{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@d5d5353{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@72f9f27c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@9679750{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@336880df{/executors/threadDump,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@9679750{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@336880df{/executors/threadDump,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@336880df{/executors/threadDump,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@1846579f{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-2650f79[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-2650f79==org.apache.spark.ui.JettyUtils$$anon$1@6675001b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-64aad809=org.apache.spark.ui.HttpSecurityFilter-64aad809==org.apache.spark.ui.HttpSecurityFilter@64aad809{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-64aad809]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-2650f79=org.apache.spark.ui.JettyUtils$$anon$1-2650f79==org.apache.spark.ui.JettyUtils$$anon$1@6675001b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@1846579f{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10237ms ServletHandler@1846579f{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-64aad809==org.apache.spark.ui.HttpSecurityFilter@64aad809{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10239ms org.apache.spark.ui.HttpSecurityFilter-64aad809==org.apache.spark.ui.HttpSecurityFilter@64aad809{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@40e32762
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-2650f79==org.apache.spark.ui.JettyUtils$$anon$1@6675001b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10240ms org.apache.spark.ui.JettyUtils$$anon$1-2650f79==org.apache.spark.ui.JettyUtils$$anon$1@6675001b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-2650f79
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@336880df{/executors/threadDump,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10241ms o.s.j.s.ServletContextHandler@336880df{/executors/threadDump,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@9679750{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@9679750{STARTING,min=32,inflate=-1} added {DeflaterPool@35a60674{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@9679750{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@35a60674{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10242ms DeflaterPool@35a60674{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10242ms GzipHandler@9679750{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@3abfe845{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-71926a36==org.apache.spark.ui.HttpSecurityFilter@71926a36{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@3abfe845{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-71926a36,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@2a367e93{STOPPED,min=32,inflate=-1} mime types IncludeExclude@7f6874f2{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@2a367e93{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@7be7e15{/executors/threadDump/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@60b34931{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@149c3204{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@59cda16e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@4acb7ecc{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7bca6fac{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@2a367e93{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7be7e15{/executors/threadDump/json,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@e4e1ef5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2459319c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1352434e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@4dba773d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@59696551{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@760cf594{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@71f0b72e{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@53d13cd4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2de50ee4{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@d5d5353{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@72f9f27c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@9679750{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@336880df{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@2a367e93{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@7be7e15{/executors/threadDump/json,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@7be7e15{/executors/threadDump/json,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@3abfe845{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-3672276e[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-3672276e==org.apache.spark.ui.JettyUtils$$anon$1@d37a6d20{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-71926a36=org.apache.spark.ui.HttpSecurityFilter-71926a36==org.apache.spark.ui.HttpSecurityFilter@71926a36{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-71926a36]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-3672276e=org.apache.spark.ui.JettyUtils$$anon$1-3672276e==org.apache.spark.ui.JettyUtils$$anon$1@d37a6d20{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@3abfe845{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10250ms ServletHandler@3abfe845{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-71926a36==org.apache.spark.ui.HttpSecurityFilter@71926a36{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10252ms org.apache.spark.ui.HttpSecurityFilter-71926a36==org.apache.spark.ui.HttpSecurityFilter@71926a36{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@1dbd580
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-3672276e==org.apache.spark.ui.JettyUtils$$anon$1@d37a6d20{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10254ms org.apache.spark.ui.JettyUtils$$anon$1-3672276e==org.apache.spark.ui.JettyUtils$$anon$1@d37a6d20{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-3672276e
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@7be7e15{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10255ms o.s.j.s.ServletContextHandler@7be7e15{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@2a367e93{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@2a367e93{STARTING,min=32,inflate=-1} added {DeflaterPool@474821de{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@2a367e93{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@474821de{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10257ms DeflaterPool@474821de{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10257ms GzipHandler@2a367e93{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@54657dd2{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-2d64c100==org.apache.spark.ui.HttpSecurityFilter@2d64c100{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@54657dd2{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-2d64c100,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@650ae78c{STOPPED,min=32,inflate=-1} mime types IncludeExclude@2e73d5eb{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@650ae78c{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@27a2a089{/static,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@650ae78c{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@27a2a089{/static,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@60b34931{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@149c3204{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@59cda16e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@4acb7ecc{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7bca6fac{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@2a367e93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7be7e15{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@e4e1ef5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2459319c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1352434e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@4dba773d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@59696551{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@760cf594{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@71f0b72e{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@53d13cd4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2de50ee4{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@d5d5353{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@72f9f27c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@9679750{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@336880df{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@650ae78c{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@27a2a089{/static,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@27a2a089{/static,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@54657dd2{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.sparkproject.jetty.servlet.DefaultServlet-4eed2acf[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.sparkproject.jetty.servlet.DefaultServlet-4eed2acf==org.sparkproject.jetty.servlet.DefaultServlet@7eb589aa{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-2d64c100=org.apache.spark.ui.HttpSecurityFilter-2d64c100==org.apache.spark.ui.HttpSecurityFilter@2d64c100{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-2d64c100]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.sparkproject.jetty.servlet.DefaultServlet-4eed2acf=org.sparkproject.jetty.servlet.DefaultServlet-4eed2acf==org.sparkproject.jetty.servlet.DefaultServlet@7eb589aa{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@54657dd2{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10273ms ServletHandler@54657dd2{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-2d64c100==org.apache.spark.ui.HttpSecurityFilter@2d64c100{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10274ms org.apache.spark.ui.HttpSecurityFilter-2d64c100==org.apache.spark.ui.HttpSecurityFilter@2d64c100{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@77681ce4
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.sparkproject.jetty.servlet.DefaultServlet-4eed2acf==org.sparkproject.jetty.servlet.DefaultServlet@7eb589aa{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10275ms org.sparkproject.jetty.servlet.DefaultServlet-4eed2acf==org.sparkproject.jetty.servlet.DefaultServlet@7eb589aa{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG ServletHolder:621 - Servlet.init null for org.sparkproject.jetty.servlet.DefaultServlet-4eed2acf
2022-02-14 10:56:22 DEBUG DefaultServlet:308 - resource base = jar:file:/C:/Users/Shridhar%20Ingale/.m2/repository/org/apache/spark/spark-core_2.12/3.0.3/spark-core_2.12-3.0.3.jar!/org/apache/spark/ui/static
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@27a2a089{/static,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10294ms o.s.j.s.ServletContextHandler@27a2a089{/static,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@650ae78c{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@650ae78c{STARTING,min=32,inflate=-1} added {DeflaterPool@4860827a{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@650ae78c{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@4860827a{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10295ms DeflaterPool@4860827a{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10295ms GzipHandler@650ae78c{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@21ac5eb4{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-4fa822ad==org.apache.spark.ui.HttpSecurityFilter@4fa822ad{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@21ac5eb4{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-4fa822ad,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@65d8dff8{STOPPED,min=32,inflate=-1} mime types IncludeExclude@444f44c5{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@65d8dff8{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@2d9f64c9{/,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@65d8dff8{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2d9f64c9{/,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@650ae78c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@27a2a089{/static,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@60b34931{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@149c3204{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@59cda16e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@4acb7ecc{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7bca6fac{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@2a367e93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7be7e15{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@e4e1ef5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2459319c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1352434e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@4dba773d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@59696551{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@760cf594{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@71f0b72e{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@53d13cd4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2de50ee4{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@d5d5353{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@72f9f27c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@9679750{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@336880df{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@65d8dff8{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@2d9f64c9{/,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@2d9f64c9{/,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@21ac5eb4{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-715d6168[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$2-715d6168==org.apache.spark.ui.JettyUtils$$anon$2@5e220a33{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-4fa822ad=org.apache.spark.ui.HttpSecurityFilter-4fa822ad==org.apache.spark.ui.HttpSecurityFilter@4fa822ad{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-4fa822ad]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-715d6168=org.apache.spark.ui.JettyUtils$$anon$2-715d6168==org.apache.spark.ui.JettyUtils$$anon$2@5e220a33{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@21ac5eb4{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10311ms ServletHandler@21ac5eb4{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-4fa822ad==org.apache.spark.ui.HttpSecurityFilter@4fa822ad{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10312ms org.apache.spark.ui.HttpSecurityFilter-4fa822ad==org.apache.spark.ui.HttpSecurityFilter@4fa822ad{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@6f9c5048
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$2-715d6168==org.apache.spark.ui.JettyUtils$$anon$2@5e220a33{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10313ms org.apache.spark.ui.JettyUtils$$anon$2-715d6168==org.apache.spark.ui.JettyUtils$$anon$2@5e220a33{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$2-715d6168
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@2d9f64c9{/,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10314ms o.s.j.s.ServletContextHandler@2d9f64c9{/,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@65d8dff8{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@65d8dff8{STARTING,min=32,inflate=-1} added {DeflaterPool@2f0bfe17{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@65d8dff8{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@2f0bfe17{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10315ms DeflaterPool@2f0bfe17{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10315ms GzipHandler@65d8dff8{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@1d540566{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-795f5d51==org.apache.spark.ui.HttpSecurityFilter@795f5d51{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@1d540566{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-795f5d51,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@43aeb5e0{STOPPED,min=32,inflate=-1} mime types IncludeExclude@2274160{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@43aeb5e0{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@75a118e6{/api,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@65d8dff8{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2d9f64c9{/,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@650ae78c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@27a2a089{/static,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@60b34931{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@149c3204{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@59cda16e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@4acb7ecc{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7bca6fac{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@2a367e93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7be7e15{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@e4e1ef5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2459319c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1352434e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@4dba773d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@59696551{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@760cf594{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@71f0b72e{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@53d13cd4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2de50ee4{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@43aeb5e0{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@75a118e6{/api,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@d5d5353{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@72f9f27c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@9679750{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@336880df{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@43aeb5e0{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@75a118e6{/api,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@75a118e6{/api,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@1d540566{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/*[EMBEDDED:null] mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-7be71476[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@5fa{/*},resource=org.glassfish.jersey.servlet.ServletContainer-7be71476==org.glassfish.jersey.servlet.ServletContainer@19f5730d{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-795f5d51=org.apache.spark.ui.HttpSecurityFilter-795f5d51==org.apache.spark.ui.HttpSecurityFilter@795f5d51{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-795f5d51]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.glassfish.jersey.servlet.ServletContainer-7be71476=org.glassfish.jersey.servlet.ServletContainer-7be71476==org.glassfish.jersey.servlet.ServletContainer@19f5730d{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:169 - Adding Default404Servlet to ServletHandler@1d540566{STARTING}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@1d540566{STARTING} added {org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-47406941==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet@a83c6efc{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@1d540566{STARTING} added {[/]=>org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-47406941,POJO}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/*[EMBEDDED:null] mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-7be71476[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@5fa{/*},resource=org.glassfish.jersey.servlet.ServletContainer-7be71476==org.glassfish.jersey.servlet.ServletContainer@19f5730d{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-47406941[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-47406941==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet@a83c6efc{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=2]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-795f5d51=org.apache.spark.ui.HttpSecurityFilter-795f5d51==org.apache.spark.ui.HttpSecurityFilter@795f5d51{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-795f5d51]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=2]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-47406941=org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-47406941==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet@a83c6efc{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}, org.glassfish.jersey.servlet.ServletContainer-7be71476=org.glassfish.jersey.servlet.ServletContainer-7be71476==org.glassfish.jersey.servlet.ServletContainer@19f5730d{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/*[EMBEDDED:null] mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-7be71476[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@5fa{/*},resource=org.glassfish.jersey.servlet.ServletContainer-7be71476==org.glassfish.jersey.servlet.ServletContainer@19f5730d{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-47406941[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-47406941==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet@a83c6efc{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=2]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-795f5d51=org.apache.spark.ui.HttpSecurityFilter-795f5d51==org.apache.spark.ui.HttpSecurityFilter@795f5d51{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-795f5d51]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=2]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-47406941=org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-47406941==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet@a83c6efc{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}, org.glassfish.jersey.servlet.ServletContainer-7be71476=org.glassfish.jersey.servlet.ServletContainer-7be71476==org.glassfish.jersey.servlet.ServletContainer@19f5730d{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@1d540566{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10344ms ServletHandler@1d540566{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-795f5d51==org.apache.spark.ui.HttpSecurityFilter@795f5d51{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10345ms org.apache.spark.ui.HttpSecurityFilter-795f5d51==org.apache.spark.ui.HttpSecurityFilter@795f5d51{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@61ab89b0
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.glassfish.jersey.servlet.ServletContainer-7be71476==org.glassfish.jersey.servlet.ServletContainer@19f5730d{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10345ms org.glassfish.jersey.servlet.ServletContainer-7be71476==org.glassfish.jersey.servlet.ServletContainer@19f5730d{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-47406941==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet@a83c6efc{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10346ms org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-47406941==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet@a83c6efc{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@75a118e6{/api,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10346ms o.s.j.s.ServletContextHandler@75a118e6{/api,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@43aeb5e0{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@43aeb5e0{STARTING,min=32,inflate=-1} added {DeflaterPool@6de6faa6{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@43aeb5e0{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@6de6faa6{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10347ms DeflaterPool@6de6faa6{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10347ms GzipHandler@43aeb5e0{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@56f521c6{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-4c447c09==org.apache.spark.ui.HttpSecurityFilter@4c447c09{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@56f521c6{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-4c447c09,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@2e09c51{STOPPED,min=32,inflate=-1} mime types IncludeExclude@869d87c{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@2e09c51{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@67fc2aad{/jobs/job/kill,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@65d8dff8{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2d9f64c9{/,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@650ae78c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@27a2a089{/static,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@60b34931{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@149c3204{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@59cda16e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@4acb7ecc{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7bca6fac{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@2a367e93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7be7e15{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@e4e1ef5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2459319c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1352434e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@4dba773d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@59696551{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@760cf594{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@71f0b72e{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@53d13cd4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2de50ee4{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@43aeb5e0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@75a118e6{/api,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@2e09c51{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@67fc2aad{/jobs/job/kill,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@d5d5353{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@72f9f27c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@9679750{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@336880df{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@2e09c51{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@67fc2aad{/jobs/job/kill,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@67fc2aad{/jobs/job/kill,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@56f521c6{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-2dd8239[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$2-2dd8239==org.apache.spark.ui.JettyUtils$$anon$2@4bd18ba5{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-4c447c09=org.apache.spark.ui.HttpSecurityFilter-4c447c09==org.apache.spark.ui.HttpSecurityFilter@4c447c09{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-4c447c09]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-2dd8239=org.apache.spark.ui.JettyUtils$$anon$2-2dd8239==org.apache.spark.ui.JettyUtils$$anon$2@4bd18ba5{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@56f521c6{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10361ms ServletHandler@56f521c6{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-4c447c09==org.apache.spark.ui.HttpSecurityFilter@4c447c09{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10362ms org.apache.spark.ui.HttpSecurityFilter-4c447c09==org.apache.spark.ui.HttpSecurityFilter@4c447c09{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@4bd5849e
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$2-2dd8239==org.apache.spark.ui.JettyUtils$$anon$2@4bd18ba5{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10363ms org.apache.spark.ui.JettyUtils$$anon$2-2dd8239==org.apache.spark.ui.JettyUtils$$anon$2@4bd18ba5{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$2-2dd8239
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@67fc2aad{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10363ms o.s.j.s.ServletContextHandler@67fc2aad{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@2e09c51{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@2e09c51{STARTING,min=32,inflate=-1} added {DeflaterPool@3c50ad4b{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@2e09c51{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@3c50ad4b{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10364ms DeflaterPool@3c50ad4b{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10364ms GzipHandler@2e09c51{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@3f92a84e{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-35f3a22c==org.apache.spark.ui.HttpSecurityFilter@35f3a22c{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ServletHandler@3f92a84e{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-35f3a22c,POJO}
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG GzipHandler:208 - GzipHandler@35ee466f{STOPPED,min=32,inflate=-1} mime types IncludeExclude@32e652b6{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@35ee466f{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@76ddd61a{/stages/stage/kill,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@65d8dff8{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2d9f64c9{/,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@4acb7ecc{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7bca6fac{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@4dba773d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@59696551{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@760cf594{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@43aeb5e0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@75a118e6{/api,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@d5d5353{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@72f9f27c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@650ae78c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@27a2a089{/static,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@60b34931{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@149c3204{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@59cda16e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@2a367e93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7be7e15{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@e4e1ef5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2459319c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1352434e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@35ee466f{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@76ddd61a{/stages/stage/kill,null,STOPPED,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@71f0b72e{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@53d13cd4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2de50ee4{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@2e09c51{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@67fc2aad{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@9679750{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@336880df{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@35ee466f{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@76ddd61a{/stages/stage/kill,null,STOPPED,@Spark}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@76ddd61a{/stages/stage/kill,null,STARTING,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting ServletHandler@3f92a84e{STOPPED}
2022-02-14 10:56:22 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-6137cf6e[EMBEDDED:null]
2022-02-14 10:56:22 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$2-6137cf6e==org.apache.spark.ui.JettyUtils$$anon$2@f072463e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-35f3a22c=org.apache.spark.ui.HttpSecurityFilter-35f3a22c==org.apache.spark.ui.HttpSecurityFilter@35f3a22c{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-35f3a22c]
2022-02-14 10:56:22 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:22 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:22 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-6137cf6e=org.apache.spark.ui.JettyUtils$$anon$2-6137cf6e==org.apache.spark.ui.JettyUtils$$anon$2@f072463e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting ServletHandler@3f92a84e{STARTING}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10379ms ServletHandler@3f92a84e{STARTED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-35f3a22c==org.apache.spark.ui.HttpSecurityFilter@35f3a22c{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10380ms org.apache.spark.ui.HttpSecurityFilter-35f3a22c==org.apache.spark.ui.HttpSecurityFilter@35f3a22c{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@2121d1f9
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$2-6137cf6e==org.apache.spark.ui.JettyUtils$$anon$2@f072463e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10381ms org.apache.spark.ui.JettyUtils$$anon$2-6137cf6e==org.apache.spark.ui.JettyUtils$$anon$2@f072463e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:22 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$2-6137cf6e
2022-02-14 10:56:22 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@76ddd61a{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10382ms o.s.j.s.ServletContextHandler@76ddd61a{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting GzipHandler@35ee466f{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG ContainerLifeCycle:412 - GzipHandler@35ee466f{STARTING,min=32,inflate=-1} added {DeflaterPool@4667c4c1{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:22 DEBUG AbstractHandler:94 - starting GzipHandler@35ee466f{STARTING,min=32,inflate=-1}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@4667c4c1{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10383ms DeflaterPool@4667c4c1{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:22 DEBUG AbstractLifeCycle:191 - STARTED @10383ms GzipHandler@35ee466f{STARTED,min=32,inflate=-1}
2022-02-14 10:56:22 INFO  SparkUI:57 - Bound SparkUI to 0.0.0.0, and started at http://Clairvoyant-320:4040
2022-02-14 10:56:23 INFO  Executor:57 - Starting executor ID driver on host Clairvoyant-320
2022-02-14 10:56:23 DEBUG TransportServer:153 - Shuffle server started on port: 60369
2022-02-14 10:56:23 INFO  Utils:57 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60369.
2022-02-14 10:56:23 INFO  NettyBlockTransferService:57 - Server created on Clairvoyant-320:60369
2022-02-14 10:56:23 INFO  BlockManager:57 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022-02-14 10:56:23 INFO  BlockManagerMaster:57 - Registering BlockManager BlockManagerId(driver, Clairvoyant-320, 60369, None)
2022-02-14 10:56:23 DEBUG DefaultTopologyMapper:61 - Got a request for Clairvoyant-320
2022-02-14 10:56:23 INFO  BlockManagerMasterEndpoint:57 - Registering block manager Clairvoyant-320:60369 with 2.2 GiB RAM, BlockManagerId(driver, Clairvoyant-320, 60369, None)
2022-02-14 10:56:23 INFO  BlockManagerMaster:57 - Registered BlockManager BlockManagerId(driver, Clairvoyant-320, 60369, None)
2022-02-14 10:56:23 INFO  BlockManager:57 - Initialized BlockManager: BlockManagerId(driver, Clairvoyant-320, 60369, None)
2022-02-14 10:56:23 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@61ff6a49
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@6042d663{/,null,STOPPED} added {ServletHandler@24043ec5{STOPPED},MANAGED}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ServletHandler@24043ec5{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-4c6a4ffd==org.apache.spark.ui.JettyUtils$$anon$1@88b71b78{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ServletHandler@24043ec5{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-4c6a4ffd,POJO}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ServletHandler@24043ec5{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-64b70f41==org.apache.spark.ui.HttpSecurityFilter@64b70f41{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ServletHandler@24043ec5{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-64b70f41,POJO}
2022-02-14 10:56:23 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:23 DEBUG GzipHandler:208 - GzipHandler@3e214105{STOPPED,min=32,inflate=-1} mime types IncludeExclude@da4cf09{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - GzipHandler@3e214105{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@6042d663{/metrics/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@65d8dff8{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2d9f64c9{/,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@4acb7ecc{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7bca6fac{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@4dba773d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@59696551{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@760cf594{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@43aeb5e0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@75a118e6{/api,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@d5d5353{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@72f9f27c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@650ae78c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@27a2a089{/static,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@60b34931{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@149c3204{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@59cda16e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@2a367e93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7be7e15{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@e4e1ef5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2459319c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1352434e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@35ee466f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@76ddd61a{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@71f0b72e{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@53d13cd4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2de50ee4{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@2e09c51{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@67fc2aad{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - metrics/json->[{GzipHandler@3e214105{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6042d663{/metrics/json,null,STOPPED,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@9679750{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@336880df{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@3e214105{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@6042d663{/metrics/json,null,STOPPED,@Spark}
2022-02-14 10:56:23 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@6042d663{/metrics/json,null,STARTING,@Spark}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting ServletHandler@24043ec5{STOPPED}
2022-02-14 10:56:23 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-4c6a4ffd[EMBEDDED:null]
2022-02-14 10:56:23 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-4c6a4ffd==org.apache.spark.ui.JettyUtils$$anon$1@88b71b78{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:23 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-64b70f41=org.apache.spark.ui.HttpSecurityFilter-64b70f41==org.apache.spark.ui.HttpSecurityFilter@64b70f41{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:23 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-64b70f41]
2022-02-14 10:56:23 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:23 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:23 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-4c6a4ffd=org.apache.spark.ui.JettyUtils$$anon$1-4c6a4ffd==org.apache.spark.ui.JettyUtils$$anon$1@88b71b78{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:23 DEBUG AbstractHandler:94 - starting ServletHandler@24043ec5{STARTING}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11121ms ServletHandler@24043ec5{STARTED}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-64b70f41==org.apache.spark.ui.HttpSecurityFilter@64b70f41{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11122ms org.apache.spark.ui.HttpSecurityFilter-64b70f41==org.apache.spark.ui.HttpSecurityFilter@64b70f41{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:23 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@286855ea
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-4c6a4ffd==org.apache.spark.ui.JettyUtils$$anon$1@88b71b78{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11123ms org.apache.spark.ui.JettyUtils$$anon$1-4c6a4ffd==org.apache.spark.ui.JettyUtils$$anon$1@88b71b78{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:23 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-4c6a4ffd
2022-02-14 10:56:23 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@6042d663{/metrics/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11123ms o.s.j.s.ServletContextHandler@6042d663{/metrics/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting GzipHandler@3e214105{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - GzipHandler@3e214105{STARTING,min=32,inflate=-1} added {DeflaterPool@6b357eb6{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:23 DEBUG AbstractHandler:94 - starting GzipHandler@3e214105{STARTING,min=32,inflate=-1}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@6b357eb6{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11124ms DeflaterPool@6b357eb6{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11124ms GzipHandler@3e214105{STARTED,min=32,inflate=-1}
2022-02-14 10:56:23 DEBUG SparkContext:61 - Adding shutdown hook
2022-02-14 10:56:23 INFO  SharedState:57 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/spark-warehouse').
2022-02-14 10:56:23 INFO  SharedState:57 - Warehouse path is 'file:/C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/spark-warehouse'.
2022-02-14 10:56:23 DEBUG SharedState:61 - Applying initial SparkSession options to SparkConf/HadoopConf: spark.master -> local
2022-02-14 10:56:23 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@5eed6dfb
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@551be9f6{/,null,STOPPED} added {ServletHandler@269222ae{STOPPED},MANAGED}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ServletHandler@269222ae{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-40d848f9==org.apache.spark.ui.JettyUtils$$anon$1@4b15c995{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ServletHandler@269222ae{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-40d848f9,POJO}
2022-02-14 10:56:23 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@46a123e4
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@3c28e5b6{/,null,STOPPED} added {ServletHandler@7558c24b{STOPPED},MANAGED}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ServletHandler@7558c24b{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-1f129467==org.apache.spark.ui.JettyUtils$$anon$1@e4a93f00{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ServletHandler@7558c24b{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-1f129467,POJO}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ServletHandler@269222ae{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-26457986==org.apache.spark.ui.HttpSecurityFilter@26457986{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ServletHandler@269222ae{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-26457986,POJO}
2022-02-14 10:56:23 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:23 DEBUG GzipHandler:208 - GzipHandler@5d1d9d73{STOPPED,min=32,inflate=-1} mime types IncludeExclude@b30a50d{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - GzipHandler@5d1d9d73{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@551be9f6{/SQL,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@65d8dff8{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2d9f64c9{/,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@4acb7ecc{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7bca6fac{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@4dba773d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@59696551{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@760cf594{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@43aeb5e0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@75a118e6{/api,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@d5d5353{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@72f9f27c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@650ae78c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@27a2a089{/static,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@60b34931{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@149c3204{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@59cda16e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@2a367e93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7be7e15{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@e4e1ef5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2459319c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1352434e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - SQL->[{GzipHandler@5d1d9d73{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@551be9f6{/SQL,null,STOPPED,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@35ee466f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@76ddd61a{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@71f0b72e{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@53d13cd4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2de50ee4{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@2e09c51{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@67fc2aad{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - metrics/json->[{GzipHandler@3e214105{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6042d663{/metrics/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@9679750{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@336880df{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@5d1d9d73{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@551be9f6{/SQL,null,STOPPED,@Spark}
2022-02-14 10:56:23 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@551be9f6{/SQL,null,STARTING,@Spark}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting ServletHandler@269222ae{STOPPED}
2022-02-14 10:56:23 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-40d848f9[EMBEDDED:null]
2022-02-14 10:56:23 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-40d848f9==org.apache.spark.ui.JettyUtils$$anon$1@4b15c995{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:23 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-26457986=org.apache.spark.ui.HttpSecurityFilter-26457986==org.apache.spark.ui.HttpSecurityFilter@26457986{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:23 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-26457986]
2022-02-14 10:56:23 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:23 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:23 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-40d848f9=org.apache.spark.ui.JettyUtils$$anon$1-40d848f9==org.apache.spark.ui.JettyUtils$$anon$1@4b15c995{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:23 DEBUG AbstractHandler:94 - starting ServletHandler@269222ae{STARTING}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11558ms ServletHandler@269222ae{STARTED}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-26457986==org.apache.spark.ui.HttpSecurityFilter@26457986{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11558ms org.apache.spark.ui.HttpSecurityFilter-26457986==org.apache.spark.ui.HttpSecurityFilter@26457986{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:23 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@7e5efcab
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-40d848f9==org.apache.spark.ui.JettyUtils$$anon$1@4b15c995{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11559ms org.apache.spark.ui.JettyUtils$$anon$1-40d848f9==org.apache.spark.ui.JettyUtils$$anon$1@4b15c995{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:23 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-40d848f9
2022-02-14 10:56:23 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@551be9f6{/SQL,null,AVAILABLE,@Spark}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11559ms o.s.j.s.ServletContextHandler@551be9f6{/SQL,null,AVAILABLE,@Spark}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting GzipHandler@5d1d9d73{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - GzipHandler@5d1d9d73{STARTING,min=32,inflate=-1} added {DeflaterPool@11a3a45f{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:23 DEBUG AbstractHandler:94 - starting GzipHandler@5d1d9d73{STARTING,min=32,inflate=-1}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@11a3a45f{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11560ms DeflaterPool@11a3a45f{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11560ms GzipHandler@5d1d9d73{STARTED,min=32,inflate=-1}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ServletHandler@7558c24b{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-1d289d3f==org.apache.spark.ui.HttpSecurityFilter@1d289d3f{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ServletHandler@7558c24b{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-1d289d3f,POJO}
2022-02-14 10:56:23 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:23 DEBUG GzipHandler:208 - GzipHandler@45801322{STOPPED,min=32,inflate=-1} mime types IncludeExclude@756b2d90{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - GzipHandler@45801322{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@3c28e5b6{/SQL/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@65d8dff8{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2d9f64c9{/,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@4acb7ecc{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7bca6fac{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@4dba773d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@59696551{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@760cf594{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@43aeb5e0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@75a118e6{/api,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@d5d5353{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@72f9f27c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@650ae78c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@27a2a089{/static,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@60b34931{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@149c3204{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@59cda16e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@2a367e93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7be7e15{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@e4e1ef5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2459319c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1352434e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - SQL->[{GzipHandler@5d1d9d73{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@551be9f6{/SQL,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@35ee466f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@76ddd61a{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@71f0b72e{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@53d13cd4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2de50ee4{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - SQL/json->[{GzipHandler@45801322{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c28e5b6{/SQL/json,null,STOPPED,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@2e09c51{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@67fc2aad{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - metrics/json->[{GzipHandler@3e214105{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6042d663{/metrics/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@9679750{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@336880df{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@45801322{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@3c28e5b6{/SQL/json,null,STOPPED,@Spark}
2022-02-14 10:56:23 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@3c28e5b6{/SQL/json,null,STARTING,@Spark}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting ServletHandler@7558c24b{STOPPED}
2022-02-14 10:56:23 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-1f129467[EMBEDDED:null]
2022-02-14 10:56:23 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-1f129467==org.apache.spark.ui.JettyUtils$$anon$1@e4a93f00{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:23 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-1d289d3f=org.apache.spark.ui.HttpSecurityFilter-1d289d3f==org.apache.spark.ui.HttpSecurityFilter@1d289d3f{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:23 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-1d289d3f]
2022-02-14 10:56:23 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:23 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:23 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-1f129467=org.apache.spark.ui.JettyUtils$$anon$1-1f129467==org.apache.spark.ui.JettyUtils$$anon$1@e4a93f00{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:23 DEBUG AbstractHandler:94 - starting ServletHandler@7558c24b{STARTING}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11575ms ServletHandler@7558c24b{STARTED}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-1d289d3f==org.apache.spark.ui.HttpSecurityFilter@1d289d3f{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11575ms org.apache.spark.ui.HttpSecurityFilter-1d289d3f==org.apache.spark.ui.HttpSecurityFilter@1d289d3f{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:23 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@21f7e537
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-1f129467==org.apache.spark.ui.JettyUtils$$anon$1@e4a93f00{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11576ms org.apache.spark.ui.JettyUtils$$anon$1-1f129467==org.apache.spark.ui.JettyUtils$$anon$1@e4a93f00{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:23 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-1f129467
2022-02-14 10:56:23 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@3c28e5b6{/SQL/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11576ms o.s.j.s.ServletContextHandler@3c28e5b6{/SQL/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting GzipHandler@45801322{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - GzipHandler@45801322{STARTING,min=32,inflate=-1} added {DeflaterPool@6af65f29{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:23 DEBUG AbstractHandler:94 - starting GzipHandler@45801322{STARTING,min=32,inflate=-1}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@6af65f29{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11577ms DeflaterPool@6af65f29{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11577ms GzipHandler@45801322{STARTED,min=32,inflate=-1}
2022-02-14 10:56:23 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@58b311ba
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@75eaba95{/,null,STOPPED} added {ServletHandler@320be73{STOPPED},MANAGED}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ServletHandler@320be73{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-6af310c7==org.apache.spark.ui.JettyUtils$$anon$1@3e0b3af9{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ServletHandler@320be73{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-6af310c7,POJO}
2022-02-14 10:56:23 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@7ddcb0dc
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@2c1d57bc{/,null,STOPPED} added {ServletHandler@26c77f54{STOPPED},MANAGED}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ServletHandler@26c77f54{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-6e9a0bea==org.apache.spark.ui.JettyUtils$$anon$1@c76294f3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ServletHandler@26c77f54{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-6e9a0bea,POJO}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ServletHandler@320be73{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-20440c6c==org.apache.spark.ui.HttpSecurityFilter@20440c6c{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ServletHandler@320be73{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-20440c6c,POJO}
2022-02-14 10:56:23 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:23 DEBUG GzipHandler:208 - GzipHandler@41e9f86{STOPPED,min=32,inflate=-1} mime types IncludeExclude@66f5b8fe{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - GzipHandler@41e9f86{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@75eaba95{/SQL/execution,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@65d8dff8{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2d9f64c9{/,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@4acb7ecc{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7bca6fac{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@4dba773d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@59696551{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@760cf594{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@43aeb5e0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@75a118e6{/api,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@d5d5353{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@72f9f27c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@650ae78c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@27a2a089{/static,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@60b34931{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@149c3204{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@59cda16e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@2a367e93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7be7e15{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@e4e1ef5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2459319c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1352434e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - SQL->[{GzipHandler@5d1d9d73{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@551be9f6{/SQL,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@35ee466f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@76ddd61a{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@71f0b72e{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@53d13cd4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2de50ee4{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - SQL/json->[{GzipHandler@45801322{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c28e5b6{/SQL/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@2e09c51{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@67fc2aad{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - metrics/json->[{GzipHandler@3e214105{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6042d663{/metrics/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - SQL/execution->[{GzipHandler@41e9f86{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@75eaba95{/SQL/execution,null,STOPPED,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@9679750{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@336880df{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@41e9f86{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@75eaba95{/SQL/execution,null,STOPPED,@Spark}
2022-02-14 10:56:23 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@75eaba95{/SQL/execution,null,STARTING,@Spark}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting ServletHandler@320be73{STOPPED}
2022-02-14 10:56:23 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-6af310c7[EMBEDDED:null]
2022-02-14 10:56:23 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-6af310c7==org.apache.spark.ui.JettyUtils$$anon$1@3e0b3af9{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:23 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-20440c6c=org.apache.spark.ui.HttpSecurityFilter-20440c6c==org.apache.spark.ui.HttpSecurityFilter@20440c6c{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:23 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-20440c6c]
2022-02-14 10:56:23 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:23 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:23 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-6af310c7=org.apache.spark.ui.JettyUtils$$anon$1-6af310c7==org.apache.spark.ui.JettyUtils$$anon$1@3e0b3af9{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:23 DEBUG AbstractHandler:94 - starting ServletHandler@320be73{STARTING}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11593ms ServletHandler@320be73{STARTED}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-20440c6c==org.apache.spark.ui.HttpSecurityFilter@20440c6c{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11593ms org.apache.spark.ui.HttpSecurityFilter-20440c6c==org.apache.spark.ui.HttpSecurityFilter@20440c6c{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:23 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@7d66e544
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-6af310c7==org.apache.spark.ui.JettyUtils$$anon$1@3e0b3af9{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11594ms org.apache.spark.ui.JettyUtils$$anon$1-6af310c7==org.apache.spark.ui.JettyUtils$$anon$1@3e0b3af9{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:23 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-6af310c7
2022-02-14 10:56:23 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@75eaba95{/SQL/execution,null,AVAILABLE,@Spark}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11594ms o.s.j.s.ServletContextHandler@75eaba95{/SQL/execution,null,AVAILABLE,@Spark}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting GzipHandler@41e9f86{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - GzipHandler@41e9f86{STARTING,min=32,inflate=-1} added {DeflaterPool@5a4d4f9c{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:23 DEBUG AbstractHandler:94 - starting GzipHandler@41e9f86{STARTING,min=32,inflate=-1}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@5a4d4f9c{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11595ms DeflaterPool@5a4d4f9c{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11595ms GzipHandler@41e9f86{STARTED,min=32,inflate=-1}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ServletHandler@26c77f54{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-51ba952e==org.apache.spark.ui.HttpSecurityFilter@51ba952e{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ServletHandler@26c77f54{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-51ba952e,POJO}
2022-02-14 10:56:23 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:23 DEBUG GzipHandler:208 - GzipHandler@1b560eb0{STOPPED,min=32,inflate=-1} mime types IncludeExclude@9e02f84{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - GzipHandler@1b560eb0{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@2c1d57bc{/SQL/execution/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@65d8dff8{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2d9f64c9{/,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@4acb7ecc{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7bca6fac{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@4dba773d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@59696551{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@760cf594{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - SQL/execution/json->[{GzipHandler@1b560eb0{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2c1d57bc{/SQL/execution/json,null,STOPPED,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@43aeb5e0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@75a118e6{/api,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@d5d5353{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@72f9f27c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@650ae78c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@27a2a089{/static,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@60b34931{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@149c3204{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@59cda16e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@2a367e93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7be7e15{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@e4e1ef5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2459319c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1352434e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - SQL->[{GzipHandler@5d1d9d73{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@551be9f6{/SQL,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@35ee466f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@76ddd61a{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@71f0b72e{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@53d13cd4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2de50ee4{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - SQL/json->[{GzipHandler@45801322{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c28e5b6{/SQL/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@2e09c51{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@67fc2aad{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - metrics/json->[{GzipHandler@3e214105{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6042d663{/metrics/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - SQL/execution->[{GzipHandler@41e9f86{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@75eaba95{/SQL/execution,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@9679750{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@336880df{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@1b560eb0{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@2c1d57bc{/SQL/execution/json,null,STOPPED,@Spark}
2022-02-14 10:56:23 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@2c1d57bc{/SQL/execution/json,null,STARTING,@Spark}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting ServletHandler@26c77f54{STOPPED}
2022-02-14 10:56:23 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-6e9a0bea[EMBEDDED:null]
2022-02-14 10:56:23 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-6e9a0bea==org.apache.spark.ui.JettyUtils$$anon$1@c76294f3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:23 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-51ba952e=org.apache.spark.ui.HttpSecurityFilter-51ba952e==org.apache.spark.ui.HttpSecurityFilter@51ba952e{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:23 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-51ba952e]
2022-02-14 10:56:23 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:23 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:23 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-6e9a0bea=org.apache.spark.ui.JettyUtils$$anon$1-6e9a0bea==org.apache.spark.ui.JettyUtils$$anon$1@c76294f3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:23 DEBUG AbstractHandler:94 - starting ServletHandler@26c77f54{STARTING}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11603ms ServletHandler@26c77f54{STARTED}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-51ba952e==org.apache.spark.ui.HttpSecurityFilter@51ba952e{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11604ms org.apache.spark.ui.HttpSecurityFilter-51ba952e==org.apache.spark.ui.HttpSecurityFilter@51ba952e{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:23 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@615efd1c
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-6e9a0bea==org.apache.spark.ui.JettyUtils$$anon$1@c76294f3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11605ms org.apache.spark.ui.JettyUtils$$anon$1-6e9a0bea==org.apache.spark.ui.JettyUtils$$anon$1@c76294f3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:23 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-6e9a0bea
2022-02-14 10:56:23 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@2c1d57bc{/SQL/execution/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11606ms o.s.j.s.ServletContextHandler@2c1d57bc{/SQL/execution/json,null,AVAILABLE,@Spark}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting GzipHandler@1b560eb0{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - GzipHandler@1b560eb0{STARTING,min=32,inflate=-1} added {DeflaterPool@6f38f084{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:23 DEBUG AbstractHandler:94 - starting GzipHandler@1b560eb0{STARTING,min=32,inflate=-1}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@6f38f084{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11607ms DeflaterPool@6f38f084{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11607ms GzipHandler@1b560eb0{STARTED,min=32,inflate=-1}
2022-02-14 10:56:23 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@526f6427
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@492521c4{/,null,STOPPED} added {ServletHandler@443a06ad{STOPPED},MANAGED}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ServletHandler@443a06ad{STOPPED} added {org.sparkproject.jetty.servlet.DefaultServlet-752b69e3==org.sparkproject.jetty.servlet.DefaultServlet@740bd8c7{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ServletHandler@443a06ad{STOPPED} added {[/]=>org.sparkproject.jetty.servlet.DefaultServlet-752b69e3,POJO}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ServletHandler@443a06ad{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-4c18516==org.apache.spark.ui.HttpSecurityFilter@4c18516{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ServletHandler@443a06ad{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-4c18516,POJO}
2022-02-14 10:56:23 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:56:23 DEBUG GzipHandler:208 - GzipHandler@6da54910{STOPPED,min=32,inflate=-1} mime types IncludeExclude@1bd8afc8{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - GzipHandler@6da54910{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@492521c4{/static/sql,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@65d8dff8{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2d9f64c9{/,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@4acb7ecc{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7bca6fac{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@4dba773d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6dfcffb5{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@59696551{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@760cf594{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - SQL/execution/json->[{GzipHandler@1b560eb0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2c1d57bc{/SQL/execution/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@43aeb5e0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@75a118e6{/api,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@d5d5353{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@38a1a26{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@72f9f27c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1108adc8{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@554f0dfb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3d7b1f1c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@650ae78c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@27a2a089{/static,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@60b34931{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@149c3204{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@59cda16e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@572e6fd9{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@2a367e93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7be7e15{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@e4e1ef5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2459319c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@102ecc22{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@747d1932{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@a62c7cd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ec65b5e{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@59dc36d4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6ab7ce48{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@7fe82967{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@719bb3b4{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1352434e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@16a49a5d{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - SQL->[{GzipHandler@5d1d9d73{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@551be9f6{/SQL,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - static/sql->[{GzipHandler@6da54910{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@492521c4{/static/sql,null,STOPPED,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@35ee466f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@76ddd61a{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@7a0ef219{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@b25b095{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@71f0b72e{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@6edcad64{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@211febf3{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@53d13cd4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2de50ee4{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - SQL/json->[{GzipHandler@45801322{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c28e5b6{/SQL/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@2e09c51{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@67fc2aad{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - metrics/json->[{GzipHandler@3e214105{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6042d663{/metrics/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - SQL/execution->[{GzipHandler@41e9f86{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@75eaba95{/SQL/execution,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@9679750{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@336880df{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@61a1ea2c{STARTED} added {GzipHandler@6da54910{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@492521c4{/static/sql,null,STOPPED,@Spark}
2022-02-14 10:56:23 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@492521c4{/static/sql,null,STARTING,@Spark}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting ServletHandler@443a06ad{STOPPED}
2022-02-14 10:56:23 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.sparkproject.jetty.servlet.DefaultServlet-752b69e3[EMBEDDED:null]
2022-02-14 10:56:23 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.sparkproject.jetty.servlet.DefaultServlet-752b69e3==org.sparkproject.jetty.servlet.DefaultServlet@740bd8c7{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:56:23 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-4c18516=org.apache.spark.ui.HttpSecurityFilter-4c18516==org.apache.spark.ui.HttpSecurityFilter@4c18516{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:23 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, INCLUDE, ERROR, FORWARD]=>org.apache.spark.ui.HttpSecurityFilter-4c18516]
2022-02-14 10:56:23 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:56:23 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:56:23 DEBUG ServletHandler:1443 - servletNameMap={org.sparkproject.jetty.servlet.DefaultServlet-752b69e3=org.sparkproject.jetty.servlet.DefaultServlet-752b69e3==org.sparkproject.jetty.servlet.DefaultServlet@740bd8c7{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:56:23 DEBUG AbstractHandler:94 - starting ServletHandler@443a06ad{STARTING}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11616ms ServletHandler@443a06ad{STARTED}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-4c18516==org.apache.spark.ui.HttpSecurityFilter@4c18516{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11616ms org.apache.spark.ui.HttpSecurityFilter-4c18516==org.apache.spark.ui.HttpSecurityFilter@4c18516{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:23 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@437ed416
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting org.sparkproject.jetty.servlet.DefaultServlet-752b69e3==org.sparkproject.jetty.servlet.DefaultServlet@740bd8c7{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11616ms org.sparkproject.jetty.servlet.DefaultServlet-752b69e3==org.sparkproject.jetty.servlet.DefaultServlet@740bd8c7{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:56:23 DEBUG ServletHolder:621 - Servlet.init null for org.sparkproject.jetty.servlet.DefaultServlet-752b69e3
2022-02-14 10:56:23 DEBUG DefaultServlet:308 - resource base = jar:file:/C:/Users/Shridhar%20Ingale/.m2/repository/org/apache/spark/spark-sql_2.12/3.0.3/spark-sql_2.12-3.0.3.jar!/org/apache/spark/sql/execution/ui/static
2022-02-14 10:56:23 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@492521c4{/static/sql,null,AVAILABLE,@Spark}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11647ms o.s.j.s.ServletContextHandler@492521c4{/static/sql,null,AVAILABLE,@Spark}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting GzipHandler@6da54910{STOPPED,min=32,inflate=-1}
2022-02-14 10:56:23 DEBUG ContainerLifeCycle:412 - GzipHandler@6da54910{STARTING,min=32,inflate=-1} added {DeflaterPool@5a592c70{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:56:23 DEBUG AbstractHandler:94 - starting GzipHandler@6da54910{STARTING,min=32,inflate=-1}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@5a592c70{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11648ms DeflaterPool@5a592c70{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:56:23 DEBUG AbstractLifeCycle:191 - STARTED @11648ms GzipHandler@6da54910{STARTED,min=32,inflate=-1}
2022-02-14 10:56:24 DEBUG DataSource:61 - Some paths were ignored:
  
2022-02-14 10:56:24 INFO  InMemoryFileIndex:57 - It took 54 ms to list leaf files for 1 paths.
2022-02-14 10:56:25 INFO  InMemoryFileIndex:57 - It took 2 ms to list leaf files for 1 paths.
2022-02-14 10:56:26 DEBUG Analyzer$ResolveReferences:61 - Resolving 'value to value#0
2022-02-14 10:56:27 DEBUG Analyzer$ResolveReferences:61 - Resolving 'value to value#6
2022-02-14 10:56:27 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-02-14 10:56:27 INFO  FileSourceStrategy:57 - Post-Scan Filters: (length(trim(value#0, None)) > 0)
2022-02-14 10:56:27 INFO  FileSourceStrategy:57 - Output Data Schema: struct<value: string>
2022-02-14 10:56:28 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while ( inputadapter_input_0.hasNext()) {
/* 026 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 027 */
/* 028 */       do {
/* 029 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 030 */         UTF8String inputadapter_value_0 = inputadapter_isNull_0 ?
/* 031 */         null : (inputadapter_row_0.getUTF8String(0));
/* 032 */
/* 033 */         boolean filter_isNull_0 = true;
/* 034 */         boolean filter_value_0 = false;
/* 035 */         boolean filter_isNull_2 = false;
/* 036 */         UTF8String filter_value_2 = null;
/* 037 */         if (inputadapter_isNull_0) {
/* 038 */           filter_isNull_2 = true;
/* 039 */         } else {
/* 040 */           filter_value_2 = inputadapter_value_0.trim();
/* 041 */         }
/* 042 */         boolean filter_isNull_1 = filter_isNull_2;
/* 043 */         int filter_value_1 = -1;
/* 044 */
/* 045 */         if (!filter_isNull_2) {
/* 046 */           filter_value_1 = (filter_value_2).numChars();
/* 047 */         }
/* 048 */         if (!filter_isNull_1) {
/* 049 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 050 */           filter_value_0 = filter_value_1 > 0;
/* 051 */
/* 052 */         }
/* 053 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 054 */
/* 055 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 056 */
/* 057 */         filter_mutableStateArray_0[0].reset();
/* 058 */
/* 059 */         filter_mutableStateArray_0[0].zeroOutNullBytes();
/* 060 */
/* 061 */         if (inputadapter_isNull_0) {
/* 062 */           filter_mutableStateArray_0[0].setNullAt(0);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[0].write(0, inputadapter_value_0);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[0].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }

2022-02-14 10:56:28 DEBUG CodeGenerator:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while ( inputadapter_input_0.hasNext()) {
/* 026 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 027 */
/* 028 */       do {
/* 029 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 030 */         UTF8String inputadapter_value_0 = inputadapter_isNull_0 ?
/* 031 */         null : (inputadapter_row_0.getUTF8String(0));
/* 032 */
/* 033 */         boolean filter_isNull_0 = true;
/* 034 */         boolean filter_value_0 = false;
/* 035 */         boolean filter_isNull_2 = false;
/* 036 */         UTF8String filter_value_2 = null;
/* 037 */         if (inputadapter_isNull_0) {
/* 038 */           filter_isNull_2 = true;
/* 039 */         } else {
/* 040 */           filter_value_2 = inputadapter_value_0.trim();
/* 041 */         }
/* 042 */         boolean filter_isNull_1 = filter_isNull_2;
/* 043 */         int filter_value_1 = -1;
/* 044 */
/* 045 */         if (!filter_isNull_2) {
/* 046 */           filter_value_1 = (filter_value_2).numChars();
/* 047 */         }
/* 048 */         if (!filter_isNull_1) {
/* 049 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 050 */           filter_value_0 = filter_value_1 > 0;
/* 051 */
/* 052 */         }
/* 053 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 054 */
/* 055 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 056 */
/* 057 */         filter_mutableStateArray_0[0].reset();
/* 058 */
/* 059 */         filter_mutableStateArray_0[0].zeroOutNullBytes();
/* 060 */
/* 061 */         if (inputadapter_isNull_0) {
/* 062 */           filter_mutableStateArray_0[0].setNullAt(0);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[0].write(0, inputadapter_value_0);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[0].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }

2022-02-14 10:56:28 INFO  CodeGenerator:57 - Code generated in 347.4344 ms
2022-02-14 10:56:28 INFO  MemoryStore:57 - Block broadcast_0 stored as values in memory (estimated size 171.1 KiB, free 2.2 GiB)
2022-02-14 10:56:28 DEBUG BlockManager:61 - Put block broadcast_0 locally took 52 ms
2022-02-14 10:56:28 DEBUG BlockManager:61 - Putting block broadcast_0 without replication took 54 ms
2022-02-14 10:56:28 INFO  MemoryStore:57 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.9 KiB, free 2.2 GiB)
2022-02-14 10:56:28 INFO  BlockManagerInfo:57 - Added broadcast_0_piece0 in memory on Clairvoyant-320:60369 (size: 23.9 KiB, free: 2.2 GiB)
2022-02-14 10:56:28 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_0_piece0
2022-02-14 10:56:28 DEBUG BlockManager:61 - Told master about block broadcast_0_piece0
2022-02-14 10:56:28 DEBUG BlockManager:61 - Put block broadcast_0_piece0 locally took 10 ms
2022-02-14 10:56:28 DEBUG BlockManager:61 - Putting block broadcast_0_piece0 without replication took 11 ms
2022-02-14 10:56:28 INFO  SparkContext:57 - Created broadcast 0 from load at UsedCase5.java:13
2022-02-14 10:56:28 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4194394 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-14 10:56:28 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-02-14 10:56:28 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-02-14 10:56:28 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$executeTake$2
2022-02-14 10:56:28 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$executeTake$2) is now cleaned +++
2022-02-14 10:56:28 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$5
2022-02-14 10:56:28 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2022-02-14 10:56:28 INFO  SparkContext:57 - Starting job: load at UsedCase5.java:13
2022-02-14 10:56:28 INFO  DAGScheduler:57 - Got job 0 (load at UsedCase5.java:13) with 1 output partitions
2022-02-14 10:56:28 INFO  DAGScheduler:57 - Final stage: ResultStage 0 (load at UsedCase5.java:13)
2022-02-14 10:56:28 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-02-14 10:56:28 INFO  DAGScheduler:57 - Missing parents: List()
2022-02-14 10:56:28 DEBUG DAGScheduler:61 - submitStage(ResultStage 0 (name=load at UsedCase5.java:13;jobs=0))
2022-02-14 10:56:28 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:56:28 INFO  DAGScheduler:57 - Submitting ResultStage 0 (MapPartitionsRDD[3] at load at UsedCase5.java:13), which has no missing parents
2022-02-14 10:56:28 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 0)
2022-02-14 10:56:29 INFO  MemoryStore:57 - Block broadcast_1 stored as values in memory (estimated size 10.7 KiB, free 2.2 GiB)
2022-02-14 10:56:29 DEBUG BlockManager:61 - Put block broadcast_1 locally took 6 ms
2022-02-14 10:56:29 DEBUG BlockManager:61 - Putting block broadcast_1 without replication took 7 ms
2022-02-14 10:56:29 INFO  MemoryStore:57 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 2.2 GiB)
2022-02-14 10:56:29 INFO  BlockManagerInfo:57 - Added broadcast_1_piece0 in memory on Clairvoyant-320:60369 (size: 5.3 KiB, free: 2.2 GiB)
2022-02-14 10:56:29 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_1_piece0
2022-02-14 10:56:29 DEBUG BlockManager:61 - Told master about block broadcast_1_piece0
2022-02-14 10:56:29 DEBUG BlockManager:61 - Put block broadcast_1_piece0 locally took 3 ms
2022-02-14 10:56:29 DEBUG BlockManager:61 - Putting block broadcast_1_piece0 without replication took 3 ms
2022-02-14 10:56:29 INFO  SparkContext:57 - Created broadcast 1 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:56:29 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at UsedCase5.java:13) (first 15 tasks are for partitions Vector(0))
2022-02-14 10:56:29 INFO  TaskSchedulerImpl:57 - Adding task set 0.0 with 1 tasks
2022-02-14 10:56:29 DEBUG TaskSetManager:61 - Epoch for TaskSet 0.0: 0
2022-02-14 10:56:29 DEBUG TaskSetManager:61 - Adding pending tasks took 5 ms
2022-02-14 10:56:29 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 0.0: NO_PREF, ANY
2022-02-14 10:56:29 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_0.0, runningTasks: 0
2022-02-14 10:56:29 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 0.0: NO_PREF, ANY
2022-02-14 10:56:29 INFO  TaskSetManager:57 - Starting task 0.0 in stage 0.0 (TID 0, Clairvoyant-320, executor driver, partition 0, PROCESS_LOCAL, 7806 bytes)
2022-02-14 10:56:29 INFO  Executor:57 - Running task 0.0 in stage 0.0 (TID 0)
2022-02-14 10:56:29 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (0, 0) -> 1
2022-02-14 10:56:29 DEBUG BlockManager:61 - Getting local block broadcast_1
2022-02-14 10:56:29 DEBUG BlockManager:61 - Level for block broadcast_1 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:56:29 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/src/main/resources/retail_db/departments/part-00000, range: 0-90, partition values: [empty row]
2022-02-14 10:56:29 DEBUG GenerateUnsafeProjection:61 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-14 10:56:29 DEBUG CodeGenerator:61 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-14 10:56:29 INFO  CodeGenerator:57 - Code generated in 20.8023 ms
2022-02-14 10:56:29 DEBUG BlockManager:61 - Getting local block broadcast_0
2022-02-14 10:56:29 DEBUG BlockManager:61 - Level for block broadcast_0 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:56:29 INFO  Executor:57 - Finished task 0.0 in stage 0.0 (TID 0). 1583 bytes result sent to driver
2022-02-14 10:56:29 DEBUG ExecutorMetricsPoller:61 - removing (0, 0) from stageTCMP
2022-02-14 10:56:29 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_0.0, runningTasks: 0
2022-02-14 10:56:29 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-14 10:56:29 INFO  TaskSetManager:57 - Finished task 0.0 in stage 0.0 (TID 0) in 411 ms on Clairvoyant-320 (executor driver) (1/1)
2022-02-14 10:56:29 INFO  TaskSchedulerImpl:57 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-02-14 10:56:29 INFO  DAGScheduler:57 - ResultStage 0 (load at UsedCase5.java:13) finished in 0.618 s
2022-02-14 10:56:29 DEBUG DAGScheduler:61 - After removal of stage 0, remaining stages = 0
2022-02-14 10:56:29 INFO  DAGScheduler:57 - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2022-02-14 10:56:29 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 0: Stage finished
2022-02-14 10:56:29 INFO  DAGScheduler:57 - Job 0 finished: load at UsedCase5.java:13, took 0.674406 s
2022-02-14 10:56:29 DEBUG GenerateSafeProjection:61 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-02-14 10:56:29 DEBUG CodeGenerator:61 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-02-14 10:56:29 INFO  CodeGenerator:57 - Code generated in 17.471 ms
2022-02-14 10:56:29 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-02-14 10:56:29 INFO  FileSourceStrategy:57 - Post-Scan Filters: 
2022-02-14 10:56:29 INFO  FileSourceStrategy:57 - Output Data Schema: struct<value: string>
2022-02-14 10:56:29 INFO  MemoryStore:57 - Block broadcast_2 stored as values in memory (estimated size 171.1 KiB, free 2.2 GiB)
2022-02-14 10:56:29 DEBUG BlockManager:61 - Put block broadcast_2 locally took 13 ms
2022-02-14 10:56:29 DEBUG BlockManager:61 - Putting block broadcast_2 without replication took 13 ms
2022-02-14 10:56:29 INFO  MemoryStore:57 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.9 KiB, free 2.2 GiB)
2022-02-14 10:56:29 INFO  BlockManagerInfo:57 - Added broadcast_2_piece0 in memory on Clairvoyant-320:60369 (size: 23.9 KiB, free: 2.2 GiB)
2022-02-14 10:56:29 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_2_piece0
2022-02-14 10:56:29 DEBUG BlockManager:61 - Told master about block broadcast_2_piece0
2022-02-14 10:56:29 DEBUG BlockManager:61 - Put block broadcast_2_piece0 locally took 5 ms
2022-02-14 10:56:29 DEBUG BlockManager:61 - Putting block broadcast_2_piece0 without replication took 5 ms
2022-02-14 10:56:29 INFO  SparkContext:57 - Created broadcast 2 from load at UsedCase5.java:13
2022-02-14 10:56:29 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4194394 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-14 10:56:29 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$rdd$1
2022-02-14 10:56:29 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$rdd$1) is now cleaned +++
2022-02-14 10:56:29 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$inferFromDataset$2
2022-02-14 10:56:29 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$inferFromDataset$2) is now cleaned +++
2022-02-14 10:56:29 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$infer$2
2022-02-14 10:56:29 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$infer$2) is now cleaned +++
2022-02-14 10:56:29 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$infer$3
2022-02-14 10:56:29 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$infer$3) is now cleaned +++
2022-02-14 10:56:29 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$6
2022-02-14 10:56:29 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$6) is now cleaned +++
2022-02-14 10:56:29 INFO  SparkContext:57 - Starting job: load at UsedCase5.java:13
2022-02-14 10:56:29 INFO  DAGScheduler:57 - Got job 1 (load at UsedCase5.java:13) with 1 output partitions
2022-02-14 10:56:29 INFO  DAGScheduler:57 - Final stage: ResultStage 1 (load at UsedCase5.java:13)
2022-02-14 10:56:29 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-02-14 10:56:29 INFO  DAGScheduler:57 - Missing parents: List()
2022-02-14 10:56:29 DEBUG DAGScheduler:61 - submitStage(ResultStage 1 (name=load at UsedCase5.java:13;jobs=1))
2022-02-14 10:56:29 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:56:29 INFO  DAGScheduler:57 - Submitting ResultStage 1 (MapPartitionsRDD[9] at load at UsedCase5.java:13), which has no missing parents
2022-02-14 10:56:29 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 1)
2022-02-14 10:56:29 INFO  MemoryStore:57 - Block broadcast_3 stored as values in memory (estimated size 15.1 KiB, free 2.2 GiB)
2022-02-14 10:56:29 DEBUG BlockManager:61 - Put block broadcast_3 locally took 5 ms
2022-02-14 10:56:29 DEBUG BlockManager:61 - Putting block broadcast_3 without replication took 6 ms
2022-02-14 10:56:29 INFO  MemoryStore:57 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 2.2 GiB)
2022-02-14 10:56:29 INFO  BlockManagerInfo:57 - Added broadcast_3_piece0 in memory on Clairvoyant-320:60369 (size: 7.6 KiB, free: 2.2 GiB)
2022-02-14 10:56:29 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_3_piece0
2022-02-14 10:56:29 DEBUG BlockManager:61 - Told master about block broadcast_3_piece0
2022-02-14 10:56:29 DEBUG BlockManager:61 - Put block broadcast_3_piece0 locally took 3 ms
2022-02-14 10:56:29 DEBUG BlockManager:61 - Putting block broadcast_3_piece0 without replication took 3 ms
2022-02-14 10:56:29 INFO  SparkContext:57 - Created broadcast 3 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:56:29 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at load at UsedCase5.java:13) (first 15 tasks are for partitions Vector(0))
2022-02-14 10:56:29 INFO  TaskSchedulerImpl:57 - Adding task set 1.0 with 1 tasks
2022-02-14 10:56:29 DEBUG TaskSetManager:61 - Epoch for TaskSet 1.0: 0
2022-02-14 10:56:29 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-02-14 10:56:29 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 1.0: NO_PREF, ANY
2022-02-14 10:56:29 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_1.0, runningTasks: 0
2022-02-14 10:56:29 INFO  TaskSetManager:57 - Starting task 0.0 in stage 1.0 (TID 1, Clairvoyant-320, executor driver, partition 0, PROCESS_LOCAL, 7806 bytes)
2022-02-14 10:56:29 INFO  Executor:57 - Running task 0.0 in stage 1.0 (TID 1)
2022-02-14 10:56:29 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (1, 0) -> 1
2022-02-14 10:56:29 DEBUG BlockManager:61 - Getting local block broadcast_3
2022-02-14 10:56:29 DEBUG BlockManager:61 - Level for block broadcast_3 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:56:29 DEBUG GenerateSafeProjection:61 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-02-14 10:56:29 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/src/main/resources/retail_db/departments/part-00000, range: 0-90, partition values: [empty row]
2022-02-14 10:56:30 DEBUG GenerateUnsafeProjection:61 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-14 10:56:30 DEBUG BlockManager:61 - Getting local block broadcast_2
2022-02-14 10:56:30 DEBUG BlockManager:61 - Level for block broadcast_2 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:56:30 INFO  Executor:57 - Finished task 0.0 in stage 1.0 (TID 1). 1599 bytes result sent to driver
2022-02-14 10:56:30 DEBUG ExecutorMetricsPoller:61 - removing (1, 0) from stageTCMP
2022-02-14 10:56:30 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_1.0, runningTasks: 0
2022-02-14 10:56:30 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-14 10:56:30 INFO  TaskSetManager:57 - Finished task 0.0 in stage 1.0 (TID 1) in 153 ms on Clairvoyant-320 (executor driver) (1/1)
2022-02-14 10:56:30 INFO  TaskSchedulerImpl:57 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-02-14 10:56:30 INFO  DAGScheduler:57 - ResultStage 1 (load at UsedCase5.java:13) finished in 0.207 s
2022-02-14 10:56:30 DEBUG DAGScheduler:61 - After removal of stage 1, remaining stages = 0
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2022-02-14 10:56:30 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 1: Stage finished
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Job 1 finished: load at UsedCase5.java:13, took 0.224875 s
2022-02-14 10:56:30 DEBUG DataSource:61 - Some paths were ignored:
  
2022-02-14 10:56:30 INFO  InMemoryFileIndex:57 - It took 2 ms to list leaf files for 1 paths.
2022-02-14 10:56:30 INFO  InMemoryFileIndex:57 - It took 2 ms to list leaf files for 1 paths.
2022-02-14 10:56:30 DEBUG Analyzer$ResolveReferences:61 - Resolving 'value to value#20
2022-02-14 10:56:30 DEBUG Analyzer$ResolveReferences:61 - Resolving 'value to value#26
2022-02-14 10:56:30 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-02-14 10:56:30 INFO  FileSourceStrategy:57 - Post-Scan Filters: (length(trim(value#20, None)) > 0)
2022-02-14 10:56:30 INFO  FileSourceStrategy:57 - Output Data Schema: struct<value: string>
2022-02-14 10:56:30 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while ( inputadapter_input_0.hasNext()) {
/* 026 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 027 */
/* 028 */       do {
/* 029 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 030 */         UTF8String inputadapter_value_0 = inputadapter_isNull_0 ?
/* 031 */         null : (inputadapter_row_0.getUTF8String(0));
/* 032 */
/* 033 */         boolean filter_isNull_0 = true;
/* 034 */         boolean filter_value_0 = false;
/* 035 */         boolean filter_isNull_2 = false;
/* 036 */         UTF8String filter_value_2 = null;
/* 037 */         if (inputadapter_isNull_0) {
/* 038 */           filter_isNull_2 = true;
/* 039 */         } else {
/* 040 */           filter_value_2 = inputadapter_value_0.trim();
/* 041 */         }
/* 042 */         boolean filter_isNull_1 = filter_isNull_2;
/* 043 */         int filter_value_1 = -1;
/* 044 */
/* 045 */         if (!filter_isNull_2) {
/* 046 */           filter_value_1 = (filter_value_2).numChars();
/* 047 */         }
/* 048 */         if (!filter_isNull_1) {
/* 049 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 050 */           filter_value_0 = filter_value_1 > 0;
/* 051 */
/* 052 */         }
/* 053 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 054 */
/* 055 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 056 */
/* 057 */         filter_mutableStateArray_0[0].reset();
/* 058 */
/* 059 */         filter_mutableStateArray_0[0].zeroOutNullBytes();
/* 060 */
/* 061 */         if (inputadapter_isNull_0) {
/* 062 */           filter_mutableStateArray_0[0].setNullAt(0);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[0].write(0, inputadapter_value_0);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[0].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }

2022-02-14 10:56:30 INFO  MemoryStore:57 - Block broadcast_4 stored as values in memory (estimated size 171.1 KiB, free 2.2 GiB)
2022-02-14 10:56:30 DEBUG BlockManager:61 - Put block broadcast_4 locally took 6 ms
2022-02-14 10:56:30 DEBUG BlockManager:61 - Putting block broadcast_4 without replication took 7 ms
2022-02-14 10:56:30 INFO  MemoryStore:57 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 23.9 KiB, free 2.2 GiB)
2022-02-14 10:56:30 INFO  BlockManagerInfo:57 - Added broadcast_4_piece0 in memory on Clairvoyant-320:60369 (size: 23.9 KiB, free: 2.2 GiB)
2022-02-14 10:56:30 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_4_piece0
2022-02-14 10:56:30 DEBUG BlockManager:61 - Told master about block broadcast_4_piece0
2022-02-14 10:56:30 DEBUG BlockManager:61 - Put block broadcast_4_piece0 locally took 7 ms
2022-02-14 10:56:30 DEBUG BlockManager:61 - Putting block broadcast_4_piece0 without replication took 9 ms
2022-02-14 10:56:30 INFO  SparkContext:57 - Created broadcast 4 from load at UsedCase5.java:16
2022-02-14 10:56:30 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4368551 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$executeTake$2
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$executeTake$2) is now cleaned +++
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$5
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2022-02-14 10:56:30 INFO  SparkContext:57 - Starting job: load at UsedCase5.java:16
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Got job 2 (load at UsedCase5.java:16) with 1 output partitions
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Final stage: ResultStage 2 (load at UsedCase5.java:16)
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Missing parents: List()
2022-02-14 10:56:30 DEBUG DAGScheduler:61 - submitStage(ResultStage 2 (name=load at UsedCase5.java:16;jobs=2))
2022-02-14 10:56:30 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Submitting ResultStage 2 (MapPartitionsRDD[13] at load at UsedCase5.java:16), which has no missing parents
2022-02-14 10:56:30 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 2)
2022-02-14 10:56:30 INFO  MemoryStore:57 - Block broadcast_5 stored as values in memory (estimated size 10.7 KiB, free 2.2 GiB)
2022-02-14 10:56:30 DEBUG BlockManager:61 - Put block broadcast_5 locally took 3 ms
2022-02-14 10:56:30 DEBUG BlockManager:61 - Putting block broadcast_5 without replication took 3 ms
2022-02-14 10:56:30 INFO  MemoryStore:57 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 2.2 GiB)
2022-02-14 10:56:30 INFO  BlockManagerInfo:57 - Added broadcast_5_piece0 in memory on Clairvoyant-320:60369 (size: 5.3 KiB, free: 2.2 GiB)
2022-02-14 10:56:30 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_5_piece0
2022-02-14 10:56:30 DEBUG BlockManager:61 - Told master about block broadcast_5_piece0
2022-02-14 10:56:30 DEBUG BlockManager:61 - Put block broadcast_5_piece0 locally took 4 ms
2022-02-14 10:56:30 DEBUG BlockManager:61 - Putting block broadcast_5_piece0 without replication took 4 ms
2022-02-14 10:56:30 INFO  SparkContext:57 - Created broadcast 5 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at load at UsedCase5.java:16) (first 15 tasks are for partitions Vector(0))
2022-02-14 10:56:30 INFO  TaskSchedulerImpl:57 - Adding task set 2.0 with 1 tasks
2022-02-14 10:56:30 DEBUG TaskSetManager:61 - Epoch for TaskSet 2.0: 0
2022-02-14 10:56:30 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-02-14 10:56:30 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 2.0: NO_PREF, ANY
2022-02-14 10:56:30 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_2.0, runningTasks: 0
2022-02-14 10:56:30 INFO  TaskSetManager:57 - Starting task 0.0 in stage 2.0 (TID 2, Clairvoyant-320, executor driver, partition 0, PROCESS_LOCAL, 7803 bytes)
2022-02-14 10:56:30 INFO  Executor:57 - Running task 0.0 in stage 2.0 (TID 2)
2022-02-14 10:56:30 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (2, 0) -> 1
2022-02-14 10:56:30 DEBUG BlockManager:61 - Getting local block broadcast_5
2022-02-14 10:56:30 DEBUG BlockManager:61 - Level for block broadcast_5 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:56:30 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/src/main/resources/retail_db/products/part-00000, range: 0-174247, partition values: [empty row]
2022-02-14 10:56:30 DEBUG GenerateUnsafeProjection:61 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-14 10:56:30 DEBUG BlockManager:61 - Getting local block broadcast_4
2022-02-14 10:56:30 DEBUG BlockManager:61 - Level for block broadcast_4 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:56:30 INFO  Executor:57 - Finished task 0.0 in stage 2.0 (TID 2). 1534 bytes result sent to driver
2022-02-14 10:56:30 DEBUG ExecutorMetricsPoller:61 - removing (2, 0) from stageTCMP
2022-02-14 10:56:30 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_2.0, runningTasks: 0
2022-02-14 10:56:30 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-14 10:56:30 INFO  TaskSetManager:57 - Finished task 0.0 in stage 2.0 (TID 2) in 29 ms on Clairvoyant-320 (executor driver) (1/1)
2022-02-14 10:56:30 INFO  TaskSchedulerImpl:57 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022-02-14 10:56:30 INFO  DAGScheduler:57 - ResultStage 2 (load at UsedCase5.java:16) finished in 0.052 s
2022-02-14 10:56:30 DEBUG DAGScheduler:61 - After removal of stage 2, remaining stages = 0
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2022-02-14 10:56:30 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 2: Stage finished
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Job 2 finished: load at UsedCase5.java:16, took 0.060799 s
2022-02-14 10:56:30 DEBUG GenerateSafeProjection:61 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-02-14 10:56:30 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-02-14 10:56:30 INFO  FileSourceStrategy:57 - Post-Scan Filters: 
2022-02-14 10:56:30 INFO  FileSourceStrategy:57 - Output Data Schema: struct<value: string>
2022-02-14 10:56:30 INFO  MemoryStore:57 - Block broadcast_6 stored as values in memory (estimated size 171.1 KiB, free 2.2 GiB)
2022-02-14 10:56:30 DEBUG BlockManager:61 - Put block broadcast_6 locally took 7 ms
2022-02-14 10:56:30 DEBUG BlockManager:61 - Putting block broadcast_6 without replication took 7 ms
2022-02-14 10:56:30 INFO  MemoryStore:57 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 23.9 KiB, free 2.2 GiB)
2022-02-14 10:56:30 INFO  BlockManagerInfo:57 - Added broadcast_6_piece0 in memory on Clairvoyant-320:60369 (size: 23.9 KiB, free: 2.2 GiB)
2022-02-14 10:56:30 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_6_piece0
2022-02-14 10:56:30 DEBUG BlockManager:61 - Told master about block broadcast_6_piece0
2022-02-14 10:56:30 DEBUG BlockManager:61 - Put block broadcast_6_piece0 locally took 5 ms
2022-02-14 10:56:30 DEBUG BlockManager:61 - Putting block broadcast_6_piece0 without replication took 6 ms
2022-02-14 10:56:30 INFO  SparkContext:57 - Created broadcast 6 from load at UsedCase5.java:16
2022-02-14 10:56:30 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4368551 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$rdd$1
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$rdd$1) is now cleaned +++
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$inferFromDataset$2
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$inferFromDataset$2) is now cleaned +++
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$infer$2
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$infer$2) is now cleaned +++
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$infer$3
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$infer$3) is now cleaned +++
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$6
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$6) is now cleaned +++
2022-02-14 10:56:30 INFO  SparkContext:57 - Starting job: load at UsedCase5.java:16
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Got job 3 (load at UsedCase5.java:16) with 1 output partitions
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Final stage: ResultStage 3 (load at UsedCase5.java:16)
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Missing parents: List()
2022-02-14 10:56:30 DEBUG DAGScheduler:61 - submitStage(ResultStage 3 (name=load at UsedCase5.java:16;jobs=3))
2022-02-14 10:56:30 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Submitting ResultStage 3 (MapPartitionsRDD[19] at load at UsedCase5.java:16), which has no missing parents
2022-02-14 10:56:30 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 3)
2022-02-14 10:56:30 INFO  MemoryStore:57 - Block broadcast_7 stored as values in memory (estimated size 15.2 KiB, free 2.2 GiB)
2022-02-14 10:56:30 DEBUG BlockManager:61 - Put block broadcast_7 locally took 2 ms
2022-02-14 10:56:30 DEBUG BlockManager:61 - Putting block broadcast_7 without replication took 2 ms
2022-02-14 10:56:30 INFO  MemoryStore:57 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 2.2 GiB)
2022-02-14 10:56:30 INFO  BlockManagerInfo:57 - Added broadcast_7_piece0 in memory on Clairvoyant-320:60369 (size: 7.6 KiB, free: 2.2 GiB)
2022-02-14 10:56:30 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_7_piece0
2022-02-14 10:56:30 DEBUG BlockManager:61 - Told master about block broadcast_7_piece0
2022-02-14 10:56:30 DEBUG BlockManager:61 - Put block broadcast_7_piece0 locally took 5 ms
2022-02-14 10:56:30 DEBUG BlockManager:61 - Putting block broadcast_7_piece0 without replication took 5 ms
2022-02-14 10:56:30 INFO  SparkContext:57 - Created broadcast 7 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[19] at load at UsedCase5.java:16) (first 15 tasks are for partitions Vector(0))
2022-02-14 10:56:30 INFO  TaskSchedulerImpl:57 - Adding task set 3.0 with 1 tasks
2022-02-14 10:56:30 DEBUG TaskSetManager:61 - Epoch for TaskSet 3.0: 0
2022-02-14 10:56:30 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-02-14 10:56:30 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 3.0: NO_PREF, ANY
2022-02-14 10:56:30 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_3.0, runningTasks: 0
2022-02-14 10:56:30 INFO  TaskSetManager:57 - Starting task 0.0 in stage 3.0 (TID 3, Clairvoyant-320, executor driver, partition 0, PROCESS_LOCAL, 7803 bytes)
2022-02-14 10:56:30 INFO  Executor:57 - Running task 0.0 in stage 3.0 (TID 3)
2022-02-14 10:56:30 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (3, 0) -> 1
2022-02-14 10:56:30 DEBUG BlockManager:61 - Getting local block broadcast_7
2022-02-14 10:56:30 DEBUG BlockManager:61 - Level for block broadcast_7 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:56:30 DEBUG GenerateSafeProjection:61 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-02-14 10:56:30 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/src/main/resources/retail_db/products/part-00000, range: 0-174247, partition values: [empty row]
2022-02-14 10:56:30 DEBUG GenerateUnsafeProjection:61 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-14 10:56:30 DEBUG BlockManager:61 - Getting local block broadcast_6
2022-02-14 10:56:30 DEBUG BlockManager:61 - Level for block broadcast_6 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:56:30 INFO  Executor:57 - Finished task 0.0 in stage 3.0 (TID 3). 1677 bytes result sent to driver
2022-02-14 10:56:30 DEBUG ExecutorMetricsPoller:61 - removing (3, 0) from stageTCMP
2022-02-14 10:56:30 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_3.0, runningTasks: 0
2022-02-14 10:56:30 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-14 10:56:30 INFO  TaskSetManager:57 - Finished task 0.0 in stage 3.0 (TID 3) in 118 ms on Clairvoyant-320 (executor driver) (1/1)
2022-02-14 10:56:30 INFO  TaskSchedulerImpl:57 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2022-02-14 10:56:30 INFO  DAGScheduler:57 - ResultStage 3 (load at UsedCase5.java:16) finished in 0.137 s
2022-02-14 10:56:30 DEBUG DAGScheduler:61 - After removal of stage 3, remaining stages = 0
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2022-02-14 10:56:30 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 3: Stage finished
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Job 3 finished: load at UsedCase5.java:16, took 0.143840 s
2022-02-14 10:56:30 DEBUG DataSource:61 - Some paths were ignored:
  
2022-02-14 10:56:30 INFO  InMemoryFileIndex:57 - It took 1 ms to list leaf files for 1 paths.
2022-02-14 10:56:30 INFO  InMemoryFileIndex:57 - It took 1 ms to list leaf files for 1 paths.
2022-02-14 10:56:30 DEBUG Analyzer$ResolveReferences:61 - Resolving 'value to value#48
2022-02-14 10:56:30 DEBUG Analyzer$ResolveReferences:61 - Resolving 'value to value#54
2022-02-14 10:56:30 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-02-14 10:56:30 INFO  FileSourceStrategy:57 - Post-Scan Filters: (length(trim(value#48, None)) > 0)
2022-02-14 10:56:30 INFO  FileSourceStrategy:57 - Output Data Schema: struct<value: string>
2022-02-14 10:56:30 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while ( inputadapter_input_0.hasNext()) {
/* 026 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 027 */
/* 028 */       do {
/* 029 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 030 */         UTF8String inputadapter_value_0 = inputadapter_isNull_0 ?
/* 031 */         null : (inputadapter_row_0.getUTF8String(0));
/* 032 */
/* 033 */         boolean filter_isNull_0 = true;
/* 034 */         boolean filter_value_0 = false;
/* 035 */         boolean filter_isNull_2 = false;
/* 036 */         UTF8String filter_value_2 = null;
/* 037 */         if (inputadapter_isNull_0) {
/* 038 */           filter_isNull_2 = true;
/* 039 */         } else {
/* 040 */           filter_value_2 = inputadapter_value_0.trim();
/* 041 */         }
/* 042 */         boolean filter_isNull_1 = filter_isNull_2;
/* 043 */         int filter_value_1 = -1;
/* 044 */
/* 045 */         if (!filter_isNull_2) {
/* 046 */           filter_value_1 = (filter_value_2).numChars();
/* 047 */         }
/* 048 */         if (!filter_isNull_1) {
/* 049 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 050 */           filter_value_0 = filter_value_1 > 0;
/* 051 */
/* 052 */         }
/* 053 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 054 */
/* 055 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 056 */
/* 057 */         filter_mutableStateArray_0[0].reset();
/* 058 */
/* 059 */         filter_mutableStateArray_0[0].zeroOutNullBytes();
/* 060 */
/* 061 */         if (inputadapter_isNull_0) {
/* 062 */           filter_mutableStateArray_0[0].setNullAt(0);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[0].write(0, inputadapter_value_0);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[0].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }

2022-02-14 10:56:30 INFO  MemoryStore:57 - Block broadcast_8 stored as values in memory (estimated size 171.1 KiB, free 2.2 GiB)
2022-02-14 10:56:30 DEBUG BlockManager:61 - Put block broadcast_8 locally took 6 ms
2022-02-14 10:56:30 DEBUG BlockManager:61 - Putting block broadcast_8 without replication took 7 ms
2022-02-14 10:56:30 INFO  MemoryStore:57 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 23.9 KiB, free 2.2 GiB)
2022-02-14 10:56:30 INFO  BlockManagerInfo:57 - Added broadcast_8_piece0 in memory on Clairvoyant-320:60369 (size: 23.9 KiB, free: 2.2 GiB)
2022-02-14 10:56:30 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_8_piece0
2022-02-14 10:56:30 DEBUG BlockManager:61 - Told master about block broadcast_8_piece0
2022-02-14 10:56:30 DEBUG BlockManager:61 - Put block broadcast_8_piece0 locally took 6 ms
2022-02-14 10:56:30 DEBUG BlockManager:61 - Putting block broadcast_8_piece0 without replication took 6 ms
2022-02-14 10:56:30 INFO  SparkContext:57 - Created broadcast 8 from load at UsedCase5.java:19
2022-02-14 10:56:30 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4195382 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$executeTake$2
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$executeTake$2) is now cleaned +++
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$5
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2022-02-14 10:56:30 INFO  SparkContext:57 - Starting job: load at UsedCase5.java:19
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Got job 4 (load at UsedCase5.java:19) with 1 output partitions
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Final stage: ResultStage 4 (load at UsedCase5.java:19)
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Missing parents: List()
2022-02-14 10:56:30 DEBUG DAGScheduler:61 - submitStage(ResultStage 4 (name=load at UsedCase5.java:19;jobs=4))
2022-02-14 10:56:30 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Submitting ResultStage 4 (MapPartitionsRDD[23] at load at UsedCase5.java:19), which has no missing parents
2022-02-14 10:56:30 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 4)
2022-02-14 10:56:30 INFO  MemoryStore:57 - Block broadcast_9 stored as values in memory (estimated size 10.7 KiB, free 2.2 GiB)
2022-02-14 10:56:30 DEBUG BlockManager:61 - Put block broadcast_9 locally took 3 ms
2022-02-14 10:56:30 DEBUG BlockManager:61 - Putting block broadcast_9 without replication took 3 ms
2022-02-14 10:56:30 INFO  MemoryStore:57 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 2.2 GiB)
2022-02-14 10:56:30 INFO  BlockManagerInfo:57 - Added broadcast_9_piece0 in memory on Clairvoyant-320:60369 (size: 5.3 KiB, free: 2.2 GiB)
2022-02-14 10:56:30 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_9_piece0
2022-02-14 10:56:30 DEBUG BlockManager:61 - Told master about block broadcast_9_piece0
2022-02-14 10:56:30 DEBUG BlockManager:61 - Put block broadcast_9_piece0 locally took 5 ms
2022-02-14 10:56:30 DEBUG BlockManager:61 - Putting block broadcast_9_piece0 without replication took 5 ms
2022-02-14 10:56:30 INFO  SparkContext:57 - Created broadcast 9 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at load at UsedCase5.java:19) (first 15 tasks are for partitions Vector(0))
2022-02-14 10:56:30 INFO  TaskSchedulerImpl:57 - Adding task set 4.0 with 1 tasks
2022-02-14 10:56:30 DEBUG TaskSetManager:61 - Epoch for TaskSet 4.0: 0
2022-02-14 10:56:30 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-02-14 10:56:30 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 4.0: NO_PREF, ANY
2022-02-14 10:56:30 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_4.0, runningTasks: 0
2022-02-14 10:56:30 INFO  TaskSetManager:57 - Starting task 0.0 in stage 4.0 (TID 4, Clairvoyant-320, executor driver, partition 0, PROCESS_LOCAL, 7805 bytes)
2022-02-14 10:56:30 INFO  Executor:57 - Running task 0.0 in stage 4.0 (TID 4)
2022-02-14 10:56:30 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (4, 0) -> 1
2022-02-14 10:56:30 DEBUG BlockManager:61 - Getting local block broadcast_9
2022-02-14 10:56:30 DEBUG BlockManager:61 - Level for block broadcast_9 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:56:30 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/src/main/resources/retail_db/categories/part-00000, range: 0-1078, partition values: [empty row]
2022-02-14 10:56:30 DEBUG GenerateUnsafeProjection:61 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-14 10:56:30 DEBUG BlockManager:61 - Getting local block broadcast_8
2022-02-14 10:56:30 DEBUG BlockManager:61 - Level for block broadcast_8 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:56:30 INFO  Executor:57 - Finished task 0.0 in stage 4.0 (TID 4). 1505 bytes result sent to driver
2022-02-14 10:56:30 DEBUG ExecutorMetricsPoller:61 - removing (4, 0) from stageTCMP
2022-02-14 10:56:30 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_4.0, runningTasks: 0
2022-02-14 10:56:30 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-14 10:56:30 INFO  TaskSetManager:57 - Finished task 0.0 in stage 4.0 (TID 4) in 19 ms on Clairvoyant-320 (executor driver) (1/1)
2022-02-14 10:56:30 INFO  TaskSchedulerImpl:57 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2022-02-14 10:56:30 INFO  DAGScheduler:57 - ResultStage 4 (load at UsedCase5.java:19) finished in 0.033 s
2022-02-14 10:56:30 DEBUG DAGScheduler:61 - After removal of stage 4, remaining stages = 0
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2022-02-14 10:56:30 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 4: Stage finished
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Job 4 finished: load at UsedCase5.java:19, took 0.041330 s
2022-02-14 10:56:30 DEBUG GenerateSafeProjection:61 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-02-14 10:56:30 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-02-14 10:56:30 INFO  FileSourceStrategy:57 - Post-Scan Filters: 
2022-02-14 10:56:30 INFO  FileSourceStrategy:57 - Output Data Schema: struct<value: string>
2022-02-14 10:56:30 INFO  MemoryStore:57 - Block broadcast_10 stored as values in memory (estimated size 171.1 KiB, free 2.2 GiB)
2022-02-14 10:56:30 DEBUG BlockManager:61 - Put block broadcast_10 locally took 5 ms
2022-02-14 10:56:30 DEBUG BlockManager:61 - Putting block broadcast_10 without replication took 5 ms
2022-02-14 10:56:30 INFO  MemoryStore:57 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 23.9 KiB, free 2.2 GiB)
2022-02-14 10:56:30 INFO  BlockManagerInfo:57 - Added broadcast_10_piece0 in memory on Clairvoyant-320:60369 (size: 23.9 KiB, free: 2.2 GiB)
2022-02-14 10:56:30 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_10_piece0
2022-02-14 10:56:30 DEBUG BlockManager:61 - Told master about block broadcast_10_piece0
2022-02-14 10:56:30 DEBUG BlockManager:61 - Put block broadcast_10_piece0 locally took 5 ms
2022-02-14 10:56:30 DEBUG BlockManager:61 - Putting block broadcast_10_piece0 without replication took 5 ms
2022-02-14 10:56:30 INFO  SparkContext:57 - Created broadcast 10 from load at UsedCase5.java:19
2022-02-14 10:56:30 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4195382 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$rdd$1
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$rdd$1) is now cleaned +++
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$inferFromDataset$2
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$inferFromDataset$2) is now cleaned +++
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$infer$2
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$infer$2) is now cleaned +++
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$infer$3
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$infer$3) is now cleaned +++
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$6
2022-02-14 10:56:30 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$6) is now cleaned +++
2022-02-14 10:56:30 INFO  SparkContext:57 - Starting job: load at UsedCase5.java:19
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Got job 5 (load at UsedCase5.java:19) with 1 output partitions
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Final stage: ResultStage 5 (load at UsedCase5.java:19)
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Missing parents: List()
2022-02-14 10:56:30 DEBUG DAGScheduler:61 - submitStage(ResultStage 5 (name=load at UsedCase5.java:19;jobs=5))
2022-02-14 10:56:30 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Submitting ResultStage 5 (MapPartitionsRDD[29] at load at UsedCase5.java:19), which has no missing parents
2022-02-14 10:56:30 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 5)
2022-02-14 10:56:30 INFO  MemoryStore:57 - Block broadcast_11 stored as values in memory (estimated size 15.1 KiB, free 2.2 GiB)
2022-02-14 10:56:30 DEBUG BlockManager:61 - Put block broadcast_11 locally took 3 ms
2022-02-14 10:56:30 DEBUG BlockManager:61 - Putting block broadcast_11 without replication took 3 ms
2022-02-14 10:56:30 INFO  MemoryStore:57 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 2.2 GiB)
2022-02-14 10:56:30 INFO  BlockManagerInfo:57 - Added broadcast_11_piece0 in memory on Clairvoyant-320:60369 (size: 7.6 KiB, free: 2.2 GiB)
2022-02-14 10:56:30 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_11_piece0
2022-02-14 10:56:30 DEBUG BlockManager:61 - Told master about block broadcast_11_piece0
2022-02-14 10:56:30 DEBUG BlockManager:61 - Put block broadcast_11_piece0 locally took 3 ms
2022-02-14 10:56:30 DEBUG BlockManager:61 - Putting block broadcast_11_piece0 without replication took 3 ms
2022-02-14 10:56:30 INFO  SparkContext:57 - Created broadcast 11 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:56:30 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at load at UsedCase5.java:19) (first 15 tasks are for partitions Vector(0))
2022-02-14 10:56:30 INFO  TaskSchedulerImpl:57 - Adding task set 5.0 with 1 tasks
2022-02-14 10:56:30 DEBUG TaskSetManager:61 - Epoch for TaskSet 5.0: 0
2022-02-14 10:56:30 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-02-14 10:56:30 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 5.0: NO_PREF, ANY
2022-02-14 10:56:30 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_5.0, runningTasks: 0
2022-02-14 10:56:30 INFO  TaskSetManager:57 - Starting task 0.0 in stage 5.0 (TID 5, Clairvoyant-320, executor driver, partition 0, PROCESS_LOCAL, 7805 bytes)
2022-02-14 10:56:30 INFO  Executor:57 - Running task 0.0 in stage 5.0 (TID 5)
2022-02-14 10:56:30 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (5, 0) -> 1
2022-02-14 10:56:30 DEBUG BlockManager:61 - Getting local block broadcast_11
2022-02-14 10:56:30 DEBUG BlockManager:61 - Level for block broadcast_11 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:56:30 DEBUG GenerateSafeProjection:61 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-02-14 10:56:30 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/src/main/resources/retail_db/categories/part-00000, range: 0-1078, partition values: [empty row]
2022-02-14 10:56:30 DEBUG GenerateUnsafeProjection:61 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-14 10:56:30 DEBUG BlockManager:61 - Getting local block broadcast_10
2022-02-14 10:56:30 DEBUG BlockManager:61 - Level for block broadcast_10 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:56:31 INFO  Executor:57 - Finished task 0.0 in stage 5.0 (TID 5). 1518 bytes result sent to driver
2022-02-14 10:56:31 DEBUG ExecutorMetricsPoller:61 - removing (5, 0) from stageTCMP
2022-02-14 10:56:31 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_5.0, runningTasks: 0
2022-02-14 10:56:31 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-14 10:56:31 INFO  TaskSetManager:57 - Finished task 0.0 in stage 5.0 (TID 5) in 31 ms on Clairvoyant-320 (executor driver) (1/1)
2022-02-14 10:56:31 INFO  TaskSchedulerImpl:57 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2022-02-14 10:56:31 INFO  DAGScheduler:57 - ResultStage 5 (load at UsedCase5.java:19) finished in 0.049 s
2022-02-14 10:56:31 DEBUG DAGScheduler:61 - After removal of stage 5, remaining stages = 0
2022-02-14 10:56:31 INFO  DAGScheduler:57 - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2022-02-14 10:56:31 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 5: Stage finished
2022-02-14 10:56:31 INFO  DAGScheduler:57 - Job 5 finished: load at UsedCase5.java:19, took 0.055721 s
2022-02-14 10:56:31 DEBUG SparkSqlParser:61 - Parsing command: departments
2022-02-14 10:56:31 DEBUG SparkSqlParser:61 - Parsing command: products
2022-02-14 10:56:31 DEBUG SparkSqlParser:61 - Parsing command: categories
2022-02-14 10:56:31 DEBUG SparkSqlParser:61 - Parsing command: SELECT d.department_id,d.department_name,count(*) as product_count
from departments d join categories c
     on d.department_id=c.category_department_id
     join products p
     on p.product_category_id=c.category_id
WHERE p.product_category_id=c.category_id
group by d.department_id,d.department_name
order by  d.department_id
2022-02-14 10:56:31 DEBUG Analyzer$ResolveReferences:61 - Resolving 'd.department_id to department_id#16
2022-02-14 10:56:31 DEBUG Analyzer$ResolveReferences:61 - Resolving 'c.category_department_id to category_department_id#65
2022-02-14 10:56:31 DEBUG Analyzer$ResolveReferences:61 - Resolving 'p.product_category_id to product_category_id#37
2022-02-14 10:56:31 DEBUG Analyzer$ResolveReferences:61 - Resolving 'c.category_id to category_id#64
2022-02-14 10:56:31 DEBUG Analyzer$ResolveReferences:61 - Resolving 'p.product_category_id to product_category_id#37
2022-02-14 10:56:31 DEBUG Analyzer$ResolveReferences:61 - Resolving 'c.category_id to category_id#64
2022-02-14 10:56:31 DEBUG Analyzer$ResolveReferences:61 - Resolving 'd.department_id to department_id#16
2022-02-14 10:56:31 DEBUG Analyzer$ResolveReferences:61 - Resolving 'd.department_name to department_name#17
2022-02-14 10:56:31 DEBUG Analyzer$ResolveReferences:61 - Resolving 'd.department_id to department_id#16
2022-02-14 10:56:31 DEBUG Analyzer$ResolveReferences:61 - Resolving 'd.department_name to department_name#17
2022-02-14 10:56:31 DEBUG Analyzer$ResolveReferences:61 - Resolving 'd.department_id to department_id#16
2022-02-14 10:56:31 DEBUG ExtractEquiJoinKeys:61 - Considering join on: Some((product_category_id#37 = category_id#64))
2022-02-14 10:56:31 DEBUG ExtractEquiJoinKeys:61 - leftKeys:List(category_id#64) | rightKeys:List(product_category_id#37)
2022-02-14 10:56:31 DEBUG ExtractEquiJoinKeys:61 - Considering join on: Some((department_id#16 = category_department_id#65))
2022-02-14 10:56:31 DEBUG ExtractEquiJoinKeys:61 - leftKeys:List(department_id#16) | rightKeys:List(category_department_id#65)
2022-02-14 10:56:31 DEBUG ExtractEquiJoinKeys:61 - Considering join on: Some((department_id#16 = category_department_id#65))
2022-02-14 10:56:31 DEBUG ExtractEquiJoinKeys:61 - leftKeys:List(department_id#16) | rightKeys:List(category_department_id#65)
2022-02-14 10:56:31 DEBUG ExtractEquiJoinKeys:61 - Considering join on: Some((product_category_id#37 = category_id#64))
2022-02-14 10:56:31 DEBUG ExtractEquiJoinKeys:61 - leftKeys:List(category_id#64) | rightKeys:List(product_category_id#37)
2022-02-14 10:56:31 DEBUG ExtractEquiJoinKeys:61 - Considering join on: Some((product_category_id#37 = category_id#64))
2022-02-14 10:56:31 DEBUG ExtractEquiJoinKeys:61 - leftKeys:List(category_id#64) | rightKeys:List(product_category_id#37)
2022-02-14 10:56:31 DEBUG ExtractEquiJoinKeys:61 - Considering join on: Some((product_category_id#37 = category_id#64))
2022-02-14 10:56:31 DEBUG ExtractEquiJoinKeys:61 - leftKeys:List(category_id#64) | rightKeys:List(product_category_id#37)
2022-02-14 10:56:31 DEBUG ExtractEquiJoinKeys:61 - Considering join on: Some((department_id#16 = category_department_id#65))
2022-02-14 10:56:31 DEBUG ExtractEquiJoinKeys:61 - leftKeys:List(department_id#16) | rightKeys:List(category_department_id#65)
2022-02-14 10:56:31 DEBUG ExtractEquiJoinKeys:61 - Considering join on: Some((department_id#16 = category_department_id#65))
2022-02-14 10:56:31 DEBUG ExtractEquiJoinKeys:61 - leftKeys:List(department_id#16) | rightKeys:List(category_department_id#65)
2022-02-14 10:56:31 INFO  FileSourceStrategy:57 - Pushed Filters: IsNotNull(department_id)
2022-02-14 10:56:31 INFO  FileSourceStrategy:57 - Post-Scan Filters: isnotnull(department_id#16)
2022-02-14 10:56:31 INFO  FileSourceStrategy:57 - Output Data Schema: struct<department_id: int, department_name: string>
2022-02-14 10:56:31 INFO  FileSourceStrategy:57 - Pushed Filters: IsNotNull(category_department_id),IsNotNull(category_id)
2022-02-14 10:56:31 INFO  FileSourceStrategy:57 - Post-Scan Filters: isnotnull(category_department_id#65),isnotnull(category_id#64)
2022-02-14 10:56:31 INFO  FileSourceStrategy:57 - Output Data Schema: struct<category_id: int, category_department_id: int>
2022-02-14 10:56:31 INFO  FileSourceStrategy:57 - Pushed Filters: IsNotNull(product_category_id)
2022-02-14 10:56:31 INFO  FileSourceStrategy:57 - Post-Scan Filters: isnotnull(product_category_id#37)
2022-02-14 10:56:31 INFO  FileSourceStrategy:57 - Output Data Schema: struct<product_category_id: int>
2022-02-14 10:56:31 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 021 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   protected void processNext() throws java.io.IOException {
/* 026 */     while ( inputadapter_input_0.hasNext()) {
/* 027 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 028 */
/* 029 */       do {
/* 030 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 031 */         int inputadapter_value_0 = inputadapter_isNull_0 ?
/* 032 */         -1 : (inputadapter_row_0.getInt(0));
/* 033 */
/* 034 */         boolean filter_value_2 = !inputadapter_isNull_0;
/* 035 */         if (!filter_value_2) continue;
/* 036 */
/* 037 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 038 */
/* 039 */         boolean inputadapter_isNull_1 = inputadapter_row_0.isNullAt(1);
/* 040 */         UTF8String inputadapter_value_1 = inputadapter_isNull_1 ?
/* 041 */         null : (inputadapter_row_0.getUTF8String(1));
/* 042 */         filter_mutableStateArray_0[1].reset();
/* 043 */
/* 044 */         filter_mutableStateArray_0[1].zeroOutNullBytes();
/* 045 */
/* 046 */         if (false) {
/* 047 */           filter_mutableStateArray_0[1].setNullAt(0);
/* 048 */         } else {
/* 049 */           filter_mutableStateArray_0[1].write(0, inputadapter_value_0);
/* 050 */         }
/* 051 */
/* 052 */         if (inputadapter_isNull_1) {
/* 053 */           filter_mutableStateArray_0[1].setNullAt(1);
/* 054 */         } else {
/* 055 */           filter_mutableStateArray_0[1].write(1, inputadapter_value_1);
/* 056 */         }
/* 057 */         append((filter_mutableStateArray_0[1].getRow()));
/* 058 */
/* 059 */       } while(false);
/* 060 */       if (shouldStop()) return;
/* 061 */     }
/* 062 */   }
/* 063 */
/* 064 */ }

2022-02-14 10:56:31 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage2(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=2
/* 006 */ final class GeneratedIteratorForCodegenStage2 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage2(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 021 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   protected void processNext() throws java.io.IOException {
/* 026 */     while ( inputadapter_input_0.hasNext()) {
/* 027 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 028 */
/* 029 */       do {
/* 030 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 031 */         int inputadapter_value_0 = inputadapter_isNull_0 ?
/* 032 */         -1 : (inputadapter_row_0.getInt(0));
/* 033 */
/* 034 */         boolean filter_value_2 = !inputadapter_isNull_0;
/* 035 */         if (!filter_value_2) continue;
/* 036 */
/* 037 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 038 */
/* 039 */         filter_mutableStateArray_0[1].reset();
/* 040 */
/* 041 */         if (false) {
/* 042 */           filter_mutableStateArray_0[1].setNullAt(0);
/* 043 */         } else {
/* 044 */           filter_mutableStateArray_0[1].write(0, inputadapter_value_0);
/* 045 */         }
/* 046 */         append((filter_mutableStateArray_0[1].getRow()));
/* 047 */
/* 048 */       } while(false);
/* 049 */       if (shouldStop()) return;
/* 050 */     }
/* 051 */   }
/* 052 */
/* 053 */ }

2022-02-14 10:56:31 DEBUG CodeGenerator:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage2(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=2
/* 006 */ final class GeneratedIteratorForCodegenStage2 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage2(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 021 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   protected void processNext() throws java.io.IOException {
/* 026 */     while ( inputadapter_input_0.hasNext()) {
/* 027 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 028 */
/* 029 */       do {
/* 030 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 031 */         int inputadapter_value_0 = inputadapter_isNull_0 ?
/* 032 */         -1 : (inputadapter_row_0.getInt(0));
/* 033 */
/* 034 */         boolean filter_value_2 = !inputadapter_isNull_0;
/* 035 */         if (!filter_value_2) continue;
/* 036 */
/* 037 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 038 */
/* 039 */         filter_mutableStateArray_0[1].reset();
/* 040 */
/* 041 */         if (false) {
/* 042 */           filter_mutableStateArray_0[1].setNullAt(0);
/* 043 */         } else {
/* 044 */           filter_mutableStateArray_0[1].write(0, inputadapter_value_0);
/* 045 */         }
/* 046 */         append((filter_mutableStateArray_0[1].getRow()));
/* 047 */
/* 048 */       } while(false);
/* 049 */       if (shouldStop()) return;
/* 050 */     }
/* 051 */   }
/* 052 */
/* 053 */ }

2022-02-14 10:56:31 DEBUG CodeGenerator:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 021 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   protected void processNext() throws java.io.IOException {
/* 026 */     while ( inputadapter_input_0.hasNext()) {
/* 027 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 028 */
/* 029 */       do {
/* 030 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 031 */         int inputadapter_value_0 = inputadapter_isNull_0 ?
/* 032 */         -1 : (inputadapter_row_0.getInt(0));
/* 033 */
/* 034 */         boolean filter_value_2 = !inputadapter_isNull_0;
/* 035 */         if (!filter_value_2) continue;
/* 036 */
/* 037 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 038 */
/* 039 */         boolean inputadapter_isNull_1 = inputadapter_row_0.isNullAt(1);
/* 040 */         UTF8String inputadapter_value_1 = inputadapter_isNull_1 ?
/* 041 */         null : (inputadapter_row_0.getUTF8String(1));
/* 042 */         filter_mutableStateArray_0[1].reset();
/* 043 */
/* 044 */         filter_mutableStateArray_0[1].zeroOutNullBytes();
/* 045 */
/* 046 */         if (false) {
/* 047 */           filter_mutableStateArray_0[1].setNullAt(0);
/* 048 */         } else {
/* 049 */           filter_mutableStateArray_0[1].write(0, inputadapter_value_0);
/* 050 */         }
/* 051 */
/* 052 */         if (inputadapter_isNull_1) {
/* 053 */           filter_mutableStateArray_0[1].setNullAt(1);
/* 054 */         } else {
/* 055 */           filter_mutableStateArray_0[1].write(1, inputadapter_value_1);
/* 056 */         }
/* 057 */         append((filter_mutableStateArray_0[1].getRow()));
/* 058 */
/* 059 */       } while(false);
/* 060 */       if (shouldStop()) return;
/* 061 */     }
/* 062 */   }
/* 063 */
/* 064 */ }

2022-02-14 10:56:31 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(217)
2022-02-14 10:56:31 DEBUG ContextCleaner:61 - Cleaning accumulator 217
2022-02-14 10:56:31 INFO  CodeGenerator:57 - Code generated in 50.657899 ms
2022-02-14 10:56:31 INFO  CodeGenerator:57 - Code generated in 53.753799 ms
2022-02-14 10:56:31 DEBUG ContextCleaner:61 - Cleaned accumulator 217
2022-02-14 10:56:31 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(18)
2022-02-14 10:56:31 DEBUG ContextCleaner:61 - Cleaning accumulator 18
2022-02-14 10:56:31 DEBUG ContextCleaner:61 - Cleaned accumulator 18
2022-02-14 10:56:31 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(176)
2022-02-14 10:56:31 DEBUG ContextCleaner:61 - Cleaning accumulator 176
2022-02-14 10:56:31 DEBUG ContextCleaner:61 - Cleaned accumulator 176
2022-02-14 10:56:31 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(170)
2022-02-14 10:56:31 DEBUG ContextCleaner:61 - Cleaning accumulator 170
2022-02-14 10:56:31 DEBUG ContextCleaner:61 - Cleaned accumulator 170
2022-02-14 10:56:31 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(185)
2022-02-14 10:56:31 DEBUG ContextCleaner:61 - Cleaning accumulator 185
2022-02-14 10:56:31 DEBUG ContextCleaner:61 - Cleaned accumulator 185
2022-02-14 10:56:31 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(165)
2022-02-14 10:56:31 DEBUG ContextCleaner:61 - Cleaning accumulator 165
2022-02-14 10:56:31 DEBUG ContextCleaner:61 - Cleaned accumulator 165
2022-02-14 10:56:31 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(197)
2022-02-14 10:56:31 DEBUG ContextCleaner:61 - Cleaning accumulator 197
2022-02-14 10:56:31 INFO  MemoryStore:57 - Block broadcast_12 stored as values in memory (estimated size 170.9 KiB, free 2.2 GiB)
2022-02-14 10:56:32 INFO  MemoryStore:57 - Block broadcast_13 stored as values in memory (estimated size 170.9 KiB, free 2.2 GiB)
2022-02-14 10:56:31 DEBUG ContextCleaner:61 - Cleaned accumulator 197
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(132)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 132
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 132
2022-02-14 10:56:32 DEBUG BlockManager:61 - Put block broadcast_12 locally took 12 ms
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(77)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 77
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 77
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(8)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 8
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 8
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(12)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 12
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 12
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(0)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning broadcast 0
2022-02-14 10:56:32 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Putting block broadcast_12 without replication took 13 ms
2022-02-14 10:56:32 DEBUG BlockManager:61 - Put block broadcast_13 locally took 15 ms
2022-02-14 10:56:32 DEBUG BlockManager:61 - Putting block broadcast_13 without replication took 15 ms
2022-02-14 10:56:32 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage5(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=5
/* 006 */ final class GeneratedIteratorForCodegenStage5 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private boolean agg_bufIsNull_0;
/* 011 */   private long agg_bufValue_0;
/* 012 */   private scala.collection.Iterator inputadapter_input_0;
/* 013 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 014 */
/* 015 */   public GeneratedIteratorForCodegenStage5(Object[] references) {
/* 016 */     this.references = references;
/* 017 */   }
/* 018 */
/* 019 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 020 */     partitionIndex = index;
/* 021 */     this.inputs = inputs;
/* 022 */
/* 023 */     inputadapter_input_0 = inputs[0];
/* 024 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 025 */
/* 026 */   }
/* 027 */
/* 028 */   private void agg_doAggregateWithoutKey_0() throws java.io.IOException {
/* 029 */     // initialize aggregation buffer
/* 030 */     agg_bufIsNull_0 = false;
/* 031 */     agg_bufValue_0 = 0L;
/* 032 */
/* 033 */     while ( inputadapter_input_0.hasNext()) {
/* 034 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 035 */
/* 036 */       long inputadapter_value_0 = inputadapter_row_0.getLong(0);
/* 037 */
/* 038 */       agg_doConsume_0(inputadapter_row_0, inputadapter_value_0);
/* 039 */       // shouldStop check is eliminated
/* 040 */     }
/* 041 */
/* 042 */   }
/* 043 */
/* 044 */   private void agg_doConsume_0(InternalRow inputadapter_row_0, long agg_expr_0_0) throws java.io.IOException {
/* 045 */     // do aggregate
/* 046 */     // common sub-expressions
/* 047 */
/* 048 */     // evaluate aggregate functions and update aggregation buffers
/* 049 */
/* 050 */     long agg_value_3 = -1L;
/* 051 */
/* 052 */     agg_value_3 = agg_bufValue_0 + agg_expr_0_0;
/* 053 */
/* 054 */     agg_bufIsNull_0 = false;
/* 055 */     agg_bufValue_0 = agg_value_3;
/* 056 */
/* 057 */   }
/* 058 */
/* 059 */   protected void processNext() throws java.io.IOException {
/* 060 */     while (!agg_initAgg_0) {
/* 061 */       agg_initAgg_0 = true;
/* 062 */       long agg_beforeAgg_0 = System.nanoTime();
/* 063 */       agg_doAggregateWithoutKey_0();
/* 064 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_0) / 1000000);
/* 065 */
/* 066 */       // output the result
/* 067 */
/* 068 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 069 */       agg_mutableStateArray_0[0].reset();
/* 070 */
/* 071 */       agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 072 */
/* 073 */       agg_mutableStateArray_0[0].write(0, agg_bufValue_0);
/* 074 */       append((agg_mutableStateArray_0[0].getRow()));
/* 075 */     }
/* 076 */   }
/* 077 */
/* 078 */ }

2022-02-14 10:56:32 DEBUG CodeGenerator:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage5(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=5
/* 006 */ final class GeneratedIteratorForCodegenStage5 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private boolean agg_bufIsNull_0;
/* 011 */   private long agg_bufValue_0;
/* 012 */   private scala.collection.Iterator inputadapter_input_0;
/* 013 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 014 */
/* 015 */   public GeneratedIteratorForCodegenStage5(Object[] references) {
/* 016 */     this.references = references;
/* 017 */   }
/* 018 */
/* 019 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 020 */     partitionIndex = index;
/* 021 */     this.inputs = inputs;
/* 022 */
/* 023 */     inputadapter_input_0 = inputs[0];
/* 024 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 025 */
/* 026 */   }
/* 027 */
/* 028 */   private void agg_doAggregateWithoutKey_0() throws java.io.IOException {
/* 029 */     // initialize aggregation buffer
/* 030 */     agg_bufIsNull_0 = false;
/* 031 */     agg_bufValue_0 = 0L;
/* 032 */
/* 033 */     while ( inputadapter_input_0.hasNext()) {
/* 034 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 035 */
/* 036 */       long inputadapter_value_0 = inputadapter_row_0.getLong(0);
/* 037 */
/* 038 */       agg_doConsume_0(inputadapter_row_0, inputadapter_value_0);
/* 039 */       // shouldStop check is eliminated
/* 040 */     }
/* 041 */
/* 042 */   }
/* 043 */
/* 044 */   private void agg_doConsume_0(InternalRow inputadapter_row_0, long agg_expr_0_0) throws java.io.IOException {
/* 045 */     // do aggregate
/* 046 */     // common sub-expressions
/* 047 */
/* 048 */     // evaluate aggregate functions and update aggregation buffers
/* 049 */
/* 050 */     long agg_value_3 = -1L;
/* 051 */
/* 052 */     agg_value_3 = agg_bufValue_0 + agg_expr_0_0;
/* 053 */
/* 054 */     agg_bufIsNull_0 = false;
/* 055 */     agg_bufValue_0 = agg_value_3;
/* 056 */
/* 057 */   }
/* 058 */
/* 059 */   protected void processNext() throws java.io.IOException {
/* 060 */     while (!agg_initAgg_0) {
/* 061 */       agg_initAgg_0 = true;
/* 062 */       long agg_beforeAgg_0 = System.nanoTime();
/* 063 */       agg_doAggregateWithoutKey_0();
/* 064 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_0) / 1000000);
/* 065 */
/* 066 */       // output the result
/* 067 */
/* 068 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 069 */       agg_mutableStateArray_0[0].reset();
/* 070 */
/* 071 */       agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 072 */
/* 073 */       agg_mutableStateArray_0[0].write(0, agg_bufValue_0);
/* 074 */       append((agg_mutableStateArray_0[0].getRow()));
/* 075 */     }
/* 076 */   }
/* 077 */
/* 078 */ }

2022-02-14 10:56:32 INFO  MemoryStore:57 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 23.9 KiB, free 2.2 GiB)
2022-02-14 10:56:32 INFO  MemoryStore:57 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 23.9 KiB, free 2.2 GiB)
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 0
2022-02-14 10:56:32 INFO  BlockManagerInfo:57 - Added broadcast_12_piece0 in memory on Clairvoyant-320:60369 (size: 23.9 KiB, free: 2.2 GiB)
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing broadcast 0
2022-02-14 10:56:32 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_12_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Told master about block broadcast_12_piece0
2022-02-14 10:56:32 INFO  CodeGenerator:57 - Code generated in 35.165299 ms
2022-02-14 10:56:32 DEBUG BlockManager:61 - Put block broadcast_12_piece0 locally took 8 ms
2022-02-14 10:56:32 DEBUG BlockManager:61 - Putting block broadcast_12_piece0 without replication took 8 ms
2022-02-14 10:56:32 INFO  SparkContext:57 - Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing block broadcast_0_piece0
2022-02-14 10:56:32 INFO  BlockManagerInfo:57 - Added broadcast_13_piece0 in memory on Clairvoyant-320:60369 (size: 23.9 KiB, free: 2.2 GiB)
2022-02-14 10:56:32 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_13_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Told master about block broadcast_13_piece0
2022-02-14 10:56:32 DEBUG MemoryStore:61 - Block broadcast_0_piece0 of size 24515 dropped from memory (free 2346279607)
2022-02-14 10:56:32 DEBUG BlockManager:61 - Put block broadcast_13_piece0 locally took 17 ms
2022-02-14 10:56:32 DEBUG BlockManager:61 - Putting block broadcast_13_piece0 without replication took 18 ms
2022-02-14 10:56:32 INFO  SparkContext:57 - Created broadcast 13 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
2022-02-14 10:56:32 INFO  BlockManagerInfo:57 - Removed broadcast_0_piece0 on Clairvoyant-320:60369 in memory (size: 23.9 KiB, free: 2.2 GiB)
2022-02-14 10:56:32 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4368551 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-14 10:56:32 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4194394 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-14 10:56:32 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_0_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Told master about block broadcast_0_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing block broadcast_0
2022-02-14 10:56:32 DEBUG MemoryStore:61 - Block broadcast_0 of size 175184 dropped from memory (free 2346454791)
2022-02-14 10:56:32 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-02-14 10:56:32 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 0, response is 0
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60354
2022-02-14 10:56:32 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-02-14 10:56:32 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-02-14 10:56:32 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$collect$2
2022-02-14 10:56:32 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$collect$2
2022-02-14 10:56:32 INFO  HashAggregateExec:57 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned broadcast 0
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(3)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 3
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 3
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(82)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 82
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 82
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(142)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 142
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 142
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(17)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 17
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 17
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(61)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 61
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 61
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(125)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 125
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 125
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(228)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 228
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 228
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(47)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 47
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 47
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(48)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 48
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 48
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(119)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 119
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 119
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(168)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 168
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 168
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(6)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 6
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 6
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(121)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 121
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 121
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(192)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 192
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 192
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(220)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 220
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 220
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(180)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 180
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 180
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(42)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 42
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 42
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(2)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning broadcast 2
2022-02-14 10:56:32 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 2
2022-02-14 10:56:32 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$collect$2) is now cleaned +++
2022-02-14 10:56:32 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$collect$2) is now cleaned +++
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 2
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing broadcast 2
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing block broadcast_2
2022-02-14 10:56:32 DEBUG MemoryStore:61 - Block broadcast_2 of size 175184 dropped from memory (free 2346629975)
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing block broadcast_2_piece0
2022-02-14 10:56:32 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$5
2022-02-14 10:56:32 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$5
2022-02-14 10:56:32 DEBUG MemoryStore:61 - Block broadcast_2_piece0 of size 24515 dropped from memory (free 2346654490)
2022-02-14 10:56:32 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage4(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=4
/* 006 */ final class GeneratedIteratorForCodegenStage4 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private boolean agg_bufIsNull_0;
/* 011 */   private long agg_bufValue_0;
/* 012 */   private boolean agg_initAgg_1;
/* 013 */   private org.apache.spark.unsafe.KVIterator agg_mapIter_0;
/* 014 */   private org.apache.spark.sql.execution.UnsafeFixedWidthAggregationMap agg_hashMap_0;
/* 015 */   private org.apache.spark.sql.execution.UnsafeKVExternalSorter agg_sorter_0;
/* 016 */   private scala.collection.Iterator inputadapter_input_0;
/* 017 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 018 */
/* 019 */   public GeneratedIteratorForCodegenStage4(Object[] references) {
/* 020 */     this.references = references;
/* 021 */   }
/* 022 */
/* 023 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 024 */     partitionIndex = index;
/* 025 */     this.inputs = inputs;
/* 026 */
/* 027 */     inputadapter_input_0 = inputs[0];
/* 028 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 029 */     agg_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 030 */
/* 031 */   }
/* 032 */
/* 033 */   private void agg_doAggregateWithoutKey_0() throws java.io.IOException {
/* 034 */     // initialize aggregation buffer
/* 035 */     agg_bufIsNull_0 = false;
/* 036 */     agg_bufValue_0 = 0L;
/* 037 */
/* 038 */     if (!agg_initAgg_1) {
/* 039 */       agg_initAgg_1 = true;
/* 040 */
/* 041 */       agg_hashMap_0 = ((org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0] /* plan */).createHashMap();
/* 042 */       long agg_beforeAgg_0 = System.nanoTime();
/* 043 */       agg_doAggregateWithKeys_0();
/* 044 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[5] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_0) / 1000000);
/* 045 */     }
/* 046 */     // output the result
/* 047 */
/* 048 */     while ( agg_mapIter_0.next()) {
/* 049 */       UnsafeRow agg_aggKey_0 = (UnsafeRow) agg_mapIter_0.getKey();
/* 050 */       UnsafeRow agg_aggBuffer_0 = (UnsafeRow) agg_mapIter_0.getValue();
/* 051 */       agg_doAggregateWithKeysOutput_0(agg_aggKey_0, agg_aggBuffer_0);
/* 052 */       if (shouldStop()) return;
/* 053 */     }
/* 054 */     agg_mapIter_0.close();
/* 055 */     if (agg_sorter_0 == null) {
/* 056 */       agg_hashMap_0.free();
/* 057 */     }
/* 058 */
/* 059 */   }
/* 060 */
/* 061 */   private void agg_doConsume_1() throws java.io.IOException {
/* 062 */     // do aggregate
/* 063 */     // common sub-expressions
/* 064 */
/* 065 */     // evaluate aggregate functions and update aggregation buffers
/* 066 */
/* 067 */     long agg_value_5 = -1L;
/* 068 */
/* 069 */     agg_value_5 = agg_bufValue_0 + 1L;
/* 070 */
/* 071 */     agg_bufIsNull_0 = false;
/* 072 */     agg_bufValue_0 = agg_value_5;
/* 073 */
/* 074 */   }
/* 075 */
/* 076 */   private void agg_doAggregateWithKeysOutput_0(UnsafeRow agg_keyTerm_0, UnsafeRow agg_bufferTerm_0)
/* 077 */   throws java.io.IOException {
/* 078 */     ((org.apache.spark.sql.execution.metric.SQLMetric) references[4] /* numOutputRows */).add(1);
/* 079 */
/* 080 */     agg_doConsume_1();
/* 081 */
/* 082 */   }
/* 083 */
/* 084 */   private void agg_doConsume_0(InternalRow inputadapter_row_0, int agg_expr_0_0, boolean agg_exprIsNull_0_0, UTF8String agg_expr_1_0, boolean agg_exprIsNull_1_0) throws java.io.IOException {
/* 085 */     UnsafeRow agg_unsafeRowAggBuffer_0 = null;
/* 086 */
/* 087 */     // generate grouping key
/* 088 */     agg_mutableStateArray_0[0].reset();
/* 089 */
/* 090 */     agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 091 */
/* 092 */     if (agg_exprIsNull_0_0) {
/* 093 */       agg_mutableStateArray_0[0].setNullAt(0);
/* 094 */     } else {
/* 095 */       agg_mutableStateArray_0[0].write(0, agg_expr_0_0);
/* 096 */     }
/* 097 */
/* 098 */     if (agg_exprIsNull_1_0) {
/* 099 */       agg_mutableStateArray_0[0].setNullAt(1);
/* 100 */     } else {
/* 101 */       agg_mutableStateArray_0[0].write(1, agg_expr_1_0);
/* 102 */     }
/* 103 */     int agg_unsafeRowKeyHash_0 = (agg_mutableStateArray_0[0].getRow()).hashCode();
/* 104 */     if (true) {
/* 105 */       // try to get the buffer from hash map
/* 106 */       agg_unsafeRowAggBuffer_0 =
/* 107 */       agg_hashMap_0.getAggregationBufferFromUnsafeRow((agg_mutableStateArray_0[0].getRow()), agg_unsafeRowKeyHash_0);
/* 108 */     }
/* 109 */     // Can't allocate buffer from the hash map. Spill the map and fallback to sort-based
/* 110 */     // aggregation after processing all input rows.
/* 111 */     if (agg_unsafeRowAggBuffer_0 == null) {
/* 112 */       if (agg_sorter_0 == null) {
/* 113 */         agg_sorter_0 = agg_hashMap_0.destructAndCreateExternalSorter();
/* 114 */       } else {
/* 115 */         agg_sorter_0.merge(agg_hashMap_0.destructAndCreateExternalSorter());
/* 116 */       }
/* 117 */
/* 118 */       // the hash map had be spilled, it should have enough memory now,
/* 119 */       // try to allocate buffer again.
/* 120 */       agg_unsafeRowAggBuffer_0 = agg_hashMap_0.getAggregationBufferFromUnsafeRow(
/* 121 */         (agg_mutableStateArray_0[0].getRow()), agg_unsafeRowKeyHash_0);
/* 122 */       if (agg_unsafeRowAggBuffer_0 == null) {
/* 123 */         // failed to allocate the first page
/* 124 */         throw new org.apache.spark.memory.SparkOutOfMemoryError("No enough memory for aggregation");
/* 125 */       }
/* 126 */     }
/* 127 */
/* 128 */     // common sub-expressions
/* 129 */
/* 130 */     // evaluate aggregate functions and update aggregation buffers
/* 131 */
/* 132 */   }
/* 133 */
/* 134 */   private void agg_doAggregateWithKeys_0() throws java.io.IOException {
/* 135 */     while ( inputadapter_input_0.hasNext()) {
/* 136 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 137 */
/* 138 */       boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 139 */       int inputadapter_value_0 = inputadapter_isNull_0 ?
/* 140 */       -1 : (inputadapter_row_0.getInt(0));
/* 141 */       boolean inputadapter_isNull_1 = inputadapter_row_0.isNullAt(1);
/* 142 */       UTF8String inputadapter_value_1 = inputadapter_isNull_1 ?
/* 143 */       null : (inputadapter_row_0.getUTF8String(1));
/* 144 */
/* 145 */       agg_doConsume_0(inputadapter_row_0, inputadapter_value_0, inputadapter_isNull_0, inputadapter_value_1, inputadapter_isNull_1);
/* 146 */       // shouldStop check is eliminated
/* 147 */     }
/* 148 */
/* 149 */     agg_mapIter_0 = ((org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0] /* plan */).finishAggregate(agg_hashMap_0, agg_sorter_0, ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* peakMemory */), ((org.apache.spark.sql.execution.metric.SQLMetric) references[2] /* spillSize */), ((org.apache.spark.sql.execution.metric.SQLMetric) references[3] /* avgHashProbe */));
/* 150 */   }
/* 151 */
/* 152 */   protected void processNext() throws java.io.IOException {
/* 153 */     while (!agg_initAgg_0) {
/* 154 */       agg_initAgg_0 = true;
/* 155 */       long agg_beforeAgg_1 = System.nanoTime();
/* 156 */       agg_doAggregateWithoutKey_0();
/* 157 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[7] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_1) / 1000000);
/* 158 */
/* 159 */       // output the result
/* 160 */
/* 161 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[6] /* numOutputRows */).add(1);
/* 162 */       agg_mutableStateArray_0[1].reset();
/* 163 */
/* 164 */       agg_mutableStateArray_0[1].zeroOutNullBytes();
/* 165 */
/* 166 */       agg_mutableStateArray_0[1].write(0, agg_bufValue_0);
/* 167 */       append((agg_mutableStateArray_0[1].getRow()));
/* 168 */     }
/* 169 */   }
/* 170 */
/* 171 */ }

2022-02-14 10:56:32 INFO  BlockManagerInfo:57 - Removed broadcast_2_piece0 on Clairvoyant-320:60369 in memory (size: 23.9 KiB, free: 2.2 GiB)
2022-02-14 10:56:32 DEBUG CodeGenerator:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage4(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=4
/* 006 */ final class GeneratedIteratorForCodegenStage4 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private boolean agg_bufIsNull_0;
/* 011 */   private long agg_bufValue_0;
/* 012 */   private boolean agg_initAgg_1;
/* 013 */   private org.apache.spark.unsafe.KVIterator agg_mapIter_0;
/* 014 */   private org.apache.spark.sql.execution.UnsafeFixedWidthAggregationMap agg_hashMap_0;
/* 015 */   private org.apache.spark.sql.execution.UnsafeKVExternalSorter agg_sorter_0;
/* 016 */   private scala.collection.Iterator inputadapter_input_0;
/* 017 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 018 */
/* 019 */   public GeneratedIteratorForCodegenStage4(Object[] references) {
/* 020 */     this.references = references;
/* 021 */   }
/* 022 */
/* 023 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 024 */     partitionIndex = index;
/* 025 */     this.inputs = inputs;
/* 026 */
/* 027 */     inputadapter_input_0 = inputs[0];
/* 028 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 029 */     agg_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 030 */
/* 031 */   }
/* 032 */
/* 033 */   private void agg_doAggregateWithoutKey_0() throws java.io.IOException {
/* 034 */     // initialize aggregation buffer
/* 035 */     agg_bufIsNull_0 = false;
/* 036 */     agg_bufValue_0 = 0L;
/* 037 */
/* 038 */     if (!agg_initAgg_1) {
/* 039 */       agg_initAgg_1 = true;
/* 040 */
/* 041 */       agg_hashMap_0 = ((org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0] /* plan */).createHashMap();
/* 042 */       long agg_beforeAgg_0 = System.nanoTime();
/* 043 */       agg_doAggregateWithKeys_0();
/* 044 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[5] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_0) / 1000000);
/* 045 */     }
/* 046 */     // output the result
/* 047 */
/* 048 */     while ( agg_mapIter_0.next()) {
/* 049 */       UnsafeRow agg_aggKey_0 = (UnsafeRow) agg_mapIter_0.getKey();
/* 050 */       UnsafeRow agg_aggBuffer_0 = (UnsafeRow) agg_mapIter_0.getValue();
/* 051 */       agg_doAggregateWithKeysOutput_0(agg_aggKey_0, agg_aggBuffer_0);
/* 052 */       if (shouldStop()) return;
/* 053 */     }
/* 054 */     agg_mapIter_0.close();
/* 055 */     if (agg_sorter_0 == null) {
/* 056 */       agg_hashMap_0.free();
/* 057 */     }
/* 058 */
/* 059 */   }
/* 060 */
/* 061 */   private void agg_doConsume_1() throws java.io.IOException {
/* 062 */     // do aggregate
/* 063 */     // common sub-expressions
/* 064 */
/* 065 */     // evaluate aggregate functions and update aggregation buffers
/* 066 */
/* 067 */     long agg_value_5 = -1L;
/* 068 */
/* 069 */     agg_value_5 = agg_bufValue_0 + 1L;
/* 070 */
/* 071 */     agg_bufIsNull_0 = false;
/* 072 */     agg_bufValue_0 = agg_value_5;
/* 073 */
/* 074 */   }
/* 075 */
/* 076 */   private void agg_doAggregateWithKeysOutput_0(UnsafeRow agg_keyTerm_0, UnsafeRow agg_bufferTerm_0)
/* 077 */   throws java.io.IOException {
/* 078 */     ((org.apache.spark.sql.execution.metric.SQLMetric) references[4] /* numOutputRows */).add(1);
/* 079 */
/* 080 */     agg_doConsume_1();
/* 081 */
/* 082 */   }
/* 083 */
/* 084 */   private void agg_doConsume_0(InternalRow inputadapter_row_0, int agg_expr_0_0, boolean agg_exprIsNull_0_0, UTF8String agg_expr_1_0, boolean agg_exprIsNull_1_0) throws java.io.IOException {
/* 085 */     UnsafeRow agg_unsafeRowAggBuffer_0 = null;
/* 086 */
/* 087 */     // generate grouping key
/* 088 */     agg_mutableStateArray_0[0].reset();
/* 089 */
/* 090 */     agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 091 */
/* 092 */     if (agg_exprIsNull_0_0) {
/* 093 */       agg_mutableStateArray_0[0].setNullAt(0);
/* 094 */     } else {
/* 095 */       agg_mutableStateArray_0[0].write(0, agg_expr_0_0);
/* 096 */     }
/* 097 */
/* 098 */     if (agg_exprIsNull_1_0) {
/* 099 */       agg_mutableStateArray_0[0].setNullAt(1);
/* 100 */     } else {
/* 101 */       agg_mutableStateArray_0[0].write(1, agg_expr_1_0);
/* 102 */     }
/* 103 */     int agg_unsafeRowKeyHash_0 = (agg_mutableStateArray_0[0].getRow()).hashCode();
/* 104 */     if (true) {
/* 105 */       // try to get the buffer from hash map
/* 106 */       agg_unsafeRowAggBuffer_0 =
/* 107 */       agg_hashMap_0.getAggregationBufferFromUnsafeRow((agg_mutableStateArray_0[0].getRow()), agg_unsafeRowKeyHash_0);
/* 108 */     }
/* 109 */     // Can't allocate buffer from the hash map. Spill the map and fallback to sort-based
/* 110 */     // aggregation after processing all input rows.
/* 111 */     if (agg_unsafeRowAggBuffer_0 == null) {
/* 112 */       if (agg_sorter_0 == null) {
/* 113 */         agg_sorter_0 = agg_hashMap_0.destructAndCreateExternalSorter();
/* 114 */       } else {
/* 115 */         agg_sorter_0.merge(agg_hashMap_0.destructAndCreateExternalSorter());
/* 116 */       }
/* 117 */
/* 118 */       // the hash map had be spilled, it should have enough memory now,
/* 119 */       // try to allocate buffer again.
/* 120 */       agg_unsafeRowAggBuffer_0 = agg_hashMap_0.getAggregationBufferFromUnsafeRow(
/* 121 */         (agg_mutableStateArray_0[0].getRow()), agg_unsafeRowKeyHash_0);
/* 122 */       if (agg_unsafeRowAggBuffer_0 == null) {
/* 123 */         // failed to allocate the first page
/* 124 */         throw new org.apache.spark.memory.SparkOutOfMemoryError("No enough memory for aggregation");
/* 125 */       }
/* 126 */     }
/* 127 */
/* 128 */     // common sub-expressions
/* 129 */
/* 130 */     // evaluate aggregate functions and update aggregation buffers
/* 131 */
/* 132 */   }
/* 133 */
/* 134 */   private void agg_doAggregateWithKeys_0() throws java.io.IOException {
/* 135 */     while ( inputadapter_input_0.hasNext()) {
/* 136 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 137 */
/* 138 */       boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 139 */       int inputadapter_value_0 = inputadapter_isNull_0 ?
/* 140 */       -1 : (inputadapter_row_0.getInt(0));
/* 141 */       boolean inputadapter_isNull_1 = inputadapter_row_0.isNullAt(1);
/* 142 */       UTF8String inputadapter_value_1 = inputadapter_isNull_1 ?
/* 143 */       null : (inputadapter_row_0.getUTF8String(1));
/* 144 */
/* 145 */       agg_doConsume_0(inputadapter_row_0, inputadapter_value_0, inputadapter_isNull_0, inputadapter_value_1, inputadapter_isNull_1);
/* 146 */       // shouldStop check is eliminated
/* 147 */     }
/* 148 */
/* 149 */     agg_mapIter_0 = ((org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0] /* plan */).finishAggregate(agg_hashMap_0, agg_sorter_0, ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* peakMemory */), ((org.apache.spark.sql.execution.metric.SQLMetric) references[2] /* spillSize */), ((org.apache.spark.sql.execution.metric.SQLMetric) references[3] /* avgHashProbe */));
/* 150 */   }
/* 151 */
/* 152 */   protected void processNext() throws java.io.IOException {
/* 153 */     while (!agg_initAgg_0) {
/* 154 */       agg_initAgg_0 = true;
/* 155 */       long agg_beforeAgg_1 = System.nanoTime();
/* 156 */       agg_doAggregateWithoutKey_0();
/* 157 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[7] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_1) / 1000000);
/* 158 */
/* 159 */       // output the result
/* 160 */
/* 161 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[6] /* numOutputRows */).add(1);
/* 162 */       agg_mutableStateArray_0[1].reset();
/* 163 */
/* 164 */       agg_mutableStateArray_0[1].zeroOutNullBytes();
/* 165 */
/* 166 */       agg_mutableStateArray_0[1].write(0, agg_bufValue_0);
/* 167 */       append((agg_mutableStateArray_0[1].getRow()));
/* 168 */     }
/* 169 */   }
/* 170 */
/* 171 */ }

2022-02-14 10:56:32 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2022-02-14 10:56:32 INFO  SparkContext:57 - Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
2022-02-14 10:56:32 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_2_piece0
2022-02-14 10:56:32 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2022-02-14 10:56:32 DEBUG BlockManager:61 - Told master about block broadcast_2_piece0
2022-02-14 10:56:32 INFO  SparkContext:57 - Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
2022-02-14 10:56:32 INFO  DAGScheduler:57 - Got job 6 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
2022-02-14 10:56:32 INFO  DAGScheduler:57 - Final stage: ResultStage 6 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
2022-02-14 10:56:32 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 2, response is 0
2022-02-14 10:56:32 INFO  DAGScheduler:57 - Missing parents: List()
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60354
2022-02-14 10:56:32 DEBUG DAGScheduler:61 - submitStage(ResultStage 6 (name=$anonfun$withThreadLocalCaptured$1 at FutureTask.java:264;jobs=6))
2022-02-14 10:56:32 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:56:32 INFO  DAGScheduler:57 - Submitting ResultStage 6 (MapPartitionsRDD[37] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
2022-02-14 10:56:32 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 6)
2022-02-14 10:56:32 INFO  MemoryStore:57 - Block broadcast_14 stored as values in memory (estimated size 12.2 KiB, free 2.2 GiB)
2022-02-14 10:56:32 DEBUG BlockManager:61 - Put block broadcast_14 locally took 19 ms
2022-02-14 10:56:32 DEBUG BlockManager:61 - Putting block broadcast_14 without replication took 20 ms
2022-02-14 10:56:32 INFO  MemoryStore:57 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 2.2 GiB)
2022-02-14 10:56:32 INFO  BlockManagerInfo:57 - Added broadcast_14_piece0 in memory on Clairvoyant-320:60369 (size: 6.2 KiB, free: 2.2 GiB)
2022-02-14 10:56:32 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_14_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Told master about block broadcast_14_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Put block broadcast_14_piece0 locally took 3 ms
2022-02-14 10:56:32 DEBUG BlockManager:61 - Putting block broadcast_14_piece0 without replication took 3 ms
2022-02-14 10:56:32 INFO  SparkContext:57 - Created broadcast 14 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:56:32 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[37] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
2022-02-14 10:56:32 INFO  TaskSchedulerImpl:57 - Adding task set 6.0 with 1 tasks
2022-02-14 10:56:32 DEBUG TaskSetManager:61 - Epoch for TaskSet 6.0: 0
2022-02-14 10:56:32 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-02-14 10:56:32 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 6.0: NO_PREF, ANY
2022-02-14 10:56:32 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_6.0, runningTasks: 0
2022-02-14 10:56:32 INFO  TaskSetManager:57 - Starting task 0.0 in stage 6.0 (TID 6, Clairvoyant-320, executor driver, partition 0, PROCESS_LOCAL, 7803 bytes)
2022-02-14 10:56:32 INFO  DAGScheduler:57 - Got job 7 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
2022-02-14 10:56:32 INFO  DAGScheduler:57 - Final stage: ResultStage 7 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
2022-02-14 10:56:32 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-02-14 10:56:32 INFO  DAGScheduler:57 - Missing parents: List()
2022-02-14 10:56:32 DEBUG DAGScheduler:61 - submitStage(ResultStage 7 (name=$anonfun$withThreadLocalCaptured$1 at FutureTask.java:264;jobs=7))
2022-02-14 10:56:32 INFO  Executor:57 - Running task 0.0 in stage 6.0 (TID 6)
2022-02-14 10:56:32 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:56:32 INFO  DAGScheduler:57 - Submitting ResultStage 7 (MapPartitionsRDD[35] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
2022-02-14 10:56:32 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 7)
2022-02-14 10:56:32 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (6, 0) -> 1
2022-02-14 10:56:32 DEBUG BlockManager:61 - Getting local block broadcast_14
2022-02-14 10:56:32 DEBUG BlockManager:61 - Level for block broadcast_14 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:56:32 INFO  MemoryStore:57 - Block broadcast_15 stored as values in memory (estimated size 12.4 KiB, free 2.2 GiB)
2022-02-14 10:56:32 DEBUG BlockManager:61 - Put block broadcast_15 locally took 1 ms
2022-02-14 10:56:32 DEBUG BlockManager:61 - Putting block broadcast_15 without replication took 1 ms
2022-02-14 10:56:32 INFO  MemoryStore:57 - Block broadcast_15_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 2.2 GiB)
2022-02-14 10:56:32 INFO  BlockManagerInfo:57 - Added broadcast_15_piece0 in memory on Clairvoyant-320:60369 (size: 6.3 KiB, free: 2.2 GiB)
2022-02-14 10:56:32 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_15_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Told master about block broadcast_15_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Put block broadcast_15_piece0 locally took 3 ms
2022-02-14 10:56:32 DEBUG BlockManager:61 - Putting block broadcast_15_piece0 without replication took 4 ms
2022-02-14 10:56:32 INFO  SparkContext:57 - Created broadcast 15 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:56:32 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[35] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
2022-02-14 10:56:32 INFO  TaskSchedulerImpl:57 - Adding task set 7.0 with 1 tasks
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned broadcast 2
2022-02-14 10:56:32 DEBUG TaskSetManager:61 - Epoch for TaskSet 7.0: 0
2022-02-14 10:56:32 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/src/main/resources/retail_db/products/part-00000, range: 0-174247, partition values: [empty row]
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(11)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning broadcast 11
2022-02-14 10:56:32 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 11
2022-02-14 10:56:32 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-14 10:56:32 DEBUG CodeGenerator:61 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-14 10:56:32 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-02-14 10:56:32 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 7.0: NO_PREF, ANY
2022-02-14 10:56:32 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_6.0, runningTasks: 1
2022-02-14 10:56:32 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_7.0, runningTasks: 0
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 11
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing broadcast 11
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing block broadcast_11
2022-02-14 10:56:32 INFO  CodeGenerator:57 - Code generated in 88.5261 ms
2022-02-14 10:56:32 DEBUG MemoryStore:61 - Block broadcast_11 of size 15496 dropped from memory (free 2346631950)
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing block broadcast_11_piece0
2022-02-14 10:56:32 DEBUG MemoryStore:61 - Block broadcast_11_piece0 of size 7750 dropped from memory (free 2346639700)
2022-02-14 10:56:32 INFO  HashAggregateExec:57 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2022-02-14 10:56:32 INFO  BlockManagerInfo:57 - Removed broadcast_11_piece0 on Clairvoyant-320:60369 in memory (size: 7.6 KiB, free: 2.2 GiB)
2022-02-14 10:56:32 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_11_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Told master about block broadcast_11_piece0
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 11, response is 0
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60354
2022-02-14 10:56:32 INFO  CodeGenerator:57 - Code generated in 42.7051 ms
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned broadcast 11
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(260)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 260
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 260
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(74)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 74
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 74
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(68)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 68
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 68
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(124)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 124
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 124
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(157)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 157
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 157
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(255)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 255
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 255
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(108)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 108
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 108
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(14)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 14
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 14
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(101)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 101
2022-02-14 10:56:32 DEBUG BlockManager:61 - Getting local block broadcast_12
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 101
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(211)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 211
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 211
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(183)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 183
2022-02-14 10:56:32 DEBUG BlockManager:61 - Level for block broadcast_12 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 183
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(199)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 199
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 199
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(258)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 258
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 258
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(118)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 118
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 118
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(158)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 158
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 158
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(182)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 182
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 182
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(193)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 193
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 193
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(205)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 205
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 205
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(231)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 231
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 231
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(21)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 21
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 21
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(104)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 104
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 104
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(9)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 9
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 9
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(69)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 69
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 69
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(72)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 72
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 72
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(177)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 177
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 177
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(90)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 90
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 90
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(206)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 206
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 206
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(46)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 46
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 46
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(166)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 166
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 166
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(99)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 99
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 99
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(88)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 88
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 88
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(109)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 109
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 109
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(201)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 201
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 201
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(62)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 62
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 62
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(184)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 184
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 184
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(51)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 51
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 51
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(35)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 35
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 35
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(141)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 141
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 141
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(94)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 94
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 94
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(100)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 100
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 100
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(195)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 195
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 195
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(186)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 186
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 186
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(6)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning broadcast 6
2022-02-14 10:56:32 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 6
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 6
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing broadcast 6
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing block broadcast_6_piece0
2022-02-14 10:56:32 DEBUG MemoryStore:61 - Block broadcast_6_piece0 of size 24515 dropped from memory (free 2346664215)
2022-02-14 10:56:32 INFO  BlockManagerInfo:57 - Removed broadcast_6_piece0 on Clairvoyant-320:60369 in memory (size: 23.9 KiB, free: 2.2 GiB)
2022-02-14 10:56:32 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_6_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Told master about block broadcast_6_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing block broadcast_6
2022-02-14 10:56:32 DEBUG MemoryStore:61 - Block broadcast_6 of size 175184 dropped from memory (free 2346839399)
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 6, response is 0
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60354
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned broadcast 6
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(45)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 45
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 45
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(22)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 22
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 22
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(218)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 218
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 218
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(151)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 151
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 151
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(222)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 222
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 222
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(117)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 117
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 117
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(85)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 85
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 85
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(130)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 130
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 130
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(163)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 163
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 163
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(139)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 139
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 139
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(4)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 4
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 4
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(148)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 148
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 148
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(146)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 146
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 146
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(79)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 79
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 79
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(261)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 261
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 261
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(204)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 204
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 204
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(105)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 105
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 105
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(16)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 16
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 16
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(127)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 127
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 127
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(153)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 153
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 153
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 1
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 1
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(189)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 189
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 189
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(43)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 43
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 43
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(92)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 92
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 92
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(145)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 145
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 145
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(58)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 58
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 58
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(202)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 202
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 202
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(160)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 160
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 160
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(181)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 181
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 181
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(137)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 137
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 137
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(187)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 187
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 187
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(156)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 156
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 156
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(167)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 167
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 167
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(40)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 40
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 40
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(171)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 171
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 171
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(29)
2022-02-14 10:56:32 DEBUG GeneratePredicate:61 - Generated predicate 'isnotnull(input[0, int, true])':
/* 001 */ public SpecificPredicate generate(Object[] references) {
/* 002 */   return new SpecificPredicate(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificPredicate extends org.apache.spark.sql.catalyst.expressions.BasePredicate {
/* 006 */   private final Object[] references;
/* 007 */
/* 008 */
/* 009 */   public SpecificPredicate(Object[] references) {
/* 010 */     this.references = references;
/* 011 */
/* 012 */   }
/* 013 */
/* 014 */   public void initialize(int partitionIndex) {
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public boolean eval(InternalRow i) {
/* 019 */     boolean isNull_1 = i.isNullAt(0);
/* 020 */     int value_1 = isNull_1 ?
/* 021 */     -1 : (i.getInt(0));
/* 022 */     boolean value_2 = !isNull_1;
/* 023 */     return !false && value_2;
/* 024 */   }
/* 025 */
/* 026 */
/* 027 */ }

2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 29
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 29
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(25)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 25
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 25
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(134)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 134
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 134
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(191)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 191
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 191
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(133)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 133
2022-02-14 10:56:32 DEBUG CodeGenerator:61 - 
/* 001 */ public SpecificPredicate generate(Object[] references) {
/* 002 */   return new SpecificPredicate(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificPredicate extends org.apache.spark.sql.catalyst.expressions.BasePredicate {
/* 006 */   private final Object[] references;
/* 007 */
/* 008 */
/* 009 */   public SpecificPredicate(Object[] references) {
/* 010 */     this.references = references;
/* 011 */
/* 012 */   }
/* 013 */
/* 014 */   public void initialize(int partitionIndex) {
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public boolean eval(InternalRow i) {
/* 019 */     boolean isNull_1 = i.isNullAt(0);
/* 020 */     int value_1 = isNull_1 ?
/* 021 */     -1 : (i.getInt(0));
/* 022 */     boolean value_2 = !isNull_1;
/* 023 */     return !false && value_2;
/* 024 */   }
/* 025 */
/* 026 */
/* 027 */ }

2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 133
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(60)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 60
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 60
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(54)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 54
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 54
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(207)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 207
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 207
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(116)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 116
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 116
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(210)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 210
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 210
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(224)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 224
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 224
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(257)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 257
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 257
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(126)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 126
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 126
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(159)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 159
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 159
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(26)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 26
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 26
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(91)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 91
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 91
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(174)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 174
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 174
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(208)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 208
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 208
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(96)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 96
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 96
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(20)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 20
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 20
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(106)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 106
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 106
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(75)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 75
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 75
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(129)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 129
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 129
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(155)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 155
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 155
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(27)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 27
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 27
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(67)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 67
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 67
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(262)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 262
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 262
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(212)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 212
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 212
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(34)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 34
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 34
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(256)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 256
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 256
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(5)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning broadcast 5
2022-02-14 10:56:32 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 5
2022-02-14 10:56:32 INFO  CodeGenerator:57 - Code generated in 14.5731 ms
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 5
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing broadcast 5
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing block broadcast_5
2022-02-14 10:56:32 DEBUG MemoryStore:61 - Block broadcast_5 of size 10992 dropped from memory (free 2346850391)
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing block broadcast_5_piece0
2022-02-14 10:56:32 DEBUG MemoryStore:61 - Block broadcast_5_piece0 of size 5458 dropped from memory (free 2346855849)
2022-02-14 10:56:32 INFO  BlockManagerInfo:57 - Removed broadcast_5_piece0 on Clairvoyant-320:60369 in memory (size: 5.3 KiB, free: 2.2 GiB)
2022-02-14 10:56:32 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_5_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Told master about block broadcast_5_piece0
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 5, response is 0
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60354
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned broadcast 5
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(49)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 49
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 49
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(150)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 150
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 150
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(71)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 71
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 71
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(103)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 103
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 103
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(76)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 76
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 76
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(65)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 65
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 65
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(216)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 216
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 216
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(200)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 200
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 200
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(5)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 5
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 5
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(123)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 123
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 123
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(215)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 215
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 215
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(144)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 144
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 144
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(59)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 59
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 59
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(213)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 213
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 213
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(4)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning broadcast 4
2022-02-14 10:56:32 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 4
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 4
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing broadcast 4
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing block broadcast_4_piece0
2022-02-14 10:56:32 DEBUG MemoryStore:61 - Block broadcast_4_piece0 of size 24515 dropped from memory (free 2346880364)
2022-02-14 10:56:32 INFO  BlockManagerInfo:57 - Removed broadcast_4_piece0 on Clairvoyant-320:60369 in memory (size: 23.9 KiB, free: 2.2 GiB)
2022-02-14 10:56:32 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_4_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Told master about block broadcast_4_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing block broadcast_4
2022-02-14 10:56:32 DEBUG MemoryStore:61 - Block broadcast_4 of size 175184 dropped from memory (free 2347055548)
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 4, response is 0
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60354
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned broadcast 4
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(263)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 263
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 263
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(131)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 131
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 131
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(55)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 55
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 55
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(31)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 31
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 31
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(86)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 86
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 86
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(188)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 188
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 188
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(194)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 194
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 194
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(264)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 264
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 264
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(87)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 87
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 87
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(219)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 219
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 219
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(63)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 63
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 63
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(114)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 114
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 114
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(36)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 36
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 36
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(169)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 169
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 169
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(110)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 110
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 110
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(7)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning broadcast 7
2022-02-14 10:56:32 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 7
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 7
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing broadcast 7
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing block broadcast_7
2022-02-14 10:56:32 DEBUG MemoryStore:61 - Block broadcast_7 of size 15552 dropped from memory (free 2347071100)
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing block broadcast_7_piece0
2022-02-14 10:56:32 DEBUG MemoryStore:61 - Block broadcast_7_piece0 of size 7784 dropped from memory (free 2347078884)
2022-02-14 10:56:32 INFO  BlockManagerInfo:57 - Removed broadcast_7_piece0 on Clairvoyant-320:60369 in memory (size: 7.6 KiB, free: 2.2 GiB)
2022-02-14 10:56:32 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_7_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Told master about block broadcast_7_piece0
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 7, response is 0
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60354
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned broadcast 7
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(73)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 73
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 73
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(227)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 227
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 227
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(70)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 70
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 70
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(162)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 162
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 162
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(152)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 152
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 152
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(164)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 164
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 164
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(175)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 175
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 175
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(41)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 41
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 41
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(203)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 203
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 203
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(78)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 78
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 78
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(259)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 259
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 259
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(56)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 56
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 56
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(161)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 161
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 161
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(154)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 154
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 154
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(107)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 107
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 107
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(173)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 173
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 173
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(112)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 112
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 112
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(149)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 149
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 149
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(209)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 209
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 209
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(52)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 52
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 52
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(115)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 115
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 115
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(0)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 0
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 0
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(10)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 10
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 10
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(198)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 198
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 198
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(254)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 254
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 254
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(97)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 97
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 97
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(225)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 225
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 225
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(10)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning broadcast 10
2022-02-14 10:56:32 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 10
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 10
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing broadcast 10
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing block broadcast_10
2022-02-14 10:56:32 DEBUG MemoryStore:61 - Block broadcast_10 of size 175184 dropped from memory (free 2347254068)
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing block broadcast_10_piece0
2022-02-14 10:56:32 DEBUG MemoryStore:61 - Block broadcast_10_piece0 of size 24515 dropped from memory (free 2347278583)
2022-02-14 10:56:32 INFO  BlockManagerInfo:57 - Removed broadcast_10_piece0 on Clairvoyant-320:60369 in memory (size: 23.9 KiB, free: 2.2 GiB)
2022-02-14 10:56:32 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_10_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Told master about block broadcast_10_piece0
2022-02-14 10:56:32 INFO  Executor:57 - Finished task 0.0 in stage 6.0 (TID 6). 2378 bytes result sent to driver
2022-02-14 10:56:32 DEBUG ExecutorMetricsPoller:61 - removing (6, 0) from stageTCMP
2022-02-14 10:56:32 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_6.0, runningTasks: 0
2022-02-14 10:56:32 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_7.0, runningTasks: 0
2022-02-14 10:56:32 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-14 10:56:32 INFO  TaskSetManager:57 - Starting task 0.0 in stage 7.0 (TID 7, Clairvoyant-320, executor driver, partition 0, PROCESS_LOCAL, 7806 bytes)
2022-02-14 10:56:32 INFO  TaskSetManager:57 - Finished task 0.0 in stage 6.0 (TID 6) in 220 ms on Clairvoyant-320 (executor driver) (1/1)
2022-02-14 10:56:32 INFO  TaskSchedulerImpl:57 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2022-02-14 10:56:32 INFO  Executor:57 - Running task 0.0 in stage 7.0 (TID 7)
2022-02-14 10:56:32 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (7, 0) -> 1
2022-02-14 10:56:32 INFO  DAGScheduler:57 - ResultStage 6 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.254 s
2022-02-14 10:56:32 DEBUG DAGScheduler:61 - After removal of stage 6, remaining stages = 1
2022-02-14 10:56:32 INFO  DAGScheduler:57 - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2022-02-14 10:56:32 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 6: Stage finished
2022-02-14 10:56:32 DEBUG BlockManager:61 - Getting local block broadcast_15
2022-02-14 10:56:32 DEBUG BlockManager:61 - Level for block broadcast_15 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:56:32 INFO  DAGScheduler:57 - Job 6 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.269454 s
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 10, response is 0
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60354
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned broadcast 10
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(140)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 140
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 140
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(33)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 33
2022-02-14 10:56:32 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/src/main/resources/retail_db/departments/part-00000, range: 0-90, partition values: [empty row]
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 33
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(23)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 23
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 23
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(223)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 223
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 223
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(7)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 7
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 7
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(8)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning broadcast 8
2022-02-14 10:56:32 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 8
2022-02-14 10:56:32 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:32 DEBUG CodeGenerator:61 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 8
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing broadcast 8
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing block broadcast_8
2022-02-14 10:56:32 DEBUG MemoryStore:61 - Block broadcast_8 of size 175184 dropped from memory (free 2347453767)
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing block broadcast_8_piece0
2022-02-14 10:56:32 DEBUG MemoryStore:61 - Block broadcast_8_piece0 of size 24515 dropped from memory (free 2347478282)
2022-02-14 10:56:32 INFO  BlockManagerInfo:57 - Removed broadcast_8_piece0 on Clairvoyant-320:60369 in memory (size: 23.9 KiB, free: 2.2 GiB)
2022-02-14 10:56:32 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_8_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Told master about block broadcast_8_piece0
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 8, response is 0
2022-02-14 10:56:32 DEBUG TaskMemoryManager:228 - Task 0 acquired 1056.0 KiB for org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@1956569
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60354
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned broadcast 8
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(83)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 83
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 83
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(135)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 135
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 135
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(84)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 84
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 84
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(111)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 111
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 111
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(147)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 147
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 147
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(15)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 15
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 15
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(179)
2022-02-14 10:56:32 INFO  CodeGenerator:57 - Code generated in 18.602801 ms
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 179
2022-02-14 10:56:32 DEBUG GenerateUnsafeProjection:61 - code for cast(input[0, int, true] as bigint):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     boolean isNull_0 = isNull_1;
/* 035 */     long value_0 = -1L;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 179
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(66)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 66
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 66
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(89)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 89
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 89
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(229)
2022-02-14 10:56:32 DEBUG CodeGenerator:61 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     boolean isNull_0 = isNull_1;
/* 035 */     long value_0 = -1L;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 229
2022-02-14 10:56:32 DEBUG BlockManager:61 - Getting local block broadcast_13
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 229
2022-02-14 10:56:32 DEBUG BlockManager:61 - Level for block broadcast_13 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(39)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 39
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 39
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(32)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 32
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 32
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(80)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 80
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 80
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(38)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 38
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 38
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(30)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 30
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 30
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(95)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 95
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 95
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(230)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 230
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 230
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(2)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 2
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 2
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(136)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 136
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 136
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(128)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 128
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 128
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(44)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 44
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 44
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(3)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning broadcast 3
2022-02-14 10:56:32 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 3
2022-02-14 10:56:32 DEBUG GeneratePredicate:61 - Generated predicate 'isnotnull(input[0, int, true])':
/* 001 */ public SpecificPredicate generate(Object[] references) {
/* 002 */   return new SpecificPredicate(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificPredicate extends org.apache.spark.sql.catalyst.expressions.BasePredicate {
/* 006 */   private final Object[] references;
/* 007 */
/* 008 */
/* 009 */   public SpecificPredicate(Object[] references) {
/* 010 */     this.references = references;
/* 011 */
/* 012 */   }
/* 013 */
/* 014 */   public void initialize(int partitionIndex) {
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public boolean eval(InternalRow i) {
/* 019 */     boolean isNull_1 = i.isNullAt(0);
/* 020 */     int value_1 = isNull_1 ?
/* 021 */     -1 : (i.getInt(0));
/* 022 */     boolean value_2 = !isNull_1;
/* 023 */     return !false && value_2;
/* 024 */   }
/* 025 */
/* 026 */
/* 027 */ }

2022-02-14 10:56:32 INFO  CodeGenerator:57 - Code generated in 20.4992 ms
2022-02-14 10:56:32 INFO  Executor:57 - Finished task 0.0 in stage 7.0 (TID 7). 1623 bytes result sent to driver
2022-02-14 10:56:32 DEBUG ExecutorMetricsPoller:61 - removing (7, 0) from stageTCMP
2022-02-14 10:56:32 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_7.0, runningTasks: 0
2022-02-14 10:56:32 DEBUG TaskMemoryManager:228 - Task 0 acquired 464.0 B for org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@1956569
2022-02-14 10:56:32 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-14 10:56:32 DEBUG TaskMemoryManager:237 - Task 0 release 32.0 KiB from org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@1956569
2022-02-14 10:56:32 INFO  TaskSetManager:57 - Finished task 0.0 in stage 7.0 (TID 7) in 84 ms on Clairvoyant-320 (executor driver) (1/1)
2022-02-14 10:56:32 INFO  TaskSchedulerImpl:57 - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2022-02-14 10:56:32 INFO  DAGScheduler:57 - ResultStage 7 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.300 s
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 3
2022-02-14 10:56:32 INFO  MemoryStore:57 - Block broadcast_16 stored as values in memory (estimated size 1024.5 KiB, free 2.2 GiB)
2022-02-14 10:56:32 DEBUG DAGScheduler:61 - After removal of stage 7, remaining stages = 0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing broadcast 3
2022-02-14 10:56:32 INFO  DAGScheduler:57 - Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2022-02-14 10:56:32 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 7: Stage finished
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing block broadcast_3_piece0
2022-02-14 10:56:32 INFO  DAGScheduler:57 - Job 7 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.348135 s
2022-02-14 10:56:32 DEBUG BlockManager:61 - Put block broadcast_16 locally took 4 ms
2022-02-14 10:56:32 DEBUG TaskMemoryManager:228 - Task 0 acquired 1024.1 KiB for org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@34b25f0c
2022-02-14 10:56:32 DEBUG BlockManager:61 - Putting block broadcast_16 without replication took 4 ms
2022-02-14 10:56:32 DEBUG MemoryStore:61 - Block broadcast_3_piece0 of size 7735 dropped from memory (free 2346436953)
2022-02-14 10:56:32 INFO  BlockManagerInfo:57 - Removed broadcast_3_piece0 on Clairvoyant-320:60369 in memory (size: 7.6 KiB, free: 2.2 GiB)
2022-02-14 10:56:32 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_3_piece0
2022-02-14 10:56:32 DEBUG GenerateUnsafeProjection:61 - code for cast(input[0, int, true] as bigint):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     boolean isNull_0 = isNull_1;
/* 035 */     long value_0 = -1L;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-02-14 10:56:32 DEBUG BlockManager:61 - Told master about block broadcast_3_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing block broadcast_3
2022-02-14 10:56:32 DEBUG MemoryStore:61 - Block broadcast_3 of size 15472 dropped from memory (free 2346452425)
2022-02-14 10:56:32 DEBUG TaskMemoryManager:228 - Task 0 acquired 256.0 B for org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@34b25f0c
2022-02-14 10:56:32 DEBUG TaskMemoryManager:237 - Task 0 release 128.0 B from org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@34b25f0c
2022-02-14 10:56:32 DEBUG TaskMemoryManager:228 - Task 0 acquired 48.0 B for org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@34b25f0c
2022-02-14 10:56:32 DEBUG TaskMemoryManager:237 - Task 0 release 256.0 B from org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@34b25f0c
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 3, response is 0
2022-02-14 10:56:32 INFO  MemoryStore:57 - Block broadcast_16_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 2.2 GiB)
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60354
2022-02-14 10:56:32 INFO  MemoryStore:57 - Block broadcast_17 stored as values in memory (estimated size 1024.1 KiB, free 2.2 GiB)
2022-02-14 10:56:32 DEBUG BlockManager:61 - Put block broadcast_17 locally took 1 ms
2022-02-14 10:56:32 DEBUG BlockManager:61 - Putting block broadcast_17 without replication took 1 ms
2022-02-14 10:56:32 INFO  BlockManagerInfo:57 - Added broadcast_16_piece0 in memory on Clairvoyant-320:60369 (size: 9.1 KiB, free: 2.2 GiB)
2022-02-14 10:56:32 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_16_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Told master about block broadcast_16_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Put block broadcast_16_piece0 locally took 2 ms
2022-02-14 10:56:32 DEBUG BlockManager:61 - Putting block broadcast_16_piece0 without replication took 2 ms
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned broadcast 3
2022-02-14 10:56:32 INFO  SparkContext:57 - Created broadcast 16 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(102)
2022-02-14 10:56:32 INFO  MemoryStore:57 - Block broadcast_17_piece0 stored as bytes in memory (estimated size 357.0 B, free 2.2 GiB)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 102
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 102
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(143)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 143
2022-02-14 10:56:32 INFO  BlockManagerInfo:57 - Added broadcast_17_piece0 in memory on Clairvoyant-320:60369 (size: 357.0 B, free: 2.2 GiB)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 143
2022-02-14 10:56:32 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_17_piece0
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(122)
2022-02-14 10:56:32 DEBUG BlockManager:61 - Told master about block broadcast_17_piece0
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 122
2022-02-14 10:56:32 DEBUG BlockManager:61 - Put block broadcast_17_piece0 locally took 2 ms
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 122
2022-02-14 10:56:32 DEBUG BlockManager:61 - Putting block broadcast_17_piece0 without replication took 2 ms
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(64)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 64
2022-02-14 10:56:32 INFO  SparkContext:57 - Created broadcast 17 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 64
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(190)
2022-02-14 10:56:32 DEBUG BlockManager:61 - Getting local block broadcast_17
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 190
2022-02-14 10:56:32 DEBUG BlockManager:61 - Level for block broadcast_17 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 190
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(214)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 214
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 214
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(24)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 24
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 24
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(138)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 138
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 138
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(113)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 113
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 113
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(98)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 98
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 98
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(11)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 11
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 11
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(28)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 28
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 28
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(9)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning broadcast 9
2022-02-14 10:56:32 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 9
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 9
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing broadcast 9
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing block broadcast_9_piece0
2022-02-14 10:56:32 DEBUG MemoryStore:61 - Block broadcast_9_piece0 of size 5459 dropped from memory (free 2345399582)
2022-02-14 10:56:32 INFO  BlockManagerInfo:57 - Removed broadcast_9_piece0 on Clairvoyant-320:60369 in memory (size: 5.3 KiB, free: 2.2 GiB)
2022-02-14 10:56:32 DEBUG BlockManager:61 - Getting local block broadcast_16
2022-02-14 10:56:32 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_9_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Told master about block broadcast_9_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Level for block broadcast_16 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing block broadcast_9
2022-02-14 10:56:32 DEBUG MemoryStore:61 - Block broadcast_9 of size 10992 dropped from memory (free 2345410574)
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 9, response is 0
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60354
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned broadcast 9
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(178)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 178
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 178
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(53)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 53
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 53
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(226)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 226
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 226
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(120)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 120
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 120
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(81)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 81
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 81
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(221)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 221
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 221
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(93)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 93
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 93
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(196)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 196
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 196
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(37)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 37
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 37
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(19)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 19
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 19
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(13)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 13
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 13
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(50)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 50
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 50
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(1)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning broadcast 1
2022-02-14 10:56:32 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 1
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 1
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing broadcast 1
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing block broadcast_1
2022-02-14 10:56:32 DEBUG MemoryStore:61 - Block broadcast_1 of size 10992 dropped from memory (free 2345421566)
2022-02-14 10:56:32 DEBUG BlockManager:61 - Removing block broadcast_1_piece0
2022-02-14 10:56:32 DEBUG MemoryStore:61 - Block broadcast_1_piece0 of size 5449 dropped from memory (free 2345427015)
2022-02-14 10:56:32 INFO  BlockManagerInfo:57 - Removed broadcast_1_piece0 on Clairvoyant-320:60369 in memory (size: 5.3 KiB, free: 2.2 GiB)
2022-02-14 10:56:32 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_1_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Told master about block broadcast_1_piece0
2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 1, response is 0
2022-02-14 10:56:32 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage3(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=3
/* 006 */ final class GeneratedIteratorForCodegenStage3 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private org.apache.spark.unsafe.KVIterator agg_mapIter_0;
/* 011 */   private org.apache.spark.sql.execution.UnsafeFixedWidthAggregationMap agg_hashMap_0;
/* 012 */   private org.apache.spark.sql.execution.UnsafeKVExternalSorter agg_sorter_0;
/* 013 */   private scala.collection.Iterator inputadapter_input_0;
/* 014 */   private org.apache.spark.sql.execution.joins.LongHashedRelation bhj_relation_0;
/* 015 */   private org.apache.spark.sql.execution.joins.LongHashedRelation bhj_relation_1;
/* 016 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[9];
/* 017 */
/* 018 */   public GeneratedIteratorForCodegenStage3(Object[] references) {
/* 019 */     this.references = references;
/* 020 */   }
/* 021 */
/* 022 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 023 */     partitionIndex = index;
/* 024 */     this.inputs = inputs;
/* 025 */     wholestagecodegen_init_0_0();
/* 026 */     wholestagecodegen_init_0_1();
/* 027 */
/* 028 */   }
/* 029 */
/* 030 */   private void agg_doAggregateWithKeysOutput_0(UnsafeRow agg_keyTerm_0, UnsafeRow agg_bufferTerm_0)
/* 031 */   throws java.io.IOException {
/* 032 */     ((org.apache.spark.sql.execution.metric.SQLMetric) references[9] /* numOutputRows */).add(1);
/* 033 */
/* 034 */     boolean agg_isNull_6 = agg_keyTerm_0.isNullAt(0);
/* 035 */     int agg_value_6 = agg_isNull_6 ?
/* 036 */     -1 : (agg_keyTerm_0.getInt(0));
/* 037 */     boolean agg_isNull_7 = agg_keyTerm_0.isNullAt(1);
/* 038 */     UTF8String agg_value_7 = agg_isNull_7 ?
/* 039 */     null : (agg_keyTerm_0.getUTF8String(1));
/* 040 */     filter_mutableStateArray_0[8].reset();
/* 041 */
/* 042 */     filter_mutableStateArray_0[8].zeroOutNullBytes();
/* 043 */
/* 044 */     if (agg_isNull_6) {
/* 045 */       filter_mutableStateArray_0[8].setNullAt(0);
/* 046 */     } else {
/* 047 */       filter_mutableStateArray_0[8].write(0, agg_value_6);
/* 048 */     }
/* 049 */
/* 050 */     if (agg_isNull_7) {
/* 051 */       filter_mutableStateArray_0[8].setNullAt(1);
/* 052 */     } else {
/* 053 */       filter_mutableStateArray_0[8].write(1, agg_value_7);
/* 054 */     }
/* 055 */     append((filter_mutableStateArray_0[8].getRow()));
/* 056 */
/* 057 */   }
/* 058 */
/* 059 */   private void wholestagecodegen_init_0_1() {
/* 060 */     filter_mutableStateArray_0[5] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 061 */     filter_mutableStateArray_0[6] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 062 */     filter_mutableStateArray_0[7] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 063 */     filter_mutableStateArray_0[8] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 064 */
/* 065 */   }
/* 066 */
/* 067 */   private void agg_doConsume_0(int agg_expr_0_0, boolean agg_exprIsNull_0_0, UTF8String agg_expr_1_0, boolean agg_exprIsNull_1_0) throws java.io.IOException {
/* 068 */     UnsafeRow agg_unsafeRowAggBuffer_0 = null;
/* 069 */
/* 070 */     // generate grouping key
/* 071 */     filter_mutableStateArray_0[7].reset();
/* 072 */
/* 073 */     filter_mutableStateArray_0[7].zeroOutNullBytes();
/* 074 */
/* 075 */     if (agg_exprIsNull_0_0) {
/* 076 */       filter_mutableStateArray_0[7].setNullAt(0);
/* 077 */     } else {
/* 078 */       filter_mutableStateArray_0[7].write(0, agg_expr_0_0);
/* 079 */     }
/* 080 */
/* 081 */     if (agg_exprIsNull_1_0) {
/* 082 */       filter_mutableStateArray_0[7].setNullAt(1);
/* 083 */     } else {
/* 084 */       filter_mutableStateArray_0[7].write(1, agg_expr_1_0);
/* 085 */     }
/* 086 */     int agg_unsafeRowKeyHash_0 = (filter_mutableStateArray_0[7].getRow()).hashCode();
/* 087 */     if (true) {
/* 088 */       // try to get the buffer from hash map
/* 089 */       agg_unsafeRowAggBuffer_0 =
/* 090 */       agg_hashMap_0.getAggregationBufferFromUnsafeRow((filter_mutableStateArray_0[7].getRow()), agg_unsafeRowKeyHash_0);
/* 091 */     }
/* 092 */     // Can't allocate buffer from the hash map. Spill the map and fallback to sort-based
/* 093 */     // aggregation after processing all input rows.
/* 094 */     if (agg_unsafeRowAggBuffer_0 == null) {
/* 095 */       if (agg_sorter_0 == null) {
/* 096 */         agg_sorter_0 = agg_hashMap_0.destructAndCreateExternalSorter();
/* 097 */       } else {
/* 098 */         agg_sorter_0.merge(agg_hashMap_0.destructAndCreateExternalSorter());
/* 099 */       }
/* 100 */
/* 101 */       // the hash map had be spilled, it should have enough memory now,
/* 102 */       // try to allocate buffer again.
/* 103 */       agg_unsafeRowAggBuffer_0 = agg_hashMap_0.getAggregationBufferFromUnsafeRow(
/* 104 */         (filter_mutableStateArray_0[7].getRow()), agg_unsafeRowKeyHash_0);
/* 105 */       if (agg_unsafeRowAggBuffer_0 == null) {
/* 106 */         // failed to allocate the first page
/* 107 */         throw new org.apache.spark.memory.SparkOutOfMemoryError("No enough memory for aggregation");
/* 108 */       }
/* 109 */     }
/* 110 */
/* 111 */     // common sub-expressions
/* 112 */
/* 113 */     // evaluate aggregate functions and update aggregation buffers
/* 114 */
/* 115 */   }
/* 116 */
/* 117 */   private void agg_doAggregateWithKeys_0() throws java.io.IOException {
/* 118 */     while ( inputadapter_input_0.hasNext()) {
/* 119 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 120 */
/* 121 */       do {
/* 122 */         boolean inputadapter_isNull_1 = inputadapter_row_0.isNullAt(1);
/* 123 */         int inputadapter_value_1 = inputadapter_isNull_1 ?
/* 124 */         -1 : (inputadapter_row_0.getInt(1));
/* 125 */
/* 126 */         boolean filter_value_2 = !inputadapter_isNull_1;
/* 127 */         if (!filter_value_2) continue;
/* 128 */
/* 129 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 130 */         int inputadapter_value_0 = inputadapter_isNull_0 ?
/* 131 */         -1 : (inputadapter_row_0.getInt(0));
/* 132 */
/* 133 */         boolean filter_value_5 = !inputadapter_isNull_0;
/* 134 */         if (!filter_value_5) continue;
/* 135 */
/* 136 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[4] /* numOutputRows */).add(1);
/* 137 */
/* 138 */         // generate join key for stream side
/* 139 */         boolean bhj_isNull_0 = false;
/* 140 */         long bhj_value_0 = -1L;
/* 141 */         if (!false) {
/* 142 */           bhj_value_0 = (long) inputadapter_value_1;
/* 143 */         }
/* 144 */         // find matches from HashedRelation
/* 145 */         UnsafeRow bhj_matched_0 = bhj_isNull_0 ? null: (UnsafeRow)bhj_relation_0.getValue(bhj_value_0);
/* 146 */         if (bhj_matched_0 != null) {
/* 147 */           {
/* 148 */             ((org.apache.spark.sql.execution.metric.SQLMetric) references[6] /* numOutputRows */).add(1);
/* 149 */
/* 150 */             // generate join key for stream side
/* 151 */             boolean bhj_isNull_8 = false;
/* 152 */             long bhj_value_8 = -1L;
/* 153 */             if (!false) {
/* 154 */               bhj_value_8 = (long) inputadapter_value_0;
/* 155 */             }
/* 156 */             // find matches from HashRelation
/* 157 */             scala.collection.Iterator bhj_matches_0 = bhj_isNull_8 ? null : (scala.collection.Iterator)bhj_relation_1.get(bhj_value_8);
/* 158 */             if (bhj_matches_0 != null) {
/* 159 */               while (bhj_matches_0.hasNext()) {
/* 160 */                 UnsafeRow bhj_matched_1 = (UnsafeRow) bhj_matches_0.next();
/* 161 */                 {
/* 162 */                   ((org.apache.spark.sql.execution.metric.SQLMetric) references[8] /* numOutputRows */).add(1);
/* 163 */
/* 164 */                   boolean bhj_isNull_2 = bhj_matched_0.isNullAt(0);
/* 165 */                   int bhj_value_2 = bhj_isNull_2 ?
/* 166 */                   -1 : (bhj_matched_0.getInt(0));
/* 167 */                   boolean bhj_isNull_3 = bhj_matched_0.isNullAt(1);
/* 168 */                   UTF8String bhj_value_3 = bhj_isNull_3 ?
/* 169 */                   null : (bhj_matched_0.getUTF8String(1));
/* 170 */
/* 171 */                   agg_doConsume_0(bhj_value_2, bhj_isNull_2, bhj_value_3, bhj_isNull_3);
/* 172 */
/* 173 */                 }
/* 174 */               }
/* 175 */             }
/* 176 */
/* 177 */           }
/* 178 */         }
/* 179 */
/* 180 */       } while(false);
/* 181 */       // shouldStop check is eliminated
/* 182 */     }
/* 183 */
/* 184 */     agg_mapIter_0 = ((org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0] /* plan */).finishAggregate(agg_hashMap_0, agg_sorter_0, ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* peakMemory */), ((org.apache.spark.sql.execution.metric.SQLMetric) references[2] /* spillSize */), ((org.apache.spark.sql.execution.metric.SQLMetric) references[3] /* avgHashProbe */));
/* 185 */   }
/* 186 */
/* 187 */   protected void processNext() throws java.io.IOException {
/* 188 */     if (!agg_initAgg_0) {
/* 189 */       agg_initAgg_0 = true;
/* 190 */
/* 191 */       agg_hashMap_0 = ((org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0] /* plan */).createHashMap();
/* 192 */       long wholestagecodegen_beforeAgg_0 = System.nanoTime();
/* 193 */       agg_doAggregateWithKeys_0();
/* 194 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[10] /* aggTime */).add((System.nanoTime() - wholestagecodegen_beforeAgg_0) / 1000000);
/* 195 */     }
/* 196 */     // output the result
/* 197 */
/* 198 */     while ( agg_mapIter_0.next()) {
/* 199 */       UnsafeRow agg_aggKey_0 = (UnsafeRow) agg_mapIter_0.getKey();
/* 200 */       UnsafeRow agg_aggBuffer_0 = (UnsafeRow) agg_mapIter_0.getValue();
/* 201 */       agg_doAggregateWithKeysOutput_0(agg_aggKey_0, agg_aggBuffer_0);
/* 202 */       if (shouldStop()) return;
/* 203 */     }
/* 204 */     agg_mapIter_0.close();
/* 205 */     if (agg_sorter_0 == null) {
/* 206 */       agg_hashMap_0.free();
/* 207 */     }
/* 208 */   }
/* 209 */
/* 210 */   private void wholestagecodegen_init_0_0() {
/* 211 */     inputadapter_input_0 = inputs[0];
/* 212 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 0);
/* 213 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 0);
/* 214 */
/* 215 */     bhj_relation_0 = ((org.apache.spark.sql.execution.joins.LongHashedRelation) ((org.apache.spark.broadcast.TorrentBroadcast) references[5] /* broadcast */).value()).asReadOnlyCopy();
/* 216 */     incPeakExecutionMemory(bhj_relation_0.estimatedSize());
/* 217 */
/* 218 */     filter_mutableStateArray_0[2] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 32);
/* 219 */     filter_mutableStateArray_0[3] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 220 */
/* 221 */     bhj_relation_1 = ((org.apache.spark.sql.execution.joins.LongHashedRelation) ((org.apache.spark.broadcast.TorrentBroadcast) references[7] /* broadcast */).value()).asReadOnlyCopy();
/* 222 */     incPeakExecutionMemory(bhj_relation_1.estimatedSize());
/* 223 */
/* 224 */     filter_mutableStateArray_0[4] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 32);
/* 225 */
/* 226 */   }
/* 227 */
/* 228 */ }

2022-02-14 10:56:32 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60354
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned broadcast 1
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(57)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 57
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 57
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(172)
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaning accumulator 172
2022-02-14 10:56:32 DEBUG ContextCleaner:61 - Cleaned accumulator 172
2022-02-14 10:56:32 DEBUG CodeGenerator:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage3(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=3
/* 006 */ final class GeneratedIteratorForCodegenStage3 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private org.apache.spark.unsafe.KVIterator agg_mapIter_0;
/* 011 */   private org.apache.spark.sql.execution.UnsafeFixedWidthAggregationMap agg_hashMap_0;
/* 012 */   private org.apache.spark.sql.execution.UnsafeKVExternalSorter agg_sorter_0;
/* 013 */   private scala.collection.Iterator inputadapter_input_0;
/* 014 */   private org.apache.spark.sql.execution.joins.LongHashedRelation bhj_relation_0;
/* 015 */   private org.apache.spark.sql.execution.joins.LongHashedRelation bhj_relation_1;
/* 016 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[9];
/* 017 */
/* 018 */   public GeneratedIteratorForCodegenStage3(Object[] references) {
/* 019 */     this.references = references;
/* 020 */   }
/* 021 */
/* 022 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 023 */     partitionIndex = index;
/* 024 */     this.inputs = inputs;
/* 025 */     wholestagecodegen_init_0_0();
/* 026 */     wholestagecodegen_init_0_1();
/* 027 */
/* 028 */   }
/* 029 */
/* 030 */   private void agg_doAggregateWithKeysOutput_0(UnsafeRow agg_keyTerm_0, UnsafeRow agg_bufferTerm_0)
/* 031 */   throws java.io.IOException {
/* 032 */     ((org.apache.spark.sql.execution.metric.SQLMetric) references[9] /* numOutputRows */).add(1);
/* 033 */
/* 034 */     boolean agg_isNull_6 = agg_keyTerm_0.isNullAt(0);
/* 035 */     int agg_value_6 = agg_isNull_6 ?
/* 036 */     -1 : (agg_keyTerm_0.getInt(0));
/* 037 */     boolean agg_isNull_7 = agg_keyTerm_0.isNullAt(1);
/* 038 */     UTF8String agg_value_7 = agg_isNull_7 ?
/* 039 */     null : (agg_keyTerm_0.getUTF8String(1));
/* 040 */     filter_mutableStateArray_0[8].reset();
/* 041 */
/* 042 */     filter_mutableStateArray_0[8].zeroOutNullBytes();
/* 043 */
/* 044 */     if (agg_isNull_6) {
/* 045 */       filter_mutableStateArray_0[8].setNullAt(0);
/* 046 */     } else {
/* 047 */       filter_mutableStateArray_0[8].write(0, agg_value_6);
/* 048 */     }
/* 049 */
/* 050 */     if (agg_isNull_7) {
/* 051 */       filter_mutableStateArray_0[8].setNullAt(1);
/* 052 */     } else {
/* 053 */       filter_mutableStateArray_0[8].write(1, agg_value_7);
/* 054 */     }
/* 055 */     append((filter_mutableStateArray_0[8].getRow()));
/* 056 */
/* 057 */   }
/* 058 */
/* 059 */   private void wholestagecodegen_init_0_1() {
/* 060 */     filter_mutableStateArray_0[5] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 061 */     filter_mutableStateArray_0[6] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 062 */     filter_mutableStateArray_0[7] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 063 */     filter_mutableStateArray_0[8] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 064 */
/* 065 */   }
/* 066 */
/* 067 */   private void agg_doConsume_0(int agg_expr_0_0, boolean agg_exprIsNull_0_0, UTF8String agg_expr_1_0, boolean agg_exprIsNull_1_0) throws java.io.IOException {
/* 068 */     UnsafeRow agg_unsafeRowAggBuffer_0 = null;
/* 069 */
/* 070 */     // generate grouping key
/* 071 */     filter_mutableStateArray_0[7].reset();
/* 072 */
/* 073 */     filter_mutableStateArray_0[7].zeroOutNullBytes();
/* 074 */
/* 075 */     if (agg_exprIsNull_0_0) {
/* 076 */       filter_mutableStateArray_0[7].setNullAt(0);
/* 077 */     } else {
/* 078 */       filter_mutableStateArray_0[7].write(0, agg_expr_0_0);
/* 079 */     }
/* 080 */
/* 081 */     if (agg_exprIsNull_1_0) {
/* 082 */       filter_mutableStateArray_0[7].setNullAt(1);
/* 083 */     } else {
/* 084 */       filter_mutableStateArray_0[7].write(1, agg_expr_1_0);
/* 085 */     }
/* 086 */     int agg_unsafeRowKeyHash_0 = (filter_mutableStateArray_0[7].getRow()).hashCode();
/* 087 */     if (true) {
/* 088 */       // try to get the buffer from hash map
/* 089 */       agg_unsafeRowAggBuffer_0 =
/* 090 */       agg_hashMap_0.getAggregationBufferFromUnsafeRow((filter_mutableStateArray_0[7].getRow()), agg_unsafeRowKeyHash_0);
/* 091 */     }
/* 092 */     // Can't allocate buffer from the hash map. Spill the map and fallback to sort-based
/* 093 */     // aggregation after processing all input rows.
/* 094 */     if (agg_unsafeRowAggBuffer_0 == null) {
/* 095 */       if (agg_sorter_0 == null) {
/* 096 */         agg_sorter_0 = agg_hashMap_0.destructAndCreateExternalSorter();
/* 097 */       } else {
/* 098 */         agg_sorter_0.merge(agg_hashMap_0.destructAndCreateExternalSorter());
/* 099 */       }
/* 100 */
/* 101 */       // the hash map had be spilled, it should have enough memory now,
/* 102 */       // try to allocate buffer again.
/* 103 */       agg_unsafeRowAggBuffer_0 = agg_hashMap_0.getAggregationBufferFromUnsafeRow(
/* 104 */         (filter_mutableStateArray_0[7].getRow()), agg_unsafeRowKeyHash_0);
/* 105 */       if (agg_unsafeRowAggBuffer_0 == null) {
/* 106 */         // failed to allocate the first page
/* 107 */         throw new org.apache.spark.memory.SparkOutOfMemoryError("No enough memory for aggregation");
/* 108 */       }
/* 109 */     }
/* 110 */
/* 111 */     // common sub-expressions
/* 112 */
/* 113 */     // evaluate aggregate functions and update aggregation buffers
/* 114 */
/* 115 */   }
/* 116 */
/* 117 */   private void agg_doAggregateWithKeys_0() throws java.io.IOException {
/* 118 */     while ( inputadapter_input_0.hasNext()) {
/* 119 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 120 */
/* 121 */       do {
/* 122 */         boolean inputadapter_isNull_1 = inputadapter_row_0.isNullAt(1);
/* 123 */         int inputadapter_value_1 = inputadapter_isNull_1 ?
/* 124 */         -1 : (inputadapter_row_0.getInt(1));
/* 125 */
/* 126 */         boolean filter_value_2 = !inputadapter_isNull_1;
/* 127 */         if (!filter_value_2) continue;
/* 128 */
/* 129 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 130 */         int inputadapter_value_0 = inputadapter_isNull_0 ?
/* 131 */         -1 : (inputadapter_row_0.getInt(0));
/* 132 */
/* 133 */         boolean filter_value_5 = !inputadapter_isNull_0;
/* 134 */         if (!filter_value_5) continue;
/* 135 */
/* 136 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[4] /* numOutputRows */).add(1);
/* 137 */
/* 138 */         // generate join key for stream side
/* 139 */         boolean bhj_isNull_0 = false;
/* 140 */         long bhj_value_0 = -1L;
/* 141 */         if (!false) {
/* 142 */           bhj_value_0 = (long) inputadapter_value_1;
/* 143 */         }
/* 144 */         // find matches from HashedRelation
/* 145 */         UnsafeRow bhj_matched_0 = bhj_isNull_0 ? null: (UnsafeRow)bhj_relation_0.getValue(bhj_value_0);
/* 146 */         if (bhj_matched_0 != null) {
/* 147 */           {
/* 148 */             ((org.apache.spark.sql.execution.metric.SQLMetric) references[6] /* numOutputRows */).add(1);
/* 149 */
/* 150 */             // generate join key for stream side
/* 151 */             boolean bhj_isNull_8 = false;
/* 152 */             long bhj_value_8 = -1L;
/* 153 */             if (!false) {
/* 154 */               bhj_value_8 = (long) inputadapter_value_0;
/* 155 */             }
/* 156 */             // find matches from HashRelation
/* 157 */             scala.collection.Iterator bhj_matches_0 = bhj_isNull_8 ? null : (scala.collection.Iterator)bhj_relation_1.get(bhj_value_8);
/* 158 */             if (bhj_matches_0 != null) {
/* 159 */               while (bhj_matches_0.hasNext()) {
/* 160 */                 UnsafeRow bhj_matched_1 = (UnsafeRow) bhj_matches_0.next();
/* 161 */                 {
/* 162 */                   ((org.apache.spark.sql.execution.metric.SQLMetric) references[8] /* numOutputRows */).add(1);
/* 163 */
/* 164 */                   boolean bhj_isNull_2 = bhj_matched_0.isNullAt(0);
/* 165 */                   int bhj_value_2 = bhj_isNull_2 ?
/* 166 */                   -1 : (bhj_matched_0.getInt(0));
/* 167 */                   boolean bhj_isNull_3 = bhj_matched_0.isNullAt(1);
/* 168 */                   UTF8String bhj_value_3 = bhj_isNull_3 ?
/* 169 */                   null : (bhj_matched_0.getUTF8String(1));
/* 170 */
/* 171 */                   agg_doConsume_0(bhj_value_2, bhj_isNull_2, bhj_value_3, bhj_isNull_3);
/* 172 */
/* 173 */                 }
/* 174 */               }
/* 175 */             }
/* 176 */
/* 177 */           }
/* 178 */         }
/* 179 */
/* 180 */       } while(false);
/* 181 */       // shouldStop check is eliminated
/* 182 */     }
/* 183 */
/* 184 */     agg_mapIter_0 = ((org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0] /* plan */).finishAggregate(agg_hashMap_0, agg_sorter_0, ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* peakMemory */), ((org.apache.spark.sql.execution.metric.SQLMetric) references[2] /* spillSize */), ((org.apache.spark.sql.execution.metric.SQLMetric) references[3] /* avgHashProbe */));
/* 185 */   }
/* 186 */
/* 187 */   protected void processNext() throws java.io.IOException {
/* 188 */     if (!agg_initAgg_0) {
/* 189 */       agg_initAgg_0 = true;
/* 190 */
/* 191 */       agg_hashMap_0 = ((org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0] /* plan */).createHashMap();
/* 192 */       long wholestagecodegen_beforeAgg_0 = System.nanoTime();
/* 193 */       agg_doAggregateWithKeys_0();
/* 194 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[10] /* aggTime */).add((System.nanoTime() - wholestagecodegen_beforeAgg_0) / 1000000);
/* 195 */     }
/* 196 */     // output the result
/* 197 */
/* 198 */     while ( agg_mapIter_0.next()) {
/* 199 */       UnsafeRow agg_aggKey_0 = (UnsafeRow) agg_mapIter_0.getKey();
/* 200 */       UnsafeRow agg_aggBuffer_0 = (UnsafeRow) agg_mapIter_0.getValue();
/* 201 */       agg_doAggregateWithKeysOutput_0(agg_aggKey_0, agg_aggBuffer_0);
/* 202 */       if (shouldStop()) return;
/* 203 */     }
/* 204 */     agg_mapIter_0.close();
/* 205 */     if (agg_sorter_0 == null) {
/* 206 */       agg_hashMap_0.free();
/* 207 */     }
/* 208 */   }
/* 209 */
/* 210 */   private void wholestagecodegen_init_0_0() {
/* 211 */     inputadapter_input_0 = inputs[0];
/* 212 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 0);
/* 213 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 0);
/* 214 */
/* 215 */     bhj_relation_0 = ((org.apache.spark.sql.execution.joins.LongHashedRelation) ((org.apache.spark.broadcast.TorrentBroadcast) references[5] /* broadcast */).value()).asReadOnlyCopy();
/* 216 */     incPeakExecutionMemory(bhj_relation_0.estimatedSize());
/* 217 */
/* 218 */     filter_mutableStateArray_0[2] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 32);
/* 219 */     filter_mutableStateArray_0[3] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 220 */
/* 221 */     bhj_relation_1 = ((org.apache.spark.sql.execution.joins.LongHashedRelation) ((org.apache.spark.broadcast.TorrentBroadcast) references[7] /* broadcast */).value()).asReadOnlyCopy();
/* 222 */     incPeakExecutionMemory(bhj_relation_1.estimatedSize());
/* 223 */
/* 224 */     filter_mutableStateArray_0[4] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 32);
/* 225 */
/* 226 */   }
/* 227 */
/* 228 */ }

2022-02-14 10:56:32 INFO  CodeGenerator:57 - Code generated in 43.9326 ms
2022-02-14 10:56:32 INFO  MemoryStore:57 - Block broadcast_18 stored as values in memory (estimated size 170.9 KiB, free 2.2 GiB)
2022-02-14 10:56:32 DEBUG BlockManager:61 - Put block broadcast_18 locally took 14 ms
2022-02-14 10:56:32 DEBUG BlockManager:61 - Putting block broadcast_18 without replication took 15 ms
2022-02-14 10:56:32 INFO  MemoryStore:57 - Block broadcast_18_piece0 stored as bytes in memory (estimated size 23.9 KiB, free 2.2 GiB)
2022-02-14 10:56:32 INFO  BlockManagerInfo:57 - Added broadcast_18_piece0 in memory on Clairvoyant-320:60369 (size: 23.9 KiB, free: 2.2 GiB)
2022-02-14 10:56:32 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_18_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Told master about block broadcast_18_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Put block broadcast_18_piece0 locally took 3 ms
2022-02-14 10:56:32 DEBUG BlockManager:61 - Putting block broadcast_18_piece0 without replication took 3 ms
2022-02-14 10:56:32 INFO  SparkContext:57 - Created broadcast 18 from count at UsedCase5.java:31
2022-02-14 10:56:32 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4195382 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-14 10:56:32 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-02-14 10:56:32 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-02-14 10:56:32 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-02-14 10:56:32 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-02-14 10:56:32 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-02-14 10:56:32 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-02-14 10:56:32 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$collect$2
2022-02-14 10:56:32 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$collect$2) is now cleaned +++
2022-02-14 10:56:32 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$5
2022-02-14 10:56:32 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2022-02-14 10:56:32 INFO  SparkContext:57 - Starting job: count at UsedCase5.java:31
2022-02-14 10:56:32 INFO  DAGScheduler:57 - Registering RDD 41 (count at UsedCase5.java:31) as input to shuffle 0
2022-02-14 10:56:32 INFO  DAGScheduler:57 - Registering RDD 44 (count at UsedCase5.java:31) as input to shuffle 1
2022-02-14 10:56:32 INFO  DAGScheduler:57 - Got job 8 (count at UsedCase5.java:31) with 1 output partitions
2022-02-14 10:56:32 INFO  DAGScheduler:57 - Final stage: ResultStage 10 (count at UsedCase5.java:31)
2022-02-14 10:56:32 INFO  DAGScheduler:57 - Parents of final stage: List(ShuffleMapStage 9)
2022-02-14 10:56:32 INFO  DAGScheduler:57 - Missing parents: List(ShuffleMapStage 9)
2022-02-14 10:56:32 DEBUG DAGScheduler:61 - submitStage(ResultStage 10 (name=count at UsedCase5.java:31;jobs=8))
2022-02-14 10:56:32 DEBUG DAGScheduler:61 - missing: List(ShuffleMapStage 9)
2022-02-14 10:56:32 DEBUG DAGScheduler:61 - submitStage(ShuffleMapStage 9 (name=count at UsedCase5.java:31;jobs=8))
2022-02-14 10:56:32 DEBUG DAGScheduler:61 - missing: List(ShuffleMapStage 8)
2022-02-14 10:56:32 DEBUG DAGScheduler:61 - submitStage(ShuffleMapStage 8 (name=count at UsedCase5.java:31;jobs=8))
2022-02-14 10:56:32 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:56:32 INFO  DAGScheduler:57 - Submitting ShuffleMapStage 8 (MapPartitionsRDD[41] at count at UsedCase5.java:31), which has no missing parents
2022-02-14 10:56:32 DEBUG DAGScheduler:61 - submitMissingTasks(ShuffleMapStage 8)
2022-02-14 10:56:32 INFO  MemoryStore:57 - Block broadcast_19 stored as values in memory (estimated size 33.8 KiB, free 2.2 GiB)
2022-02-14 10:56:32 DEBUG BlockManager:61 - Put block broadcast_19 locally took 6 ms
2022-02-14 10:56:32 DEBUG BlockManager:61 - Putting block broadcast_19 without replication took 6 ms
2022-02-14 10:56:32 INFO  MemoryStore:57 - Block broadcast_19_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 2.2 GiB)
2022-02-14 10:56:32 INFO  BlockManagerInfo:57 - Added broadcast_19_piece0 in memory on Clairvoyant-320:60369 (size: 15.2 KiB, free: 2.2 GiB)
2022-02-14 10:56:32 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_19_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Told master about block broadcast_19_piece0
2022-02-14 10:56:32 DEBUG BlockManager:61 - Put block broadcast_19_piece0 locally took 4 ms
2022-02-14 10:56:32 DEBUG BlockManager:61 - Putting block broadcast_19_piece0 without replication took 4 ms
2022-02-14 10:56:32 INFO  SparkContext:57 - Created broadcast 19 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:56:32 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[41] at count at UsedCase5.java:31) (first 15 tasks are for partitions Vector(0))
2022-02-14 10:56:32 INFO  TaskSchedulerImpl:57 - Adding task set 8.0 with 1 tasks
2022-02-14 10:56:32 DEBUG TaskSetManager:61 - Epoch for TaskSet 8.0: 0
2022-02-14 10:56:32 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-02-14 10:56:32 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 8.0: NO_PREF, ANY
2022-02-14 10:56:32 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_8.0, runningTasks: 0
2022-02-14 10:56:32 INFO  TaskSetManager:57 - Starting task 0.0 in stage 8.0 (TID 8, Clairvoyant-320, executor driver, partition 0, PROCESS_LOCAL, 7794 bytes)
2022-02-14 10:56:32 INFO  Executor:57 - Running task 0.0 in stage 8.0 (TID 8)
2022-02-14 10:56:32 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (8, 0) -> 1
2022-02-14 10:56:32 DEBUG BlockManager:61 - Getting local block broadcast_19
2022-02-14 10:56:32 DEBUG BlockManager:61 - Level for block broadcast_19 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:56:32 DEBUG GenerateUnsafeProjection:61 - code for pmod(hash(input[0, int, true], input[1, string, true], 42), 200):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = false;
/* 032 */     int value_0 = -1;
/* 033 */     if (200 == 0) {
/* 034 */       isNull_0 = true;
/* 035 */     } else {
/* 036 */       int value_1 = 42;
/* 037 */       boolean isNull_2 = i.isNullAt(0);
/* 038 */       int value_2 = isNull_2 ?
/* 039 */       -1 : (i.getInt(0));
/* 040 */       if (!isNull_2) {
/* 041 */         value_1 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashInt(value_2, value_1);
/* 042 */       }
/* 043 */       boolean isNull_3 = i.isNullAt(1);
/* 044 */       UTF8String value_3 = isNull_3 ?
/* 045 */       null : (i.getUTF8String(1));
/* 046 */       if (!isNull_3) {
/* 047 */         value_1 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashUnsafeBytes(value_3.getBaseObject(), value_3.getBaseOffset(), value_3.numBytes(), value_1);
/* 048 */       }
/* 049 */
/* 050 */       int remainder_0 = value_1 % 200;
/* 051 */       if (remainder_0 < 0) {
/* 052 */         value_0=(remainder_0 + 200) % 200;
/* 053 */       } else {
/* 054 */         value_0=remainder_0;
/* 055 */       }
/* 056 */
/* 057 */     }
/* 058 */     if (isNull_0) {
/* 059 */       mutableStateArray_0[0].setNullAt(0);
/* 060 */     } else {
/* 061 */       mutableStateArray_0[0].write(0, value_0);
/* 062 */     }
/* 063 */     return (mutableStateArray_0[0].getRow());
/* 064 */   }
/* 065 */
/* 066 */
/* 067 */ }

2022-02-14 10:56:32 DEBUG CodeGenerator:61 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = false;
/* 032 */     int value_0 = -1;
/* 033 */     if (200 == 0) {
/* 034 */       isNull_0 = true;
/* 035 */     } else {
/* 036 */       int value_1 = 42;
/* 037 */       boolean isNull_2 = i.isNullAt(0);
/* 038 */       int value_2 = isNull_2 ?
/* 039 */       -1 : (i.getInt(0));
/* 040 */       if (!isNull_2) {
/* 041 */         value_1 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashInt(value_2, value_1);
/* 042 */       }
/* 043 */       boolean isNull_3 = i.isNullAt(1);
/* 044 */       UTF8String value_3 = isNull_3 ?
/* 045 */       null : (i.getUTF8String(1));
/* 046 */       if (!isNull_3) {
/* 047 */         value_1 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashUnsafeBytes(value_3.getBaseObject(), value_3.getBaseOffset(), value_3.numBytes(), value_1);
/* 048 */       }
/* 049 */
/* 050 */       int remainder_0 = value_1 % 200;
/* 051 */       if (remainder_0 < 0) {
/* 052 */         value_0=(remainder_0 + 200) % 200;
/* 053 */       } else {
/* 054 */         value_0=remainder_0;
/* 055 */       }
/* 056 */
/* 057 */     }
/* 058 */     if (isNull_0) {
/* 059 */       mutableStateArray_0[0].setNullAt(0);
/* 060 */     } else {
/* 061 */       mutableStateArray_0[0].write(0, value_0);
/* 062 */     }
/* 063 */     return (mutableStateArray_0[0].getRow());
/* 064 */   }
/* 065 */
/* 066 */
/* 067 */ }

2022-02-14 10:56:32 INFO  CodeGenerator:57 - Code generated in 22.0602 ms
2022-02-14 10:56:32 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:32 DEBUG CodeGenerator:61 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:32 INFO  CodeGenerator:57 - Code generated in 12.0917 ms
2022-02-14 10:56:32 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:32 DEBUG TaskMemoryManager:228 - Task 8 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7e4a7d58
2022-02-14 10:56:32 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:32 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/src/main/resources/retail_db/categories/part-00000, range: 0-1078, partition values: [empty row]
2022-02-14 10:56:32 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:32 DEBUG CodeGenerator:61 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:32 INFO  CodeGenerator:57 - Code generated in 13.0862 ms
2022-02-14 10:56:32 DEBUG BlockManager:61 - Getting local block broadcast_18
2022-02-14 10:56:32 DEBUG BlockManager:61 - Level for block broadcast_18 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:56:32 DEBUG GeneratePredicate:61 - Generated predicate 'isnotnull(input[0, int, true])':
/* 001 */ public SpecificPredicate generate(Object[] references) {
/* 002 */   return new SpecificPredicate(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificPredicate extends org.apache.spark.sql.catalyst.expressions.BasePredicate {
/* 006 */   private final Object[] references;
/* 007 */
/* 008 */
/* 009 */   public SpecificPredicate(Object[] references) {
/* 010 */     this.references = references;
/* 011 */
/* 012 */   }
/* 013 */
/* 014 */   public void initialize(int partitionIndex) {
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public boolean eval(InternalRow i) {
/* 019 */     boolean isNull_1 = i.isNullAt(0);
/* 020 */     int value_1 = isNull_1 ?
/* 021 */     -1 : (i.getInt(0));
/* 022 */     boolean value_2 = !isNull_1;
/* 023 */     return !false && value_2;
/* 024 */   }
/* 025 */
/* 026 */
/* 027 */ }

2022-02-14 10:56:32 DEBUG GeneratePredicate:61 - Generated predicate 'isnotnull(input[1, int, true])':
/* 001 */ public SpecificPredicate generate(Object[] references) {
/* 002 */   return new SpecificPredicate(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificPredicate extends org.apache.spark.sql.catalyst.expressions.BasePredicate {
/* 006 */   private final Object[] references;
/* 007 */
/* 008 */
/* 009 */   public SpecificPredicate(Object[] references) {
/* 010 */     this.references = references;
/* 011 */
/* 012 */   }
/* 013 */
/* 014 */   public void initialize(int partitionIndex) {
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public boolean eval(InternalRow i) {
/* 019 */     boolean isNull_1 = i.isNullAt(1);
/* 020 */     int value_1 = isNull_1 ?
/* 021 */     -1 : (i.getInt(1));
/* 022 */     boolean value_2 = !isNull_1;
/* 023 */     return !false && value_2;
/* 024 */   }
/* 025 */
/* 026 */
/* 027 */ }

2022-02-14 10:56:32 DEBUG CodeGenerator:61 - 
/* 001 */ public SpecificPredicate generate(Object[] references) {
/* 002 */   return new SpecificPredicate(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificPredicate extends org.apache.spark.sql.catalyst.expressions.BasePredicate {
/* 006 */   private final Object[] references;
/* 007 */
/* 008 */
/* 009 */   public SpecificPredicate(Object[] references) {
/* 010 */     this.references = references;
/* 011 */
/* 012 */   }
/* 013 */
/* 014 */   public void initialize(int partitionIndex) {
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public boolean eval(InternalRow i) {
/* 019 */     boolean isNull_1 = i.isNullAt(1);
/* 020 */     int value_1 = isNull_1 ?
/* 021 */     -1 : (i.getInt(1));
/* 022 */     boolean value_2 = !isNull_1;
/* 023 */     return !false && value_2;
/* 024 */   }
/* 025 */
/* 026 */
/* 027 */ }

2022-02-14 10:56:32 INFO  CodeGenerator:57 - Code generated in 8.126101 ms
2022-02-14 10:56:32 DEBUG TaskMemoryManager:228 - Task 8 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@7e4a7d58
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(15)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning broadcast 15
2022-02-14 10:56:33 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 15
2022-02-14 10:56:33 DEBUG TaskMemoryManager:237 - Task 8 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7e4a7d58
2022-02-14 10:56:33 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 15
2022-02-14 10:56:33 DEBUG BlockManager:61 - Removing broadcast 15
2022-02-14 10:56:33 DEBUG BlockManager:61 - Removing block broadcast_15
2022-02-14 10:56:33 DEBUG MemoryStore:61 - Block broadcast_15 of size 12720 dropped from memory (free 2278081203)
2022-02-14 10:56:33 DEBUG BlockManager:61 - Removing block broadcast_15_piece0
2022-02-14 10:56:33 DEBUG MemoryStore:61 - Block broadcast_15_piece0 of size 6433 dropped from memory (free 2278087636)
2022-02-14 10:56:33 INFO  BlockManagerInfo:57 - Removed broadcast_15_piece0 on Clairvoyant-320:60369 in memory (size: 6.3 KiB, free: 2.2 GiB)
2022-02-14 10:56:33 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_15_piece0
2022-02-14 10:56:33 DEBUG BlockManager:61 - Told master about block broadcast_15_piece0
2022-02-14 10:56:33 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 15, response is 0
2022-02-14 10:56:33 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60354
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned broadcast 15
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(330)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 330
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 330
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(14)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning broadcast 14
2022-02-14 10:56:33 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 14
2022-02-14 10:56:33 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 14
2022-02-14 10:56:33 DEBUG BlockManager:61 - Removing broadcast 14
2022-02-14 10:56:33 DEBUG BlockManager:61 - Removing block broadcast_14
2022-02-14 10:56:33 DEBUG MemoryStore:61 - Block broadcast_14 of size 12512 dropped from memory (free 2278100148)
2022-02-14 10:56:33 DEBUG BlockManager:61 - Removing block broadcast_14_piece0
2022-02-14 10:56:33 DEBUG MemoryStore:61 - Block broadcast_14_piece0 of size 6371 dropped from memory (free 2278106519)
2022-02-14 10:56:33 INFO  BlockManagerInfo:57 - Removed broadcast_14_piece0 on Clairvoyant-320:60369 in memory (size: 6.2 KiB, free: 2.2 GiB)
2022-02-14 10:56:33 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_14_piece0
2022-02-14 10:56:33 DEBUG BlockManager:61 - Told master about block broadcast_14_piece0
2022-02-14 10:56:33 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 14, response is 0
2022-02-14 10:56:33 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60354
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned broadcast 14
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(374)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 374
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 374
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(333)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 333
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 333
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(334)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 334
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 334
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(332)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 332
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 332
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(351)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 351
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 351
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(341)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 341
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 341
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(361)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 361
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 361
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(350)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 350
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 350
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(363)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 363
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 363
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(339)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 339
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 339
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(375)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 375
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 375
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(369)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 369
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 369
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(345)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 345
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 345
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(368)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 368
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 368
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(343)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 343
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 343
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(357)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 357
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 357
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(358)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 358
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 358
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(338)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 338
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 338
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(328)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 328
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 328
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(360)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 360
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 360
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(349)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 349
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 349
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(365)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 365
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 365
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(336)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 336
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 336
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(354)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 354
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 354
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(364)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 364
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 364
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(367)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 367
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 367
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(353)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 353
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 353
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(352)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 352
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 352
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(355)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 355
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 355
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(371)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 371
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 371
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(331)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 331
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 331
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(366)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 366
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 366
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(326)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 326
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 326
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(329)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 329
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 329
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(370)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 370
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 370
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(346)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 346
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 346
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(342)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 342
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 342
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(372)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 372
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 372
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(359)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 359
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 359
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(335)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 335
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 335
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(362)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 362
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 362
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(327)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 327
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 327
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(348)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 348
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 348
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(356)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 356
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 356
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(337)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 337
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 337
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(344)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 344
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 344
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(340)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 340
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 340
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(347)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 347
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 347
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(373)
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaning accumulator 373
2022-02-14 10:56:33 DEBUG ContextCleaner:61 - Cleaned accumulator 373
2022-02-14 10:56:33 DEBUG TaskMemoryManager:237 - Task 8 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@7e4a7d58
2022-02-14 10:56:33 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 8 with length 200
2022-02-14 10:56:33 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 8: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,72,0,0,0,0,0,0,0,0,0,0,72,0,0,0,0,0,0,0,72,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,72,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,72,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,72,0,0]
2022-02-14 10:56:33 INFO  Executor:57 - Finished task 0.0 in stage 8.0 (TID 8). 4190 bytes result sent to driver
2022-02-14 10:56:33 DEBUG ExecutorMetricsPoller:61 - removing (8, 0) from stageTCMP
2022-02-14 10:56:33 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_8.0, runningTasks: 0
2022-02-14 10:56:33 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-14 10:56:33 INFO  TaskSetManager:57 - Finished task 0.0 in stage 8.0 (TID 8) in 501 ms on Clairvoyant-320 (executor driver) (1/1)
2022-02-14 10:56:33 INFO  TaskSchedulerImpl:57 - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2022-02-14 10:56:33 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:33 INFO  DAGScheduler:57 - ShuffleMapStage 8 (count at UsedCase5.java:31) finished in 0.542 s
2022-02-14 10:56:33 INFO  DAGScheduler:57 - looking for newly runnable stages
2022-02-14 10:56:33 INFO  DAGScheduler:57 - running: Set()
2022-02-14 10:56:33 INFO  DAGScheduler:57 - waiting: Set(ShuffleMapStage 9, ResultStage 10)
2022-02-14 10:56:33 INFO  DAGScheduler:57 - failed: Set()
2022-02-14 10:56:33 DEBUG MapOutputTrackerMaster:61 - Increasing epoch to 1
2022-02-14 10:56:33 DEBUG DAGScheduler:61 - submitStage(ShuffleMapStage 9 (name=count at UsedCase5.java:31;jobs=8))
2022-02-14 10:56:33 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:56:33 INFO  DAGScheduler:57 - Submitting ShuffleMapStage 9 (MapPartitionsRDD[44] at count at UsedCase5.java:31), which has no missing parents
2022-02-14 10:56:33 DEBUG DAGScheduler:61 - submitMissingTasks(ShuffleMapStage 9)
2022-02-14 10:56:33 INFO  MemoryStore:57 - Block broadcast_20 stored as values in memory (estimated size 39.0 KiB, free 2.2 GiB)
2022-02-14 10:56:33 DEBUG BlockManager:61 - Put block broadcast_20 locally took 2 ms
2022-02-14 10:56:33 DEBUG BlockManager:61 - Putting block broadcast_20 without replication took 3 ms
2022-02-14 10:56:33 INFO  MemoryStore:57 - Block broadcast_20_piece0 stored as bytes in memory (estimated size 19.0 KiB, free 2.2 GiB)
2022-02-14 10:56:33 INFO  BlockManagerInfo:57 - Added broadcast_20_piece0 in memory on Clairvoyant-320:60369 (size: 19.0 KiB, free: 2.2 GiB)
2022-02-14 10:56:33 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_20_piece0
2022-02-14 10:56:33 DEBUG BlockManager:61 - Told master about block broadcast_20_piece0
2022-02-14 10:56:33 DEBUG BlockManager:61 - Put block broadcast_20_piece0 locally took 2 ms
2022-02-14 10:56:33 DEBUG BlockManager:61 - Putting block broadcast_20_piece0 without replication took 3 ms
2022-02-14 10:56:33 INFO  SparkContext:57 - Created broadcast 20 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:56:33 INFO  DAGScheduler:57 - Submitting 200 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[44] at count at UsedCase5.java:31) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2022-02-14 10:56:33 INFO  TaskSchedulerImpl:57 - Adding task set 9.0 with 200 tasks
2022-02-14 10:56:33 DEBUG TaskSetManager:61 - Epoch for TaskSet 9.0: 1
2022-02-14 10:56:33 DEBUG TaskSetManager:61 - Adding pending tasks took 5 ms
2022-02-14 10:56:33 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 9.0: NODE_LOCAL, NO_PREF, ANY
2022-02-14 10:56:33 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:33 INFO  TaskSetManager:57 - Starting task 97.0 in stage 9.0 (TID 9, Clairvoyant-320, executor driver, partition 97, NODE_LOCAL, 7314 bytes)
2022-02-14 10:56:33 INFO  Executor:57 - Running task 97.0 in stage 9.0 (TID 9)
2022-02-14 10:56:33 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:33 DEBUG BlockManager:61 - Getting local block broadcast_20
2022-02-14 10:56:33 DEBUG BlockManager:61 - Level for block broadcast_20 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:56:33 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 97-98
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:33 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:33 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 17 ms
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_8_97,0)
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 22 ms
2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:33 DEBUG TaskMemoryManager:228 - Task 9 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@99bda37
2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:33 DEBUG TaskMemoryManager:228 - Task 9 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@99bda37
2022-02-14 10:56:33 DEBUG TaskMemoryManager:237 - Task 9 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@99bda37
2022-02-14 10:56:33 DEBUG TaskMemoryManager:237 - Task 9 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@99bda37
2022-02-14 10:56:33 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 9 with length 1
2022-02-14 10:56:33 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 9: [59]
2022-02-14 10:56:33 INFO  Executor:57 - Finished task 97.0 in stage 9.0 (TID 9). 5544 bytes result sent to driver
2022-02-14 10:56:33 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:33 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:33 INFO  TaskSetManager:57 - Starting task 108.0 in stage 9.0 (TID 10, Clairvoyant-320, executor driver, partition 108, NODE_LOCAL, 7314 bytes)
2022-02-14 10:56:33 INFO  Executor:57 - Running task 108.0 in stage 9.0 (TID 10)
2022-02-14 10:56:33 INFO  TaskSetManager:57 - Finished task 97.0 in stage 9.0 (TID 9) in 136 ms on Clairvoyant-320 (executor driver) (1/200)
2022-02-14 10:56:33 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:33 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:33 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 108-109
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:33 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:33 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_8_108,0)
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:33 DEBUG TaskMemoryManager:228 - Task 10 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5e6f6116
2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:33 DEBUG TaskMemoryManager:228 - Task 10 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@5e6f6116
2022-02-14 10:56:33 DEBUG TaskMemoryManager:237 - Task 10 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5e6f6116
2022-02-14 10:56:33 DEBUG TaskMemoryManager:237 - Task 10 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@5e6f6116
2022-02-14 10:56:33 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 10 with length 1
2022-02-14 10:56:33 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 10: [59]
2022-02-14 10:56:33 INFO  Executor:57 - Finished task 108.0 in stage 9.0 (TID 10). 5587 bytes result sent to driver
2022-02-14 10:56:33 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:33 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:33 INFO  TaskSetManager:57 - Starting task 116.0 in stage 9.0 (TID 11, Clairvoyant-320, executor driver, partition 116, NODE_LOCAL, 7314 bytes)
2022-02-14 10:56:33 INFO  Executor:57 - Running task 116.0 in stage 9.0 (TID 11)
2022-02-14 10:56:33 INFO  TaskSetManager:57 - Finished task 108.0 in stage 9.0 (TID 10) in 60 ms on Clairvoyant-320 (executor driver) (2/200)
2022-02-14 10:56:33 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:33 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:33 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 116-117
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:33 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:33 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_8_116,0)
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:33 DEBUG TaskMemoryManager:228 - Task 11 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@48018d5a
2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:33 DEBUG TaskMemoryManager:228 - Task 11 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@48018d5a
2022-02-14 10:56:33 DEBUG TaskMemoryManager:237 - Task 11 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@48018d5a
2022-02-14 10:56:33 DEBUG TaskMemoryManager:237 - Task 11 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@48018d5a
2022-02-14 10:56:33 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 11 with length 1
2022-02-14 10:56:33 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 11: [59]
2022-02-14 10:56:33 INFO  Executor:57 - Finished task 116.0 in stage 9.0 (TID 11). 5587 bytes result sent to driver
2022-02-14 10:56:33 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:33 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:33 INFO  TaskSetManager:57 - Starting task 134.0 in stage 9.0 (TID 12, Clairvoyant-320, executor driver, partition 134, NODE_LOCAL, 7314 bytes)
2022-02-14 10:56:33 INFO  TaskSetManager:57 - Finished task 116.0 in stage 9.0 (TID 11) in 60 ms on Clairvoyant-320 (executor driver) (3/200)
2022-02-14 10:56:33 INFO  Executor:57 - Running task 134.0 in stage 9.0 (TID 12)
2022-02-14 10:56:33 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:33 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:33 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 134-135
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:33 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:33 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_8_134,0)
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:33 DEBUG TaskMemoryManager:228 - Task 12 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1f04e9be
2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:33 DEBUG TaskMemoryManager:228 - Task 12 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@1f04e9be
2022-02-14 10:56:33 DEBUG TaskMemoryManager:237 - Task 12 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1f04e9be
2022-02-14 10:56:33 DEBUG TaskMemoryManager:237 - Task 12 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@1f04e9be
2022-02-14 10:56:33 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 12 with length 1
2022-02-14 10:56:33 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 12: [59]
2022-02-14 10:56:33 INFO  Executor:57 - Finished task 134.0 in stage 9.0 (TID 12). 5587 bytes result sent to driver
2022-02-14 10:56:33 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:33 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:33 INFO  TaskSetManager:57 - Starting task 156.0 in stage 9.0 (TID 13, Clairvoyant-320, executor driver, partition 156, NODE_LOCAL, 7314 bytes)
2022-02-14 10:56:33 INFO  Executor:57 - Running task 156.0 in stage 9.0 (TID 13)
2022-02-14 10:56:33 INFO  TaskSetManager:57 - Finished task 134.0 in stage 9.0 (TID 12) in 76 ms on Clairvoyant-320 (executor driver) (4/200)
2022-02-14 10:56:33 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:33 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:33 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 156-157
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:33 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:33 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_8_156,0)
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:33 DEBUG TaskMemoryManager:228 - Task 13 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7833e68c
2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:33 DEBUG TaskMemoryManager:228 - Task 13 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@7833e68c
2022-02-14 10:56:33 DEBUG TaskMemoryManager:237 - Task 13 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7833e68c
2022-02-14 10:56:33 DEBUG TaskMemoryManager:237 - Task 13 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@7833e68c
2022-02-14 10:56:33 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 13 with length 1
2022-02-14 10:56:33 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 13: [59]
2022-02-14 10:56:33 INFO  Executor:57 - Finished task 156.0 in stage 9.0 (TID 13). 5587 bytes result sent to driver
2022-02-14 10:56:33 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:33 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:33 INFO  TaskSetManager:57 - Starting task 197.0 in stage 9.0 (TID 14, Clairvoyant-320, executor driver, partition 197, NODE_LOCAL, 7314 bytes)
2022-02-14 10:56:33 INFO  TaskSetManager:57 - Finished task 156.0 in stage 9.0 (TID 13) in 62 ms on Clairvoyant-320 (executor driver) (5/200)
2022-02-14 10:56:33 INFO  Executor:57 - Running task 197.0 in stage 9.0 (TID 14)
2022-02-14 10:56:33 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:33 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:33 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 197-198
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:33 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:33 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_8_197,0)
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:33 DEBUG TaskMemoryManager:228 - Task 14 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@718bc1f6
2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:33 DEBUG TaskMemoryManager:228 - Task 14 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@718bc1f6
2022-02-14 10:56:33 DEBUG TaskMemoryManager:237 - Task 14 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@718bc1f6
2022-02-14 10:56:33 DEBUG TaskMemoryManager:237 - Task 14 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@718bc1f6
2022-02-14 10:56:33 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 14 with length 1
2022-02-14 10:56:33 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 14: [59]
2022-02-14 10:56:33 INFO  Executor:57 - Finished task 197.0 in stage 9.0 (TID 14). 5587 bytes result sent to driver
2022-02-14 10:56:33 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:33 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:33 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-02-14 10:56:33 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-02-14 10:56:33 INFO  TaskSetManager:57 - Starting task 0.0 in stage 9.0 (TID 15, Clairvoyant-320, executor driver, partition 0, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:33 INFO  Executor:57 - Running task 0.0 in stage 9.0 (TID 15)
2022-02-14 10:56:33 INFO  TaskSetManager:57 - Finished task 197.0 in stage 9.0 (TID 14) in 61 ms on Clairvoyant-320 (executor driver) (6/200)
2022-02-14 10:56:33 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:33 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:33 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 0-1
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:33 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:33 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:33 DEBUG TaskMemoryManager:228 - Task 15 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@c79fd0d
2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:33 DEBUG TaskMemoryManager:237 - Task 15 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@c79fd0d
2022-02-14 10:56:33 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 15 with length 1
2022-02-14 10:56:33 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 15: [56]
2022-02-14 10:56:33 INFO  Executor:57 - Finished task 0.0 in stage 9.0 (TID 15). 5544 bytes result sent to driver
2022-02-14 10:56:33 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:33 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:33 INFO  TaskSetManager:57 - Starting task 1.0 in stage 9.0 (TID 16, Clairvoyant-320, executor driver, partition 1, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:33 INFO  TaskSetManager:57 - Finished task 0.0 in stage 9.0 (TID 15) in 64 ms on Clairvoyant-320 (executor driver) (7/200)
2022-02-14 10:56:33 INFO  Executor:57 - Running task 1.0 in stage 9.0 (TID 16)
2022-02-14 10:56:33 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:33 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:33 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 1-2
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:33 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:33 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:33 DEBUG TaskMemoryManager:228 - Task 16 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@27d70c8e
2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:33 DEBUG TaskMemoryManager:237 - Task 16 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@27d70c8e
2022-02-14 10:56:33 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 16 with length 1
2022-02-14 10:56:33 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 16: [56]
2022-02-14 10:56:33 INFO  Executor:57 - Finished task 1.0 in stage 9.0 (TID 16). 5544 bytes result sent to driver
2022-02-14 10:56:33 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:33 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:33 INFO  TaskSetManager:57 - Starting task 2.0 in stage 9.0 (TID 17, Clairvoyant-320, executor driver, partition 2, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:33 INFO  Executor:57 - Running task 2.0 in stage 9.0 (TID 17)
2022-02-14 10:56:33 INFO  TaskSetManager:57 - Finished task 1.0 in stage 9.0 (TID 16) in 87 ms on Clairvoyant-320 (executor driver) (8/200)
2022-02-14 10:56:33 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:33 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:33 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 2-3
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:33 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:33 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:33 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:33 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:33 DEBUG TaskMemoryManager:228 - Task 17 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7d9c21b6
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:237 - Task 17 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7d9c21b6
2022-02-14 10:56:34 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 17 with length 1
2022-02-14 10:56:34 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 17: [56]
2022-02-14 10:56:34 INFO  Executor:57 - Finished task 2.0 in stage 9.0 (TID 17). 5544 bytes result sent to driver
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:34 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Starting task 3.0 in stage 9.0 (TID 18, Clairvoyant-320, executor driver, partition 3, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Finished task 2.0 in stage 9.0 (TID 17) in 55 ms on Clairvoyant-320 (executor driver) (9/200)
2022-02-14 10:56:34 INFO  Executor:57 - Running task 3.0 in stage 9.0 (TID 18)
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:34 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:34 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 3-4
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:228 - Task 18 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5da3d945
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:237 - Task 18 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5da3d945
2022-02-14 10:56:34 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 18 with length 1
2022-02-14 10:56:34 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 18: [56]
2022-02-14 10:56:34 INFO  Executor:57 - Finished task 3.0 in stage 9.0 (TID 18). 5587 bytes result sent to driver
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:34 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Starting task 4.0 in stage 9.0 (TID 19, Clairvoyant-320, executor driver, partition 4, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:34 INFO  Executor:57 - Running task 4.0 in stage 9.0 (TID 19)
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Finished task 3.0 in stage 9.0 (TID 18) in 65 ms on Clairvoyant-320 (executor driver) (10/200)
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:34 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:34 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 4-5
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 3 ms
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 3 ms
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:228 - Task 19 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@6a724050
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:237 - Task 19 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@6a724050
2022-02-14 10:56:34 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 19 with length 1
2022-02-14 10:56:34 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 19: [56]
2022-02-14 10:56:34 INFO  Executor:57 - Finished task 4.0 in stage 9.0 (TID 19). 5544 bytes result sent to driver
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:34 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Starting task 5.0 in stage 9.0 (TID 20, Clairvoyant-320, executor driver, partition 5, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:34 INFO  Executor:57 - Running task 5.0 in stage 9.0 (TID 20)
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Finished task 4.0 in stage 9.0 (TID 19) in 66 ms on Clairvoyant-320 (executor driver) (11/200)
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:34 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:34 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 5-6
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:228 - Task 20 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@65a61f0a
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:237 - Task 20 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@65a61f0a
2022-02-14 10:56:34 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 20 with length 1
2022-02-14 10:56:34 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 20: [56]
2022-02-14 10:56:34 INFO  Executor:57 - Finished task 5.0 in stage 9.0 (TID 20). 5587 bytes result sent to driver
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:34 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Starting task 6.0 in stage 9.0 (TID 21, Clairvoyant-320, executor driver, partition 6, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:34 INFO  Executor:57 - Running task 6.0 in stage 9.0 (TID 21)
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Finished task 5.0 in stage 9.0 (TID 20) in 67 ms on Clairvoyant-320 (executor driver) (12/200)
2022-02-14 10:56:34 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:34 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 6-7
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:228 - Task 21 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5ec582e0
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:237 - Task 21 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5ec582e0
2022-02-14 10:56:34 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 21 with length 1
2022-02-14 10:56:34 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 21: [56]
2022-02-14 10:56:34 INFO  Executor:57 - Finished task 6.0 in stage 9.0 (TID 21). 5544 bytes result sent to driver
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:34 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Starting task 7.0 in stage 9.0 (TID 22, Clairvoyant-320, executor driver, partition 7, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Finished task 6.0 in stage 9.0 (TID 21) in 66 ms on Clairvoyant-320 (executor driver) (13/200)
2022-02-14 10:56:34 INFO  Executor:57 - Running task 7.0 in stage 9.0 (TID 22)
2022-02-14 10:56:34 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:34 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 7-8
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:228 - Task 22 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2f3d0005
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:237 - Task 22 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2f3d0005
2022-02-14 10:56:34 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 22 with length 1
2022-02-14 10:56:34 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 22: [56]
2022-02-14 10:56:34 INFO  Executor:57 - Finished task 7.0 in stage 9.0 (TID 22). 5544 bytes result sent to driver
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:34 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Starting task 8.0 in stage 9.0 (TID 23, Clairvoyant-320, executor driver, partition 8, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:34 INFO  Executor:57 - Running task 8.0 in stage 9.0 (TID 23)
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Finished task 7.0 in stage 9.0 (TID 22) in 68 ms on Clairvoyant-320 (executor driver) (14/200)
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:34 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:34 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 8-9
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:228 - Task 23 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@327a2d8d
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:237 - Task 23 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@327a2d8d
2022-02-14 10:56:34 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 23 with length 1
2022-02-14 10:56:34 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 23: [56]
2022-02-14 10:56:34 INFO  Executor:57 - Finished task 8.0 in stage 9.0 (TID 23). 5544 bytes result sent to driver
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:34 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Starting task 9.0 in stage 9.0 (TID 24, Clairvoyant-320, executor driver, partition 9, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:34 INFO  Executor:57 - Running task 9.0 in stage 9.0 (TID 24)
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Finished task 8.0 in stage 9.0 (TID 23) in 67 ms on Clairvoyant-320 (executor driver) (15/200)
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:34 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:34 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 9-10
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:228 - Task 24 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2a0796ba
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:237 - Task 24 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2a0796ba
2022-02-14 10:56:34 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 24 with length 1
2022-02-14 10:56:34 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 24: [56]
2022-02-14 10:56:34 INFO  Executor:57 - Finished task 9.0 in stage 9.0 (TID 24). 5587 bytes result sent to driver
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:34 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Starting task 10.0 in stage 9.0 (TID 25, Clairvoyant-320, executor driver, partition 10, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:34 INFO  Executor:57 - Running task 10.0 in stage 9.0 (TID 25)
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Finished task 9.0 in stage 9.0 (TID 24) in 69 ms on Clairvoyant-320 (executor driver) (16/200)
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:34 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:34 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 10-11
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:228 - Task 25 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@c7603c0
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:237 - Task 25 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@c7603c0
2022-02-14 10:56:34 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 25 with length 1
2022-02-14 10:56:34 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 25: [56]
2022-02-14 10:56:34 INFO  Executor:57 - Finished task 10.0 in stage 9.0 (TID 25). 5544 bytes result sent to driver
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:34 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Starting task 11.0 in stage 9.0 (TID 26, Clairvoyant-320, executor driver, partition 11, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:34 INFO  Executor:57 - Running task 11.0 in stage 9.0 (TID 26)
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Finished task 10.0 in stage 9.0 (TID 25) in 61 ms on Clairvoyant-320 (executor driver) (17/200)
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:34 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:34 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 11-12
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:228 - Task 26 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@12ac3bb6
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:237 - Task 26 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@12ac3bb6
2022-02-14 10:56:34 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 26 with length 1
2022-02-14 10:56:34 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 26: [56]
2022-02-14 10:56:34 INFO  Executor:57 - Finished task 11.0 in stage 9.0 (TID 26). 5544 bytes result sent to driver
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:34 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Starting task 12.0 in stage 9.0 (TID 27, Clairvoyant-320, executor driver, partition 12, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:34 INFO  Executor:57 - Running task 12.0 in stage 9.0 (TID 27)
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Finished task 11.0 in stage 9.0 (TID 26) in 52 ms on Clairvoyant-320 (executor driver) (18/200)
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:34 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:34 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 12-13
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 2 ms
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:228 - Task 27 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@138d1f24
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:237 - Task 27 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@138d1f24
2022-02-14 10:56:34 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 27 with length 1
2022-02-14 10:56:34 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 27: [56]
2022-02-14 10:56:34 INFO  Executor:57 - Finished task 12.0 in stage 9.0 (TID 27). 5544 bytes result sent to driver
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:34 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Starting task 13.0 in stage 9.0 (TID 28, Clairvoyant-320, executor driver, partition 13, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:34 INFO  Executor:57 - Running task 13.0 in stage 9.0 (TID 28)
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Finished task 12.0 in stage 9.0 (TID 27) in 49 ms on Clairvoyant-320 (executor driver) (19/200)
2022-02-14 10:56:34 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:34 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 13-14
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:228 - Task 28 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@42390012
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:237 - Task 28 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@42390012
2022-02-14 10:56:34 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 28 with length 1
2022-02-14 10:56:34 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 28: [56]
2022-02-14 10:56:34 INFO  Executor:57 - Finished task 13.0 in stage 9.0 (TID 28). 5587 bytes result sent to driver
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:34 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Starting task 14.0 in stage 9.0 (TID 29, Clairvoyant-320, executor driver, partition 14, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Finished task 13.0 in stage 9.0 (TID 28) in 56 ms on Clairvoyant-320 (executor driver) (20/200)
2022-02-14 10:56:34 INFO  Executor:57 - Running task 14.0 in stage 9.0 (TID 29)
2022-02-14 10:56:34 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:34 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 14-15
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:228 - Task 29 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@434da009
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:237 - Task 29 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@434da009
2022-02-14 10:56:34 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 29 with length 1
2022-02-14 10:56:34 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 29: [56]
2022-02-14 10:56:34 INFO  Executor:57 - Finished task 14.0 in stage 9.0 (TID 29). 5544 bytes result sent to driver
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:34 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Starting task 15.0 in stage 9.0 (TID 30, Clairvoyant-320, executor driver, partition 15, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:34 INFO  Executor:57 - Running task 15.0 in stage 9.0 (TID 30)
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Finished task 14.0 in stage 9.0 (TID 29) in 61 ms on Clairvoyant-320 (executor driver) (21/200)
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:34 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:34 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 15-16
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:228 - Task 30 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@6b1fbe42
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:237 - Task 30 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@6b1fbe42
2022-02-14 10:56:34 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 30 with length 1
2022-02-14 10:56:34 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 30: [56]
2022-02-14 10:56:34 INFO  Executor:57 - Finished task 15.0 in stage 9.0 (TID 30). 5587 bytes result sent to driver
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:34 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Starting task 16.0 in stage 9.0 (TID 31, Clairvoyant-320, executor driver, partition 16, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:34 INFO  Executor:57 - Running task 16.0 in stage 9.0 (TID 31)
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Finished task 15.0 in stage 9.0 (TID 30) in 57 ms on Clairvoyant-320 (executor driver) (22/200)
2022-02-14 10:56:34 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:34 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 16-17
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 2 ms
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 3 ms
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:228 - Task 31 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7d03dd2a
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:237 - Task 31 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7d03dd2a
2022-02-14 10:56:34 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 31 with length 1
2022-02-14 10:56:34 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 31: [56]
2022-02-14 10:56:34 INFO  Executor:57 - Finished task 16.0 in stage 9.0 (TID 31). 5544 bytes result sent to driver
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:34 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Starting task 17.0 in stage 9.0 (TID 32, Clairvoyant-320, executor driver, partition 17, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:34 INFO  Executor:57 - Running task 17.0 in stage 9.0 (TID 32)
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Finished task 16.0 in stage 9.0 (TID 31) in 45 ms on Clairvoyant-320 (executor driver) (23/200)
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:34 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:34 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 17-18
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:228 - Task 32 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2dbd9a19
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:237 - Task 32 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2dbd9a19
2022-02-14 10:56:34 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 32 with length 1
2022-02-14 10:56:34 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 32: [56]
2022-02-14 10:56:34 INFO  Executor:57 - Finished task 17.0 in stage 9.0 (TID 32). 5544 bytes result sent to driver
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:34 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Starting task 18.0 in stage 9.0 (TID 33, Clairvoyant-320, executor driver, partition 18, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Finished task 17.0 in stage 9.0 (TID 32) in 38 ms on Clairvoyant-320 (executor driver) (24/200)
2022-02-14 10:56:34 INFO  Executor:57 - Running task 18.0 in stage 9.0 (TID 33)
2022-02-14 10:56:34 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:34 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 18-19
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:228 - Task 33 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@585363fc
2022-02-14 10:56:34 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:34 DEBUG TaskMemoryManager:237 - Task 33 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@585363fc
2022-02-14 10:56:34 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 33 with length 1
2022-02-14 10:56:34 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 33: [56]
2022-02-14 10:56:34 INFO  Executor:57 - Finished task 18.0 in stage 9.0 (TID 33). 5544 bytes result sent to driver
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:34 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Starting task 19.0 in stage 9.0 (TID 34, Clairvoyant-320, executor driver, partition 19, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:34 INFO  Executor:57 - Running task 19.0 in stage 9.0 (TID 34)
2022-02-14 10:56:34 INFO  TaskSetManager:57 - Finished task 18.0 in stage 9.0 (TID 33) in 73 ms on Clairvoyant-320 (executor driver) (25/200)
2022-02-14 10:56:34 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:34 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:34 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 19-20
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:34 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:34 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:228 - Task 34 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2e9d72eb
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:237 - Task 34 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2e9d72eb
2022-02-14 10:56:35 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 34 with length 1
2022-02-14 10:56:35 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 34: [56]
2022-02-14 10:56:35 INFO  Executor:57 - Finished task 19.0 in stage 9.0 (TID 34). 5544 bytes result sent to driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:35 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Starting task 20.0 in stage 9.0 (TID 35, Clairvoyant-320, executor driver, partition 20, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:35 INFO  Executor:57 - Running task 20.0 in stage 9.0 (TID 35)
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Finished task 19.0 in stage 9.0 (TID 34) in 68 ms on Clairvoyant-320 (executor driver) (26/200)
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:35 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:35 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 20-21
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:228 - Task 35 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2140fca9
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:237 - Task 35 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2140fca9
2022-02-14 10:56:35 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 35 with length 1
2022-02-14 10:56:35 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 35: [56]
2022-02-14 10:56:35 INFO  Executor:57 - Finished task 20.0 in stage 9.0 (TID 35). 5544 bytes result sent to driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:35 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Starting task 21.0 in stage 9.0 (TID 36, Clairvoyant-320, executor driver, partition 21, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:35 INFO  Executor:57 - Running task 21.0 in stage 9.0 (TID 36)
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Finished task 20.0 in stage 9.0 (TID 35) in 75 ms on Clairvoyant-320 (executor driver) (27/200)
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:35 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:35 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 21-22
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:228 - Task 36 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@65ecc597
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:237 - Task 36 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@65ecc597
2022-02-14 10:56:35 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 36 with length 1
2022-02-14 10:56:35 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 36: [56]
2022-02-14 10:56:35 INFO  Executor:57 - Finished task 21.0 in stage 9.0 (TID 36). 5544 bytes result sent to driver
2022-02-14 10:56:35 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Starting task 22.0 in stage 9.0 (TID 37, Clairvoyant-320, executor driver, partition 22, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:35 INFO  Executor:57 - Running task 22.0 in stage 9.0 (TID 37)
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Finished task 21.0 in stage 9.0 (TID 36) in 71 ms on Clairvoyant-320 (executor driver) (28/200)
2022-02-14 10:56:35 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:35 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 22-23
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 2 ms
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 3 ms
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:228 - Task 37 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4f13c627
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:237 - Task 37 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4f13c627
2022-02-14 10:56:35 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 37 with length 1
2022-02-14 10:56:35 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 37: [56]
2022-02-14 10:56:35 INFO  Executor:57 - Finished task 22.0 in stage 9.0 (TID 37). 5544 bytes result sent to driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:35 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Starting task 23.0 in stage 9.0 (TID 38, Clairvoyant-320, executor driver, partition 23, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:35 INFO  Executor:57 - Running task 23.0 in stage 9.0 (TID 38)
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Finished task 22.0 in stage 9.0 (TID 37) in 68 ms on Clairvoyant-320 (executor driver) (29/200)
2022-02-14 10:56:35 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:35 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 23-24
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:228 - Task 38 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@664c41b3
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:237 - Task 38 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@664c41b3
2022-02-14 10:56:35 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 38 with length 1
2022-02-14 10:56:35 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 38: [56]
2022-02-14 10:56:35 INFO  Executor:57 - Finished task 23.0 in stage 9.0 (TID 38). 5544 bytes result sent to driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:35 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Starting task 24.0 in stage 9.0 (TID 39, Clairvoyant-320, executor driver, partition 24, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Finished task 23.0 in stage 9.0 (TID 38) in 52 ms on Clairvoyant-320 (executor driver) (30/200)
2022-02-14 10:56:35 INFO  Executor:57 - Running task 24.0 in stage 9.0 (TID 39)
2022-02-14 10:56:35 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:35 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 24-25
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:228 - Task 39 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@b100437
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:237 - Task 39 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@b100437
2022-02-14 10:56:35 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 39 with length 1
2022-02-14 10:56:35 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 39: [56]
2022-02-14 10:56:35 INFO  Executor:57 - Finished task 24.0 in stage 9.0 (TID 39). 5544 bytes result sent to driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:35 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Starting task 25.0 in stage 9.0 (TID 40, Clairvoyant-320, executor driver, partition 25, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Finished task 24.0 in stage 9.0 (TID 39) in 64 ms on Clairvoyant-320 (executor driver) (31/200)
2022-02-14 10:56:35 INFO  Executor:57 - Running task 25.0 in stage 9.0 (TID 40)
2022-02-14 10:56:35 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:35 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 25-26
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 2 ms
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 3 ms
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:228 - Task 40 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@25922d97
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:237 - Task 40 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@25922d97
2022-02-14 10:56:35 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 40 with length 1
2022-02-14 10:56:35 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 40: [56]
2022-02-14 10:56:35 INFO  Executor:57 - Finished task 25.0 in stage 9.0 (TID 40). 5544 bytes result sent to driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:35 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Starting task 26.0 in stage 9.0 (TID 41, Clairvoyant-320, executor driver, partition 26, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:35 INFO  Executor:57 - Running task 26.0 in stage 9.0 (TID 41)
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Finished task 25.0 in stage 9.0 (TID 40) in 64 ms on Clairvoyant-320 (executor driver) (32/200)
2022-02-14 10:56:35 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:35 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 26-27
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:228 - Task 41 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@72efbd3e
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:237 - Task 41 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@72efbd3e
2022-02-14 10:56:35 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 41 with length 1
2022-02-14 10:56:35 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 41: [56]
2022-02-14 10:56:35 INFO  Executor:57 - Finished task 26.0 in stage 9.0 (TID 41). 5544 bytes result sent to driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:35 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Starting task 27.0 in stage 9.0 (TID 42, Clairvoyant-320, executor driver, partition 27, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Finished task 26.0 in stage 9.0 (TID 41) in 41 ms on Clairvoyant-320 (executor driver) (33/200)
2022-02-14 10:56:35 INFO  Executor:57 - Running task 27.0 in stage 9.0 (TID 42)
2022-02-14 10:56:35 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:35 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 27-28
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:228 - Task 42 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@42f4cb13
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:237 - Task 42 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@42f4cb13
2022-02-14 10:56:35 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 42 with length 1
2022-02-14 10:56:35 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 42: [56]
2022-02-14 10:56:35 INFO  Executor:57 - Finished task 27.0 in stage 9.0 (TID 42). 5587 bytes result sent to driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:35 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Starting task 28.0 in stage 9.0 (TID 43, Clairvoyant-320, executor driver, partition 28, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:35 INFO  Executor:57 - Running task 28.0 in stage 9.0 (TID 43)
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Finished task 27.0 in stage 9.0 (TID 42) in 48 ms on Clairvoyant-320 (executor driver) (34/200)
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:35 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:35 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 28-29
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:228 - Task 43 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@6a9820d9
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:237 - Task 43 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@6a9820d9
2022-02-14 10:56:35 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 43 with length 1
2022-02-14 10:56:35 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 43: [56]
2022-02-14 10:56:35 INFO  Executor:57 - Finished task 28.0 in stage 9.0 (TID 43). 5544 bytes result sent to driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:35 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Starting task 29.0 in stage 9.0 (TID 44, Clairvoyant-320, executor driver, partition 29, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:35 INFO  Executor:57 - Running task 29.0 in stage 9.0 (TID 44)
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Finished task 28.0 in stage 9.0 (TID 43) in 41 ms on Clairvoyant-320 (executor driver) (35/200)
2022-02-14 10:56:35 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:35 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 29-30
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:228 - Task 44 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7abe4a80
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:237 - Task 44 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7abe4a80
2022-02-14 10:56:35 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 44 with length 1
2022-02-14 10:56:35 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 44: [56]
2022-02-14 10:56:35 INFO  Executor:57 - Finished task 29.0 in stage 9.0 (TID 44). 5587 bytes result sent to driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:35 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Starting task 30.0 in stage 9.0 (TID 45, Clairvoyant-320, executor driver, partition 30, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:35 INFO  Executor:57 - Running task 30.0 in stage 9.0 (TID 45)
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Finished task 29.0 in stage 9.0 (TID 44) in 47 ms on Clairvoyant-320 (executor driver) (36/200)
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:35 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:35 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 30-31
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:228 - Task 45 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@35db243e
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:237 - Task 45 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@35db243e
2022-02-14 10:56:35 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 45 with length 1
2022-02-14 10:56:35 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 45: [56]
2022-02-14 10:56:35 INFO  Executor:57 - Finished task 30.0 in stage 9.0 (TID 45). 5544 bytes result sent to driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:35 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Starting task 31.0 in stage 9.0 (TID 46, Clairvoyant-320, executor driver, partition 31, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:35 INFO  Executor:57 - Running task 31.0 in stage 9.0 (TID 46)
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Finished task 30.0 in stage 9.0 (TID 45) in 57 ms on Clairvoyant-320 (executor driver) (37/200)
2022-02-14 10:56:35 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:35 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 31-32
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:228 - Task 46 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3a6f7cc0
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:237 - Task 46 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3a6f7cc0
2022-02-14 10:56:35 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 46 with length 1
2022-02-14 10:56:35 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 46: [56]
2022-02-14 10:56:35 INFO  Executor:57 - Finished task 31.0 in stage 9.0 (TID 46). 5544 bytes result sent to driver
2022-02-14 10:56:35 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Starting task 32.0 in stage 9.0 (TID 47, Clairvoyant-320, executor driver, partition 32, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Finished task 31.0 in stage 9.0 (TID 46) in 61 ms on Clairvoyant-320 (executor driver) (38/200)
2022-02-14 10:56:35 INFO  Executor:57 - Running task 32.0 in stage 9.0 (TID 47)
2022-02-14 10:56:35 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:35 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 32-33
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:228 - Task 47 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@d177461
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:237 - Task 47 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@d177461
2022-02-14 10:56:35 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 47 with length 1
2022-02-14 10:56:35 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 47: [56]
2022-02-14 10:56:35 INFO  Executor:57 - Finished task 32.0 in stage 9.0 (TID 47). 5544 bytes result sent to driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:35 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Starting task 33.0 in stage 9.0 (TID 48, Clairvoyant-320, executor driver, partition 33, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:35 INFO  Executor:57 - Running task 33.0 in stage 9.0 (TID 48)
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Finished task 32.0 in stage 9.0 (TID 47) in 54 ms on Clairvoyant-320 (executor driver) (39/200)
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:35 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:35 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 33-34
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:228 - Task 48 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@21f41888
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:237 - Task 48 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@21f41888
2022-02-14 10:56:35 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 48 with length 1
2022-02-14 10:56:35 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 48: [56]
2022-02-14 10:56:35 INFO  Executor:57 - Finished task 33.0 in stage 9.0 (TID 48). 5587 bytes result sent to driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:35 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Starting task 34.0 in stage 9.0 (TID 49, Clairvoyant-320, executor driver, partition 34, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Finished task 33.0 in stage 9.0 (TID 48) in 42 ms on Clairvoyant-320 (executor driver) (40/200)
2022-02-14 10:56:35 INFO  Executor:57 - Running task 34.0 in stage 9.0 (TID 49)
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:35 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:35 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 34-35
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:228 - Task 49 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@389df3c6
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:237 - Task 49 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@389df3c6
2022-02-14 10:56:35 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 49 with length 1
2022-02-14 10:56:35 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 49: [56]
2022-02-14 10:56:35 INFO  Executor:57 - Finished task 34.0 in stage 9.0 (TID 49). 5544 bytes result sent to driver
2022-02-14 10:56:35 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Starting task 35.0 in stage 9.0 (TID 50, Clairvoyant-320, executor driver, partition 35, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Finished task 34.0 in stage 9.0 (TID 49) in 59 ms on Clairvoyant-320 (executor driver) (41/200)
2022-02-14 10:56:35 INFO  Executor:57 - Running task 35.0 in stage 9.0 (TID 50)
2022-02-14 10:56:35 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:35 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 35-36
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:228 - Task 50 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2e1ca25
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:237 - Task 50 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2e1ca25
2022-02-14 10:56:35 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 50 with length 1
2022-02-14 10:56:35 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 50: [56]
2022-02-14 10:56:35 INFO  Executor:57 - Finished task 35.0 in stage 9.0 (TID 50). 5544 bytes result sent to driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:35 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Starting task 36.0 in stage 9.0 (TID 51, Clairvoyant-320, executor driver, partition 36, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Finished task 35.0 in stage 9.0 (TID 50) in 57 ms on Clairvoyant-320 (executor driver) (42/200)
2022-02-14 10:56:35 INFO  Executor:57 - Running task 36.0 in stage 9.0 (TID 51)
2022-02-14 10:56:35 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:35 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 36-37
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:228 - Task 51 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@12c11d07
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:35 DEBUG TaskMemoryManager:237 - Task 51 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@12c11d07
2022-02-14 10:56:35 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 51 with length 1
2022-02-14 10:56:35 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 51: [56]
2022-02-14 10:56:35 INFO  Executor:57 - Finished task 36.0 in stage 9.0 (TID 51). 5587 bytes result sent to driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:35 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Starting task 37.0 in stage 9.0 (TID 52, Clairvoyant-320, executor driver, partition 37, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:35 INFO  Executor:57 - Running task 37.0 in stage 9.0 (TID 52)
2022-02-14 10:56:35 INFO  TaskSetManager:57 - Finished task 36.0 in stage 9.0 (TID 51) in 55 ms on Clairvoyant-320 (executor driver) (43/200)
2022-02-14 10:56:35 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:35 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:35 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 37-38
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:35 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:35 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:35 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:228 - Task 52 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@15464c34
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:237 - Task 52 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@15464c34
2022-02-14 10:56:36 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 52 with length 1
2022-02-14 10:56:36 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 52: [56]
2022-02-14 10:56:36 INFO  Executor:57 - Finished task 37.0 in stage 9.0 (TID 52). 5544 bytes result sent to driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:36 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Starting task 38.0 in stage 9.0 (TID 53, Clairvoyant-320, executor driver, partition 38, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:36 INFO  Executor:57 - Running task 38.0 in stage 9.0 (TID 53)
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Finished task 37.0 in stage 9.0 (TID 52) in 58 ms on Clairvoyant-320 (executor driver) (44/200)
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:36 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:36 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 38-39
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:228 - Task 53 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@72b18ee3
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:237 - Task 53 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@72b18ee3
2022-02-14 10:56:36 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 53 with length 1
2022-02-14 10:56:36 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 53: [56]
2022-02-14 10:56:36 INFO  Executor:57 - Finished task 38.0 in stage 9.0 (TID 53). 5544 bytes result sent to driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:36 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Starting task 39.0 in stage 9.0 (TID 54, Clairvoyant-320, executor driver, partition 39, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:36 INFO  Executor:57 - Running task 39.0 in stage 9.0 (TID 54)
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Finished task 38.0 in stage 9.0 (TID 53) in 48 ms on Clairvoyant-320 (executor driver) (45/200)
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:36 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:36 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 39-40
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:228 - Task 54 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4f12c92d
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:237 - Task 54 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4f12c92d
2022-02-14 10:56:36 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 54 with length 1
2022-02-14 10:56:36 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 54: [56]
2022-02-14 10:56:36 INFO  Executor:57 - Finished task 39.0 in stage 9.0 (TID 54). 5544 bytes result sent to driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:36 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Starting task 40.0 in stage 9.0 (TID 55, Clairvoyant-320, executor driver, partition 40, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Finished task 39.0 in stage 9.0 (TID 54) in 45 ms on Clairvoyant-320 (executor driver) (46/200)
2022-02-14 10:56:36 INFO  Executor:57 - Running task 40.0 in stage 9.0 (TID 55)
2022-02-14 10:56:36 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:36 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 40-41
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:228 - Task 55 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5b2e6173
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:237 - Task 55 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5b2e6173
2022-02-14 10:56:36 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 55 with length 1
2022-02-14 10:56:36 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 55: [56]
2022-02-14 10:56:36 INFO  Executor:57 - Finished task 40.0 in stage 9.0 (TID 55). 5544 bytes result sent to driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:36 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Starting task 41.0 in stage 9.0 (TID 56, Clairvoyant-320, executor driver, partition 41, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:36 INFO  Executor:57 - Running task 41.0 in stage 9.0 (TID 56)
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Finished task 40.0 in stage 9.0 (TID 55) in 57 ms on Clairvoyant-320 (executor driver) (47/200)
2022-02-14 10:56:36 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:36 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 41-42
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:228 - Task 56 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2f4ef808
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:237 - Task 56 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2f4ef808
2022-02-14 10:56:36 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 56 with length 1
2022-02-14 10:56:36 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 56: [56]
2022-02-14 10:56:36 INFO  Executor:57 - Finished task 41.0 in stage 9.0 (TID 56). 5544 bytes result sent to driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:36 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Starting task 42.0 in stage 9.0 (TID 57, Clairvoyant-320, executor driver, partition 42, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Finished task 41.0 in stage 9.0 (TID 56) in 40 ms on Clairvoyant-320 (executor driver) (48/200)
2022-02-14 10:56:36 INFO  Executor:57 - Running task 42.0 in stage 9.0 (TID 57)
2022-02-14 10:56:36 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:36 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 42-43
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:228 - Task 57 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@45345cb4
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:237 - Task 57 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@45345cb4
2022-02-14 10:56:36 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 57 with length 1
2022-02-14 10:56:36 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 57: [56]
2022-02-14 10:56:36 INFO  Executor:57 - Finished task 42.0 in stage 9.0 (TID 57). 5544 bytes result sent to driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:36 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Starting task 43.0 in stage 9.0 (TID 58, Clairvoyant-320, executor driver, partition 43, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Finished task 42.0 in stage 9.0 (TID 57) in 43 ms on Clairvoyant-320 (executor driver) (49/200)
2022-02-14 10:56:36 INFO  Executor:57 - Running task 43.0 in stage 9.0 (TID 58)
2022-02-14 10:56:36 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:36 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 43-44
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:228 - Task 58 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@43df467a
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:237 - Task 58 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@43df467a
2022-02-14 10:56:36 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 58 with length 1
2022-02-14 10:56:36 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 58: [56]
2022-02-14 10:56:36 INFO  Executor:57 - Finished task 43.0 in stage 9.0 (TID 58). 5587 bytes result sent to driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:36 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Starting task 44.0 in stage 9.0 (TID 59, Clairvoyant-320, executor driver, partition 44, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:36 INFO  Executor:57 - Running task 44.0 in stage 9.0 (TID 59)
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Finished task 43.0 in stage 9.0 (TID 58) in 43 ms on Clairvoyant-320 (executor driver) (50/200)
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:36 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:36 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 44-45
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:228 - Task 59 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@193a7c3b
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:237 - Task 59 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@193a7c3b
2022-02-14 10:56:36 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 59 with length 1
2022-02-14 10:56:36 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 59: [56]
2022-02-14 10:56:36 INFO  Executor:57 - Finished task 44.0 in stage 9.0 (TID 59). 5587 bytes result sent to driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:36 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Starting task 45.0 in stage 9.0 (TID 60, Clairvoyant-320, executor driver, partition 45, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:36 INFO  Executor:57 - Running task 45.0 in stage 9.0 (TID 60)
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Finished task 44.0 in stage 9.0 (TID 59) in 45 ms on Clairvoyant-320 (executor driver) (51/200)
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:36 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:36 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 45-46
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:228 - Task 60 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2611e3d
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:237 - Task 60 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2611e3d
2022-02-14 10:56:36 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 60 with length 1
2022-02-14 10:56:36 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 60: [56]
2022-02-14 10:56:36 INFO  Executor:57 - Finished task 45.0 in stage 9.0 (TID 60). 5501 bytes result sent to driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:36 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Starting task 46.0 in stage 9.0 (TID 61, Clairvoyant-320, executor driver, partition 46, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Finished task 45.0 in stage 9.0 (TID 60) in 43 ms on Clairvoyant-320 (executor driver) (52/200)
2022-02-14 10:56:36 INFO  Executor:57 - Running task 46.0 in stage 9.0 (TID 61)
2022-02-14 10:56:36 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:36 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 46-47
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:228 - Task 61 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@66a6ae88
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:237 - Task 61 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@66a6ae88
2022-02-14 10:56:36 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 61 with length 1
2022-02-14 10:56:36 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 61: [56]
2022-02-14 10:56:36 INFO  Executor:57 - Finished task 46.0 in stage 9.0 (TID 61). 5544 bytes result sent to driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:36 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Starting task 47.0 in stage 9.0 (TID 62, Clairvoyant-320, executor driver, partition 47, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Finished task 46.0 in stage 9.0 (TID 61) in 38 ms on Clairvoyant-320 (executor driver) (53/200)
2022-02-14 10:56:36 INFO  Executor:57 - Running task 47.0 in stage 9.0 (TID 62)
2022-02-14 10:56:36 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:36 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 47-48
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:228 - Task 62 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@726ddefa
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:237 - Task 62 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@726ddefa
2022-02-14 10:56:36 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 62 with length 1
2022-02-14 10:56:36 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 62: [56]
2022-02-14 10:56:36 INFO  Executor:57 - Finished task 47.0 in stage 9.0 (TID 62). 5544 bytes result sent to driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:36 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Starting task 48.0 in stage 9.0 (TID 63, Clairvoyant-320, executor driver, partition 48, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Finished task 47.0 in stage 9.0 (TID 62) in 46 ms on Clairvoyant-320 (executor driver) (54/200)
2022-02-14 10:56:36 INFO  Executor:57 - Running task 48.0 in stage 9.0 (TID 63)
2022-02-14 10:56:36 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:36 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 48-49
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:228 - Task 63 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@33af9b
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:237 - Task 63 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@33af9b
2022-02-14 10:56:36 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 63 with length 1
2022-02-14 10:56:36 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(19)
2022-02-14 10:56:36 DEBUG ContextCleaner:61 - Cleaning broadcast 19
2022-02-14 10:56:36 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 19
2022-02-14 10:56:36 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 19
2022-02-14 10:56:36 DEBUG BlockManager:61 - Removing broadcast 19
2022-02-14 10:56:36 DEBUG BlockManager:61 - Removing block broadcast_19_piece0
2022-02-14 10:56:36 DEBUG MemoryStore:61 - Block broadcast_19_piece0 of size 15611 dropped from memory (free 2345171593)
2022-02-14 10:56:36 INFO  BlockManagerInfo:57 - Removed broadcast_19_piece0 on Clairvoyant-320:60369 in memory (size: 15.2 KiB, free: 2.2 GiB)
2022-02-14 10:56:36 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_19_piece0
2022-02-14 10:56:36 DEBUG BlockManager:61 - Told master about block broadcast_19_piece0
2022-02-14 10:56:36 DEBUG BlockManager:61 - Removing block broadcast_19
2022-02-14 10:56:36 DEBUG MemoryStore:61 - Block broadcast_19 of size 34576 dropped from memory (free 2345206169)
2022-02-14 10:56:36 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 19, response is 0
2022-02-14 10:56:36 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60354
2022-02-14 10:56:36 DEBUG ContextCleaner:61 - Cleaned broadcast 19
2022-02-14 10:56:36 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 63: [56]
2022-02-14 10:56:36 INFO  Executor:57 - Finished task 48.0 in stage 9.0 (TID 63). 5587 bytes result sent to driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:36 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Starting task 49.0 in stage 9.0 (TID 64, Clairvoyant-320, executor driver, partition 49, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:36 INFO  Executor:57 - Running task 49.0 in stage 9.0 (TID 64)
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Finished task 48.0 in stage 9.0 (TID 63) in 65 ms on Clairvoyant-320 (executor driver) (55/200)
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:36 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:36 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 49-50
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:228 - Task 64 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@41d4f56f
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:237 - Task 64 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@41d4f56f
2022-02-14 10:56:36 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 64 with length 1
2022-02-14 10:56:36 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 64: [56]
2022-02-14 10:56:36 INFO  Executor:57 - Finished task 49.0 in stage 9.0 (TID 64). 5544 bytes result sent to driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:36 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Starting task 50.0 in stage 9.0 (TID 65, Clairvoyant-320, executor driver, partition 50, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:36 INFO  Executor:57 - Running task 50.0 in stage 9.0 (TID 65)
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Finished task 49.0 in stage 9.0 (TID 64) in 45 ms on Clairvoyant-320 (executor driver) (56/200)
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:36 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:36 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 50-51
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:228 - Task 65 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7f410c08
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:237 - Task 65 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7f410c08
2022-02-14 10:56:36 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 65 with length 1
2022-02-14 10:56:36 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 65: [56]
2022-02-14 10:56:36 INFO  Executor:57 - Finished task 50.0 in stage 9.0 (TID 65). 5544 bytes result sent to driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:36 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Starting task 51.0 in stage 9.0 (TID 66, Clairvoyant-320, executor driver, partition 51, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Finished task 50.0 in stage 9.0 (TID 65) in 28 ms on Clairvoyant-320 (executor driver) (57/200)
2022-02-14 10:56:36 INFO  Executor:57 - Running task 51.0 in stage 9.0 (TID 66)
2022-02-14 10:56:36 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:36 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 51-52
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:228 - Task 66 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@f22f92a
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:237 - Task 66 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@f22f92a
2022-02-14 10:56:36 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 66 with length 1
2022-02-14 10:56:36 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 66: [56]
2022-02-14 10:56:36 INFO  Executor:57 - Finished task 51.0 in stage 9.0 (TID 66). 5544 bytes result sent to driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:36 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Starting task 52.0 in stage 9.0 (TID 67, Clairvoyant-320, executor driver, partition 52, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:36 INFO  Executor:57 - Running task 52.0 in stage 9.0 (TID 67)
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Finished task 51.0 in stage 9.0 (TID 66) in 43 ms on Clairvoyant-320 (executor driver) (58/200)
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:36 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:36 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 52-53
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:228 - Task 67 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4650e36d
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:237 - Task 67 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4650e36d
2022-02-14 10:56:36 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 67 with length 1
2022-02-14 10:56:36 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 67: [56]
2022-02-14 10:56:36 INFO  Executor:57 - Finished task 52.0 in stage 9.0 (TID 67). 5587 bytes result sent to driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:36 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Starting task 53.0 in stage 9.0 (TID 68, Clairvoyant-320, executor driver, partition 53, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Finished task 52.0 in stage 9.0 (TID 67) in 34 ms on Clairvoyant-320 (executor driver) (59/200)
2022-02-14 10:56:36 INFO  Executor:57 - Running task 53.0 in stage 9.0 (TID 68)
2022-02-14 10:56:36 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:36 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 53-54
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:228 - Task 68 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1d11f41d
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:237 - Task 68 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1d11f41d
2022-02-14 10:56:36 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 68 with length 1
2022-02-14 10:56:36 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 68: [56]
2022-02-14 10:56:36 INFO  Executor:57 - Finished task 53.0 in stage 9.0 (TID 68). 5544 bytes result sent to driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:36 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Starting task 54.0 in stage 9.0 (TID 69, Clairvoyant-320, executor driver, partition 54, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Finished task 53.0 in stage 9.0 (TID 68) in 48 ms on Clairvoyant-320 (executor driver) (60/200)
2022-02-14 10:56:36 INFO  Executor:57 - Running task 54.0 in stage 9.0 (TID 69)
2022-02-14 10:56:36 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:36 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 54-55
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:228 - Task 69 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1fce0e0f
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:237 - Task 69 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1fce0e0f
2022-02-14 10:56:36 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 69 with length 1
2022-02-14 10:56:36 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 69: [56]
2022-02-14 10:56:36 INFO  Executor:57 - Finished task 54.0 in stage 9.0 (TID 69). 5587 bytes result sent to driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:36 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Starting task 55.0 in stage 9.0 (TID 70, Clairvoyant-320, executor driver, partition 55, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:36 INFO  Executor:57 - Running task 55.0 in stage 9.0 (TID 70)
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Finished task 54.0 in stage 9.0 (TID 69) in 30 ms on Clairvoyant-320 (executor driver) (61/200)
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:36 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:36 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 55-56
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:228 - Task 70 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@468680d3
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:237 - Task 70 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@468680d3
2022-02-14 10:56:36 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 70 with length 1
2022-02-14 10:56:36 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 70: [56]
2022-02-14 10:56:36 INFO  Executor:57 - Finished task 55.0 in stage 9.0 (TID 70). 5587 bytes result sent to driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:36 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Starting task 56.0 in stage 9.0 (TID 71, Clairvoyant-320, executor driver, partition 56, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:36 INFO  Executor:57 - Running task 56.0 in stage 9.0 (TID 71)
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Finished task 55.0 in stage 9.0 (TID 70) in 40 ms on Clairvoyant-320 (executor driver) (62/200)
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:36 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:36 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 56-57
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 5 ms
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 5 ms
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:228 - Task 71 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@29d603fc
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:237 - Task 71 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@29d603fc
2022-02-14 10:56:36 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 71 with length 1
2022-02-14 10:56:36 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 71: [56]
2022-02-14 10:56:36 INFO  Executor:57 - Finished task 56.0 in stage 9.0 (TID 71). 5544 bytes result sent to driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:36 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Starting task 57.0 in stage 9.0 (TID 72, Clairvoyant-320, executor driver, partition 57, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Finished task 56.0 in stage 9.0 (TID 71) in 37 ms on Clairvoyant-320 (executor driver) (63/200)
2022-02-14 10:56:36 INFO  Executor:57 - Running task 57.0 in stage 9.0 (TID 72)
2022-02-14 10:56:36 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:36 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 57-58
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:228 - Task 72 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@51858ebf
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:237 - Task 72 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@51858ebf
2022-02-14 10:56:36 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 72 with length 1
2022-02-14 10:56:36 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 72: [56]
2022-02-14 10:56:36 INFO  Executor:57 - Finished task 57.0 in stage 9.0 (TID 72). 5587 bytes result sent to driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:36 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Starting task 58.0 in stage 9.0 (TID 73, Clairvoyant-320, executor driver, partition 58, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Finished task 57.0 in stage 9.0 (TID 72) in 49 ms on Clairvoyant-320 (executor driver) (64/200)
2022-02-14 10:56:36 INFO  Executor:57 - Running task 58.0 in stage 9.0 (TID 73)
2022-02-14 10:56:36 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:36 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 58-59
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:228 - Task 73 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4a233f9
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:237 - Task 73 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4a233f9
2022-02-14 10:56:36 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 73 with length 1
2022-02-14 10:56:36 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 73: [56]
2022-02-14 10:56:36 INFO  Executor:57 - Finished task 58.0 in stage 9.0 (TID 73). 5544 bytes result sent to driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:36 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Starting task 59.0 in stage 9.0 (TID 74, Clairvoyant-320, executor driver, partition 59, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:36 INFO  Executor:57 - Running task 59.0 in stage 9.0 (TID 74)
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Finished task 58.0 in stage 9.0 (TID 73) in 44 ms on Clairvoyant-320 (executor driver) (65/200)
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:36 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:36 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 59-60
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:228 - Task 74 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1ed7e062
2022-02-14 10:56:36 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:36 DEBUG TaskMemoryManager:237 - Task 74 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1ed7e062
2022-02-14 10:56:36 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 74 with length 1
2022-02-14 10:56:36 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 74: [56]
2022-02-14 10:56:36 INFO  Executor:57 - Finished task 59.0 in stage 9.0 (TID 74). 5587 bytes result sent to driver
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:36 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Starting task 60.0 in stage 9.0 (TID 75, Clairvoyant-320, executor driver, partition 60, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:36 INFO  Executor:57 - Running task 60.0 in stage 9.0 (TID 75)
2022-02-14 10:56:36 INFO  TaskSetManager:57 - Finished task 59.0 in stage 9.0 (TID 74) in 42 ms on Clairvoyant-320 (executor driver) (66/200)
2022-02-14 10:56:36 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:36 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:36 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 60-61
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:36 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:36 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 75 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@482dbb5
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 75 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@482dbb5
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 75 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 75: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 60.0 in stage 9.0 (TID 75). 5587 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 61.0 in stage 9.0 (TID 76, Clairvoyant-320, executor driver, partition 61, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 61.0 in stage 9.0 (TID 76)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 60.0 in stage 9.0 (TID 75) in 59 ms on Clairvoyant-320 (executor driver) (67/200)
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 61-62
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 76 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@dd8c15a
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 76 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@dd8c15a
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 76 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 76: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 61.0 in stage 9.0 (TID 76). 5544 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 62.0 in stage 9.0 (TID 77, Clairvoyant-320, executor driver, partition 62, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 62.0 in stage 9.0 (TID 77)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 61.0 in stage 9.0 (TID 76) in 34 ms on Clairvoyant-320 (executor driver) (68/200)
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 62-63
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 77 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@884980e
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 77 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@884980e
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 77 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 77: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 62.0 in stage 9.0 (TID 77). 5544 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 63.0 in stage 9.0 (TID 78, Clairvoyant-320, executor driver, partition 63, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 63.0 in stage 9.0 (TID 78)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 62.0 in stage 9.0 (TID 77) in 41 ms on Clairvoyant-320 (executor driver) (69/200)
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 63-64
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 78 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2ddefb37
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 78 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2ddefb37
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 78 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 78: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 63.0 in stage 9.0 (TID 78). 5544 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 64.0 in stage 9.0 (TID 79, Clairvoyant-320, executor driver, partition 64, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 64.0 in stage 9.0 (TID 79)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 63.0 in stage 9.0 (TID 78) in 35 ms on Clairvoyant-320 (executor driver) (70/200)
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 64-65
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 79 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@41e235f
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 79 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@41e235f
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 79 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 79: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 64.0 in stage 9.0 (TID 79). 5587 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 65.0 in stage 9.0 (TID 80, Clairvoyant-320, executor driver, partition 65, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 65.0 in stage 9.0 (TID 80)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 64.0 in stage 9.0 (TID 79) in 46 ms on Clairvoyant-320 (executor driver) (71/200)
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 65-66
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 80 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@10998cf2
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 80 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@10998cf2
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 80 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 80: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 65.0 in stage 9.0 (TID 80). 5587 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 66.0 in stage 9.0 (TID 81, Clairvoyant-320, executor driver, partition 66, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 66.0 in stage 9.0 (TID 81)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 65.0 in stage 9.0 (TID 80) in 35 ms on Clairvoyant-320 (executor driver) (72/200)
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 66-67
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 81 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@54ad4aca
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 81 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@54ad4aca
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 81 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 81: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 66.0 in stage 9.0 (TID 81). 5544 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 67.0 in stage 9.0 (TID 82, Clairvoyant-320, executor driver, partition 67, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 67.0 in stage 9.0 (TID 82)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 66.0 in stage 9.0 (TID 81) in 38 ms on Clairvoyant-320 (executor driver) (73/200)
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 67-68
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 82 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@ab3cd9a
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 82 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@ab3cd9a
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 82 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 82: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 67.0 in stage 9.0 (TID 82). 5587 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 68.0 in stage 9.0 (TID 83, Clairvoyant-320, executor driver, partition 68, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 67.0 in stage 9.0 (TID 82) in 32 ms on Clairvoyant-320 (executor driver) (74/200)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 68.0 in stage 9.0 (TID 83)
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 68-69
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 83 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@301be72a
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 83 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@301be72a
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 83 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 83: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 68.0 in stage 9.0 (TID 83). 5587 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 69.0 in stage 9.0 (TID 84, Clairvoyant-320, executor driver, partition 69, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 69.0 in stage 9.0 (TID 84)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 68.0 in stage 9.0 (TID 83) in 40 ms on Clairvoyant-320 (executor driver) (75/200)
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 69-70
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 84 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@43db6ad6
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 84 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@43db6ad6
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 84 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 84: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 69.0 in stage 9.0 (TID 84). 5544 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 70.0 in stage 9.0 (TID 85, Clairvoyant-320, executor driver, partition 70, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 69.0 in stage 9.0 (TID 84) in 36 ms on Clairvoyant-320 (executor driver) (76/200)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 70.0 in stage 9.0 (TID 85)
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 70-71
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 85 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@604bf417
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 85 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@604bf417
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 85 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 85: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 70.0 in stage 9.0 (TID 85). 5544 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 71.0 in stage 9.0 (TID 86, Clairvoyant-320, executor driver, partition 71, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 70.0 in stage 9.0 (TID 85) in 36 ms on Clairvoyant-320 (executor driver) (77/200)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 71.0 in stage 9.0 (TID 86)
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 71-72
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 86 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@6e68921
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 86 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@6e68921
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 86 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 86: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 71.0 in stage 9.0 (TID 86). 5544 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 72.0 in stage 9.0 (TID 87, Clairvoyant-320, executor driver, partition 72, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 72.0 in stage 9.0 (TID 87)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 71.0 in stage 9.0 (TID 86) in 39 ms on Clairvoyant-320 (executor driver) (78/200)
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 72-73
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 87 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2eda44ad
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 87 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2eda44ad
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 87 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 87: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 72.0 in stage 9.0 (TID 87). 5544 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 73.0 in stage 9.0 (TID 88, Clairvoyant-320, executor driver, partition 73, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 72.0 in stage 9.0 (TID 87) in 32 ms on Clairvoyant-320 (executor driver) (79/200)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 73.0 in stage 9.0 (TID 88)
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 73-74
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 88 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4f2e1806
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 88 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4f2e1806
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 88 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 88: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 73.0 in stage 9.0 (TID 88). 5544 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 74.0 in stage 9.0 (TID 89, Clairvoyant-320, executor driver, partition 74, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 73.0 in stage 9.0 (TID 88) in 37 ms on Clairvoyant-320 (executor driver) (80/200)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 74.0 in stage 9.0 (TID 89)
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 74-75
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 89 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@350e8ef3
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 89 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@350e8ef3
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 89 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 89: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 74.0 in stage 9.0 (TID 89). 5587 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 75.0 in stage 9.0 (TID 90, Clairvoyant-320, executor driver, partition 75, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 75.0 in stage 9.0 (TID 90)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 74.0 in stage 9.0 (TID 89) in 41 ms on Clairvoyant-320 (executor driver) (81/200)
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 75-76
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 90 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@158b05fa
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 90 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@158b05fa
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 90 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 90: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 75.0 in stage 9.0 (TID 90). 5544 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 76.0 in stage 9.0 (TID 91, Clairvoyant-320, executor driver, partition 76, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 75.0 in stage 9.0 (TID 90) in 35 ms on Clairvoyant-320 (executor driver) (82/200)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 76.0 in stage 9.0 (TID 91)
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 76-77
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 91 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@10ce5930
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 91 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@10ce5930
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 91 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 91: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 76.0 in stage 9.0 (TID 91). 5544 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 77.0 in stage 9.0 (TID 92, Clairvoyant-320, executor driver, partition 77, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 76.0 in stage 9.0 (TID 91) in 35 ms on Clairvoyant-320 (executor driver) (83/200)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 77.0 in stage 9.0 (TID 92)
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 77-78
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 92 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1087de7e
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 92 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1087de7e
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 92 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 92: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 77.0 in stage 9.0 (TID 92). 5544 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 78.0 in stage 9.0 (TID 93, Clairvoyant-320, executor driver, partition 78, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 77.0 in stage 9.0 (TID 92) in 45 ms on Clairvoyant-320 (executor driver) (84/200)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 78.0 in stage 9.0 (TID 93)
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 78-79
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 93 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@36aa8909
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 93 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@36aa8909
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 93 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 93: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 78.0 in stage 9.0 (TID 93). 5544 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 79.0 in stage 9.0 (TID 94, Clairvoyant-320, executor driver, partition 79, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 78.0 in stage 9.0 (TID 93) in 34 ms on Clairvoyant-320 (executor driver) (85/200)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 79.0 in stage 9.0 (TID 94)
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 79-80
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 94 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@20bf84ad
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 94 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@20bf84ad
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 94 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 94: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 79.0 in stage 9.0 (TID 94). 5587 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 80.0 in stage 9.0 (TID 95, Clairvoyant-320, executor driver, partition 80, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 80.0 in stage 9.0 (TID 95)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 79.0 in stage 9.0 (TID 94) in 41 ms on Clairvoyant-320 (executor driver) (86/200)
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 80-81
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 95 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@75066dab
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 95 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@75066dab
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 95 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 95: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 80.0 in stage 9.0 (TID 95). 5544 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 81.0 in stage 9.0 (TID 96, Clairvoyant-320, executor driver, partition 81, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 80.0 in stage 9.0 (TID 95) in 42 ms on Clairvoyant-320 (executor driver) (87/200)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 81.0 in stage 9.0 (TID 96)
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 81-82
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 96 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5849b355
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 96 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5849b355
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 96 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 96: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 81.0 in stage 9.0 (TID 96). 5587 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 82.0 in stage 9.0 (TID 97, Clairvoyant-320, executor driver, partition 82, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 81.0 in stage 9.0 (TID 96) in 56 ms on Clairvoyant-320 (executor driver) (88/200)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 82.0 in stage 9.0 (TID 97)
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 82-83
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 97 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4c7dfce9
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 97 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4c7dfce9
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 97 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 97: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 82.0 in stage 9.0 (TID 97). 5544 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 83.0 in stage 9.0 (TID 98, Clairvoyant-320, executor driver, partition 83, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 83.0 in stage 9.0 (TID 98)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 82.0 in stage 9.0 (TID 97) in 44 ms on Clairvoyant-320 (executor driver) (89/200)
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 83-84
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 98 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@30bb7245
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 98 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@30bb7245
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 98 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 98: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 83.0 in stage 9.0 (TID 98). 5544 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 84.0 in stage 9.0 (TID 99, Clairvoyant-320, executor driver, partition 84, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 83.0 in stage 9.0 (TID 98) in 41 ms on Clairvoyant-320 (executor driver) (90/200)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 84.0 in stage 9.0 (TID 99)
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 84-85
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 99 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@24f9f069
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:237 - Task 99 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@24f9f069
2022-02-14 10:56:37 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 99 with length 1
2022-02-14 10:56:37 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 99: [56]
2022-02-14 10:56:37 INFO  Executor:57 - Finished task 84.0 in stage 9.0 (TID 99). 5544 bytes result sent to driver
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:37 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Starting task 85.0 in stage 9.0 (TID 100, Clairvoyant-320, executor driver, partition 85, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:37 INFO  Executor:57 - Running task 85.0 in stage 9.0 (TID 100)
2022-02-14 10:56:37 INFO  TaskSetManager:57 - Finished task 84.0 in stage 9.0 (TID 99) in 46 ms on Clairvoyant-320 (executor driver) (91/200)
2022-02-14 10:56:37 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:37 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:37 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 85-86
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:37 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:37 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:37 DEBUG TaskMemoryManager:228 - Task 100 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7048c254
2022-02-14 10:56:37 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:237 - Task 100 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7048c254
2022-02-14 10:56:38 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 100 with length 1
2022-02-14 10:56:38 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 100: [56]
2022-02-14 10:56:38 INFO  Executor:57 - Finished task 85.0 in stage 9.0 (TID 100). 5544 bytes result sent to driver
2022-02-14 10:56:38 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Starting task 86.0 in stage 9.0 (TID 101, Clairvoyant-320, executor driver, partition 86, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:38 INFO  Executor:57 - Running task 86.0 in stage 9.0 (TID 101)
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Finished task 85.0 in stage 9.0 (TID 100) in 177 ms on Clairvoyant-320 (executor driver) (92/200)
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:38 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:38 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 86-87
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:228 - Task 101 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1c0db2d
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:237 - Task 101 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1c0db2d
2022-02-14 10:56:38 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 101 with length 1
2022-02-14 10:56:38 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 101: [56]
2022-02-14 10:56:38 INFO  Executor:57 - Finished task 86.0 in stage 9.0 (TID 101). 5587 bytes result sent to driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:38 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Starting task 87.0 in stage 9.0 (TID 102, Clairvoyant-320, executor driver, partition 87, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:38 INFO  Executor:57 - Running task 87.0 in stage 9.0 (TID 102)
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Finished task 86.0 in stage 9.0 (TID 101) in 61 ms on Clairvoyant-320 (executor driver) (93/200)
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:38 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:38 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 87-88
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:228 - Task 102 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5690c6aa
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:237 - Task 102 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5690c6aa
2022-02-14 10:56:38 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 102 with length 1
2022-02-14 10:56:38 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 102: [56]
2022-02-14 10:56:38 INFO  Executor:57 - Finished task 87.0 in stage 9.0 (TID 102). 5587 bytes result sent to driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:38 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Starting task 88.0 in stage 9.0 (TID 103, Clairvoyant-320, executor driver, partition 88, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:38 INFO  Executor:57 - Running task 88.0 in stage 9.0 (TID 103)
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Finished task 87.0 in stage 9.0 (TID 102) in 36 ms on Clairvoyant-320 (executor driver) (94/200)
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:38 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:38 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 88-89
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:228 - Task 103 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7cf50cc
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:237 - Task 103 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7cf50cc
2022-02-14 10:56:38 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 103 with length 1
2022-02-14 10:56:38 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 103: [56]
2022-02-14 10:56:38 INFO  Executor:57 - Finished task 88.0 in stage 9.0 (TID 103). 5587 bytes result sent to driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:38 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Starting task 89.0 in stage 9.0 (TID 104, Clairvoyant-320, executor driver, partition 89, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Finished task 88.0 in stage 9.0 (TID 103) in 40 ms on Clairvoyant-320 (executor driver) (95/200)
2022-02-14 10:56:38 INFO  Executor:57 - Running task 89.0 in stage 9.0 (TID 104)
2022-02-14 10:56:38 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:38 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 89-90
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:228 - Task 104 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@73f3ba9b
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:237 - Task 104 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@73f3ba9b
2022-02-14 10:56:38 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 104 with length 1
2022-02-14 10:56:38 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 104: [56]
2022-02-14 10:56:38 INFO  Executor:57 - Finished task 89.0 in stage 9.0 (TID 104). 5544 bytes result sent to driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:38 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Starting task 90.0 in stage 9.0 (TID 105, Clairvoyant-320, executor driver, partition 90, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Finished task 89.0 in stage 9.0 (TID 104) in 45 ms on Clairvoyant-320 (executor driver) (96/200)
2022-02-14 10:56:38 INFO  Executor:57 - Running task 90.0 in stage 9.0 (TID 105)
2022-02-14 10:56:38 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:38 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 90-91
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:228 - Task 105 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2be16bf6
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:237 - Task 105 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2be16bf6
2022-02-14 10:56:38 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 105 with length 1
2022-02-14 10:56:38 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 105: [56]
2022-02-14 10:56:38 INFO  Executor:57 - Finished task 90.0 in stage 9.0 (TID 105). 5544 bytes result sent to driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:38 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Starting task 91.0 in stage 9.0 (TID 106, Clairvoyant-320, executor driver, partition 91, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:38 INFO  Executor:57 - Running task 91.0 in stage 9.0 (TID 106)
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Finished task 90.0 in stage 9.0 (TID 105) in 36 ms on Clairvoyant-320 (executor driver) (97/200)
2022-02-14 10:56:38 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:38 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 91-92
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:228 - Task 106 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@37a3d226
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:237 - Task 106 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@37a3d226
2022-02-14 10:56:38 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 106 with length 1
2022-02-14 10:56:38 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 106: [56]
2022-02-14 10:56:38 INFO  Executor:57 - Finished task 91.0 in stage 9.0 (TID 106). 5544 bytes result sent to driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:38 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Starting task 92.0 in stage 9.0 (TID 107, Clairvoyant-320, executor driver, partition 92, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Finished task 91.0 in stage 9.0 (TID 106) in 54 ms on Clairvoyant-320 (executor driver) (98/200)
2022-02-14 10:56:38 INFO  Executor:57 - Running task 92.0 in stage 9.0 (TID 107)
2022-02-14 10:56:38 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:38 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 92-93
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:228 - Task 107 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@28f41663
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:237 - Task 107 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@28f41663
2022-02-14 10:56:38 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 107 with length 1
2022-02-14 10:56:38 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 107: [56]
2022-02-14 10:56:38 INFO  Executor:57 - Finished task 92.0 in stage 9.0 (TID 107). 5544 bytes result sent to driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:38 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Starting task 93.0 in stage 9.0 (TID 108, Clairvoyant-320, executor driver, partition 93, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Finished task 92.0 in stage 9.0 (TID 107) in 45 ms on Clairvoyant-320 (executor driver) (99/200)
2022-02-14 10:56:38 INFO  Executor:57 - Running task 93.0 in stage 9.0 (TID 108)
2022-02-14 10:56:38 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:38 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 93-94
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:228 - Task 108 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3eabbc87
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:237 - Task 108 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3eabbc87
2022-02-14 10:56:38 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 108 with length 1
2022-02-14 10:56:38 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 108: [56]
2022-02-14 10:56:38 INFO  Executor:57 - Finished task 93.0 in stage 9.0 (TID 108). 5544 bytes result sent to driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:38 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Starting task 94.0 in stage 9.0 (TID 109, Clairvoyant-320, executor driver, partition 94, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:38 INFO  Executor:57 - Running task 94.0 in stage 9.0 (TID 109)
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Finished task 93.0 in stage 9.0 (TID 108) in 36 ms on Clairvoyant-320 (executor driver) (100/200)
2022-02-14 10:56:38 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:38 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 94-95
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:228 - Task 109 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2981efeb
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:237 - Task 109 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2981efeb
2022-02-14 10:56:38 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 109 with length 1
2022-02-14 10:56:38 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 109: [56]
2022-02-14 10:56:38 INFO  Executor:57 - Finished task 94.0 in stage 9.0 (TID 109). 5544 bytes result sent to driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:38 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Starting task 95.0 in stage 9.0 (TID 110, Clairvoyant-320, executor driver, partition 95, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Finished task 94.0 in stage 9.0 (TID 109) in 44 ms on Clairvoyant-320 (executor driver) (101/200)
2022-02-14 10:56:38 INFO  Executor:57 - Running task 95.0 in stage 9.0 (TID 110)
2022-02-14 10:56:38 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:38 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 95-96
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:228 - Task 110 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3639df8c
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:237 - Task 110 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3639df8c
2022-02-14 10:56:38 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 110 with length 1
2022-02-14 10:56:38 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 110: [56]
2022-02-14 10:56:38 INFO  Executor:57 - Finished task 95.0 in stage 9.0 (TID 110). 5544 bytes result sent to driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:38 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Starting task 96.0 in stage 9.0 (TID 111, Clairvoyant-320, executor driver, partition 96, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Finished task 95.0 in stage 9.0 (TID 110) in 42 ms on Clairvoyant-320 (executor driver) (102/200)
2022-02-14 10:56:38 INFO  Executor:57 - Running task 96.0 in stage 9.0 (TID 111)
2022-02-14 10:56:38 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:38 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 96-97
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:228 - Task 111 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@735ae668
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:237 - Task 111 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@735ae668
2022-02-14 10:56:38 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 111 with length 1
2022-02-14 10:56:38 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 111: [56]
2022-02-14 10:56:38 INFO  Executor:57 - Finished task 96.0 in stage 9.0 (TID 111). 5544 bytes result sent to driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:38 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Starting task 98.0 in stage 9.0 (TID 112, Clairvoyant-320, executor driver, partition 98, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Finished task 96.0 in stage 9.0 (TID 111) in 50 ms on Clairvoyant-320 (executor driver) (103/200)
2022-02-14 10:56:38 INFO  Executor:57 - Running task 98.0 in stage 9.0 (TID 112)
2022-02-14 10:56:38 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:38 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 98-99
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:228 - Task 112 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@c788fdd
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:237 - Task 112 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@c788fdd
2022-02-14 10:56:38 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 112 with length 1
2022-02-14 10:56:38 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 112: [56]
2022-02-14 10:56:38 INFO  Executor:57 - Finished task 98.0 in stage 9.0 (TID 112). 5587 bytes result sent to driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:38 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Starting task 99.0 in stage 9.0 (TID 113, Clairvoyant-320, executor driver, partition 99, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:38 INFO  Executor:57 - Running task 99.0 in stage 9.0 (TID 113)
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Finished task 98.0 in stage 9.0 (TID 112) in 63 ms on Clairvoyant-320 (executor driver) (104/200)
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:38 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:38 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 99-100
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:228 - Task 113 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2087191a
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:237 - Task 113 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2087191a
2022-02-14 10:56:38 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 113 with length 1
2022-02-14 10:56:38 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 113: [56]
2022-02-14 10:56:38 INFO  Executor:57 - Finished task 99.0 in stage 9.0 (TID 113). 5544 bytes result sent to driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:38 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Starting task 100.0 in stage 9.0 (TID 114, Clairvoyant-320, executor driver, partition 100, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Finished task 99.0 in stage 9.0 (TID 113) in 39 ms on Clairvoyant-320 (executor driver) (105/200)
2022-02-14 10:56:38 INFO  Executor:57 - Running task 100.0 in stage 9.0 (TID 114)
2022-02-14 10:56:38 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:38 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 100-101
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:228 - Task 114 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5acdb501
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:237 - Task 114 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5acdb501
2022-02-14 10:56:38 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 114 with length 1
2022-02-14 10:56:38 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 114: [56]
2022-02-14 10:56:38 INFO  Executor:57 - Finished task 100.0 in stage 9.0 (TID 114). 5587 bytes result sent to driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:38 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Starting task 101.0 in stage 9.0 (TID 115, Clairvoyant-320, executor driver, partition 101, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Finished task 100.0 in stage 9.0 (TID 114) in 41 ms on Clairvoyant-320 (executor driver) (106/200)
2022-02-14 10:56:38 INFO  Executor:57 - Running task 101.0 in stage 9.0 (TID 115)
2022-02-14 10:56:38 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:38 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 101-102
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:228 - Task 115 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@39507d9a
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:237 - Task 115 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@39507d9a
2022-02-14 10:56:38 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 115 with length 1
2022-02-14 10:56:38 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 115: [56]
2022-02-14 10:56:38 INFO  Executor:57 - Finished task 101.0 in stage 9.0 (TID 115). 5544 bytes result sent to driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:38 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Starting task 102.0 in stage 9.0 (TID 116, Clairvoyant-320, executor driver, partition 102, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:38 INFO  Executor:57 - Running task 102.0 in stage 9.0 (TID 116)
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Finished task 101.0 in stage 9.0 (TID 115) in 43 ms on Clairvoyant-320 (executor driver) (107/200)
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:38 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:38 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 102-103
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:228 - Task 116 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@408d457
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:237 - Task 116 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@408d457
2022-02-14 10:56:38 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 116 with length 1
2022-02-14 10:56:38 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 116: [56]
2022-02-14 10:56:38 INFO  Executor:57 - Finished task 102.0 in stage 9.0 (TID 116). 5544 bytes result sent to driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:38 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Starting task 103.0 in stage 9.0 (TID 117, Clairvoyant-320, executor driver, partition 103, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Finished task 102.0 in stage 9.0 (TID 116) in 41 ms on Clairvoyant-320 (executor driver) (108/200)
2022-02-14 10:56:38 INFO  Executor:57 - Running task 103.0 in stage 9.0 (TID 117)
2022-02-14 10:56:38 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:38 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 103-104
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:228 - Task 117 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@55391df5
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:237 - Task 117 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@55391df5
2022-02-14 10:56:38 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 117 with length 1
2022-02-14 10:56:38 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 117: [56]
2022-02-14 10:56:38 INFO  Executor:57 - Finished task 103.0 in stage 9.0 (TID 117). 5587 bytes result sent to driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:38 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Starting task 104.0 in stage 9.0 (TID 118, Clairvoyant-320, executor driver, partition 104, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:38 INFO  Executor:57 - Running task 104.0 in stage 9.0 (TID 118)
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Finished task 103.0 in stage 9.0 (TID 117) in 46 ms on Clairvoyant-320 (executor driver) (109/200)
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:38 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:38 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 104-105
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:228 - Task 118 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@18157c47
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:237 - Task 118 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@18157c47
2022-02-14 10:56:38 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 118 with length 1
2022-02-14 10:56:38 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 118: [56]
2022-02-14 10:56:38 INFO  Executor:57 - Finished task 104.0 in stage 9.0 (TID 118). 5544 bytes result sent to driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:38 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Starting task 105.0 in stage 9.0 (TID 119, Clairvoyant-320, executor driver, partition 105, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Finished task 104.0 in stage 9.0 (TID 118) in 32 ms on Clairvoyant-320 (executor driver) (110/200)
2022-02-14 10:56:38 INFO  Executor:57 - Running task 105.0 in stage 9.0 (TID 119)
2022-02-14 10:56:38 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:38 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 105-106
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:228 - Task 119 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5ff35555
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:237 - Task 119 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5ff35555
2022-02-14 10:56:38 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 119 with length 1
2022-02-14 10:56:38 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 119: [56]
2022-02-14 10:56:38 INFO  Executor:57 - Finished task 105.0 in stage 9.0 (TID 119). 5544 bytes result sent to driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:38 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Starting task 106.0 in stage 9.0 (TID 120, Clairvoyant-320, executor driver, partition 106, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Finished task 105.0 in stage 9.0 (TID 119) in 37 ms on Clairvoyant-320 (executor driver) (111/200)
2022-02-14 10:56:38 INFO  Executor:57 - Running task 106.0 in stage 9.0 (TID 120)
2022-02-14 10:56:38 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:38 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 106-107
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:38 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:38 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:228 - Task 120 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@32f31830
2022-02-14 10:56:38 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:38 DEBUG TaskMemoryManager:237 - Task 120 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@32f31830
2022-02-14 10:56:38 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 120 with length 1
2022-02-14 10:56:38 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 120: [56]
2022-02-14 10:56:38 INFO  Executor:57 - Finished task 106.0 in stage 9.0 (TID 120). 5544 bytes result sent to driver
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:38 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Starting task 107.0 in stage 9.0 (TID 121, Clairvoyant-320, executor driver, partition 107, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:38 INFO  Executor:57 - Running task 107.0 in stage 9.0 (TID 121)
2022-02-14 10:56:38 INFO  TaskSetManager:57 - Finished task 106.0 in stage 9.0 (TID 120) in 44 ms on Clairvoyant-320 (executor driver) (112/200)
2022-02-14 10:56:38 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:38 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:38 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 107-108
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:228 - Task 121 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3a0abbf9
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:237 - Task 121 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3a0abbf9
2022-02-14 10:56:39 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 121 with length 1
2022-02-14 10:56:39 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 121: [56]
2022-02-14 10:56:39 INFO  Executor:57 - Finished task 107.0 in stage 9.0 (TID 121). 5544 bytes result sent to driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:39 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Starting task 109.0 in stage 9.0 (TID 122, Clairvoyant-320, executor driver, partition 109, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:39 INFO  Executor:57 - Running task 109.0 in stage 9.0 (TID 122)
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Finished task 107.0 in stage 9.0 (TID 121) in 53 ms on Clairvoyant-320 (executor driver) (113/200)
2022-02-14 10:56:39 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:39 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 109-110
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:228 - Task 122 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@387223d5
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:237 - Task 122 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@387223d5
2022-02-14 10:56:39 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 122 with length 1
2022-02-14 10:56:39 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 122: [56]
2022-02-14 10:56:39 INFO  Executor:57 - Finished task 109.0 in stage 9.0 (TID 122). 5544 bytes result sent to driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:39 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Starting task 110.0 in stage 9.0 (TID 123, Clairvoyant-320, executor driver, partition 110, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Finished task 109.0 in stage 9.0 (TID 122) in 50 ms on Clairvoyant-320 (executor driver) (114/200)
2022-02-14 10:56:39 INFO  Executor:57 - Running task 110.0 in stage 9.0 (TID 123)
2022-02-14 10:56:39 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:39 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 110-111
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:228 - Task 123 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@81a377f
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:237 - Task 123 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@81a377f
2022-02-14 10:56:39 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 123 with length 1
2022-02-14 10:56:39 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 123: [56]
2022-02-14 10:56:39 INFO  Executor:57 - Finished task 110.0 in stage 9.0 (TID 123). 5544 bytes result sent to driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:39 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Starting task 111.0 in stage 9.0 (TID 124, Clairvoyant-320, executor driver, partition 111, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:39 INFO  Executor:57 - Running task 111.0 in stage 9.0 (TID 124)
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Finished task 110.0 in stage 9.0 (TID 123) in 54 ms on Clairvoyant-320 (executor driver) (115/200)
2022-02-14 10:56:39 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:39 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 111-112
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:228 - Task 124 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@37783e36
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:237 - Task 124 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@37783e36
2022-02-14 10:56:39 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 124 with length 1
2022-02-14 10:56:39 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 124: [56]
2022-02-14 10:56:39 INFO  Executor:57 - Finished task 111.0 in stage 9.0 (TID 124). 5544 bytes result sent to driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:39 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Starting task 112.0 in stage 9.0 (TID 125, Clairvoyant-320, executor driver, partition 112, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:39 INFO  Executor:57 - Running task 112.0 in stage 9.0 (TID 125)
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Finished task 111.0 in stage 9.0 (TID 124) in 37 ms on Clairvoyant-320 (executor driver) (116/200)
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:39 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:39 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 112-113
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:228 - Task 125 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@17717d77
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:237 - Task 125 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@17717d77
2022-02-14 10:56:39 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 125 with length 1
2022-02-14 10:56:39 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 125: [56]
2022-02-14 10:56:39 INFO  Executor:57 - Finished task 112.0 in stage 9.0 (TID 125). 5587 bytes result sent to driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:39 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Starting task 113.0 in stage 9.0 (TID 126, Clairvoyant-320, executor driver, partition 113, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:39 INFO  Executor:57 - Running task 113.0 in stage 9.0 (TID 126)
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Finished task 112.0 in stage 9.0 (TID 125) in 58 ms on Clairvoyant-320 (executor driver) (117/200)
2022-02-14 10:56:39 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:39 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 113-114
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:228 - Task 126 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5fa86ec7
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:237 - Task 126 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5fa86ec7
2022-02-14 10:56:39 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 126 with length 1
2022-02-14 10:56:39 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 126: [56]
2022-02-14 10:56:39 INFO  Executor:57 - Finished task 113.0 in stage 9.0 (TID 126). 5544 bytes result sent to driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:39 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Starting task 114.0 in stage 9.0 (TID 127, Clairvoyant-320, executor driver, partition 114, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Finished task 113.0 in stage 9.0 (TID 126) in 45 ms on Clairvoyant-320 (executor driver) (118/200)
2022-02-14 10:56:39 INFO  Executor:57 - Running task 114.0 in stage 9.0 (TID 127)
2022-02-14 10:56:39 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:39 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 114-115
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:228 - Task 127 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@12f0f3e2
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:237 - Task 127 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@12f0f3e2
2022-02-14 10:56:39 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 127 with length 1
2022-02-14 10:56:39 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 127: [56]
2022-02-14 10:56:39 INFO  Executor:57 - Finished task 114.0 in stage 9.0 (TID 127). 5544 bytes result sent to driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:39 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Starting task 115.0 in stage 9.0 (TID 128, Clairvoyant-320, executor driver, partition 115, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:39 INFO  Executor:57 - Running task 115.0 in stage 9.0 (TID 128)
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Finished task 114.0 in stage 9.0 (TID 127) in 52 ms on Clairvoyant-320 (executor driver) (119/200)
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:39 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:39 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 115-116
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:228 - Task 128 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@704c45ef
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:237 - Task 128 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@704c45ef
2022-02-14 10:56:39 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 128 with length 1
2022-02-14 10:56:39 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 128: [56]
2022-02-14 10:56:39 INFO  Executor:57 - Finished task 115.0 in stage 9.0 (TID 128). 5587 bytes result sent to driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:39 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Starting task 117.0 in stage 9.0 (TID 129, Clairvoyant-320, executor driver, partition 117, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Finished task 115.0 in stage 9.0 (TID 128) in 47 ms on Clairvoyant-320 (executor driver) (120/200)
2022-02-14 10:56:39 INFO  Executor:57 - Running task 117.0 in stage 9.0 (TID 129)
2022-02-14 10:56:39 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:39 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 117-118
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:228 - Task 129 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@adaf844
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:237 - Task 129 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@adaf844
2022-02-14 10:56:39 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 129 with length 1
2022-02-14 10:56:39 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 129: [56]
2022-02-14 10:56:39 INFO  Executor:57 - Finished task 117.0 in stage 9.0 (TID 129). 5544 bytes result sent to driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:39 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Starting task 118.0 in stage 9.0 (TID 130, Clairvoyant-320, executor driver, partition 118, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Finished task 117.0 in stage 9.0 (TID 129) in 50 ms on Clairvoyant-320 (executor driver) (121/200)
2022-02-14 10:56:39 INFO  Executor:57 - Running task 118.0 in stage 9.0 (TID 130)
2022-02-14 10:56:39 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:39 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 118-119
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:228 - Task 130 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3e856632
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:237 - Task 130 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3e856632
2022-02-14 10:56:39 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 130 with length 1
2022-02-14 10:56:39 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 130: [56]
2022-02-14 10:56:39 INFO  Executor:57 - Finished task 118.0 in stage 9.0 (TID 130). 5544 bytes result sent to driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:39 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Starting task 119.0 in stage 9.0 (TID 131, Clairvoyant-320, executor driver, partition 119, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:39 INFO  Executor:57 - Running task 119.0 in stage 9.0 (TID 131)
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Finished task 118.0 in stage 9.0 (TID 130) in 43 ms on Clairvoyant-320 (executor driver) (122/200)
2022-02-14 10:56:39 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:39 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 119-120
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:228 - Task 131 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@30f41410
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:237 - Task 131 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@30f41410
2022-02-14 10:56:39 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 131 with length 1
2022-02-14 10:56:39 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 131: [56]
2022-02-14 10:56:39 INFO  Executor:57 - Finished task 119.0 in stage 9.0 (TID 131). 5544 bytes result sent to driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:39 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Starting task 120.0 in stage 9.0 (TID 132, Clairvoyant-320, executor driver, partition 120, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Finished task 119.0 in stage 9.0 (TID 131) in 44 ms on Clairvoyant-320 (executor driver) (123/200)
2022-02-14 10:56:39 INFO  Executor:57 - Running task 120.0 in stage 9.0 (TID 132)
2022-02-14 10:56:39 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:39 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 120-121
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:228 - Task 132 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@76ed70e3
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:237 - Task 132 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@76ed70e3
2022-02-14 10:56:39 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 132 with length 1
2022-02-14 10:56:39 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 132: [56]
2022-02-14 10:56:39 INFO  Executor:57 - Finished task 120.0 in stage 9.0 (TID 132). 5587 bytes result sent to driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:39 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Starting task 121.0 in stage 9.0 (TID 133, Clairvoyant-320, executor driver, partition 121, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Finished task 120.0 in stage 9.0 (TID 132) in 39 ms on Clairvoyant-320 (executor driver) (124/200)
2022-02-14 10:56:39 INFO  Executor:57 - Running task 121.0 in stage 9.0 (TID 133)
2022-02-14 10:56:39 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:39 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 121-122
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:228 - Task 133 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1c73f732
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:237 - Task 133 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1c73f732
2022-02-14 10:56:39 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 133 with length 1
2022-02-14 10:56:39 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 133: [56]
2022-02-14 10:56:39 INFO  Executor:57 - Finished task 121.0 in stage 9.0 (TID 133). 5544 bytes result sent to driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:39 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Starting task 122.0 in stage 9.0 (TID 134, Clairvoyant-320, executor driver, partition 122, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:39 INFO  Executor:57 - Running task 122.0 in stage 9.0 (TID 134)
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Finished task 121.0 in stage 9.0 (TID 133) in 46 ms on Clairvoyant-320 (executor driver) (125/200)
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:39 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:39 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 122-123
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:228 - Task 134 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@b6c226a
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:237 - Task 134 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@b6c226a
2022-02-14 10:56:39 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 134 with length 1
2022-02-14 10:56:39 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 134: [56]
2022-02-14 10:56:39 INFO  Executor:57 - Finished task 122.0 in stage 9.0 (TID 134). 5544 bytes result sent to driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:39 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Starting task 123.0 in stage 9.0 (TID 135, Clairvoyant-320, executor driver, partition 123, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Finished task 122.0 in stage 9.0 (TID 134) in 55 ms on Clairvoyant-320 (executor driver) (126/200)
2022-02-14 10:56:39 INFO  Executor:57 - Running task 123.0 in stage 9.0 (TID 135)
2022-02-14 10:56:39 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:39 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 123-124
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:228 - Task 135 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5ce33dad
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:237 - Task 135 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5ce33dad
2022-02-14 10:56:39 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 135 with length 1
2022-02-14 10:56:39 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 135: [56]
2022-02-14 10:56:39 INFO  Executor:57 - Finished task 123.0 in stage 9.0 (TID 135). 5544 bytes result sent to driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:39 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Starting task 124.0 in stage 9.0 (TID 136, Clairvoyant-320, executor driver, partition 124, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:39 INFO  Executor:57 - Running task 124.0 in stage 9.0 (TID 136)
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Finished task 123.0 in stage 9.0 (TID 135) in 51 ms on Clairvoyant-320 (executor driver) (127/200)
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:39 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:39 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 124-125
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:228 - Task 136 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5ebbf8fa
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:237 - Task 136 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5ebbf8fa
2022-02-14 10:56:39 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 136 with length 1
2022-02-14 10:56:39 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 136: [56]
2022-02-14 10:56:39 INFO  Executor:57 - Finished task 124.0 in stage 9.0 (TID 136). 5587 bytes result sent to driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:39 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Starting task 125.0 in stage 9.0 (TID 137, Clairvoyant-320, executor driver, partition 125, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Finished task 124.0 in stage 9.0 (TID 136) in 44 ms on Clairvoyant-320 (executor driver) (128/200)
2022-02-14 10:56:39 INFO  Executor:57 - Running task 125.0 in stage 9.0 (TID 137)
2022-02-14 10:56:39 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:39 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 125-126
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:228 - Task 137 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@296140d1
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:237 - Task 137 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@296140d1
2022-02-14 10:56:39 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 137 with length 1
2022-02-14 10:56:39 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 137: [56]
2022-02-14 10:56:39 INFO  Executor:57 - Finished task 125.0 in stage 9.0 (TID 137). 5544 bytes result sent to driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:39 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Starting task 126.0 in stage 9.0 (TID 138, Clairvoyant-320, executor driver, partition 126, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:39 INFO  Executor:57 - Running task 126.0 in stage 9.0 (TID 138)
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Finished task 125.0 in stage 9.0 (TID 137) in 37 ms on Clairvoyant-320 (executor driver) (129/200)
2022-02-14 10:56:39 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:39 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 126-127
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:228 - Task 138 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@6eaa9d9d
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:237 - Task 138 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@6eaa9d9d
2022-02-14 10:56:39 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 138 with length 1
2022-02-14 10:56:39 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 138: [56]
2022-02-14 10:56:39 INFO  Executor:57 - Finished task 126.0 in stage 9.0 (TID 138). 5587 bytes result sent to driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:39 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Starting task 127.0 in stage 9.0 (TID 139, Clairvoyant-320, executor driver, partition 127, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Finished task 126.0 in stage 9.0 (TID 138) in 43 ms on Clairvoyant-320 (executor driver) (130/200)
2022-02-14 10:56:39 INFO  Executor:57 - Running task 127.0 in stage 9.0 (TID 139)
2022-02-14 10:56:39 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:39 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 127-128
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:228 - Task 139 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5250315d
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:237 - Task 139 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5250315d
2022-02-14 10:56:39 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 139 with length 1
2022-02-14 10:56:39 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 139: [56]
2022-02-14 10:56:39 INFO  Executor:57 - Finished task 127.0 in stage 9.0 (TID 139). 5544 bytes result sent to driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:39 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Starting task 128.0 in stage 9.0 (TID 140, Clairvoyant-320, executor driver, partition 128, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Finished task 127.0 in stage 9.0 (TID 139) in 33 ms on Clairvoyant-320 (executor driver) (131/200)
2022-02-14 10:56:39 INFO  Executor:57 - Running task 128.0 in stage 9.0 (TID 140)
2022-02-14 10:56:39 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:39 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 128-129
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:228 - Task 140 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@103507bf
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:237 - Task 140 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@103507bf
2022-02-14 10:56:39 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 140 with length 1
2022-02-14 10:56:39 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 140: [56]
2022-02-14 10:56:39 INFO  Executor:57 - Finished task 128.0 in stage 9.0 (TID 140). 5544 bytes result sent to driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:39 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Starting task 129.0 in stage 9.0 (TID 141, Clairvoyant-320, executor driver, partition 129, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Finished task 128.0 in stage 9.0 (TID 140) in 40 ms on Clairvoyant-320 (executor driver) (132/200)
2022-02-14 10:56:39 INFO  Executor:57 - Running task 129.0 in stage 9.0 (TID 141)
2022-02-14 10:56:39 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:39 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 129-130
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:228 - Task 141 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2f801bd7
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:237 - Task 141 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2f801bd7
2022-02-14 10:56:39 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 141 with length 1
2022-02-14 10:56:39 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 141: [56]
2022-02-14 10:56:39 INFO  Executor:57 - Finished task 129.0 in stage 9.0 (TID 141). 5587 bytes result sent to driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:39 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Starting task 130.0 in stage 9.0 (TID 142, Clairvoyant-320, executor driver, partition 130, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Finished task 129.0 in stage 9.0 (TID 141) in 41 ms on Clairvoyant-320 (executor driver) (133/200)
2022-02-14 10:56:39 INFO  Executor:57 - Running task 130.0 in stage 9.0 (TID 142)
2022-02-14 10:56:39 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:39 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 130-131
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:228 - Task 142 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@29ae21c0
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:237 - Task 142 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@29ae21c0
2022-02-14 10:56:39 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 142 with length 1
2022-02-14 10:56:39 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 142: [56]
2022-02-14 10:56:39 INFO  Executor:57 - Finished task 130.0 in stage 9.0 (TID 142). 5544 bytes result sent to driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:39 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Starting task 131.0 in stage 9.0 (TID 143, Clairvoyant-320, executor driver, partition 131, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:39 INFO  TaskSetManager:57 - Finished task 130.0 in stage 9.0 (TID 142) in 37 ms on Clairvoyant-320 (executor driver) (134/200)
2022-02-14 10:56:39 INFO  Executor:57 - Running task 131.0 in stage 9.0 (TID 143)
2022-02-14 10:56:39 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:39 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:39 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 131-132
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:39 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:39 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:228 - Task 143 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@51590716
2022-02-14 10:56:39 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:39 DEBUG TaskMemoryManager:237 - Task 143 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@51590716
2022-02-14 10:56:39 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 143 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 143: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 131.0 in stage 9.0 (TID 143). 5544 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 132.0 in stage 9.0 (TID 144, Clairvoyant-320, executor driver, partition 132, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 132.0 in stage 9.0 (TID 144)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 131.0 in stage 9.0 (TID 143) in 39 ms on Clairvoyant-320 (executor driver) (135/200)
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 132-133
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 144 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@530ccf1c
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 144 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@530ccf1c
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 144 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 144: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 132.0 in stage 9.0 (TID 144). 5544 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 133.0 in stage 9.0 (TID 145, Clairvoyant-320, executor driver, partition 133, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 132.0 in stage 9.0 (TID 144) in 34 ms on Clairvoyant-320 (executor driver) (136/200)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 133.0 in stage 9.0 (TID 145)
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 133-134
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 2 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 145 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@23c1d40a
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 145 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@23c1d40a
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 145 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 145: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 133.0 in stage 9.0 (TID 145). 5544 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 135.0 in stage 9.0 (TID 146, Clairvoyant-320, executor driver, partition 135, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 133.0 in stage 9.0 (TID 145) in 37 ms on Clairvoyant-320 (executor driver) (137/200)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 135.0 in stage 9.0 (TID 146)
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 135-136
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 146 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1f179f28
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 146 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1f179f28
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 146 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 146: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 135.0 in stage 9.0 (TID 146). 5587 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 136.0 in stage 9.0 (TID 147, Clairvoyant-320, executor driver, partition 136, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 135.0 in stage 9.0 (TID 146) in 41 ms on Clairvoyant-320 (executor driver) (138/200)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 136.0 in stage 9.0 (TID 147)
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 136-137
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 147 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@676e92fb
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 147 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@676e92fb
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 147 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 147: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 136.0 in stage 9.0 (TID 147). 5544 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 137.0 in stage 9.0 (TID 148, Clairvoyant-320, executor driver, partition 137, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 136.0 in stage 9.0 (TID 147) in 39 ms on Clairvoyant-320 (executor driver) (139/200)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 137.0 in stage 9.0 (TID 148)
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 137-138
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 148 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@71417265
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 148 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@71417265
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 148 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 148: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 137.0 in stage 9.0 (TID 148). 5544 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 138.0 in stage 9.0 (TID 149, Clairvoyant-320, executor driver, partition 138, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 137.0 in stage 9.0 (TID 148) in 42 ms on Clairvoyant-320 (executor driver) (140/200)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 138.0 in stage 9.0 (TID 149)
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 138-139
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 149 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@79a7070f
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 149 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@79a7070f
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 149 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 149: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 138.0 in stage 9.0 (TID 149). 5544 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 139.0 in stage 9.0 (TID 150, Clairvoyant-320, executor driver, partition 139, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 138.0 in stage 9.0 (TID 149) in 56 ms on Clairvoyant-320 (executor driver) (141/200)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 139.0 in stage 9.0 (TID 150)
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 139-140
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 150 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3874e58d
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 150 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3874e58d
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 150 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 150: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 139.0 in stage 9.0 (TID 150). 5544 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 140.0 in stage 9.0 (TID 151, Clairvoyant-320, executor driver, partition 140, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 139.0 in stage 9.0 (TID 150) in 41 ms on Clairvoyant-320 (executor driver) (142/200)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 140.0 in stage 9.0 (TID 151)
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 140-141
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 151 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@79471d35
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 151 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@79471d35
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 151 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 151: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 140.0 in stage 9.0 (TID 151). 5544 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 141.0 in stage 9.0 (TID 152, Clairvoyant-320, executor driver, partition 141, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 141.0 in stage 9.0 (TID 152)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 140.0 in stage 9.0 (TID 151) in 43 ms on Clairvoyant-320 (executor driver) (143/200)
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 141-142
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 152 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@31fd1ba
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 152 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@31fd1ba
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 152 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 152: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 141.0 in stage 9.0 (TID 152). 5544 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 142.0 in stage 9.0 (TID 153, Clairvoyant-320, executor driver, partition 142, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 142.0 in stage 9.0 (TID 153)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 141.0 in stage 9.0 (TID 152) in 39 ms on Clairvoyant-320 (executor driver) (144/200)
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 142-143
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 153 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4dea99bf
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 153 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4dea99bf
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 153 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 153: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 142.0 in stage 9.0 (TID 153). 5544 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 143.0 in stage 9.0 (TID 154, Clairvoyant-320, executor driver, partition 143, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 142.0 in stage 9.0 (TID 153) in 38 ms on Clairvoyant-320 (executor driver) (145/200)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 143.0 in stage 9.0 (TID 154)
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 143-144
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 154 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1ddd5d0
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 154 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1ddd5d0
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 154 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 154: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 143.0 in stage 9.0 (TID 154). 5544 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 144.0 in stage 9.0 (TID 155, Clairvoyant-320, executor driver, partition 144, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 143.0 in stage 9.0 (TID 154) in 56 ms on Clairvoyant-320 (executor driver) (146/200)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 144.0 in stage 9.0 (TID 155)
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 144-145
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 155 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@6a7d2d0f
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 155 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@6a7d2d0f
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 155 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 155: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 144.0 in stage 9.0 (TID 155). 5544 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 145.0 in stage 9.0 (TID 156, Clairvoyant-320, executor driver, partition 145, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 144.0 in stage 9.0 (TID 155) in 55 ms on Clairvoyant-320 (executor driver) (147/200)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 145.0 in stage 9.0 (TID 156)
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 145-146
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 156 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@72ac7c32
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 156 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@72ac7c32
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 156 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 156: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 145.0 in stage 9.0 (TID 156). 5587 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 146.0 in stage 9.0 (TID 157, Clairvoyant-320, executor driver, partition 146, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 146.0 in stage 9.0 (TID 157)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 145.0 in stage 9.0 (TID 156) in 40 ms on Clairvoyant-320 (executor driver) (148/200)
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 WARN  ProcfsMetricsGetter:69 - Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 146-147
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 157 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1bda3575
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 157 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1bda3575
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 157 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 157: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 146.0 in stage 9.0 (TID 157). 5544 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 147.0 in stage 9.0 (TID 158, Clairvoyant-320, executor driver, partition 147, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 146.0 in stage 9.0 (TID 157) in 34 ms on Clairvoyant-320 (executor driver) (149/200)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 147.0 in stage 9.0 (TID 158)
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 147-148
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 158 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7c4e3df4
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 158 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7c4e3df4
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 158 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 158: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 147.0 in stage 9.0 (TID 158). 5544 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 148.0 in stage 9.0 (TID 159, Clairvoyant-320, executor driver, partition 148, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 147.0 in stage 9.0 (TID 158) in 38 ms on Clairvoyant-320 (executor driver) (150/200)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 148.0 in stage 9.0 (TID 159)
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 148-149
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 159 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4338d1b1
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 159 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4338d1b1
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 159 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 159: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 148.0 in stage 9.0 (TID 159). 5544 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 149.0 in stage 9.0 (TID 160, Clairvoyant-320, executor driver, partition 149, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 148.0 in stage 9.0 (TID 159) in 44 ms on Clairvoyant-320 (executor driver) (151/200)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 149.0 in stage 9.0 (TID 160)
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 149-150
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 160 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@68fd538f
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 160 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@68fd538f
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 160 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 160: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 149.0 in stage 9.0 (TID 160). 5544 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 150.0 in stage 9.0 (TID 161, Clairvoyant-320, executor driver, partition 150, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 149.0 in stage 9.0 (TID 160) in 42 ms on Clairvoyant-320 (executor driver) (152/200)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 150.0 in stage 9.0 (TID 161)
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 150-151
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 161 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2f8d3fef
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 161 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2f8d3fef
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 161 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 161: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 150.0 in stage 9.0 (TID 161). 5544 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 151.0 in stage 9.0 (TID 162, Clairvoyant-320, executor driver, partition 151, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 151.0 in stage 9.0 (TID 162)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 150.0 in stage 9.0 (TID 161) in 45 ms on Clairvoyant-320 (executor driver) (153/200)
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 151-152
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 162 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5711ec44
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 162 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5711ec44
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 162 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 162: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 151.0 in stage 9.0 (TID 162). 5544 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 152.0 in stage 9.0 (TID 163, Clairvoyant-320, executor driver, partition 152, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 151.0 in stage 9.0 (TID 162) in 37 ms on Clairvoyant-320 (executor driver) (154/200)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 152.0 in stage 9.0 (TID 163)
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 152-153
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 163 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1e1a2bbd
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 163 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1e1a2bbd
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 163 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 163: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 152.0 in stage 9.0 (TID 163). 5544 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 153.0 in stage 9.0 (TID 164, Clairvoyant-320, executor driver, partition 153, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 152.0 in stage 9.0 (TID 163) in 37 ms on Clairvoyant-320 (executor driver) (155/200)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 153.0 in stage 9.0 (TID 164)
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 153-154
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 164 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4bdade82
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 164 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4bdade82
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 164 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 164: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 153.0 in stage 9.0 (TID 164). 5587 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 154.0 in stage 9.0 (TID 165, Clairvoyant-320, executor driver, partition 154, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 153.0 in stage 9.0 (TID 164) in 29 ms on Clairvoyant-320 (executor driver) (156/200)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 154.0 in stage 9.0 (TID 165)
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 154-155
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 165 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1703ad31
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 165 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1703ad31
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 165 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 165: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 154.0 in stage 9.0 (TID 165). 5544 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 155.0 in stage 9.0 (TID 166, Clairvoyant-320, executor driver, partition 155, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 155.0 in stage 9.0 (TID 166)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 154.0 in stage 9.0 (TID 165) in 36 ms on Clairvoyant-320 (executor driver) (157/200)
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 155-156
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 166 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1472341f
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 166 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1472341f
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 166 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 166: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 155.0 in stage 9.0 (TID 166). 5544 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 157.0 in stage 9.0 (TID 167, Clairvoyant-320, executor driver, partition 157, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 155.0 in stage 9.0 (TID 166) in 36 ms on Clairvoyant-320 (executor driver) (158/200)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 157.0 in stage 9.0 (TID 167)
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 157-158
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 167 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7eefe4e1
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 167 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7eefe4e1
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 167 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 167: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 157.0 in stage 9.0 (TID 167). 5587 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 158.0 in stage 9.0 (TID 168, Clairvoyant-320, executor driver, partition 158, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 157.0 in stage 9.0 (TID 167) in 45 ms on Clairvoyant-320 (executor driver) (159/200)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 158.0 in stage 9.0 (TID 168)
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 158-159
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:40 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:228 - Task 168 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@48e6b66b
2022-02-14 10:56:40 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:40 DEBUG TaskMemoryManager:237 - Task 168 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@48e6b66b
2022-02-14 10:56:40 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 168 with length 1
2022-02-14 10:56:40 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 168: [56]
2022-02-14 10:56:40 INFO  Executor:57 - Finished task 158.0 in stage 9.0 (TID 168). 5544 bytes result sent to driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:40 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Starting task 159.0 in stage 9.0 (TID 169, Clairvoyant-320, executor driver, partition 159, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:40 INFO  TaskSetManager:57 - Finished task 158.0 in stage 9.0 (TID 168) in 36 ms on Clairvoyant-320 (executor driver) (160/200)
2022-02-14 10:56:40 INFO  Executor:57 - Running task 159.0 in stage 9.0 (TID 169)
2022-02-14 10:56:40 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:40 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:40 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 159-160
2022-02-14 10:56:40 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 169 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1a91c2a
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 169 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1a91c2a
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 169 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 169: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 159.0 in stage 9.0 (TID 169). 5587 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 160.0 in stage 9.0 (TID 170, Clairvoyant-320, executor driver, partition 160, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 159.0 in stage 9.0 (TID 169) in 46 ms on Clairvoyant-320 (executor driver) (161/200)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 160.0 in stage 9.0 (TID 170)
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 160-161
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 170 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1de2e1c2
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 170 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1de2e1c2
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 170 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 170: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 160.0 in stage 9.0 (TID 170). 5587 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 161.0 in stage 9.0 (TID 171, Clairvoyant-320, executor driver, partition 161, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 160.0 in stage 9.0 (TID 170) in 39 ms on Clairvoyant-320 (executor driver) (162/200)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 161.0 in stage 9.0 (TID 171)
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 161-162
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 171 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2f65a41e
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 171 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2f65a41e
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 171 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 171: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 161.0 in stage 9.0 (TID 171). 5544 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 162.0 in stage 9.0 (TID 172, Clairvoyant-320, executor driver, partition 162, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 161.0 in stage 9.0 (TID 171) in 41 ms on Clairvoyant-320 (executor driver) (163/200)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 162.0 in stage 9.0 (TID 172)
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 162-163
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 172 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7bb4394f
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 172 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7bb4394f
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 172 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 172: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 162.0 in stage 9.0 (TID 172). 5587 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 163.0 in stage 9.0 (TID 173, Clairvoyant-320, executor driver, partition 163, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 162.0 in stage 9.0 (TID 172) in 41 ms on Clairvoyant-320 (executor driver) (164/200)
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 INFO  Executor:57 - Running task 163.0 in stage 9.0 (TID 173)
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 163-164
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 173 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1d8e0ddf
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 173 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1d8e0ddf
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 173 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 173: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 163.0 in stage 9.0 (TID 173). 5544 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 164.0 in stage 9.0 (TID 174, Clairvoyant-320, executor driver, partition 164, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 163.0 in stage 9.0 (TID 173) in 35 ms on Clairvoyant-320 (executor driver) (165/200)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 164.0 in stage 9.0 (TID 174)
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 164-165
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 174 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5fcf53dc
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 174 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5fcf53dc
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 174 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 174: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 164.0 in stage 9.0 (TID 174). 5544 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 165.0 in stage 9.0 (TID 175, Clairvoyant-320, executor driver, partition 165, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 164.0 in stage 9.0 (TID 174) in 35 ms on Clairvoyant-320 (executor driver) (166/200)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 165.0 in stage 9.0 (TID 175)
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 165-166
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 175 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@286e385
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 175 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@286e385
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 175 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 175: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 165.0 in stage 9.0 (TID 175). 5544 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 166.0 in stage 9.0 (TID 176, Clairvoyant-320, executor driver, partition 166, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 165.0 in stage 9.0 (TID 175) in 31 ms on Clairvoyant-320 (executor driver) (167/200)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 166.0 in stage 9.0 (TID 176)
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 166-167
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 176 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@11535380
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 176 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@11535380
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 176 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 176: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 166.0 in stage 9.0 (TID 176). 5544 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 167.0 in stage 9.0 (TID 177, Clairvoyant-320, executor driver, partition 167, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 166.0 in stage 9.0 (TID 176) in 33 ms on Clairvoyant-320 (executor driver) (168/200)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 167.0 in stage 9.0 (TID 177)
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 167-168
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 177 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@31cd1371
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 177 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@31cd1371
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 177 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 177: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 167.0 in stage 9.0 (TID 177). 5544 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 168.0 in stage 9.0 (TID 178, Clairvoyant-320, executor driver, partition 168, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 168.0 in stage 9.0 (TID 178)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 167.0 in stage 9.0 (TID 177) in 37 ms on Clairvoyant-320 (executor driver) (169/200)
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 168-169
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 178 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@54c7f46e
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 178 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@54c7f46e
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 178 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 178: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 168.0 in stage 9.0 (TID 178). 5587 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 169.0 in stage 9.0 (TID 179, Clairvoyant-320, executor driver, partition 169, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 168.0 in stage 9.0 (TID 178) in 39 ms on Clairvoyant-320 (executor driver) (170/200)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 169.0 in stage 9.0 (TID 179)
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 169-170
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 179 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3713ac9c
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 179 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3713ac9c
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 179 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 179: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 169.0 in stage 9.0 (TID 179). 5544 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 170.0 in stage 9.0 (TID 180, Clairvoyant-320, executor driver, partition 170, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 169.0 in stage 9.0 (TID 179) in 43 ms on Clairvoyant-320 (executor driver) (171/200)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 170.0 in stage 9.0 (TID 180)
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 170-171
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 180 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@53dfaa32
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 180 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@53dfaa32
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 180 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 180: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 170.0 in stage 9.0 (TID 180). 5544 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 171.0 in stage 9.0 (TID 181, Clairvoyant-320, executor driver, partition 171, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 171.0 in stage 9.0 (TID 181)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 170.0 in stage 9.0 (TID 180) in 50 ms on Clairvoyant-320 (executor driver) (172/200)
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 171-172
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 181 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2473acbd
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 181 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2473acbd
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 181 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 181: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 171.0 in stage 9.0 (TID 181). 5544 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 172.0 in stage 9.0 (TID 182, Clairvoyant-320, executor driver, partition 172, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 171.0 in stage 9.0 (TID 181) in 55 ms on Clairvoyant-320 (executor driver) (173/200)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 172.0 in stage 9.0 (TID 182)
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 172-173
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 182 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@720adce3
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 182 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@720adce3
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 182 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 182: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 172.0 in stage 9.0 (TID 182). 5544 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 173.0 in stage 9.0 (TID 183, Clairvoyant-320, executor driver, partition 173, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 172.0 in stage 9.0 (TID 182) in 55 ms on Clairvoyant-320 (executor driver) (174/200)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 173.0 in stage 9.0 (TID 183)
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 173-174
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 183 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@748c87b1
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 183 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@748c87b1
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 183 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 183: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 173.0 in stage 9.0 (TID 183). 5587 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 174.0 in stage 9.0 (TID 184, Clairvoyant-320, executor driver, partition 174, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 173.0 in stage 9.0 (TID 183) in 46 ms on Clairvoyant-320 (executor driver) (175/200)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 174.0 in stage 9.0 (TID 184)
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 174-175
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 184 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2469ea59
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 184 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2469ea59
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 184 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 184: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 174.0 in stage 9.0 (TID 184). 5544 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 175.0 in stage 9.0 (TID 185, Clairvoyant-320, executor driver, partition 175, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 174.0 in stage 9.0 (TID 184) in 30 ms on Clairvoyant-320 (executor driver) (176/200)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 175.0 in stage 9.0 (TID 185)
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 175-176
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 185 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@513876e4
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 185 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@513876e4
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 185 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 185: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 175.0 in stage 9.0 (TID 185). 5587 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 176.0 in stage 9.0 (TID 186, Clairvoyant-320, executor driver, partition 176, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 175.0 in stage 9.0 (TID 185) in 36 ms on Clairvoyant-320 (executor driver) (177/200)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 176.0 in stage 9.0 (TID 186)
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 176-177
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 186 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@73ba1b0b
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 186 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@73ba1b0b
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 186 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 186: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 176.0 in stage 9.0 (TID 186). 5544 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 177.0 in stage 9.0 (TID 187, Clairvoyant-320, executor driver, partition 177, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 177.0 in stage 9.0 (TID 187)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 176.0 in stage 9.0 (TID 186) in 35 ms on Clairvoyant-320 (executor driver) (178/200)
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 177-178
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 187 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@8aad67c
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 187 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@8aad67c
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 187 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 187: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 177.0 in stage 9.0 (TID 187). 5544 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 178.0 in stage 9.0 (TID 188, Clairvoyant-320, executor driver, partition 178, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 178.0 in stage 9.0 (TID 188)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 177.0 in stage 9.0 (TID 187) in 29 ms on Clairvoyant-320 (executor driver) (179/200)
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 178-179
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 188 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@51a3d227
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 188 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@51a3d227
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 188 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 188: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 178.0 in stage 9.0 (TID 188). 5544 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 179.0 in stage 9.0 (TID 189, Clairvoyant-320, executor driver, partition 179, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 179.0 in stage 9.0 (TID 189)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 178.0 in stage 9.0 (TID 188) in 36 ms on Clairvoyant-320 (executor driver) (180/200)
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 179-180
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 189 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1e7ceae2
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 189 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1e7ceae2
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 189 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 189: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 179.0 in stage 9.0 (TID 189). 5544 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 180.0 in stage 9.0 (TID 190, Clairvoyant-320, executor driver, partition 180, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 179.0 in stage 9.0 (TID 189) in 30 ms on Clairvoyant-320 (executor driver) (181/200)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 180.0 in stage 9.0 (TID 190)
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 180-181
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 190 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2c003b08
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 190 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2c003b08
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 190 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 190: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 180.0 in stage 9.0 (TID 190). 5544 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 181.0 in stage 9.0 (TID 191, Clairvoyant-320, executor driver, partition 181, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 181.0 in stage 9.0 (TID 191)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 180.0 in stage 9.0 (TID 190) in 40 ms on Clairvoyant-320 (executor driver) (182/200)
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 181-182
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 191 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4b7fca0e
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 191 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4b7fca0e
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 191 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 191: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 181.0 in stage 9.0 (TID 191). 5544 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 182.0 in stage 9.0 (TID 192, Clairvoyant-320, executor driver, partition 182, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 182.0 in stage 9.0 (TID 192)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 181.0 in stage 9.0 (TID 191) in 30 ms on Clairvoyant-320 (executor driver) (183/200)
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 182-183
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 192 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@251082bb
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 192 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@251082bb
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 192 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 192: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 182.0 in stage 9.0 (TID 192). 5544 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 183.0 in stage 9.0 (TID 193, Clairvoyant-320, executor driver, partition 183, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 183.0 in stage 9.0 (TID 193)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 182.0 in stage 9.0 (TID 192) in 43 ms on Clairvoyant-320 (executor driver) (184/200)
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 183-184
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 193 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1bcb35a9
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 193 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1bcb35a9
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 193 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 193: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 183.0 in stage 9.0 (TID 193). 5544 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 184.0 in stage 9.0 (TID 194, Clairvoyant-320, executor driver, partition 184, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 183.0 in stage 9.0 (TID 193) in 36 ms on Clairvoyant-320 (executor driver) (185/200)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 184.0 in stage 9.0 (TID 194)
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 184-185
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 194 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@25934311
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 194 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@25934311
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 194 with length 1
2022-02-14 10:56:41 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 194: [56]
2022-02-14 10:56:41 INFO  Executor:57 - Finished task 184.0 in stage 9.0 (TID 194). 5587 bytes result sent to driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:41 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Starting task 185.0 in stage 9.0 (TID 195, Clairvoyant-320, executor driver, partition 185, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:41 INFO  TaskSetManager:57 - Finished task 184.0 in stage 9.0 (TID 194) in 41 ms on Clairvoyant-320 (executor driver) (186/200)
2022-02-14 10:56:41 INFO  Executor:57 - Running task 185.0 in stage 9.0 (TID 195)
2022-02-14 10:56:41 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:41 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:41 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 185-186
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:41 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:41 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:228 - Task 195 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3083eb50
2022-02-14 10:56:41 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:41 DEBUG TaskMemoryManager:237 - Task 195 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3083eb50
2022-02-14 10:56:41 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 195 with length 1
2022-02-14 10:56:42 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 195: [56]
2022-02-14 10:56:42 INFO  Executor:57 - Finished task 185.0 in stage 9.0 (TID 195). 5544 bytes result sent to driver
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:42 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Starting task 186.0 in stage 9.0 (TID 196, Clairvoyant-320, executor driver, partition 186, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:42 INFO  Executor:57 - Running task 186.0 in stage 9.0 (TID 196)
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Finished task 185.0 in stage 9.0 (TID 195) in 30 ms on Clairvoyant-320 (executor driver) (187/200)
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:42 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:42 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 186-187
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:228 - Task 196 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7b4a37ef
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:237 - Task 196 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7b4a37ef
2022-02-14 10:56:42 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 196 with length 1
2022-02-14 10:56:42 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 196: [56]
2022-02-14 10:56:42 INFO  Executor:57 - Finished task 186.0 in stage 9.0 (TID 196). 5544 bytes result sent to driver
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:42 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Starting task 187.0 in stage 9.0 (TID 197, Clairvoyant-320, executor driver, partition 187, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:42 INFO  Executor:57 - Running task 187.0 in stage 9.0 (TID 197)
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Finished task 186.0 in stage 9.0 (TID 196) in 34 ms on Clairvoyant-320 (executor driver) (188/200)
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:42 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:42 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 187-188
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:228 - Task 197 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5e8c10fc
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:237 - Task 197 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5e8c10fc
2022-02-14 10:56:42 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 197 with length 1
2022-02-14 10:56:42 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 197: [56]
2022-02-14 10:56:42 INFO  Executor:57 - Finished task 187.0 in stage 9.0 (TID 197). 5587 bytes result sent to driver
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:42 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Starting task 188.0 in stage 9.0 (TID 198, Clairvoyant-320, executor driver, partition 188, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Finished task 187.0 in stage 9.0 (TID 197) in 35 ms on Clairvoyant-320 (executor driver) (189/200)
2022-02-14 10:56:42 INFO  Executor:57 - Running task 188.0 in stage 9.0 (TID 198)
2022-02-14 10:56:42 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:42 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 188-189
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:228 - Task 198 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@10150a9d
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:237 - Task 198 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@10150a9d
2022-02-14 10:56:42 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 198 with length 1
2022-02-14 10:56:42 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 198: [56]
2022-02-14 10:56:42 INFO  Executor:57 - Finished task 188.0 in stage 9.0 (TID 198). 5544 bytes result sent to driver
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:42 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Starting task 189.0 in stage 9.0 (TID 199, Clairvoyant-320, executor driver, partition 189, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:42 INFO  Executor:57 - Running task 189.0 in stage 9.0 (TID 199)
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Finished task 188.0 in stage 9.0 (TID 198) in 36 ms on Clairvoyant-320 (executor driver) (190/200)
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:42 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:42 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 189-190
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:228 - Task 199 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4fa65fe7
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:237 - Task 199 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4fa65fe7
2022-02-14 10:56:42 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 199 with length 1
2022-02-14 10:56:42 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 199: [56]
2022-02-14 10:56:42 INFO  Executor:57 - Finished task 189.0 in stage 9.0 (TID 199). 5587 bytes result sent to driver
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:42 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Starting task 190.0 in stage 9.0 (TID 200, Clairvoyant-320, executor driver, partition 190, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:42 INFO  Executor:57 - Running task 190.0 in stage 9.0 (TID 200)
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Finished task 189.0 in stage 9.0 (TID 199) in 44 ms on Clairvoyant-320 (executor driver) (191/200)
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:42 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:42 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 190-191
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:228 - Task 200 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@23f60cb8
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:237 - Task 200 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@23f60cb8
2022-02-14 10:56:42 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 200 with length 1
2022-02-14 10:56:42 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 200: [56]
2022-02-14 10:56:42 INFO  Executor:57 - Finished task 190.0 in stage 9.0 (TID 200). 5544 bytes result sent to driver
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:42 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Starting task 191.0 in stage 9.0 (TID 201, Clairvoyant-320, executor driver, partition 191, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Finished task 190.0 in stage 9.0 (TID 200) in 36 ms on Clairvoyant-320 (executor driver) (192/200)
2022-02-14 10:56:42 INFO  Executor:57 - Running task 191.0 in stage 9.0 (TID 201)
2022-02-14 10:56:42 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:42 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 191-192
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:228 - Task 201 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@12638ef1
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:237 - Task 201 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@12638ef1
2022-02-14 10:56:42 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 201 with length 1
2022-02-14 10:56:42 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 201: [56]
2022-02-14 10:56:42 INFO  Executor:57 - Finished task 191.0 in stage 9.0 (TID 201). 5544 bytes result sent to driver
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:42 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Starting task 192.0 in stage 9.0 (TID 202, Clairvoyant-320, executor driver, partition 192, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:42 INFO  Executor:57 - Running task 192.0 in stage 9.0 (TID 202)
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Finished task 191.0 in stage 9.0 (TID 201) in 40 ms on Clairvoyant-320 (executor driver) (193/200)
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:42 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:42 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 192-193
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:228 - Task 202 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2c2c9dc4
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:237 - Task 202 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2c2c9dc4
2022-02-14 10:56:42 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 202 with length 1
2022-02-14 10:56:42 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 202: [56]
2022-02-14 10:56:42 INFO  Executor:57 - Finished task 192.0 in stage 9.0 (TID 202). 5544 bytes result sent to driver
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:42 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Starting task 193.0 in stage 9.0 (TID 203, Clairvoyant-320, executor driver, partition 193, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:42 INFO  Executor:57 - Running task 193.0 in stage 9.0 (TID 203)
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Finished task 192.0 in stage 9.0 (TID 202) in 30 ms on Clairvoyant-320 (executor driver) (194/200)
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:42 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:42 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 193-194
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:228 - Task 203 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@387699e6
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:237 - Task 203 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@387699e6
2022-02-14 10:56:42 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 203 with length 1
2022-02-14 10:56:42 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 203: [56]
2022-02-14 10:56:42 INFO  Executor:57 - Finished task 193.0 in stage 9.0 (TID 203). 5544 bytes result sent to driver
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:42 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Starting task 194.0 in stage 9.0 (TID 204, Clairvoyant-320, executor driver, partition 194, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:42 INFO  Executor:57 - Running task 194.0 in stage 9.0 (TID 204)
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Finished task 193.0 in stage 9.0 (TID 203) in 23 ms on Clairvoyant-320 (executor driver) (195/200)
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:42 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:42 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 194-195
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:228 - Task 204 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@59852a47
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:237 - Task 204 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@59852a47
2022-02-14 10:56:42 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 204 with length 1
2022-02-14 10:56:42 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 204: [56]
2022-02-14 10:56:42 INFO  Executor:57 - Finished task 194.0 in stage 9.0 (TID 204). 5587 bytes result sent to driver
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:42 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Starting task 195.0 in stage 9.0 (TID 205, Clairvoyant-320, executor driver, partition 195, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Finished task 194.0 in stage 9.0 (TID 204) in 37 ms on Clairvoyant-320 (executor driver) (196/200)
2022-02-14 10:56:42 INFO  Executor:57 - Running task 195.0 in stage 9.0 (TID 205)
2022-02-14 10:56:42 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:42 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 195-196
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:228 - Task 205 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@fc91e1e
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:237 - Task 205 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@fc91e1e
2022-02-14 10:56:42 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 205 with length 1
2022-02-14 10:56:42 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 205: [56]
2022-02-14 10:56:42 INFO  Executor:57 - Finished task 195.0 in stage 9.0 (TID 205). 5544 bytes result sent to driver
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:42 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Starting task 196.0 in stage 9.0 (TID 206, Clairvoyant-320, executor driver, partition 196, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:42 INFO  Executor:57 - Running task 196.0 in stage 9.0 (TID 206)
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Finished task 195.0 in stage 9.0 (TID 205) in 41 ms on Clairvoyant-320 (executor driver) (197/200)
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:42 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:42 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 196-197
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:228 - Task 206 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@14374a12
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:237 - Task 206 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@14374a12
2022-02-14 10:56:42 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 206 with length 1
2022-02-14 10:56:42 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 206: [56]
2022-02-14 10:56:42 INFO  Executor:57 - Finished task 196.0 in stage 9.0 (TID 206). 5587 bytes result sent to driver
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:42 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Starting task 198.0 in stage 9.0 (TID 207, Clairvoyant-320, executor driver, partition 198, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Finished task 196.0 in stage 9.0 (TID 206) in 45 ms on Clairvoyant-320 (executor driver) (198/200)
2022-02-14 10:56:42 INFO  Executor:57 - Running task 198.0 in stage 9.0 (TID 207)
2022-02-14 10:56:42 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:42 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 198-199
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:228 - Task 207 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2060a092
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:237 - Task 207 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2060a092
2022-02-14 10:56:42 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 207 with length 1
2022-02-14 10:56:42 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 207: [56]
2022-02-14 10:56:42 INFO  Executor:57 - Finished task 198.0 in stage 9.0 (TID 207). 5587 bytes result sent to driver
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:42 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Starting task 199.0 in stage 9.0 (TID 208, Clairvoyant-320, executor driver, partition 199, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:56:42 INFO  Executor:57 - Running task 199.0 in stage 9.0 (TID 208)
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Finished task 198.0 in stage 9.0 (TID 207) in 48 ms on Clairvoyant-320 (executor driver) (199/200)
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:56:42 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:42 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 199-200
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:228 - Task 208 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@da3bf85
2022-02-14 10:56:42 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:56:42 DEBUG TaskMemoryManager:237 - Task 208 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@da3bf85
2022-02-14 10:56:42 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 208 with length 1
2022-02-14 10:56:42 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 208: [56]
2022-02-14 10:56:42 INFO  Executor:57 - Finished task 199.0 in stage 9.0 (TID 208). 5587 bytes result sent to driver
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:56:42 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Finished task 199.0 in stage 9.0 (TID 208) in 41 ms on Clairvoyant-320 (executor driver) (200/200)
2022-02-14 10:56:42 INFO  TaskSchedulerImpl:57 - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2022-02-14 10:56:42 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:56:42 INFO  DAGScheduler:57 - ShuffleMapStage 9 (count at UsedCase5.java:31) finished in 9.143 s
2022-02-14 10:56:42 INFO  DAGScheduler:57 - looking for newly runnable stages
2022-02-14 10:56:42 INFO  DAGScheduler:57 - running: Set()
2022-02-14 10:56:42 INFO  DAGScheduler:57 - waiting: Set(ResultStage 10)
2022-02-14 10:56:42 INFO  DAGScheduler:57 - failed: Set()
2022-02-14 10:56:42 DEBUG MapOutputTrackerMaster:61 - Increasing epoch to 2
2022-02-14 10:56:42 DEBUG DAGScheduler:61 - submitStage(ResultStage 10 (name=count at UsedCase5.java:31;jobs=8))
2022-02-14 10:56:42 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:56:42 INFO  DAGScheduler:57 - Submitting ResultStage 10 (MapPartitionsRDD[47] at count at UsedCase5.java:31), which has no missing parents
2022-02-14 10:56:42 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 10)
2022-02-14 10:56:42 INFO  MemoryStore:57 - Block broadcast_21 stored as values in memory (estimated size 10.1 KiB, free 2.2 GiB)
2022-02-14 10:56:42 DEBUG BlockManager:61 - Put block broadcast_21 locally took 0 ms
2022-02-14 10:56:42 DEBUG BlockManager:61 - Putting block broadcast_21 without replication took 0 ms
2022-02-14 10:56:42 INFO  MemoryStore:57 - Block broadcast_21_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 2.2 GiB)
2022-02-14 10:56:42 INFO  BlockManagerInfo:57 - Added broadcast_21_piece0 in memory on Clairvoyant-320:60369 (size: 5.0 KiB, free: 2.2 GiB)
2022-02-14 10:56:42 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_21_piece0
2022-02-14 10:56:42 DEBUG BlockManager:61 - Told master about block broadcast_21_piece0
2022-02-14 10:56:42 DEBUG BlockManager:61 - Put block broadcast_21_piece0 locally took 1 ms
2022-02-14 10:56:42 DEBUG BlockManager:61 - Putting block broadcast_21_piece0 without replication took 1 ms
2022-02-14 10:56:42 INFO  SparkContext:57 - Created broadcast 21 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:56:42 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[47] at count at UsedCase5.java:31) (first 15 tasks are for partitions Vector(0))
2022-02-14 10:56:42 INFO  TaskSchedulerImpl:57 - Adding task set 10.0 with 1 tasks
2022-02-14 10:56:42 DEBUG TaskSetManager:61 - Epoch for TaskSet 10.0: 2
2022-02-14 10:56:42 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-02-14 10:56:42 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 10.0: NODE_LOCAL, ANY
2022-02-14 10:56:42 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_10.0, runningTasks: 0
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Starting task 0.0 in stage 10.0 (TID 209, Clairvoyant-320, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
2022-02-14 10:56:42 INFO  Executor:57 - Running task 0.0 in stage 10.0 (TID 209)
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (10, 0) -> 1
2022-02-14 10:56:42 DEBUG BlockManager:61 - Getting local block broadcast_21
2022-02-14 10:56:42 DEBUG BlockManager:61 - Level for block broadcast_21 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:56:42 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 1, partitions 0-1
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Getting 200 (11.7 KiB) non-empty blocks including 200 (11.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:56:42 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 3 ms
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_1_15_0,0), (shuffle_1_16_0,1), (shuffle_1_17_0,2), (shuffle_1_18_0,3), (shuffle_1_19_0,4), (shuffle_1_20_0,5), (shuffle_1_21_0,6), (shuffle_1_22_0,7), (shuffle_1_23_0,8), (shuffle_1_24_0,9), (shuffle_1_25_0,10), (shuffle_1_26_0,11), (shuffle_1_27_0,12), (shuffle_1_28_0,13), (shuffle_1_29_0,14), (shuffle_1_30_0,15), (shuffle_1_31_0,16), (shuffle_1_32_0,17), (shuffle_1_33_0,18), (shuffle_1_34_0,19), (shuffle_1_35_0,20), (shuffle_1_36_0,21), (shuffle_1_37_0,22), (shuffle_1_38_0,23), (shuffle_1_39_0,24), (shuffle_1_40_0,25), (shuffle_1_41_0,26), (shuffle_1_42_0,27), (shuffle_1_43_0,28), (shuffle_1_44_0,29), (shuffle_1_45_0,30), (shuffle_1_46_0,31), (shuffle_1_47_0,32), (shuffle_1_48_0,33), (shuffle_1_49_0,34), (shuffle_1_50_0,35), (shuffle_1_51_0,36), (shuffle_1_52_0,37), (shuffle_1_53_0,38), (shuffle_1_54_0,39), (shuffle_1_55_0,40), (shuffle_1_56_0,41), (shuffle_1_57_0,42), (shuffle_1_58_0,43), (shuffle_1_59_0,44), (shuffle_1_60_0,45), (shuffle_1_61_0,46), (shuffle_1_62_0,47), (shuffle_1_63_0,48), (shuffle_1_64_0,49), (shuffle_1_65_0,50), (shuffle_1_66_0,51), (shuffle_1_67_0,52), (shuffle_1_68_0,53), (shuffle_1_69_0,54), (shuffle_1_70_0,55), (shuffle_1_71_0,56), (shuffle_1_72_0,57), (shuffle_1_73_0,58), (shuffle_1_74_0,59), (shuffle_1_75_0,60), (shuffle_1_76_0,61), (shuffle_1_77_0,62), (shuffle_1_78_0,63), (shuffle_1_79_0,64), (shuffle_1_80_0,65), (shuffle_1_81_0,66), (shuffle_1_82_0,67), (shuffle_1_83_0,68), (shuffle_1_84_0,69), (shuffle_1_85_0,70), (shuffle_1_86_0,71), (shuffle_1_87_0,72), (shuffle_1_88_0,73), (shuffle_1_89_0,74), (shuffle_1_90_0,75), (shuffle_1_91_0,76), (shuffle_1_92_0,77), (shuffle_1_93_0,78), (shuffle_1_94_0,79), (shuffle_1_95_0,80), (shuffle_1_96_0,81), (shuffle_1_97_0,82), (shuffle_1_98_0,83), (shuffle_1_99_0,84), (shuffle_1_100_0,85), (shuffle_1_101_0,86), (shuffle_1_102_0,87), (shuffle_1_103_0,88), (shuffle_1_104_0,89), (shuffle_1_105_0,90), (shuffle_1_106_0,91), (shuffle_1_107_0,92), (shuffle_1_108_0,93), (shuffle_1_109_0,94), (shuffle_1_110_0,95), (shuffle_1_111_0,96), (shuffle_1_9_0,97), (shuffle_1_112_0,98), (shuffle_1_113_0,99), (shuffle_1_114_0,100), (shuffle_1_115_0,101), (shuffle_1_116_0,102), (shuffle_1_117_0,103), (shuffle_1_118_0,104), (shuffle_1_119_0,105), (shuffle_1_120_0,106), (shuffle_1_121_0,107), (shuffle_1_10_0,108), (shuffle_1_122_0,109), (shuffle_1_123_0,110), (shuffle_1_124_0,111), (shuffle_1_125_0,112), (shuffle_1_126_0,113), (shuffle_1_127_0,114), (shuffle_1_128_0,115), (shuffle_1_11_0,116), (shuffle_1_129_0,117), (shuffle_1_130_0,118), (shuffle_1_131_0,119), (shuffle_1_132_0,120), (shuffle_1_133_0,121), (shuffle_1_134_0,122), (shuffle_1_135_0,123), (shuffle_1_136_0,124), (shuffle_1_137_0,125), (shuffle_1_138_0,126), (shuffle_1_139_0,127), (shuffle_1_140_0,128), (shuffle_1_141_0,129), (shuffle_1_142_0,130), (shuffle_1_143_0,131), (shuffle_1_144_0,132), (shuffle_1_145_0,133), (shuffle_1_12_0,134), (shuffle_1_146_0,135), (shuffle_1_147_0,136), (shuffle_1_148_0,137), (shuffle_1_149_0,138), (shuffle_1_150_0,139), (shuffle_1_151_0,140), (shuffle_1_152_0,141), (shuffle_1_153_0,142), (shuffle_1_154_0,143), (shuffle_1_155_0,144), (shuffle_1_156_0,145), (shuffle_1_157_0,146), (shuffle_1_158_0,147), (shuffle_1_159_0,148), (shuffle_1_160_0,149), (shuffle_1_161_0,150), (shuffle_1_162_0,151), (shuffle_1_163_0,152), (shuffle_1_164_0,153), (shuffle_1_165_0,154), (shuffle_1_166_0,155), (shuffle_1_13_0,156), (shuffle_1_167_0,157), (shuffle_1_168_0,158), (shuffle_1_169_0,159), (shuffle_1_170_0,160), (shuffle_1_171_0,161), (shuffle_1_172_0,162), (shuffle_1_173_0,163), (shuffle_1_174_0,164), (shuffle_1_175_0,165), (shuffle_1_176_0,166), (shuffle_1_177_0,167), (shuffle_1_178_0,168), (shuffle_1_179_0,169), (shuffle_1_180_0,170), (shuffle_1_181_0,171), (shuffle_1_182_0,172), (shuffle_1_183_0,173), (shuffle_1_184_0,174), (shuffle_1_185_0,175), (shuffle_1_186_0,176), (shuffle_1_187_0,177), (shuffle_1_188_0,178), (shuffle_1_189_0,179), (shuffle_1_190_0,180), (shuffle_1_191_0,181), (shuffle_1_192_0,182), (shuffle_1_193_0,183), (shuffle_1_194_0,184), (shuffle_1_195_0,185), (shuffle_1_196_0,186), (shuffle_1_197_0,187), (shuffle_1_198_0,188), (shuffle_1_199_0,189), (shuffle_1_200_0,190), (shuffle_1_201_0,191), (shuffle_1_202_0,192), (shuffle_1_203_0,193), (shuffle_1_204_0,194), (shuffle_1_205_0,195), (shuffle_1_206_0,196), (shuffle_1_14_0,197), (shuffle_1_207_0,198), (shuffle_1_208_0,199)
2022-02-14 10:56:42 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 40 ms
2022-02-14 10:56:42 INFO  Executor:57 - Finished task 0.0 in stage 10.0 (TID 209). 2605 bytes result sent to driver
2022-02-14 10:56:42 DEBUG ExecutorMetricsPoller:61 - removing (10, 0) from stageTCMP
2022-02-14 10:56:42 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_10.0, runningTasks: 0
2022-02-14 10:56:42 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
2022-02-14 10:56:42 INFO  TaskSetManager:57 - Finished task 0.0 in stage 10.0 (TID 209) in 82 ms on Clairvoyant-320 (executor driver) (1/1)
2022-02-14 10:56:42 INFO  TaskSchedulerImpl:57 - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2022-02-14 10:56:42 INFO  DAGScheduler:57 - ResultStage 10 (count at UsedCase5.java:31) finished in 0.091 s
2022-02-14 10:56:42 DEBUG DAGScheduler:61 - After removal of stage 8, remaining stages = 2
2022-02-14 10:56:42 DEBUG DAGScheduler:61 - After removal of stage 10, remaining stages = 1
2022-02-14 10:56:42 DEBUG DAGScheduler:61 - After removal of stage 9, remaining stages = 0
2022-02-14 10:56:42 INFO  DAGScheduler:57 - Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
2022-02-14 10:56:42 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 10: Stage finished
2022-02-14 10:56:42 INFO  DAGScheduler:57 - Job 8 finished: count at UsedCase5.java:31, took 9.833408 s
2022-02-14 10:56:42 INFO  SparkContext:57 - Invoking stop() from shutdown hook
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:212 - stopping Server@1aa6e3c0{STARTED}[9.4.40.v20210413]
2022-02-14 10:56:42 DEBUG Server:433 - doStop Server@1aa6e3c0{STOPPING}[9.4.40.v20210413]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1038 - ran SparkUI-35-acceptor-0@7a8406c2-ServerConnector@78226c36{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} in QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=3,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}]
2022-02-14 10:56:42 DEBUG AbstractHandlerContainer:167 - Graceful shutdown Server@1aa6e3c0{STOPPING}[9.4.40.v20210413] by 
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:212 - stopping Spark@78226c36{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:212 - stopping SelectorManager@Spark@78226c36{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:212 - stopping ManagedSelector@10fda3d0{STARTED} id=3 keys=0 selected=0 updates=0
2022-02-14 10:56:42 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$CloseConnections@35e48ed1 on ManagedSelector@10fda3d0{STOPPING} id=3 keys=0 selected=0 updates=0
2022-02-14 10:56:42 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@10fda3d0{STOPPING} id=3 keys=0 selected=0 updates=1
2022-02-14 10:56:42 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@2300575e woken with none selected
2022-02-14 10:56:42 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@2300575e woken up from select, 0/0/0 selected
2022-02-14 10:56:42 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@2300575e processing 0 keys, 1 updates
2022-02-14 10:56:42 DEBUG ManagedSelector:558 - updateable 1
2022-02-14 10:56:42 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$CloseConnections@35e48ed1
2022-02-14 10:56:42 DEBUG ManagedSelector:996 - Closing 0 connections on ManagedSelector@10fda3d0{STOPPING} id=3 keys=0 selected=0 updates=0
2022-02-14 10:56:42 DEBUG ManagedSelector:587 - updates 0
2022-02-14 10:56:42 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@2300575e waiting with 0 keys
2022-02-14 10:56:42 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$StopSelector@6e8816f9 on ManagedSelector@10fda3d0{STOPPING} id=3 keys=0 selected=0 updates=0
2022-02-14 10:56:42 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@10fda3d0{STOPPING} id=3 keys=0 selected=0 updates=1
2022-02-14 10:56:42 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@2300575e woken with none selected
2022-02-14 10:56:42 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@2300575e woken up from select, 0/0/0 selected
2022-02-14 10:56:42 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@2300575e processing 0 keys, 1 updates
2022-02-14 10:56:42 DEBUG ManagedSelector:558 - updateable 1
2022-02-14 10:56:42 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$StopSelector@6e8816f9
2022-02-14 10:56:42 DEBUG ManagedSelector:587 - updates 0
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:212 - stopping EatWhatYouKill@6f1a80fb/SelectorProducer@5a237731/PRODUCING/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:42.6149501+05:30
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.io.ManagedSelector$$Lambda$447/0x000000080052ac40@212dfd39 in QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}]
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:224 - STOPPED EatWhatYouKill@6f1a80fb/SelectorProducer@5a237731/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:42.6149501+05:30
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:224 - STOPPED ManagedSelector@10fda3d0{STOPPED} id=3 keys=-1 selected=-1 updates=0
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:212 - stopping ManagedSelector@41fe8e5f{STARTED} id=2 keys=0 selected=0 updates=0
2022-02-14 10:56:42 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$CloseConnections@2d4ce76b on ManagedSelector@41fe8e5f{STOPPING} id=2 keys=0 selected=0 updates=0
2022-02-14 10:56:42 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@41fe8e5f{STOPPING} id=2 keys=0 selected=0 updates=1
2022-02-14 10:56:42 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@24bf7b21 woken with none selected
2022-02-14 10:56:42 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@24bf7b21 woken up from select, 0/0/0 selected
2022-02-14 10:56:42 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@24bf7b21 processing 0 keys, 1 updates
2022-02-14 10:56:42 DEBUG ManagedSelector:558 - updateable 1
2022-02-14 10:56:42 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$CloseConnections@2d4ce76b
2022-02-14 10:56:42 DEBUG ManagedSelector:996 - Closing 0 connections on ManagedSelector@41fe8e5f{STOPPING} id=2 keys=0 selected=0 updates=0
2022-02-14 10:56:42 DEBUG ManagedSelector:587 - updates 0
2022-02-14 10:56:42 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@24bf7b21 waiting with 0 keys
2022-02-14 10:56:42 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$StopSelector@5817f0e7 on ManagedSelector@41fe8e5f{STOPPING} id=2 keys=0 selected=0 updates=0
2022-02-14 10:56:42 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@41fe8e5f{STOPPING} id=2 keys=0 selected=0 updates=1
2022-02-14 10:56:42 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@24bf7b21 woken with none selected
2022-02-14 10:56:42 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@24bf7b21 woken up from select, 0/0/0 selected
2022-02-14 10:56:42 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@24bf7b21 processing 0 keys, 1 updates
2022-02-14 10:56:42 DEBUG ManagedSelector:558 - updateable 1
2022-02-14 10:56:42 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$StopSelector@5817f0e7
2022-02-14 10:56:42 DEBUG ManagedSelector:587 - updates 0
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:212 - stopping EatWhatYouKill@245ec1a6/SelectorProducer@782be4eb/PRODUCING/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:42.6149501+05:30
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.io.ManagedSelector$$Lambda$447/0x000000080052ac40@7c251f90 in QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}]
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:224 - STOPPED EatWhatYouKill@245ec1a6/SelectorProducer@782be4eb/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:42.6149501+05:30
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:224 - STOPPED ManagedSelector@41fe8e5f{STOPPED} id=2 keys=-1 selected=-1 updates=0
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:212 - stopping ManagedSelector@36bf84e{STARTED} id=1 keys=0 selected=0 updates=0
2022-02-14 10:56:42 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$CloseConnections@3b48bdb5 on ManagedSelector@36bf84e{STOPPING} id=1 keys=0 selected=0 updates=0
2022-02-14 10:56:42 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@36bf84e{STOPPING} id=1 keys=0 selected=0 updates=1
2022-02-14 10:56:42 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@6c214f82 woken with none selected
2022-02-14 10:56:42 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@6c214f82 woken up from select, 0/0/0 selected
2022-02-14 10:56:42 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@6c214f82 processing 0 keys, 1 updates
2022-02-14 10:56:42 DEBUG ManagedSelector:558 - updateable 1
2022-02-14 10:56:42 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$CloseConnections@3b48bdb5
2022-02-14 10:56:42 DEBUG ManagedSelector:996 - Closing 0 connections on ManagedSelector@36bf84e{STOPPING} id=1 keys=0 selected=0 updates=0
2022-02-14 10:56:42 DEBUG ManagedSelector:587 - updates 0
2022-02-14 10:56:42 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@6c214f82 waiting with 0 keys
2022-02-14 10:56:42 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$StopSelector@70e72d1e on ManagedSelector@36bf84e{STOPPING} id=1 keys=0 selected=0 updates=0
2022-02-14 10:56:42 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@36bf84e{STOPPING} id=1 keys=0 selected=0 updates=1
2022-02-14 10:56:42 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@6c214f82 woken with none selected
2022-02-14 10:56:42 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@6c214f82 woken up from select, 0/0/0 selected
2022-02-14 10:56:42 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@6c214f82 processing 0 keys, 1 updates
2022-02-14 10:56:42 DEBUG ManagedSelector:558 - updateable 1
2022-02-14 10:56:42 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$StopSelector@70e72d1e
2022-02-14 10:56:42 DEBUG ManagedSelector:587 - updates 0
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:212 - stopping EatWhatYouKill@5f172d4a/SelectorProducer@77ec6a3d/PRODUCING/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:42.6149501+05:30
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.io.ManagedSelector$$Lambda$447/0x000000080052ac40@3f725306 in QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}]
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:224 - STOPPED EatWhatYouKill@5f172d4a/SelectorProducer@77ec6a3d/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:42.6149501+05:30
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:224 - STOPPED ManagedSelector@36bf84e{STOPPED} id=1 keys=-1 selected=-1 updates=0
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:212 - stopping ManagedSelector@56afdf9a{STARTED} id=0 keys=0 selected=0 updates=0
2022-02-14 10:56:42 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$CloseConnections@77fe6af6 on ManagedSelector@56afdf9a{STOPPING} id=0 keys=0 selected=0 updates=0
2022-02-14 10:56:42 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@56afdf9a{STOPPING} id=0 keys=0 selected=0 updates=1
2022-02-14 10:56:42 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@580815ba woken with none selected
2022-02-14 10:56:42 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@580815ba woken up from select, 0/0/0 selected
2022-02-14 10:56:42 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@580815ba processing 0 keys, 1 updates
2022-02-14 10:56:42 DEBUG ManagedSelector:558 - updateable 1
2022-02-14 10:56:42 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$CloseConnections@77fe6af6
2022-02-14 10:56:42 DEBUG ManagedSelector:996 - Closing 0 connections on ManagedSelector@56afdf9a{STOPPING} id=0 keys=0 selected=0 updates=0
2022-02-14 10:56:42 DEBUG ManagedSelector:587 - updates 0
2022-02-14 10:56:42 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$StopSelector@2014135 on ManagedSelector@56afdf9a{STOPPING} id=0 keys=0 selected=0 updates=0
2022-02-14 10:56:42 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@580815ba waiting with 0 keys
2022-02-14 10:56:42 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@56afdf9a{STOPPING} id=0 keys=0 selected=0 updates=1
2022-02-14 10:56:42 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@580815ba woken with none selected
2022-02-14 10:56:42 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@580815ba woken up from select, 0/0/0 selected
2022-02-14 10:56:42 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@580815ba processing 0 keys, 1 updates
2022-02-14 10:56:42 DEBUG ManagedSelector:558 - updateable 1
2022-02-14 10:56:42 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$StopSelector@2014135
2022-02-14 10:56:42 DEBUG ManagedSelector:587 - updates 0
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:212 - stopping EatWhatYouKill@750ff7d3/SelectorProducer@1729ec00/PRODUCING/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:42.6231667+05:30
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.io.ManagedSelector$$Lambda$447/0x000000080052ac40@73fb1d7f in QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}]
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:224 - STOPPED EatWhatYouKill@750ff7d3/SelectorProducer@1729ec00/IDLE/p=false/QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:56:42.6231667+05:30
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:224 - STOPPED ManagedSelector@56afdf9a{STOPPED} id=0 keys=-1 selected=-1 updates=0
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:224 - STOPPED SelectorManager@Spark@78226c36{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:212 - stopping HttpConnectionFactory@3c0bbc9f[HTTP/1.1]
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:224 - STOPPED HttpConnectionFactory@3c0bbc9f[HTTP/1.1]
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:212 - stopping ScheduledExecutorScheduler@987455b{STARTED}
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:224 - STOPPED ScheduledExecutorScheduler@987455b{STOPPED}
2022-02-14 10:56:42 INFO  AbstractConnector:381 - Stopped Spark@78226c36{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:224 - STOPPED Spark@78226c36{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-14 10:56:42 DEBUG AbstractHandler:107 - stopping Server@1aa6e3c0{STOPPING}[9.4.40.v20210413]
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:212 - stopping ContextHandlerCollection@61a1ea2c{STARTED}
2022-02-14 10:56:42 DEBUG AbstractHandler:107 - stopping ContextHandlerCollection@61a1ea2c{STOPPING}
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:224 - STOPPED ContextHandlerCollection@61a1ea2c{STOPPED}
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:212 - stopping ErrorHandler@2caa5d7c{STARTED}
2022-02-14 10:56:42 DEBUG AbstractHandler:107 - stopping ErrorHandler@2caa5d7c{STOPPING}
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:224 - STOPPED ErrorHandler@2caa5d7c{STOPPED}
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:212 - stopping QueuedThreadPool[SparkUI]@fabb651{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:224 - Stopping QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@43d38654{s=0/8,p=0}]
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:212 - stopping ReservedThreadExecutor@43d38654{s=0/8,p=0}
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:224 - STOPPED ReservedThreadExecutor@43d38654{s=-1/8,p=0}
2022-02-14 10:56:42 DEBUG QueuedThreadPool:317 - Waiting for Thread[SparkUI-35,5,main] for 14999
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@b1ac567 in QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@b1ac567 in QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@b1ac567 in QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@b1ac567 in QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@b1ac567 in QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@b1ac567 in QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@b1ac567 in QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@b1ac567 in QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@b1ac567 in QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@b1ac567 in QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-33,5,main] exited for QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@b1ac567 in QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@b1ac567 in QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@b1ac567 in QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@b1ac567 in QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@b1ac567 in QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-35,5,main] exited for QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-37,5,main] exited for QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-36,5,main] exited for QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-32,5,main] exited for QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-34,5,main] exited for QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@b1ac567 in QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:317 - Waiting for Thread[SparkUI-34,5,main] for 14997
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-31,5,main] exited for QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG QueuedThreadPool:317 - Waiting for Thread[SparkUI-38,5,main] for 14996
2022-02-14 10:56:42 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-38,5,main] exited for QueuedThreadPool[SparkUI]@fabb651{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:224 - STOPPED QueuedThreadPool[SparkUI]@fabb651{STOPPED,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:56:42 DEBUG AbstractLifeCycle:224 - STOPPED Server@1aa6e3c0{STOPPED}[9.4.40.v20210413]
2022-02-14 10:56:42 INFO  SparkUI:57 - Stopped Spark web UI at http://Clairvoyant-320:4040
2022-02-14 10:56:42 INFO  MapOutputTrackerMasterEndpoint:57 - MapOutputTrackerMasterEndpoint stopped!
2022-02-14 10:56:44 INFO  MemoryStore:57 - MemoryStore cleared
2022-02-14 10:56:44 INFO  BlockManager:57 - BlockManager stopped
2022-02-14 10:56:44 INFO  BlockManagerMaster:57 - BlockManagerMaster stopped
2022-02-14 10:56:44 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:57 - OutputCommitCoordinator stopped!
2022-02-14 10:56:44 INFO  SparkContext:57 - Successfully stopped SparkContext
2022-02-14 10:56:44 INFO  ShutdownHookManager:57 - Shutdown hook called
2022-02-14 10:56:44 INFO  ShutdownHookManager:57 - Deleting directory C:\Users\Shridhar Ingale\AppData\Local\Temp\spark-d49c8f9c-28c3-4454-b702-a7392d725a83

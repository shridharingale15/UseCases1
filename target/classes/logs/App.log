2022-02-14 10:55:35 INFO  SparkContext:57 - Running Spark version 3.0.3
2022-02-14 10:55:35 DEBUG MutableMetricsFactory:42 - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about="", sampleName="Ops", always=false, type=DEFAULT, valueName="Time", value={"Rate of successful kerberos logins and latency (milliseconds)"})
2022-02-14 10:55:35 DEBUG MutableMetricsFactory:42 - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about="", sampleName="Ops", always=false, type=DEFAULT, valueName="Time", value={"Rate of failed kerberos logins and latency (milliseconds)"})
2022-02-14 10:55:35 DEBUG MutableMetricsFactory:42 - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about="", sampleName="Ops", always=false, type=DEFAULT, valueName="Time", value={"GetGroups"})
2022-02-14 10:55:35 DEBUG MetricsSystemImpl:232 - UgiMetrics, User and group related metrics
2022-02-14 10:55:35 DEBUG KerberosName:89 - Kerberos krb5 configuration not found, setting default realm to empty
2022-02-14 10:55:35 DEBUG Groups:301 -  Creating new Groups object
2022-02-14 10:55:35 DEBUG NativeCodeLoader:46 - Trying to load the custom-built native-hadoop library...
2022-02-14 10:55:35 DEBUG NativeCodeLoader:50 - Loaded the native-hadoop library
2022-02-14 10:55:35 DEBUG JniBasedUnixGroupsMapping:50 - Using JniBasedUnixGroupsMapping for Group resolution
2022-02-14 10:55:35 DEBUG JniBasedUnixGroupsMappingWithFallback:45 - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
2022-02-14 10:55:36 DEBUG Groups:112 - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2022-02-14 10:55:36 DEBUG UserGroupInformation:223 - hadoop login
2022-02-14 10:55:36 DEBUG UserGroupInformation:158 - hadoop login commit
2022-02-14 10:55:36 DEBUG UserGroupInformation:188 - using local user:NTUserPrincipal: Shridhar Ingale
2022-02-14 10:55:36 DEBUG UserGroupInformation:194 - Using user: "NTUserPrincipal: Shridhar Ingale" with name Shridhar Ingale
2022-02-14 10:55:36 DEBUG UserGroupInformation:204 - User entry: "Shridhar Ingale"
2022-02-14 10:55:36 DEBUG UserGroupInformation:816 - Assuming keytab is managed externally since logged in from subject.
2022-02-14 10:55:36 DEBUG UserGroupInformation:844 - UGI loginUser:Shridhar Ingale (auth:SIMPLE)
2022-02-14 10:55:36 INFO  ResourceUtils:57 - ==============================================================
2022-02-14 10:55:36 INFO  ResourceUtils:57 - Resources for spark.driver:

2022-02-14 10:55:36 INFO  ResourceUtils:57 - ==============================================================
2022-02-14 10:55:36 INFO  SparkContext:57 - Submitted application: 114c29dd-c543-4d03-9add-2da445b8eb3d
2022-02-14 10:55:36 INFO  SecurityManager:57 - Changing view acls to: Shridhar Ingale
2022-02-14 10:55:36 INFO  SecurityManager:57 - Changing modify acls to: Shridhar Ingale
2022-02-14 10:55:36 INFO  SecurityManager:57 - Changing view acls groups to: 
2022-02-14 10:55:36 INFO  SecurityManager:57 - Changing modify acls groups to: 
2022-02-14 10:55:36 INFO  SecurityManager:57 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Shridhar Ingale); groups with view permissions: Set(); users  with modify permissions: Set(Shridhar Ingale); groups with modify permissions: Set()
2022-02-14 10:55:36 DEBUG InternalLoggerFactory:45 - Using SLF4J as the default logging framework
2022-02-14 10:55:36 DEBUG InternalThreadLocalMap:56 - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2022-02-14 10:55:36 DEBUG InternalThreadLocalMap:59 - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2022-02-14 10:55:36 DEBUG MultithreadEventLoopGroup:44 - -Dio.netty.eventLoopThreads: 16
2022-02-14 10:55:36 DEBUG NioEventLoop:106 - -Dio.netty.noKeySetOptimization: false
2022-02-14 10:55:36 DEBUG NioEventLoop:107 - -Dio.netty.selectorAutoRebuildThreshold: 512
2022-02-14 10:55:36 DEBUG PlatformDependent:1003 - Platform: Windows
2022-02-14 10:55:36 DEBUG PlatformDependent0:396 - -Dio.netty.noUnsafe: false
2022-02-14 10:55:36 DEBUG PlatformDependent0:852 - Java version: 11
2022-02-14 10:55:36 DEBUG PlatformDependent0:121 - sun.misc.Unsafe.theUnsafe: available
2022-02-14 10:55:36 DEBUG PlatformDependent0:145 - sun.misc.Unsafe.copyMemory: available
2022-02-14 10:55:36 DEBUG PlatformDependent0:183 - java.nio.Buffer.address: available
2022-02-14 10:55:36 DEBUG PlatformDependent0:253 - direct buffer constructor: unavailable
java.lang.UnsupportedOperationException: Reflective setAccessible(true) disabled
	at io.netty.util.internal.ReflectionUtil.trySetAccessible(ReflectionUtil.java:31)
	at io.netty.util.internal.PlatformDependent0$4.run(PlatformDependent0.java:225)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:219)
	at io.netty.util.internal.PlatformDependent.isAndroid(PlatformDependent.java:289)
	at io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:92)
	at io.netty.channel.nio.NioEventLoop.newTaskQueue0(NioEventLoop.java:279)
	at io.netty.channel.nio.NioEventLoop.newTaskQueue(NioEventLoop.java:150)
	at io.netty.channel.nio.NioEventLoop.<init>(NioEventLoop.java:138)
	at io.netty.channel.nio.NioEventLoopGroup.newChild(NioEventLoopGroup.java:146)
	at io.netty.channel.nio.NioEventLoopGroup.newChild(NioEventLoopGroup.java:37)
	at io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:84)
	at io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:58)
	at io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:47)
	at io.netty.channel.MultithreadEventLoopGroup.<init>(MultithreadEventLoopGroup.java:59)
	at io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:86)
	at io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:81)
	at io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:68)
	at org.apache.spark.network.util.NettyUtils.createEventLoop(NettyUtils.java:66)
	at org.apache.spark.network.client.TransportClientFactory.<init>(TransportClientFactory.java:102)
	at org.apache.spark.network.TransportContext.createClientFactory(TransportContext.java:142)
	at org.apache.spark.rpc.netty.NettyRpcEnv.<init>(NettyRpcEnv.scala:77)
	at org.apache.spark.rpc.netty.NettyRpcEnvFactory.create(NettyRpcEnv.scala:486)
	at org.apache.spark.rpc.RpcEnv$.create(RpcEnv.scala:57)
	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:266)
	at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:189)
	at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:272)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2589)
	at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:937)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:931)
	at My_UsedCases.UsedCase4.My_func_swap2(UsedCase4.java:11)
	at MyTEsts.UseCaseTest4.My_func5(UseCaseTest4.java:9)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:220)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:53)
2022-02-14 10:55:36 DEBUG PlatformDependent0:314 - java.nio.Bits.unaligned: available, true
2022-02-14 10:55:36 DEBUG PlatformDependent0:373 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable
java.lang.IllegalAccessException: class io.netty.util.internal.PlatformDependent0$6 cannot access class jdk.internal.misc.Unsafe (in module java.base) because module java.base does not export jdk.internal.misc to unnamed module @7331196b
	at java.base/jdk.internal.reflect.Reflection.newIllegalAccessException(Reflection.java:361)
	at java.base/java.lang.reflect.AccessibleObject.checkAccess(AccessibleObject.java:591)
	at java.base/java.lang.reflect.Method.invoke(Method.java:558)
	at io.netty.util.internal.PlatformDependent0$6.run(PlatformDependent0.java:335)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:326)
	at io.netty.util.internal.PlatformDependent.isAndroid(PlatformDependent.java:289)
	at io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:92)
	at io.netty.channel.nio.NioEventLoop.newTaskQueue0(NioEventLoop.java:279)
	at io.netty.channel.nio.NioEventLoop.newTaskQueue(NioEventLoop.java:150)
	at io.netty.channel.nio.NioEventLoop.<init>(NioEventLoop.java:138)
	at io.netty.channel.nio.NioEventLoopGroup.newChild(NioEventLoopGroup.java:146)
	at io.netty.channel.nio.NioEventLoopGroup.newChild(NioEventLoopGroup.java:37)
	at io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:84)
	at io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:58)
	at io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:47)
	at io.netty.channel.MultithreadEventLoopGroup.<init>(MultithreadEventLoopGroup.java:59)
	at io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:86)
	at io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:81)
	at io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:68)
	at org.apache.spark.network.util.NettyUtils.createEventLoop(NettyUtils.java:66)
	at org.apache.spark.network.client.TransportClientFactory.<init>(TransportClientFactory.java:102)
	at org.apache.spark.network.TransportContext.createClientFactory(TransportContext.java:142)
	at org.apache.spark.rpc.netty.NettyRpcEnv.<init>(NettyRpcEnv.scala:77)
	at org.apache.spark.rpc.netty.NettyRpcEnvFactory.create(NettyRpcEnv.scala:486)
	at org.apache.spark.rpc.RpcEnv$.create(RpcEnv.scala:57)
	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:266)
	at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:189)
	at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:272)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2589)
	at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:937)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:931)
	at My_UsedCases.UsedCase4.My_func_swap2(UsedCase4.java:11)
	at MyTEsts.UseCaseTest4.My_func5(UseCaseTest4.java:9)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:220)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:53)
2022-02-14 10:55:36 DEBUG PlatformDependent0:386 - java.nio.DirectByteBuffer.<init>(long, int): unavailable
2022-02-14 10:55:36 DEBUG PlatformDependent:1046 - sun.misc.Unsafe: available
2022-02-14 10:55:36 DEBUG PlatformDependent:1146 - maxDirectMemory: 4227858432 bytes (maybe)
2022-02-14 10:55:36 DEBUG PlatformDependent:1165 - -Dio.netty.tmpdir: C:\Users\SHRIDH~1\AppData\Local\Temp (java.io.tmpdir)
2022-02-14 10:55:36 DEBUG PlatformDependent:1244 - -Dio.netty.bitMode: 64 (sun.arch.data.model)
2022-02-14 10:55:36 DEBUG PlatformDependent:177 - -Dio.netty.maxDirectMemory: -1 bytes
2022-02-14 10:55:36 DEBUG PlatformDependent:184 - -Dio.netty.uninitializedArrayAllocationThreshold: -1
2022-02-14 10:55:36 DEBUG CleanerJava9:71 - java.nio.ByteBuffer.cleaner(): available
2022-02-14 10:55:36 DEBUG PlatformDependent:204 - -Dio.netty.noPreferDirect: false
2022-02-14 10:55:36 DEBUG PlatformDependent:907 - org.jctools-core.MpscChunkedArrayQueue: available
2022-02-14 10:55:36 DEBUG ResourceLeakDetector:130 - -Dio.netty.leakDetection.level: simple
2022-02-14 10:55:36 DEBUG ResourceLeakDetector:131 - -Dio.netty.leakDetection.targetRecords: 4
2022-02-14 10:55:36 DEBUG PooledByteBufAllocator:156 - -Dio.netty.allocator.numHeapArenas: 16
2022-02-14 10:55:36 DEBUG PooledByteBufAllocator:157 - -Dio.netty.allocator.numDirectArenas: 16
2022-02-14 10:55:36 DEBUG PooledByteBufAllocator:159 - -Dio.netty.allocator.pageSize: 8192
2022-02-14 10:55:36 DEBUG PooledByteBufAllocator:164 - -Dio.netty.allocator.maxOrder: 11
2022-02-14 10:55:36 DEBUG PooledByteBufAllocator:168 - -Dio.netty.allocator.chunkSize: 16777216
2022-02-14 10:55:36 DEBUG PooledByteBufAllocator:169 - -Dio.netty.allocator.tinyCacheSize: 512
2022-02-14 10:55:36 DEBUG PooledByteBufAllocator:170 - -Dio.netty.allocator.smallCacheSize: 256
2022-02-14 10:55:36 DEBUG PooledByteBufAllocator:171 - -Dio.netty.allocator.normalCacheSize: 64
2022-02-14 10:55:36 DEBUG PooledByteBufAllocator:172 - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2022-02-14 10:55:36 DEBUG PooledByteBufAllocator:173 - -Dio.netty.allocator.cacheTrimInterval: 8192
2022-02-14 10:55:36 DEBUG PooledByteBufAllocator:174 - -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2022-02-14 10:55:36 DEBUG PooledByteBufAllocator:175 - -Dio.netty.allocator.useCacheForAllThreads: true
2022-02-14 10:55:36 DEBUG PooledByteBufAllocator:176 - -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2022-02-14 10:55:36 DEBUG DefaultChannelId:79 - -Dio.netty.processId: 3708 (auto-detected)
2022-02-14 10:55:36 DEBUG NetUtil:139 - -Djava.net.preferIPv4Stack: false
2022-02-14 10:55:36 DEBUG NetUtil:140 - -Djava.net.preferIPv6Addresses: false
2022-02-14 10:55:37 DEBUG NetUtil:224 - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
2022-02-14 10:55:37 DEBUG NetUtil:289 - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
2022-02-14 10:55:37 DEBUG DefaultChannelId:101 - -Dio.netty.machineId: 00:50:56:ff:fe:c0:00:01 (auto-detected)
2022-02-14 10:55:37 DEBUG ByteBufUtil:86 - -Dio.netty.allocator.type: pooled
2022-02-14 10:55:37 DEBUG ByteBufUtil:95 - -Dio.netty.threadLocalDirectBufferSize: 0
2022-02-14 10:55:37 DEBUG ByteBufUtil:98 - -Dio.netty.maxThreadLocalCharBufferSize: 16384
2022-02-14 10:55:37 DEBUG TransportServer:153 - Shuffle server started on port: 60325
2022-02-14 10:55:37 INFO  Utils:57 - Successfully started service 'sparkDriver' on port 60325.
2022-02-14 10:55:37 DEBUG SparkEnv:61 - Using serializer: class org.apache.spark.serializer.JavaSerializer
2022-02-14 10:55:37 INFO  SparkEnv:57 - Registering MapOutputTracker
2022-02-14 10:55:37 DEBUG MapOutputTrackerMasterEndpoint:61 - init
2022-02-14 10:55:37 INFO  SparkEnv:57 - Registering BlockManagerMaster
2022-02-14 10:55:37 INFO  BlockManagerMasterEndpoint:57 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022-02-14 10:55:37 INFO  BlockManagerMasterEndpoint:57 - BlockManagerMasterEndpoint up
2022-02-14 10:55:37 INFO  SparkEnv:57 - Registering BlockManagerMasterHeartbeat
2022-02-14 10:55:37 INFO  DiskBlockManager:57 - Created local directory at C:\Users\Shridhar Ingale\AppData\Local\Temp\blockmgr-2036601a-b309-4d0a-95f6-ceaa42e16ee9
2022-02-14 10:55:37 DEBUG DiskBlockManager:61 - Adding shutdown hook
2022-02-14 10:55:37 DEBUG ShutdownHookManager:61 - Adding shutdown hook
2022-02-14 10:55:37 INFO  MemoryStore:57 - MemoryStore started with capacity 2.2 GiB
2022-02-14 10:55:37 INFO  SparkEnv:57 - Registering OutputCommitCoordinator
2022-02-14 10:55:37 DEBUG OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:61 - init
2022-02-14 10:55:37 DEBUG SecurityManager:61 - Created SSL options for ui: SSLOptions{enabled=false, port=None, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2022-02-14 10:55:37 DEBUG log:159 - Logging to org.slf4j.impl.Log4jLoggerAdapter(org.sparkproject.jetty.util.log) via org.sparkproject.jetty.util.log.Slf4jLog
2022-02-14 10:55:37 INFO  log:169 - Logging initialized @9770ms to org.sparkproject.jetty.util.log.Slf4jLog
2022-02-14 10:55:37 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@327ed9f5
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@379ce046{/,null,STOPPED} added {ServletHandler@7ed9499e{STOPPED},MANAGED}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@7ed9499e{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-1ff55ff==org.apache.spark.ui.JettyUtils$$anon$1@862b7623{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@7ed9499e{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-1ff55ff,POJO}
2022-02-14 10:55:37 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@7df76d99
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@2acbc859{/,null,STOPPED} added {ServletHandler@6ab7ce48{STOPPED},MANAGED}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@6ab7ce48{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-e322ec9==org.apache.spark.ui.JettyUtils$$anon$1@eb0ae7ff{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@6ab7ce48{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-e322ec9,POJO}
2022-02-14 10:55:37 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@25a5c7db
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@28f878a0{/,null,STOPPED} added {ServletHandler@20411320{STOPPED},MANAGED}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@20411320{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-3c782d8e==org.apache.spark.ui.JettyUtils$$anon$1@20480dbe{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@20411320{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-3c782d8e,POJO}
2022-02-14 10:55:37 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@58b71ceb
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@12abdfb{/,null,STOPPED} added {ServletHandler@b0e5507{STOPPED},MANAGED}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@b0e5507{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-3c46dcbe==org.apache.spark.ui.JettyUtils$$anon$1@1b2410c2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@b0e5507{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-3c46dcbe,POJO}
2022-02-14 10:55:37 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@2eb917d0
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@73437222{/,null,STOPPED} added {ServletHandler@ca93621{STOPPED},MANAGED}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@ca93621{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-3f985a86==org.apache.spark.ui.JettyUtils$$anon$1@c265c26a{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@ca93621{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-3f985a86,POJO}
2022-02-14 10:55:37 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@3d278b4d
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@9d3c67{/,null,STOPPED} added {ServletHandler@6c806c8b{STOPPED},MANAGED}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@6c806c8b{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-184fb68d==org.apache.spark.ui.JettyUtils$$anon$1@6b589487{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@6c806c8b{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-184fb68d,POJO}
2022-02-14 10:55:37 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@71466383
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@4088741b{/,null,STOPPED} added {ServletHandler@16a49a5d{STOPPED},MANAGED}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@16a49a5d{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-23706db8==org.apache.spark.ui.JettyUtils$$anon$1@ccccdf0c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@16a49a5d{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-23706db8,POJO}
2022-02-14 10:55:37 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@23592946
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@7c2b58c0{/,null,STOPPED} added {ServletHandler@11b377c5{STOPPED},MANAGED}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@11b377c5{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-5c60b0a0==org.apache.spark.ui.JettyUtils$$anon$1@edf9e633{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@11b377c5{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-5c60b0a0,POJO}
2022-02-14 10:55:37 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@10fbbdb
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@31d6f3fe{/,null,STOPPED} added {ServletHandler@760cf594{STOPPED},MANAGED}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@760cf594{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-37303f12==org.apache.spark.ui.JettyUtils$$anon$1@1723ae3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@760cf594{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-37303f12,POJO}
2022-02-14 10:55:37 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@20a05b32
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@5c73f672{/,null,STOPPED} added {ServletHandler@8ee0c23{STOPPED},MANAGED}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@8ee0c23{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-4dc8c0ea==org.apache.spark.ui.JettyUtils$$anon$1@83a399c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@8ee0c23{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-4dc8c0ea,POJO}
2022-02-14 10:55:37 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@5eed2d86
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@69a2b3b6{/,null,STOPPED} added {ServletHandler@4f3e7344{STOPPED},MANAGED}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@4f3e7344{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-62d73ead==org.apache.spark.ui.JettyUtils$$anon$1@8496b672{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@4f3e7344{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-62d73ead,POJO}
2022-02-14 10:55:37 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@1d0a61c8
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@782bf610{/,null,STOPPED} added {ServletHandler@3db663d0{STOPPED},MANAGED}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@3db663d0{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-2de50ee4==org.apache.spark.ui.JettyUtils$$anon$1@3ba0e274{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@3db663d0{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-2de50ee4,POJO}
2022-02-14 10:55:37 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@10895b16
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@2cc03cd1{/,null,STOPPED} added {ServletHandler@4e17913b{STOPPED},MANAGED}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@4e17913b{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-64f16277==org.apache.spark.ui.JettyUtils$$anon$1@f178e993{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@4e17913b{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-64f16277,POJO}
2022-02-14 10:55:37 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@4e6f2bb5
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@3f628ce9{/,null,STOPPED} added {ServletHandler@35e8316e{STOPPED},MANAGED}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@35e8316e{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-336880df==org.apache.spark.ui.JettyUtils$$anon$1@336a154a{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:37 DEBUG ContainerLifeCycle:412 - ServletHandler@35e8316e{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-336880df,POJO}
2022-02-14 10:55:37 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@7be7e15
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@7a0f244f{/,null,STOPPED} added {ServletHandler@3672276e{STOPPED},MANAGED}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@3672276e{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-7f08caf==org.apache.spark.ui.JettyUtils$$anon$1@c099eda3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@3672276e{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-7f08caf,POJO}
2022-02-14 10:55:38 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@24b4d544
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@54657dd2{/,null,STOPPED} added {ServletHandler@706eab5d{STOPPED},MANAGED}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@706eab5d{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-40e60ece==org.apache.spark.ui.JettyUtils$$anon$1@4cad4a72{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@706eab5d{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-40e60ece,POJO}
2022-02-14 10:55:38 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@2d0ecb24
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@3bfc6a5e{/,null,STOPPED} added {ServletHandler@51b35e4e{STOPPED},MANAGED}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@51b35e4e{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-6d7cada5==org.apache.spark.ui.JettyUtils$$anon$1@8f45247f{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@51b35e4e{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-6d7cada5,POJO}
2022-02-14 10:55:38 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@b0fc838
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@62db0521{/,null,STOPPED} added {ServletHandler@1b4ae4e0{STOPPED},MANAGED}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@1b4ae4e0{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-5fbdc49b==org.apache.spark.ui.JettyUtils$$anon$1@da9f183b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@1b4ae4e0{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-5fbdc49b,POJO}
2022-02-14 10:55:38 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@7be3a9ce
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@3baf6936{/,null,STOPPED} added {ServletHandler@285f38f6{STOPPED},MANAGED}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@285f38f6{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-3ab6678b==org.apache.spark.ui.JettyUtils$$anon$1@ffc0f37b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@285f38f6{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-3ab6678b,POJO}
2022-02-14 10:55:38 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@476e8796
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@36fc05ff{/,null,STOPPED} added {ServletHandler@57c47a9e{STOPPED},MANAGED}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@57c47a9e{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-4339e0de==org.apache.spark.ui.JettyUtils$$anon$1@964f447f{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@57c47a9e{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-4339e0de,POJO}
2022-02-14 10:55:38 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@21ac5eb4
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@715d6168{/,null,STOPPED} added {ServletHandler@27b2faa6{STOPPED},MANAGED}
2022-02-14 10:55:38 DEBUG PreEncodedHttpField:61 - HttpField encoders loaded: []
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@27b2faa6{STOPPED} added {org.sparkproject.jetty.servlet.DefaultServlet-2e53b094==org.sparkproject.jetty.servlet.DefaultServlet@5a6d2702{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@27b2faa6{STOPPED} added {[/]=>org.sparkproject.jetty.servlet.DefaultServlet-2e53b094,POJO}
2022-02-14 10:55:38 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@6137cf6e
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@53b8afea{/,null,STOPPED} added {ServletHandler@6c302a1d{STOPPED},MANAGED}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@6c302a1d{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$2-5fcfca62==org.apache.spark.ui.JettyUtils$$anon$2@d0ba395b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@6c302a1d{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-5fcfca62,POJO}
2022-02-14 10:55:38 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@28501a4b
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@639aba11{/,null,STOPPED} added {ServletHandler@341672e{STOPPED},MANAGED}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@341672e{STOPPED} added {org.glassfish.jersey.servlet.ServletContainer-58496c97==org.glassfish.jersey.servlet.ServletContainer@48ef0fc1{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@341672e{STOPPED} added {[/*]=>org.glassfish.jersey.servlet.ServletContainer-58496c97,POJO}
2022-02-14 10:55:38 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@6c518474
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@2a066689{/,null,STOPPED} added {ServletHandler@3e3861d7{STOPPED},MANAGED}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@3e3861d7{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$2-6d025d1d==org.apache.spark.ui.JettyUtils$$anon$2@74d6239f{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@3e3861d7{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-6d025d1d,POJO}
2022-02-14 10:55:38 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@79d06bbd
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@5bb51241{/,null,STOPPED} added {ServletHandler@7479b626{STOPPED},MANAGED}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@7479b626{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$2-74dbb1ee==org.apache.spark.ui.JettyUtils$$anon$2@4d005857{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@7479b626{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-74dbb1ee,POJO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - QueuedThreadPool[qtp1041905665]@3e1a3801{STOPPED,8<=0<=200,i=0,r=-1,q=0}[NO_TRY] added {org.sparkproject.jetty.util.thread.ThreadPoolBudget@216914,POJO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - Server@59901c4d{STOPPED}[9.4.40.v20210413] added {QueuedThreadPool[SparkUI]@3e1a3801{STOPPED,8<=0<=200,i=0,r=-1,q=0}[NO_TRY],AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - Server@59901c4d{STOPPED}[9.4.40.v20210413] added {ErrorHandler@47af099e{STOPPED},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - Server@59901c4d{STOPPED}[9.4.40.v20210413] added {ContextHandlerCollection@7139bd31{STOPPED},MANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting Server@59901c4d{STOPPED}[9.4.40.v20210413]
2022-02-14 10:55:38 INFO  Server:375 - jetty-9.4.40.v20210413; built: 2021-04-13T20:42:42.668Z; git: b881a572662e1943a14ae12e7e1207989f218b74; jvm 11.0.8+10-LTS
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting Server@59901c4d{STARTING}[9.4.40.v20210413]
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting QueuedThreadPool[SparkUI]@3e1a3801{STOPPED,8<=0<=200,i=0,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:38 DEBUG ReservedThreadExecutor:85 - ReservedThreadExecutor@18acfe88{s=0/8,p=0}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - QueuedThreadPool[SparkUI]@3e1a3801{STARTING,8<=0<=200,i=0,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}] added {ReservedThreadExecutor@18acfe88{s=0/8,p=0},AUTO}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ReservedThreadExecutor@18acfe88{s=0/8,p=0}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @9959ms ReservedThreadExecutor@18acfe88{s=0/8,p=0}
2022-02-14 10:55:38 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-31,5,main]
2022-02-14 10:55:38 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-32,5,main]
2022-02-14 10:55:38 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-33,5,main]
2022-02-14 10:55:38 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@3e1a3801{STARTING,8<=2<=200,i=2,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}]
2022-02-14 10:55:38 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@3e1a3801{STARTING,8<=4<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}]
2022-02-14 10:55:38 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@3e1a3801{STARTING,8<=4<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}]
2022-02-14 10:55:38 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-34,5,main]
2022-02-14 10:55:38 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-35,5,main]
2022-02-14 10:55:38 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-36,5,main]
2022-02-14 10:55:38 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@3e1a3801{STARTING,8<=5<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}]
2022-02-14 10:55:38 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-37,5,main]
2022-02-14 10:55:38 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@3e1a3801{STARTING,8<=7<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}]
2022-02-14 10:55:38 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@3e1a3801{STARTING,8<=6<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}]
2022-02-14 10:55:38 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-38,5,main]
2022-02-14 10:55:38 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@3e1a3801{STARTING,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}]
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @9967ms QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}]
2022-02-14 10:55:38 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}]
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ErrorHandler@47af099e{STOPPED}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ErrorHandler@47af099e{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @9968ms ErrorHandler@47af099e{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ContextHandlerCollection@7139bd31{STOPPED}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ContextHandlerCollection@7139bd31{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @9968ms ContextHandlerCollection@7139bd31{STARTED}
2022-02-14 10:55:38 INFO  Server:415 - Started @9969ms
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @9969ms Server@59901c4d{STARTED}[9.4.40.v20210413]
2022-02-14 10:55:38 DEBUG JettyUtils:61 - Using requestHeaderSize: 8192
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - HttpConnectionFactory@74d3b638[HTTP/1.1] added {HttpConfiguration@4487c0c2{32768/8192,8192/8192,https://:0,[]},POJO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServerConnector@42b6d0cc{null, ()}{0.0.0.0:0} added {Server@59901c4d{STARTED}[9.4.40.v20210413],UNMANAGED}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServerConnector@42b6d0cc{null, ()}{0.0.0.0:0} added {QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}],UNMANAGED}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServerConnector@42b6d0cc{null, ()}{0.0.0.0:0} added {ScheduledExecutorScheduler@14b7786{STOPPED},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServerConnector@42b6d0cc{null, ()}{0.0.0.0:0} added {org.sparkproject.jetty.io.ArrayByteBufferPool@63b3ee82,POJO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServerConnector@42b6d0cc{null, (http/1.1)}{0.0.0.0:0} added {HttpConnectionFactory@74d3b638[HTTP/1.1],AUTO}
2022-02-14 10:55:38 DEBUG AbstractConnector:484 - ServerConnector@42b6d0cc{HTTP/1.1, (http/1.1)}{0.0.0.0:0} added HttpConnectionFactory@74d3b638[HTTP/1.1]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServerConnector@42b6d0cc{HTTP/1.1, (http/1.1)}{0.0.0.0:0} added {SelectorManager@ServerConnector@42b6d0cc{HTTP/1.1, (http/1.1)}{0.0.0.0:0},MANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServerConnector@42b6d0cc{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServerConnector@42b6d0cc{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} added {sun.nio.ch.ServerSocketChannelImpl[/0:0:0:0:0:0:0:0:4040],POJO}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ScheduledExecutorScheduler@14b7786{STOPPED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10018ms ScheduledExecutorScheduler@14b7786{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting HttpConnectionFactory@74d3b638[HTTP/1.1]
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10019ms HttpConnectionFactory@74d3b638[HTTP/1.1]
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting SelectorManager@ServerConnector@42b6d0cc{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@67efd2c2/SelectorProducer@10fda3d0/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.1727955+05:30 added {SelectorProducer@10fda3d0,POJO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@67efd2c2/SelectorProducer@10fda3d0/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.1727955+05:30 added {QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}],UNMANAGED}
2022-02-14 10:55:38 DEBUG EatWhatYouKill:93 - EatWhatYouKill@67efd2c2/SelectorProducer@10fda3d0/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.1727955+05:30 created
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ManagedSelector@51841ac6{STOPPED} id=0 keys=-1 selected=-1 updates=0 added {EatWhatYouKill@67efd2c2/SelectorProducer@10fda3d0/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.1783886+05:30,MANAGED}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - SelectorManager@ServerConnector@42b6d0cc{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} added {ManagedSelector@51841ac6{STOPPED} id=0 keys=-1 selected=-1 updates=0,AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@17d32e9b/SelectorProducer@66f0548d/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.1787818+05:30 added {SelectorProducer@66f0548d,POJO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@17d32e9b/SelectorProducer@66f0548d/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.1787818+05:30 added {QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}],UNMANAGED}
2022-02-14 10:55:38 DEBUG EatWhatYouKill:93 - EatWhatYouKill@17d32e9b/SelectorProducer@66f0548d/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.1787818+05:30 created
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ManagedSelector@741f8dbe{STOPPED} id=1 keys=-1 selected=-1 updates=0 added {EatWhatYouKill@17d32e9b/SelectorProducer@66f0548d/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.1787818+05:30,MANAGED}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - SelectorManager@ServerConnector@42b6d0cc{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} added {ManagedSelector@741f8dbe{STOPPED} id=1 keys=-1 selected=-1 updates=0,AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@65d57e4e/SelectorProducer@6daf7d37/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.1787818+05:30 added {SelectorProducer@6daf7d37,POJO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@65d57e4e/SelectorProducer@6daf7d37/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.1787818+05:30 added {QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}],UNMANAGED}
2022-02-14 10:55:38 DEBUG EatWhatYouKill:93 - EatWhatYouKill@65d57e4e/SelectorProducer@6daf7d37/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.1828012+05:30 created
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ManagedSelector@1fac1d5c{STOPPED} id=2 keys=-1 selected=-1 updates=0 added {EatWhatYouKill@65d57e4e/SelectorProducer@6daf7d37/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.182833+05:30,MANAGED}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - SelectorManager@ServerConnector@42b6d0cc{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} added {ManagedSelector@1fac1d5c{STOPPED} id=2 keys=-1 selected=-1 updates=0,AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@17690e14/SelectorProducer@6850b758/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.182833+05:30 added {SelectorProducer@6850b758,POJO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@17690e14/SelectorProducer@6850b758/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.182833+05:30 added {QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}],UNMANAGED}
2022-02-14 10:55:38 DEBUG EatWhatYouKill:93 - EatWhatYouKill@17690e14/SelectorProducer@6850b758/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.182833+05:30 created
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ManagedSelector@4207609e{STOPPED} id=3 keys=-1 selected=-1 updates=0 added {EatWhatYouKill@17690e14/SelectorProducer@6850b758/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.182833+05:30,MANAGED}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - SelectorManager@ServerConnector@42b6d0cc{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} added {ManagedSelector@4207609e{STOPPED} id=3 keys=-1 selected=-1 updates=0,AUTO}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ManagedSelector@51841ac6{STOPPED} id=0 keys=-1 selected=-1 updates=0
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting EatWhatYouKill@67efd2c2/SelectorProducer@10fda3d0/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.182833+05:30
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10053ms EatWhatYouKill@67efd2c2/SelectorProducer@10fda3d0/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.182833+05:30
2022-02-14 10:55:38 DEBUG QueuedThreadPool:719 - queue org.sparkproject.jetty.io.ManagedSelector$$Lambda$447/0x000000080052ac40@3bddc676 startThread=0
2022-02-14 10:55:38 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.io.ManagedSelector$$Lambda$447/0x000000080052ac40@3bddc676 in QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}]
2022-02-14 10:55:38 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$Start@67b100fe on ManagedSelector@51841ac6{STARTING} id=0 keys=0 selected=0 updates=0
2022-02-14 10:55:38 DEBUG EatWhatYouKill:141 - EatWhatYouKill@67efd2c2/SelectorProducer@10fda3d0/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.1931468+05:30 tryProduce false
2022-02-14 10:55:38 DEBUG ManagedSelector:558 - updateable 1
2022-02-14 10:55:38 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$Start@67b100fe
2022-02-14 10:55:38 DEBUG ManagedSelector:587 - updates 0
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10064ms ManagedSelector@51841ac6{STARTED} id=0 keys=0 selected=0 updates=0
2022-02-14 10:55:38 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@18fd92dc waiting with 0 keys
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ManagedSelector@741f8dbe{STOPPED} id=1 keys=-1 selected=-1 updates=0
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting EatWhatYouKill@17d32e9b/SelectorProducer@66f0548d/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.1982624+05:30
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10066ms EatWhatYouKill@17d32e9b/SelectorProducer@66f0548d/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.1985697+05:30
2022-02-14 10:55:38 DEBUG QueuedThreadPool:719 - queue org.sparkproject.jetty.io.ManagedSelector$$Lambda$447/0x000000080052ac40@6c931d35 startThread=0
2022-02-14 10:55:38 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.io.ManagedSelector$$Lambda$447/0x000000080052ac40@6c931d35 in QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}]
2022-02-14 10:55:38 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$Start@49122b8f on ManagedSelector@741f8dbe{STARTING} id=1 keys=0 selected=0 updates=0
2022-02-14 10:55:38 DEBUG EatWhatYouKill:141 - EatWhatYouKill@17d32e9b/SelectorProducer@66f0548d/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.1985697+05:30 tryProduce false
2022-02-14 10:55:38 DEBUG ManagedSelector:558 - updateable 1
2022-02-14 10:55:38 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$Start@49122b8f
2022-02-14 10:55:38 DEBUG ManagedSelector:587 - updates 0
2022-02-14 10:55:38 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@7be3e310 waiting with 0 keys
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10069ms ManagedSelector@741f8dbe{STARTED} id=1 keys=0 selected=0 updates=0
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ManagedSelector@1fac1d5c{STOPPED} id=2 keys=-1 selected=-1 updates=0
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting EatWhatYouKill@65d57e4e/SelectorProducer@6daf7d37/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.1985697+05:30
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10071ms EatWhatYouKill@65d57e4e/SelectorProducer@6daf7d37/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.2044036+05:30
2022-02-14 10:55:38 DEBUG QueuedThreadPool:719 - queue org.sparkproject.jetty.io.ManagedSelector$$Lambda$447/0x000000080052ac40@59ed3e6c startThread=0
2022-02-14 10:55:38 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.io.ManagedSelector$$Lambda$447/0x000000080052ac40@59ed3e6c in QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}]
2022-02-14 10:55:38 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$Start@317e9c3c on ManagedSelector@1fac1d5c{STARTING} id=2 keys=0 selected=0 updates=0
2022-02-14 10:55:38 DEBUG EatWhatYouKill:141 - EatWhatYouKill@65d57e4e/SelectorProducer@6daf7d37/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.2087399+05:30 tryProduce false
2022-02-14 10:55:38 DEBUG ManagedSelector:558 - updateable 1
2022-02-14 10:55:38 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$Start@317e9c3c
2022-02-14 10:55:38 DEBUG ManagedSelector:587 - updates 0
2022-02-14 10:55:38 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@6c74b96a waiting with 0 keys
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10077ms ManagedSelector@1fac1d5c{STARTED} id=2 keys=0 selected=0 updates=0
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ManagedSelector@4207609e{STOPPED} id=3 keys=-1 selected=-1 updates=0
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting EatWhatYouKill@17690e14/SelectorProducer@6850b758/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.2087399+05:30
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10078ms EatWhatYouKill@17690e14/SelectorProducer@6850b758/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.2087399+05:30
2022-02-14 10:55:38 DEBUG QueuedThreadPool:719 - queue org.sparkproject.jetty.io.ManagedSelector$$Lambda$447/0x000000080052ac40@7d04529c startThread=0
2022-02-14 10:55:38 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.io.ManagedSelector$$Lambda$447/0x000000080052ac40@7d04529c in QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}]
2022-02-14 10:55:38 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$Start@b16e202 on ManagedSelector@4207609e{STARTING} id=3 keys=0 selected=0 updates=0
2022-02-14 10:55:38 DEBUG EatWhatYouKill:141 - EatWhatYouKill@17690e14/SelectorProducer@6850b758/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:38.2136441+05:30 tryProduce false
2022-02-14 10:55:38 DEBUG ManagedSelector:558 - updateable 1
2022-02-14 10:55:38 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$Start@b16e202
2022-02-14 10:55:38 DEBUG ManagedSelector:587 - updates 0
2022-02-14 10:55:38 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@396675eb waiting with 0 keys
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10083ms ManagedSelector@4207609e{STARTED} id=3 keys=0 selected=0 updates=0
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10083ms SelectorManager@ServerConnector@42b6d0cc{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServerConnector@42b6d0cc{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} added {acceptor-0@4edef76c,POJO}
2022-02-14 10:55:38 DEBUG QueuedThreadPool:719 - queue acceptor-0@4edef76c startThread=0
2022-02-14 10:55:38 DEBUG QueuedThreadPool:1035 - run acceptor-0@4edef76c in QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=3,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}]
2022-02-14 10:55:38 INFO  AbstractConnector:331 - Started ServerConnector@42b6d0cc{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10087ms ServerConnector@42b6d0cc{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-14 10:55:38 INFO  Utils:57 - Successfully started service 'SparkUI' on port 4040.
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - Server@59901c4d{STARTED}[9.4.40.v20210413] added {Spark@42b6d0cc{HTTP/1.1, (http/1.1)}{0.0.0.0:4040},UNMANAGED}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@7ed9499e{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-cf518cf==org.apache.spark.ui.HttpSecurityFilter@cf518cf{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@7ed9499e{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-cf518cf,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@33899f7a{STOPPED,min=32,inflate=-1} mime types IncludeExclude@7899de11{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@33899f7a{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@379ce046{/jobs,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@33899f7a{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@379ce046{/jobs,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@379ce046{/jobs,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@7ed9499e{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-1ff55ff[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-1ff55ff==org.apache.spark.ui.JettyUtils$$anon$1@862b7623{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-cf518cf=org.apache.spark.ui.HttpSecurityFilter-cf518cf==org.apache.spark.ui.HttpSecurityFilter@cf518cf{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-cf518cf]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-1ff55ff=org.apache.spark.ui.JettyUtils$$anon$1-1ff55ff==org.apache.spark.ui.JettyUtils$$anon$1@862b7623{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@7ed9499e{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10132ms ServletHandler@7ed9499e{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-cf518cf==org.apache.spark.ui.HttpSecurityFilter@cf518cf{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10134ms org.apache.spark.ui.HttpSecurityFilter-cf518cf==org.apache.spark.ui.HttpSecurityFilter@cf518cf{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@71904469
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-1ff55ff==org.apache.spark.ui.JettyUtils$$anon$1@862b7623{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10141ms org.apache.spark.ui.JettyUtils$$anon$1-1ff55ff==org.apache.spark.ui.JettyUtils$$anon$1@862b7623{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-1ff55ff
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10144ms o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@33899f7a{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@33899f7a{STARTING,min=32,inflate=-1} added {DeflaterPool@660f0c{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@33899f7a{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@660f0c{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10148ms DeflaterPool@660f0c{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10148ms GzipHandler@33899f7a{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@6ab7ce48{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-25290bca==org.apache.spark.ui.HttpSecurityFilter@25290bca{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@6ab7ce48{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-25290bca,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@508a65bf{STOPPED,min=32,inflate=-1} mime types IncludeExclude@17f2dd85{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@508a65bf{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@508a65bf{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@6ab7ce48{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-e322ec9[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-e322ec9==org.apache.spark.ui.JettyUtils$$anon$1@eb0ae7ff{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-25290bca=org.apache.spark.ui.HttpSecurityFilter-25290bca==org.apache.spark.ui.HttpSecurityFilter@25290bca{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-25290bca]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-e322ec9=org.apache.spark.ui.JettyUtils$$anon$1-e322ec9==org.apache.spark.ui.JettyUtils$$anon$1@eb0ae7ff{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@6ab7ce48{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10152ms ServletHandler@6ab7ce48{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-25290bca==org.apache.spark.ui.HttpSecurityFilter@25290bca{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10153ms org.apache.spark.ui.HttpSecurityFilter-25290bca==org.apache.spark.ui.HttpSecurityFilter@25290bca{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@262816a8
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-e322ec9==org.apache.spark.ui.JettyUtils$$anon$1@eb0ae7ff{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10153ms org.apache.spark.ui.JettyUtils$$anon$1-e322ec9==org.apache.spark.ui.JettyUtils$$anon$1@eb0ae7ff{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-e322ec9
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10154ms o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@508a65bf{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@508a65bf{STARTING,min=32,inflate=-1} added {DeflaterPool@6d1dcdff{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@508a65bf{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@6d1dcdff{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10155ms DeflaterPool@6d1dcdff{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10156ms GzipHandler@508a65bf{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@20411320{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-2643d762==org.apache.spark.ui.HttpSecurityFilter@2643d762{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@20411320{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-2643d762,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@767a014e{STOPPED,min=32,inflate=-1} mime types IncludeExclude@d109c4f{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@767a014e{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@767a014e{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@20411320{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-3c782d8e[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-3c782d8e==org.apache.spark.ui.JettyUtils$$anon$1@20480dbe{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-2643d762=org.apache.spark.ui.HttpSecurityFilter-2643d762==org.apache.spark.ui.HttpSecurityFilter@2643d762{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-2643d762]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-3c782d8e=org.apache.spark.ui.JettyUtils$$anon$1-3c782d8e==org.apache.spark.ui.JettyUtils$$anon$1@20480dbe{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@20411320{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10162ms ServletHandler@20411320{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-2643d762==org.apache.spark.ui.HttpSecurityFilter@2643d762{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10163ms org.apache.spark.ui.HttpSecurityFilter-2643d762==org.apache.spark.ui.HttpSecurityFilter@2643d762{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@7aac8884
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-3c782d8e==org.apache.spark.ui.JettyUtils$$anon$1@20480dbe{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10164ms org.apache.spark.ui.JettyUtils$$anon$1-3c782d8e==org.apache.spark.ui.JettyUtils$$anon$1@20480dbe{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-3c782d8e
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10164ms o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@767a014e{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@767a014e{STARTING,min=32,inflate=-1} added {DeflaterPool@71a06021{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@767a014e{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@71a06021{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10165ms DeflaterPool@71a06021{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10165ms GzipHandler@767a014e{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@b0e5507{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-623dcf2a==org.apache.spark.ui.HttpSecurityFilter@623dcf2a{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@b0e5507{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-623dcf2a,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@117525fe{STOPPED,min=32,inflate=-1} mime types IncludeExclude@5f7989fa{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@117525fe{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@117525fe{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@b0e5507{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-3c46dcbe[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-3c46dcbe==org.apache.spark.ui.JettyUtils$$anon$1@1b2410c2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-623dcf2a=org.apache.spark.ui.HttpSecurityFilter-623dcf2a==org.apache.spark.ui.HttpSecurityFilter@623dcf2a{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-623dcf2a]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-3c46dcbe=org.apache.spark.ui.JettyUtils$$anon$1-3c46dcbe==org.apache.spark.ui.JettyUtils$$anon$1@1b2410c2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@b0e5507{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10173ms ServletHandler@b0e5507{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-623dcf2a==org.apache.spark.ui.HttpSecurityFilter@623dcf2a{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10174ms org.apache.spark.ui.HttpSecurityFilter-623dcf2a==org.apache.spark.ui.HttpSecurityFilter@623dcf2a{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@6cd64ee8
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-3c46dcbe==org.apache.spark.ui.JettyUtils$$anon$1@1b2410c2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10175ms org.apache.spark.ui.JettyUtils$$anon$1-3c46dcbe==org.apache.spark.ui.JettyUtils$$anon$1@1b2410c2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-3c46dcbe
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10176ms o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@117525fe{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@117525fe{STARTING,min=32,inflate=-1} added {DeflaterPool@68d7a2df{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@117525fe{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@68d7a2df{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10177ms DeflaterPool@68d7a2df{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10177ms GzipHandler@117525fe{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@ca93621{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-4f0f7849==org.apache.spark.ui.HttpSecurityFilter@4f0f7849{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@ca93621{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-4f0f7849,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@4d41ba0f{STOPPED,min=32,inflate=-1} mime types IncludeExclude@3c87e6b7{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@4d41ba0f{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@73437222{/stages,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@4d41ba0f{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@73437222{/stages,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@73437222{/stages,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@ca93621{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-3f985a86[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-3f985a86==org.apache.spark.ui.JettyUtils$$anon$1@c265c26a{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-4f0f7849=org.apache.spark.ui.HttpSecurityFilter-4f0f7849==org.apache.spark.ui.HttpSecurityFilter@4f0f7849{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-4f0f7849]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-3f985a86=org.apache.spark.ui.JettyUtils$$anon$1-3f985a86==org.apache.spark.ui.JettyUtils$$anon$1@c265c26a{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@ca93621{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10185ms ServletHandler@ca93621{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-4f0f7849==org.apache.spark.ui.HttpSecurityFilter@4f0f7849{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10186ms org.apache.spark.ui.HttpSecurityFilter-4f0f7849==org.apache.spark.ui.HttpSecurityFilter@4f0f7849{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@524a076e
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-3f985a86==org.apache.spark.ui.JettyUtils$$anon$1@c265c26a{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10186ms org.apache.spark.ui.JettyUtils$$anon$1-3f985a86==org.apache.spark.ui.JettyUtils$$anon$1@c265c26a{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-3f985a86
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10187ms o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@4d41ba0f{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@4d41ba0f{STARTING,min=32,inflate=-1} added {DeflaterPool@611a990b{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@4d41ba0f{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@611a990b{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10189ms DeflaterPool@611a990b{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10190ms GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@6c806c8b{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-522bf64e==org.apache.spark.ui.HttpSecurityFilter@522bf64e{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@6c806c8b{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-522bf64e,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@c3edf4c{STOPPED,min=32,inflate=-1} mime types IncludeExclude@5af8bb51{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@c3edf4c{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@c3edf4c{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@6c806c8b{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-184fb68d[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-184fb68d==org.apache.spark.ui.JettyUtils$$anon$1@6b589487{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-522bf64e=org.apache.spark.ui.HttpSecurityFilter-522bf64e==org.apache.spark.ui.HttpSecurityFilter@522bf64e{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-522bf64e]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-184fb68d=org.apache.spark.ui.JettyUtils$$anon$1-184fb68d==org.apache.spark.ui.JettyUtils$$anon$1@6b589487{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@6c806c8b{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10199ms ServletHandler@6c806c8b{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-522bf64e==org.apache.spark.ui.HttpSecurityFilter@522bf64e{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10200ms org.apache.spark.ui.HttpSecurityFilter-522bf64e==org.apache.spark.ui.HttpSecurityFilter@522bf64e{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@a098d76
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-184fb68d==org.apache.spark.ui.JettyUtils$$anon$1@6b589487{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10201ms org.apache.spark.ui.JettyUtils$$anon$1-184fb68d==org.apache.spark.ui.JettyUtils$$anon$1@6b589487{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-184fb68d
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10202ms o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@c3edf4c{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@c3edf4c{STARTING,min=32,inflate=-1} added {DeflaterPool@328d044f{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@c3edf4c{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@328d044f{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10203ms DeflaterPool@328d044f{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10203ms GzipHandler@c3edf4c{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@16a49a5d{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-296e281a==org.apache.spark.ui.HttpSecurityFilter@296e281a{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@16a49a5d{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-296e281a,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@4a163575{STOPPED,min=32,inflate=-1} mime types IncludeExclude@7e642b88{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@4a163575{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@4a163575{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@16a49a5d{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-23706db8[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-23706db8==org.apache.spark.ui.JettyUtils$$anon$1@ccccdf0c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-296e281a=org.apache.spark.ui.HttpSecurityFilter-296e281a==org.apache.spark.ui.HttpSecurityFilter@296e281a{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-296e281a]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-23706db8=org.apache.spark.ui.JettyUtils$$anon$1-23706db8==org.apache.spark.ui.JettyUtils$$anon$1@ccccdf0c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@16a49a5d{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10212ms ServletHandler@16a49a5d{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-296e281a==org.apache.spark.ui.HttpSecurityFilter@296e281a{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10212ms org.apache.spark.ui.HttpSecurityFilter-296e281a==org.apache.spark.ui.HttpSecurityFilter@296e281a{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@68ab0936
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-23706db8==org.apache.spark.ui.JettyUtils$$anon$1@ccccdf0c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10212ms org.apache.spark.ui.JettyUtils$$anon$1-23706db8==org.apache.spark.ui.JettyUtils$$anon$1@ccccdf0c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-23706db8
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10213ms o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@4a163575{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@4a163575{STARTING,min=32,inflate=-1} added {DeflaterPool@27d33393{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@4a163575{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@27d33393{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10214ms DeflaterPool@27d33393{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10214ms GzipHandler@4a163575{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@11b377c5{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-43af351a==org.apache.spark.ui.HttpSecurityFilter@43af351a{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@11b377c5{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-43af351a,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@23f3da8b{STOPPED,min=32,inflate=-1} mime types IncludeExclude@5634d0f4{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@23f3da8b{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@23f3da8b{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@23f3da8b{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@11b377c5{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-5c60b0a0[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-5c60b0a0==org.apache.spark.ui.JettyUtils$$anon$1@edf9e633{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-43af351a=org.apache.spark.ui.HttpSecurityFilter-43af351a==org.apache.spark.ui.HttpSecurityFilter@43af351a{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-43af351a]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-5c60b0a0=org.apache.spark.ui.JettyUtils$$anon$1-5c60b0a0==org.apache.spark.ui.JettyUtils$$anon$1@edf9e633{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@11b377c5{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10219ms ServletHandler@11b377c5{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-43af351a==org.apache.spark.ui.HttpSecurityFilter@43af351a{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10219ms org.apache.spark.ui.HttpSecurityFilter-43af351a==org.apache.spark.ui.HttpSecurityFilter@43af351a{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@7fb29ca9
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-5c60b0a0==org.apache.spark.ui.JettyUtils$$anon$1@edf9e633{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10219ms org.apache.spark.ui.JettyUtils$$anon$1-5c60b0a0==org.apache.spark.ui.JettyUtils$$anon$1@edf9e633{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-5c60b0a0
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10220ms o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@23f3da8b{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@23f3da8b{STARTING,min=32,inflate=-1} added {DeflaterPool@176996c3{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@23f3da8b{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@176996c3{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10222ms DeflaterPool@176996c3{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10223ms GzipHandler@23f3da8b{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@760cf594{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-242b6e1a==org.apache.spark.ui.HttpSecurityFilter@242b6e1a{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@760cf594{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-242b6e1a,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@45acdd11{STOPPED,min=32,inflate=-1} mime types IncludeExclude@3f0d6038{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@45acdd11{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@23f3da8b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@45acdd11{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@45acdd11{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@760cf594{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-37303f12[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-37303f12==org.apache.spark.ui.JettyUtils$$anon$1@1723ae3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-242b6e1a=org.apache.spark.ui.HttpSecurityFilter-242b6e1a==org.apache.spark.ui.HttpSecurityFilter@242b6e1a{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-242b6e1a]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-37303f12=org.apache.spark.ui.JettyUtils$$anon$1-37303f12==org.apache.spark.ui.JettyUtils$$anon$1@1723ae3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@760cf594{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10232ms ServletHandler@760cf594{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-242b6e1a==org.apache.spark.ui.HttpSecurityFilter@242b6e1a{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10233ms org.apache.spark.ui.HttpSecurityFilter-242b6e1a==org.apache.spark.ui.HttpSecurityFilter@242b6e1a{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@c755b2
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-37303f12==org.apache.spark.ui.JettyUtils$$anon$1@1723ae3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10233ms org.apache.spark.ui.JettyUtils$$anon$1-37303f12==org.apache.spark.ui.JettyUtils$$anon$1@1723ae3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-37303f12
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10234ms o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@45acdd11{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@45acdd11{STARTING,min=32,inflate=-1} added {DeflaterPool@291373d3{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@45acdd11{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@291373d3{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10235ms DeflaterPool@291373d3{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10235ms GzipHandler@45acdd11{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@8ee0c23{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-4dba773d==org.apache.spark.ui.HttpSecurityFilter@4dba773d{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@8ee0c23{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-4dba773d,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@10b1a751{STOPPED,min=32,inflate=-1} mime types IncludeExclude@53cf9c99{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@10b1a751{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@23f3da8b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@10b1a751{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@45acdd11{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@10b1a751{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@8ee0c23{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-4dc8c0ea[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-4dc8c0ea==org.apache.spark.ui.JettyUtils$$anon$1@83a399c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-4dba773d=org.apache.spark.ui.HttpSecurityFilter-4dba773d==org.apache.spark.ui.HttpSecurityFilter@4dba773d{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-4dba773d]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-4dc8c0ea=org.apache.spark.ui.JettyUtils$$anon$1-4dc8c0ea==org.apache.spark.ui.JettyUtils$$anon$1@83a399c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@8ee0c23{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10246ms ServletHandler@8ee0c23{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-4dba773d==org.apache.spark.ui.HttpSecurityFilter@4dba773d{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10246ms org.apache.spark.ui.HttpSecurityFilter-4dba773d==org.apache.spark.ui.HttpSecurityFilter@4dba773d{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@3a66e67e
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-4dc8c0ea==org.apache.spark.ui.JettyUtils$$anon$1@83a399c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10247ms org.apache.spark.ui.JettyUtils$$anon$1-4dc8c0ea==org.apache.spark.ui.JettyUtils$$anon$1@83a399c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-4dc8c0ea
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10247ms o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@10b1a751{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@10b1a751{STARTING,min=32,inflate=-1} added {DeflaterPool@6cf0a747{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@10b1a751{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@6cf0a747{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10248ms DeflaterPool@6cf0a747{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10248ms GzipHandler@10b1a751{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@4f3e7344{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-3c3c4a71==org.apache.spark.ui.HttpSecurityFilter@3c3c4a71{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@4f3e7344{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-3c3c4a71,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@75de6341{STOPPED,min=32,inflate=-1} mime types IncludeExclude@74170687{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@75de6341{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@23f3da8b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@75de6341{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@10b1a751{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@45acdd11{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@75de6341{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@4f3e7344{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-62d73ead[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-62d73ead==org.apache.spark.ui.JettyUtils$$anon$1@8496b672{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-3c3c4a71=org.apache.spark.ui.HttpSecurityFilter-3c3c4a71==org.apache.spark.ui.HttpSecurityFilter@3c3c4a71{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-3c3c4a71]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-62d73ead=org.apache.spark.ui.JettyUtils$$anon$1-62d73ead==org.apache.spark.ui.JettyUtils$$anon$1@8496b672{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@4f3e7344{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10261ms ServletHandler@4f3e7344{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-3c3c4a71==org.apache.spark.ui.HttpSecurityFilter@3c3c4a71{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10261ms org.apache.spark.ui.HttpSecurityFilter-3c3c4a71==org.apache.spark.ui.HttpSecurityFilter@3c3c4a71{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@17f3eefb
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-62d73ead==org.apache.spark.ui.JettyUtils$$anon$1@8496b672{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10262ms org.apache.spark.ui.JettyUtils$$anon$1-62d73ead==org.apache.spark.ui.JettyUtils$$anon$1@8496b672{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-62d73ead
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10263ms o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@75de6341{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@75de6341{STARTING,min=32,inflate=-1} added {DeflaterPool@46a145ba{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@75de6341{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@46a145ba{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10264ms DeflaterPool@46a145ba{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10265ms GzipHandler@75de6341{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@3db663d0{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-63884e4==org.apache.spark.ui.HttpSecurityFilter@63884e4{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@3db663d0{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-63884e4,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@6812fa3a{STOPPED,min=32,inflate=-1} mime types IncludeExclude@29149030{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@6812fa3a{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@23f3da8b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@6812fa3a{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@75de6341{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@10b1a751{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@45acdd11{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@6812fa3a{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@3db663d0{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-2de50ee4[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-2de50ee4==org.apache.spark.ui.JettyUtils$$anon$1@3ba0e274{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-63884e4=org.apache.spark.ui.HttpSecurityFilter-63884e4==org.apache.spark.ui.HttpSecurityFilter@63884e4{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-63884e4]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-2de50ee4=org.apache.spark.ui.JettyUtils$$anon$1-2de50ee4==org.apache.spark.ui.JettyUtils$$anon$1@3ba0e274{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@3db663d0{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10278ms ServletHandler@3db663d0{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-63884e4==org.apache.spark.ui.HttpSecurityFilter@63884e4{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10278ms org.apache.spark.ui.HttpSecurityFilter-63884e4==org.apache.spark.ui.HttpSecurityFilter@63884e4{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@4adc663e
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-2de50ee4==org.apache.spark.ui.JettyUtils$$anon$1@3ba0e274{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10280ms org.apache.spark.ui.JettyUtils$$anon$1-2de50ee4==org.apache.spark.ui.JettyUtils$$anon$1@3ba0e274{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-2de50ee4
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10280ms o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@6812fa3a{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@6812fa3a{STARTING,min=32,inflate=-1} added {DeflaterPool@64db4967{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@6812fa3a{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@64db4967{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10281ms DeflaterPool@64db4967{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10282ms GzipHandler@6812fa3a{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@4e17913b{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-1e9469b8==org.apache.spark.ui.HttpSecurityFilter@1e9469b8{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@4e17913b{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-1e9469b8,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@648d0e6d{STOPPED,min=32,inflate=-1} mime types IncludeExclude@79e66b2f{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@648d0e6d{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@2cc03cd1{/storage/rdd,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@23f3da8b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@648d0e6d{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2cc03cd1{/storage/rdd,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@6812fa3a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@75de6341{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@10b1a751{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@45acdd11{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@648d0e6d{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@2cc03cd1{/storage/rdd,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@2cc03cd1{/storage/rdd,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@4e17913b{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-64f16277[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-64f16277==org.apache.spark.ui.JettyUtils$$anon$1@f178e993{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-1e9469b8=org.apache.spark.ui.HttpSecurityFilter-1e9469b8==org.apache.spark.ui.HttpSecurityFilter@1e9469b8{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-1e9469b8]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-64f16277=org.apache.spark.ui.JettyUtils$$anon$1-64f16277==org.apache.spark.ui.JettyUtils$$anon$1@f178e993{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@4e17913b{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10292ms ServletHandler@4e17913b{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-1e9469b8==org.apache.spark.ui.HttpSecurityFilter@1e9469b8{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10292ms org.apache.spark.ui.HttpSecurityFilter-1e9469b8==org.apache.spark.ui.HttpSecurityFilter@1e9469b8{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@1b1c538d
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-64f16277==org.apache.spark.ui.JettyUtils$$anon$1@f178e993{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10294ms org.apache.spark.ui.JettyUtils$$anon$1-64f16277==org.apache.spark.ui.JettyUtils$$anon$1@f178e993{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-64f16277
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@2cc03cd1{/storage/rdd,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10297ms o.s.j.s.ServletContextHandler@2cc03cd1{/storage/rdd,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@648d0e6d{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@648d0e6d{STARTING,min=32,inflate=-1} added {DeflaterPool@2da3b078{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@648d0e6d{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@2da3b078{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10299ms DeflaterPool@2da3b078{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10299ms GzipHandler@648d0e6d{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@35e8316e{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-46aa712c==org.apache.spark.ui.HttpSecurityFilter@46aa712c{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@35e8316e{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-46aa712c,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@7b4a0aef{STOPPED,min=32,inflate=-1} mime types IncludeExclude@45cec376{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@7b4a0aef{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@3f628ce9{/storage/rdd/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@23f3da8b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@648d0e6d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2cc03cd1{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@6812fa3a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@75de6341{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@7b4a0aef{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3f628ce9{/storage/rdd/json,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@10b1a751{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@45acdd11{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@7b4a0aef{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@3f628ce9{/storage/rdd/json,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@3f628ce9{/storage/rdd/json,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@35e8316e{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-336880df[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-336880df==org.apache.spark.ui.JettyUtils$$anon$1@336a154a{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-46aa712c=org.apache.spark.ui.HttpSecurityFilter-46aa712c==org.apache.spark.ui.HttpSecurityFilter@46aa712c{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-46aa712c]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-336880df=org.apache.spark.ui.JettyUtils$$anon$1-336880df==org.apache.spark.ui.JettyUtils$$anon$1@336a154a{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@35e8316e{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10315ms ServletHandler@35e8316e{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-46aa712c==org.apache.spark.ui.HttpSecurityFilter@46aa712c{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10316ms org.apache.spark.ui.HttpSecurityFilter-46aa712c==org.apache.spark.ui.HttpSecurityFilter@46aa712c{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@7d3c09ec
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-336880df==org.apache.spark.ui.JettyUtils$$anon$1@336a154a{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10316ms org.apache.spark.ui.JettyUtils$$anon$1-336880df==org.apache.spark.ui.JettyUtils$$anon$1@336a154a{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-336880df
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@3f628ce9{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10317ms o.s.j.s.ServletContextHandler@3f628ce9{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@7b4a0aef{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@7b4a0aef{STARTING,min=32,inflate=-1} added {DeflaterPool@2100d047{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@7b4a0aef{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@2100d047{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10318ms DeflaterPool@2100d047{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10318ms GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@3672276e{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-47be0f9b==org.apache.spark.ui.HttpSecurityFilter@47be0f9b{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@3672276e{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-47be0f9b,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@4b74b35{STOPPED,min=32,inflate=-1} mime types IncludeExclude@e4e1ef5{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@4b74b35{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@7a0f244f{/environment,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@23f3da8b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@648d0e6d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2cc03cd1{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@6812fa3a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@75de6341{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3f628ce9{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@4b74b35{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7a0f244f{/environment,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@10b1a751{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@45acdd11{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@4b74b35{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@7a0f244f{/environment,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@7a0f244f{/environment,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@3672276e{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-7f08caf[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-7f08caf==org.apache.spark.ui.JettyUtils$$anon$1@c099eda3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-47be0f9b=org.apache.spark.ui.HttpSecurityFilter-47be0f9b==org.apache.spark.ui.HttpSecurityFilter@47be0f9b{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-47be0f9b]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-7f08caf=org.apache.spark.ui.JettyUtils$$anon$1-7f08caf==org.apache.spark.ui.JettyUtils$$anon$1@c099eda3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@3672276e{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10334ms ServletHandler@3672276e{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-47be0f9b==org.apache.spark.ui.HttpSecurityFilter@47be0f9b{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10335ms org.apache.spark.ui.HttpSecurityFilter-47be0f9b==org.apache.spark.ui.HttpSecurityFilter@47be0f9b{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@2373ad99
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-7f08caf==org.apache.spark.ui.JettyUtils$$anon$1@c099eda3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10336ms org.apache.spark.ui.JettyUtils$$anon$1-7f08caf==org.apache.spark.ui.JettyUtils$$anon$1@c099eda3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-7f08caf
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@7a0f244f{/environment,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10337ms o.s.j.s.ServletContextHandler@7a0f244f{/environment,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@4b74b35{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@4b74b35{STARTING,min=32,inflate=-1} added {DeflaterPool@2975a9e{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@4b74b35{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@2975a9e{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10341ms DeflaterPool@2975a9e{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10341ms GzipHandler@4b74b35{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@706eab5d{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-2dd0f797==org.apache.spark.ui.HttpSecurityFilter@2dd0f797{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@706eab5d{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-2dd0f797,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@3291b443{STOPPED,min=32,inflate=-1} mime types IncludeExclude@671c4166{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@3291b443{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@54657dd2{/environment/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@23f3da8b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@648d0e6d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2cc03cd1{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@3291b443{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@54657dd2{/environment/json,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@6812fa3a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@75de6341{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3f628ce9{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@4b74b35{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7a0f244f{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@10b1a751{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@45acdd11{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@3291b443{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@54657dd2{/environment/json,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@54657dd2{/environment/json,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@706eab5d{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-40e60ece[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-40e60ece==org.apache.spark.ui.JettyUtils$$anon$1@4cad4a72{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-2dd0f797=org.apache.spark.ui.HttpSecurityFilter-2dd0f797==org.apache.spark.ui.HttpSecurityFilter@2dd0f797{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-2dd0f797]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-40e60ece=org.apache.spark.ui.JettyUtils$$anon$1-40e60ece==org.apache.spark.ui.JettyUtils$$anon$1@4cad4a72{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@706eab5d{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10351ms ServletHandler@706eab5d{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-2dd0f797==org.apache.spark.ui.HttpSecurityFilter@2dd0f797{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10352ms org.apache.spark.ui.HttpSecurityFilter-2dd0f797==org.apache.spark.ui.HttpSecurityFilter@2dd0f797{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@cda6019
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-40e60ece==org.apache.spark.ui.JettyUtils$$anon$1@4cad4a72{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10353ms org.apache.spark.ui.JettyUtils$$anon$1-40e60ece==org.apache.spark.ui.JettyUtils$$anon$1@4cad4a72{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-40e60ece
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@54657dd2{/environment/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10354ms o.s.j.s.ServletContextHandler@54657dd2{/environment/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@3291b443{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@3291b443{STARTING,min=32,inflate=-1} added {DeflaterPool@26bbe604{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@3291b443{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@26bbe604{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10356ms DeflaterPool@26bbe604{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10357ms GzipHandler@3291b443{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@51b35e4e{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-2c8c16c0==org.apache.spark.ui.HttpSecurityFilter@2c8c16c0{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@51b35e4e{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-2c8c16c0,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@7f5b9db{STOPPED,min=32,inflate=-1} mime types IncludeExclude@507d64aa{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@7f5b9db{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@3bfc6a5e{/executors,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@23f3da8b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@648d0e6d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2cc03cd1{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@3291b443{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@54657dd2{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@6812fa3a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@75de6341{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3f628ce9{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@4b74b35{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7a0f244f{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@7f5b9db{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bfc6a5e{/executors,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@10b1a751{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@45acdd11{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@7f5b9db{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@3bfc6a5e{/executors,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@3bfc6a5e{/executors,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@51b35e4e{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-6d7cada5[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-6d7cada5==org.apache.spark.ui.JettyUtils$$anon$1@8f45247f{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-2c8c16c0=org.apache.spark.ui.HttpSecurityFilter-2c8c16c0==org.apache.spark.ui.HttpSecurityFilter@2c8c16c0{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-2c8c16c0]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-6d7cada5=org.apache.spark.ui.JettyUtils$$anon$1-6d7cada5==org.apache.spark.ui.JettyUtils$$anon$1@8f45247f{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@51b35e4e{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10368ms ServletHandler@51b35e4e{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-2c8c16c0==org.apache.spark.ui.HttpSecurityFilter@2c8c16c0{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10368ms org.apache.spark.ui.HttpSecurityFilter-2c8c16c0==org.apache.spark.ui.HttpSecurityFilter@2c8c16c0{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@25673087
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-6d7cada5==org.apache.spark.ui.JettyUtils$$anon$1@8f45247f{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10369ms org.apache.spark.ui.JettyUtils$$anon$1-6d7cada5==org.apache.spark.ui.JettyUtils$$anon$1@8f45247f{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-6d7cada5
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@3bfc6a5e{/executors,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10370ms o.s.j.s.ServletContextHandler@3bfc6a5e{/executors,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@7f5b9db{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@7f5b9db{STARTING,min=32,inflate=-1} added {DeflaterPool@6920b0bc{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@7f5b9db{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@6920b0bc{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10373ms DeflaterPool@6920b0bc{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10374ms GzipHandler@7f5b9db{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@1b4ae4e0{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-5c441290==org.apache.spark.ui.HttpSecurityFilter@5c441290{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@1b4ae4e0{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-5c441290,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@64aad809{STOPPED,min=32,inflate=-1} mime types IncludeExclude@1f03fba0{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@64aad809{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@62db0521{/executors/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@64aad809{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@62db0521{/executors/json,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@23f3da8b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@648d0e6d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2cc03cd1{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@3291b443{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@54657dd2{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@6812fa3a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@75de6341{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3f628ce9{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@4b74b35{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7a0f244f{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@7f5b9db{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bfc6a5e{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@10b1a751{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@45acdd11{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@64aad809{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@62db0521{/executors/json,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@62db0521{/executors/json,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@1b4ae4e0{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-5fbdc49b[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-5fbdc49b==org.apache.spark.ui.JettyUtils$$anon$1@da9f183b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-5c441290=org.apache.spark.ui.HttpSecurityFilter-5c441290==org.apache.spark.ui.HttpSecurityFilter@5c441290{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-5c441290]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-5fbdc49b=org.apache.spark.ui.JettyUtils$$anon$1-5fbdc49b==org.apache.spark.ui.JettyUtils$$anon$1@da9f183b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@1b4ae4e0{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10386ms ServletHandler@1b4ae4e0{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-5c441290==org.apache.spark.ui.HttpSecurityFilter@5c441290{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10386ms org.apache.spark.ui.HttpSecurityFilter-5c441290==org.apache.spark.ui.HttpSecurityFilter@5c441290{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@2c05ff9d
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-5fbdc49b==org.apache.spark.ui.JettyUtils$$anon$1@da9f183b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10387ms org.apache.spark.ui.JettyUtils$$anon$1-5fbdc49b==org.apache.spark.ui.JettyUtils$$anon$1@da9f183b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-5fbdc49b
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@62db0521{/executors/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10392ms o.s.j.s.ServletContextHandler@62db0521{/executors/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@64aad809{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@64aad809{STARTING,min=32,inflate=-1} added {DeflaterPool@54db056b{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@64aad809{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@54db056b{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10393ms DeflaterPool@54db056b{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10394ms GzipHandler@64aad809{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@285f38f6{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-63d4f0a2==org.apache.spark.ui.HttpSecurityFilter@63d4f0a2{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@285f38f6{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-63d4f0a2,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@4b4eced1{STOPPED,min=32,inflate=-1} mime types IncludeExclude@71926a36{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@4b4eced1{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@3baf6936{/executors/threadDump,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@64aad809{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@62db0521{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@23f3da8b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@648d0e6d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2cc03cd1{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@3291b443{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@54657dd2{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@6812fa3a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@75de6341{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3f628ce9{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@4b74b35{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7a0f244f{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@7f5b9db{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bfc6a5e{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@10b1a751{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@45acdd11{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@4b4eced1{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3baf6936{/executors/threadDump,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@4b4eced1{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@3baf6936{/executors/threadDump,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@3baf6936{/executors/threadDump,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@285f38f6{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-3ab6678b[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-3ab6678b==org.apache.spark.ui.JettyUtils$$anon$1@ffc0f37b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-63d4f0a2=org.apache.spark.ui.HttpSecurityFilter-63d4f0a2==org.apache.spark.ui.HttpSecurityFilter@63d4f0a2{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-63d4f0a2]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-3ab6678b=org.apache.spark.ui.JettyUtils$$anon$1-3ab6678b==org.apache.spark.ui.JettyUtils$$anon$1@ffc0f37b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@285f38f6{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10411ms ServletHandler@285f38f6{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-63d4f0a2==org.apache.spark.ui.HttpSecurityFilter@63d4f0a2{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10412ms org.apache.spark.ui.HttpSecurityFilter-63d4f0a2==org.apache.spark.ui.HttpSecurityFilter@63d4f0a2{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@54402c04
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-3ab6678b==org.apache.spark.ui.JettyUtils$$anon$1@ffc0f37b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10413ms org.apache.spark.ui.JettyUtils$$anon$1-3ab6678b==org.apache.spark.ui.JettyUtils$$anon$1@ffc0f37b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-3ab6678b
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@3baf6936{/executors/threadDump,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10414ms o.s.j.s.ServletContextHandler@3baf6936{/executors/threadDump,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@4b4eced1{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@4b4eced1{STARTING,min=32,inflate=-1} added {DeflaterPool@7d0d91a1{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@4b4eced1{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@7d0d91a1{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10416ms DeflaterPool@7d0d91a1{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10416ms GzipHandler@4b4eced1{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@57c47a9e{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-474821de==org.apache.spark.ui.HttpSecurityFilter@474821de{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@57c47a9e{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-474821de,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@47d023b7{STOPPED,min=32,inflate=-1} mime types IncludeExclude@5c83ae01{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@47d023b7{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@36fc05ff{/executors/threadDump/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@64aad809{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@62db0521{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@23f3da8b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@648d0e6d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2cc03cd1{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@47d023b7{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@36fc05ff{/executors/threadDump/json,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@3291b443{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@54657dd2{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@6812fa3a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@75de6341{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3f628ce9{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@4b74b35{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7a0f244f{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@7f5b9db{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bfc6a5e{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@10b1a751{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@45acdd11{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@4b4eced1{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3baf6936{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@47d023b7{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@36fc05ff{/executors/threadDump/json,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@36fc05ff{/executors/threadDump/json,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@57c47a9e{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-4339e0de[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-4339e0de==org.apache.spark.ui.JettyUtils$$anon$1@964f447f{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-474821de=org.apache.spark.ui.HttpSecurityFilter-474821de==org.apache.spark.ui.HttpSecurityFilter@474821de{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-474821de]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-4339e0de=org.apache.spark.ui.JettyUtils$$anon$1-4339e0de==org.apache.spark.ui.JettyUtils$$anon$1@964f447f{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@57c47a9e{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10434ms ServletHandler@57c47a9e{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-474821de==org.apache.spark.ui.HttpSecurityFilter@474821de{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10434ms org.apache.spark.ui.HttpSecurityFilter-474821de==org.apache.spark.ui.HttpSecurityFilter@474821de{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@41853299
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-4339e0de==org.apache.spark.ui.JettyUtils$$anon$1@964f447f{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10435ms org.apache.spark.ui.JettyUtils$$anon$1-4339e0de==org.apache.spark.ui.JettyUtils$$anon$1@964f447f{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-4339e0de
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@36fc05ff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10436ms o.s.j.s.ServletContextHandler@36fc05ff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@47d023b7{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@47d023b7{STARTING,min=32,inflate=-1} added {DeflaterPool@5d96bdf8{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@47d023b7{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@5d96bdf8{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10439ms DeflaterPool@5d96bdf8{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10440ms GzipHandler@47d023b7{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@27b2faa6{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-7da39774==org.apache.spark.ui.HttpSecurityFilter@7da39774{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@27b2faa6{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-7da39774,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@32b0876c{STOPPED,min=32,inflate=-1} mime types IncludeExclude@2aaf152b{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@32b0876c{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@715d6168{/static,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@32b0876c{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@715d6168{/static,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@64aad809{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@62db0521{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@23f3da8b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@648d0e6d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2cc03cd1{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@47d023b7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@36fc05ff{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@3291b443{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@54657dd2{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@6812fa3a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@75de6341{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3f628ce9{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@4b74b35{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7a0f244f{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@7f5b9db{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bfc6a5e{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@10b1a751{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@45acdd11{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@4b4eced1{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3baf6936{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@32b0876c{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@715d6168{/static,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@715d6168{/static,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@27b2faa6{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.sparkproject.jetty.servlet.DefaultServlet-2e53b094[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.sparkproject.jetty.servlet.DefaultServlet-2e53b094==org.sparkproject.jetty.servlet.DefaultServlet@5a6d2702{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-7da39774=org.apache.spark.ui.HttpSecurityFilter-7da39774==org.apache.spark.ui.HttpSecurityFilter@7da39774{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-7da39774]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.sparkproject.jetty.servlet.DefaultServlet-2e53b094=org.sparkproject.jetty.servlet.DefaultServlet-2e53b094==org.sparkproject.jetty.servlet.DefaultServlet@5a6d2702{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@27b2faa6{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10459ms ServletHandler@27b2faa6{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-7da39774==org.apache.spark.ui.HttpSecurityFilter@7da39774{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10460ms org.apache.spark.ui.HttpSecurityFilter-7da39774==org.apache.spark.ui.HttpSecurityFilter@7da39774{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@5cc9d3d0
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.sparkproject.jetty.servlet.DefaultServlet-2e53b094==org.sparkproject.jetty.servlet.DefaultServlet@5a6d2702{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10461ms org.sparkproject.jetty.servlet.DefaultServlet-2e53b094==org.sparkproject.jetty.servlet.DefaultServlet@5a6d2702{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG ServletHolder:621 - Servlet.init null for org.sparkproject.jetty.servlet.DefaultServlet-2e53b094
2022-02-14 10:55:38 DEBUG DefaultServlet:308 - resource base = jar:file:/C:/Users/Shridhar%20Ingale/.m2/repository/org/apache/spark/spark-core_2.12/3.0.3/spark-core_2.12-3.0.3.jar!/org/apache/spark/ui/static
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@715d6168{/static,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10480ms o.s.j.s.ServletContextHandler@715d6168{/static,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@32b0876c{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@32b0876c{STARTING,min=32,inflate=-1} added {DeflaterPool@6f9c5048{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@32b0876c{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@6f9c5048{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10482ms DeflaterPool@6f9c5048{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10483ms GzipHandler@32b0876c{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@6c302a1d{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-3a894088==org.apache.spark.ui.HttpSecurityFilter@3a894088{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@6c302a1d{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-3a894088,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@42fb8c87{STOPPED,min=32,inflate=-1} mime types IncludeExclude@15eb0ae9{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@42fb8c87{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@53b8afea{/,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@42fb8c87{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@53b8afea{/,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@32b0876c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@715d6168{/static,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@64aad809{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@62db0521{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@23f3da8b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@648d0e6d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2cc03cd1{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@47d023b7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@36fc05ff{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@3291b443{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@54657dd2{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@6812fa3a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@75de6341{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3f628ce9{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@4b74b35{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7a0f244f{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@7f5b9db{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bfc6a5e{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@10b1a751{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@45acdd11{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@4b4eced1{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3baf6936{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@42fb8c87{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@53b8afea{/,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@53b8afea{/,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@6c302a1d{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-5fcfca62[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$2-5fcfca62==org.apache.spark.ui.JettyUtils$$anon$2@d0ba395b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-3a894088=org.apache.spark.ui.HttpSecurityFilter-3a894088==org.apache.spark.ui.HttpSecurityFilter@3a894088{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-3a894088]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-5fcfca62=org.apache.spark.ui.JettyUtils$$anon$2-5fcfca62==org.apache.spark.ui.JettyUtils$$anon$2@d0ba395b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@6c302a1d{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10497ms ServletHandler@6c302a1d{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-3a894088==org.apache.spark.ui.HttpSecurityFilter@3a894088{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10498ms org.apache.spark.ui.HttpSecurityFilter-3a894088==org.apache.spark.ui.HttpSecurityFilter@3a894088{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@433c6abb
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$2-5fcfca62==org.apache.spark.ui.JettyUtils$$anon$2@d0ba395b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10498ms org.apache.spark.ui.JettyUtils$$anon$2-5fcfca62==org.apache.spark.ui.JettyUtils$$anon$2@d0ba395b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$2-5fcfca62
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@53b8afea{/,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10499ms o.s.j.s.ServletContextHandler@53b8afea{/,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@42fb8c87{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@42fb8c87{STARTING,min=32,inflate=-1} added {DeflaterPool@47406941{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@42fb8c87{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@47406941{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10500ms DeflaterPool@47406941{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10500ms GzipHandler@42fb8c87{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@341672e{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-44784e2f==org.apache.spark.ui.HttpSecurityFilter@44784e2f{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@341672e{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-44784e2f,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@5922d3e9{STOPPED,min=32,inflate=-1} mime types IncludeExclude@7d57dbb5{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@5922d3e9{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@639aba11{/api,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@42fb8c87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@53b8afea{/,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@32b0876c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@715d6168{/static,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@64aad809{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@62db0521{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@23f3da8b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@648d0e6d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2cc03cd1{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@47d023b7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@36fc05ff{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@3291b443{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@54657dd2{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@6812fa3a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@75de6341{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3f628ce9{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@4b74b35{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7a0f244f{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@7f5b9db{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bfc6a5e{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@5922d3e9{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@639aba11{/api,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@10b1a751{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@45acdd11{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@4b4eced1{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3baf6936{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@5922d3e9{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@639aba11{/api,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@639aba11{/api,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@341672e{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/*[EMBEDDED:null] mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-58496c97[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@5fa{/*},resource=org.glassfish.jersey.servlet.ServletContainer-58496c97==org.glassfish.jersey.servlet.ServletContainer@48ef0fc1{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-44784e2f=org.apache.spark.ui.HttpSecurityFilter-44784e2f==org.apache.spark.ui.HttpSecurityFilter@44784e2f{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-44784e2f]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.glassfish.jersey.servlet.ServletContainer-58496c97=org.glassfish.jersey.servlet.ServletContainer-58496c97==org.glassfish.jersey.servlet.ServletContainer@48ef0fc1{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:169 - Adding Default404Servlet to ServletHandler@341672e{STARTING}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@341672e{STARTING} added {org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-414f13fc==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet@6dcdaa8b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@341672e{STARTING} added {[/]=>org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-414f13fc,POJO}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/*[EMBEDDED:null] mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-58496c97[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@5fa{/*},resource=org.glassfish.jersey.servlet.ServletContainer-58496c97==org.glassfish.jersey.servlet.ServletContainer@48ef0fc1{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-414f13fc[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-414f13fc==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet@6dcdaa8b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=2]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-44784e2f=org.apache.spark.ui.HttpSecurityFilter-44784e2f==org.apache.spark.ui.HttpSecurityFilter@44784e2f{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-44784e2f]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=2]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-414f13fc=org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-414f13fc==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet@6dcdaa8b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}, org.glassfish.jersey.servlet.ServletContainer-58496c97=org.glassfish.jersey.servlet.ServletContainer-58496c97==org.glassfish.jersey.servlet.ServletContainer@48ef0fc1{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/*[EMBEDDED:null] mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-58496c97[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@5fa{/*},resource=org.glassfish.jersey.servlet.ServletContainer-58496c97==org.glassfish.jersey.servlet.ServletContainer@48ef0fc1{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-414f13fc[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-414f13fc==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet@6dcdaa8b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=2]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-44784e2f=org.apache.spark.ui.HttpSecurityFilter-44784e2f==org.apache.spark.ui.HttpSecurityFilter@44784e2f{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-44784e2f]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=2]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-414f13fc=org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-414f13fc==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet@6dcdaa8b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}, org.glassfish.jersey.servlet.ServletContainer-58496c97=org.glassfish.jersey.servlet.ServletContainer-58496c97==org.glassfish.jersey.servlet.ServletContainer@48ef0fc1{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@341672e{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10519ms ServletHandler@341672e{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-44784e2f==org.apache.spark.ui.HttpSecurityFilter@44784e2f{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10519ms org.apache.spark.ui.HttpSecurityFilter-44784e2f==org.apache.spark.ui.HttpSecurityFilter@44784e2f{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@279dd959
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.glassfish.jersey.servlet.ServletContainer-58496c97==org.glassfish.jersey.servlet.ServletContainer@48ef0fc1{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10520ms org.glassfish.jersey.servlet.ServletContainer-58496c97==org.glassfish.jersey.servlet.ServletContainer@48ef0fc1{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-414f13fc==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet@6dcdaa8b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10520ms org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-414f13fc==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet@6dcdaa8b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@639aba11{/api,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10521ms o.s.j.s.ServletContextHandler@639aba11{/api,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@5922d3e9{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@5922d3e9{STARTING,min=32,inflate=-1} added {DeflaterPool@29fd8e67{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@5922d3e9{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@29fd8e67{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10525ms DeflaterPool@29fd8e67{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10526ms GzipHandler@5922d3e9{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@3e3861d7{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-7343922c==org.apache.spark.ui.HttpSecurityFilter@7343922c{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@3e3861d7{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-7343922c,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@3c50ad4b{STOPPED,min=32,inflate=-1} mime types IncludeExclude@37496720{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@3c50ad4b{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@2a066689{/jobs/job/kill,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@42fb8c87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@53b8afea{/,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@32b0876c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@715d6168{/static,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@64aad809{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@62db0521{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@23f3da8b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@648d0e6d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2cc03cd1{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@47d023b7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@36fc05ff{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@3291b443{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@54657dd2{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@6812fa3a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@75de6341{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3f628ce9{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@4b74b35{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7a0f244f{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@7f5b9db{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bfc6a5e{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@5922d3e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@639aba11{/api,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@3c50ad4b{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2a066689{/jobs/job/kill,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@10b1a751{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@45acdd11{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@4b4eced1{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3baf6936{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@3c50ad4b{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@2a066689{/jobs/job/kill,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@2a066689{/jobs/job/kill,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@3e3861d7{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-6d025d1d[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$2-6d025d1d==org.apache.spark.ui.JettyUtils$$anon$2@74d6239f{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-7343922c=org.apache.spark.ui.HttpSecurityFilter-7343922c==org.apache.spark.ui.HttpSecurityFilter@7343922c{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-7343922c]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-6d025d1d=org.apache.spark.ui.JettyUtils$$anon$2-6d025d1d==org.apache.spark.ui.JettyUtils$$anon$2@74d6239f{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@3e3861d7{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10541ms ServletHandler@3e3861d7{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-7343922c==org.apache.spark.ui.HttpSecurityFilter@7343922c{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10542ms org.apache.spark.ui.HttpSecurityFilter-7343922c==org.apache.spark.ui.HttpSecurityFilter@7343922c{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@15efda6c
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$2-6d025d1d==org.apache.spark.ui.JettyUtils$$anon$2@74d6239f{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10543ms org.apache.spark.ui.JettyUtils$$anon$2-6d025d1d==org.apache.spark.ui.JettyUtils$$anon$2@74d6239f{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$2-6d025d1d
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@2a066689{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10544ms o.s.j.s.ServletContextHandler@2a066689{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@3c50ad4b{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@3c50ad4b{STARTING,min=32,inflate=-1} added {DeflaterPool@58b91d57{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@3c50ad4b{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@58b91d57{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10545ms DeflaterPool@58b91d57{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10545ms GzipHandler@3c50ad4b{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@7479b626{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-462e1e64==org.apache.spark.ui.HttpSecurityFilter@462e1e64{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ServletHandler@7479b626{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-462e1e64,POJO}
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG GzipHandler:208 - GzipHandler@52d6d273{STOPPED,min=32,inflate=-1} mime types IncludeExclude@4667c4c1{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@52d6d273{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@5bb51241{/stages/stage/kill,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@42fb8c87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@53b8afea{/,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@648d0e6d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2cc03cd1{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@75de6341{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3f628ce9{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@5922d3e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@639aba11{/api,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@10b1a751{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@45acdd11{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@32b0876c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@715d6168{/static,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@64aad809{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@62db0521{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@23f3da8b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@47d023b7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@36fc05ff{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@3291b443{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@54657dd2{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@6812fa3a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@52d6d273{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5bb51241{/stages/stage/kill,null,STOPPED,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@4b74b35{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7a0f244f{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@7f5b9db{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bfc6a5e{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@3c50ad4b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2a066689{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@4b4eced1{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3baf6936{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@52d6d273{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@5bb51241{/stages/stage/kill,null,STOPPED,@Spark}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@5bb51241{/stages/stage/kill,null,STARTING,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting ServletHandler@7479b626{STOPPED}
2022-02-14 10:55:38 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-74dbb1ee[EMBEDDED:null]
2022-02-14 10:55:38 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$2-74dbb1ee==org.apache.spark.ui.JettyUtils$$anon$2@4d005857{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-462e1e64=org.apache.spark.ui.HttpSecurityFilter-462e1e64==org.apache.spark.ui.HttpSecurityFilter@462e1e64{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-462e1e64]
2022-02-14 10:55:38 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:38 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:38 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-74dbb1ee=org.apache.spark.ui.JettyUtils$$anon$2-74dbb1ee==org.apache.spark.ui.JettyUtils$$anon$2@4d005857{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting ServletHandler@7479b626{STARTING}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10559ms ServletHandler@7479b626{STARTED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-462e1e64==org.apache.spark.ui.HttpSecurityFilter@462e1e64{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10559ms org.apache.spark.ui.HttpSecurityFilter-462e1e64==org.apache.spark.ui.HttpSecurityFilter@462e1e64{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@4b4ee511
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$2-74dbb1ee==org.apache.spark.ui.JettyUtils$$anon$2@4d005857{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10560ms org.apache.spark.ui.JettyUtils$$anon$2-74dbb1ee==org.apache.spark.ui.JettyUtils$$anon$2@4d005857{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:38 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$2-74dbb1ee
2022-02-14 10:55:38 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@5bb51241{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10560ms o.s.j.s.ServletContextHandler@5bb51241{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting GzipHandler@52d6d273{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG ContainerLifeCycle:412 - GzipHandler@52d6d273{STARTING,min=32,inflate=-1} added {DeflaterPool@1b6924cb{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:38 DEBUG AbstractHandler:94 - starting GzipHandler@52d6d273{STARTING,min=32,inflate=-1}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@1b6924cb{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10561ms DeflaterPool@1b6924cb{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:38 DEBUG AbstractLifeCycle:191 - STARTED @10561ms GzipHandler@52d6d273{STARTED,min=32,inflate=-1}
2022-02-14 10:55:38 INFO  SparkUI:57 - Bound SparkUI to 0.0.0.0, and started at http://Clairvoyant-320:4040
2022-02-14 10:55:39 INFO  Executor:57 - Starting executor ID driver on host Clairvoyant-320
2022-02-14 10:55:39 DEBUG TransportServer:153 - Shuffle server started on port: 60340
2022-02-14 10:55:39 INFO  Utils:57 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60340.
2022-02-14 10:55:39 INFO  NettyBlockTransferService:57 - Server created on Clairvoyant-320:60340
2022-02-14 10:55:39 INFO  BlockManager:57 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022-02-14 10:55:39 INFO  BlockManagerMaster:57 - Registering BlockManager BlockManagerId(driver, Clairvoyant-320, 60340, None)
2022-02-14 10:55:39 DEBUG DefaultTopologyMapper:61 - Got a request for Clairvoyant-320
2022-02-14 10:55:39 INFO  BlockManagerMasterEndpoint:57 - Registering block manager Clairvoyant-320:60340 with 2.2 GiB RAM, BlockManagerId(driver, Clairvoyant-320, 60340, None)
2022-02-14 10:55:39 INFO  BlockManagerMaster:57 - Registered BlockManager BlockManagerId(driver, Clairvoyant-320, 60340, None)
2022-02-14 10:55:39 INFO  BlockManager:57 - Initialized BlockManager: BlockManagerId(driver, Clairvoyant-320, 60340, None)
2022-02-14 10:55:39 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@4130a648
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@18dd5ed3{/,null,STOPPED} added {ServletHandler@6042d663{STOPPED},MANAGED}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ServletHandler@6042d663{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-3e33b52e==org.apache.spark.ui.JettyUtils$$anon$1@830fcce6{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ServletHandler@6042d663{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-3e33b52e,POJO}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ServletHandler@6042d663{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-61a2aeb7==org.apache.spark.ui.HttpSecurityFilter@61a2aeb7{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ServletHandler@6042d663{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-61a2aeb7,POJO}
2022-02-14 10:55:39 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:39 DEBUG GzipHandler:208 - GzipHandler@62b09715{STOPPED,min=32,inflate=-1} mime types IncludeExclude@3e214105{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - GzipHandler@62b09715{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@18dd5ed3{/metrics/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@42fb8c87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@53b8afea{/,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@648d0e6d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2cc03cd1{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@75de6341{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3f628ce9{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@5922d3e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@639aba11{/api,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@10b1a751{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@45acdd11{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@32b0876c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@715d6168{/static,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@64aad809{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@62db0521{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@23f3da8b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@47d023b7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@36fc05ff{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@3291b443{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@54657dd2{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@6812fa3a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@52d6d273{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5bb51241{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@4b74b35{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7a0f244f{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@7f5b9db{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bfc6a5e{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@3c50ad4b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2a066689{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - metrics/json->[{GzipHandler@62b09715{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18dd5ed3{/metrics/json,null,STOPPED,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@4b4eced1{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3baf6936{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@62b09715{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@18dd5ed3{/metrics/json,null,STOPPED,@Spark}
2022-02-14 10:55:39 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@18dd5ed3{/metrics/json,null,STARTING,@Spark}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting ServletHandler@6042d663{STOPPED}
2022-02-14 10:55:39 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-3e33b52e[EMBEDDED:null]
2022-02-14 10:55:39 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-3e33b52e==org.apache.spark.ui.JettyUtils$$anon$1@830fcce6{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:39 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-61a2aeb7=org.apache.spark.ui.HttpSecurityFilter-61a2aeb7==org.apache.spark.ui.HttpSecurityFilter@61a2aeb7{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:39 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-61a2aeb7]
2022-02-14 10:55:39 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:39 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:39 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-3e33b52e=org.apache.spark.ui.JettyUtils$$anon$1-3e33b52e==org.apache.spark.ui.JettyUtils$$anon$1@830fcce6{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:39 DEBUG AbstractHandler:94 - starting ServletHandler@6042d663{STARTING}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11296ms ServletHandler@6042d663{STARTED}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-61a2aeb7==org.apache.spark.ui.HttpSecurityFilter@61a2aeb7{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11297ms org.apache.spark.ui.HttpSecurityFilter-61a2aeb7==org.apache.spark.ui.HttpSecurityFilter@61a2aeb7{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:39 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@7c40ffef
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-3e33b52e==org.apache.spark.ui.JettyUtils$$anon$1@830fcce6{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11297ms org.apache.spark.ui.JettyUtils$$anon$1-3e33b52e==org.apache.spark.ui.JettyUtils$$anon$1@830fcce6{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:39 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-3e33b52e
2022-02-14 10:55:39 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@18dd5ed3{/metrics/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11298ms o.s.j.s.ServletContextHandler@18dd5ed3{/metrics/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting GzipHandler@62b09715{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - GzipHandler@62b09715{STARTING,min=32,inflate=-1} added {DeflaterPool@4451f60c{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:39 DEBUG AbstractHandler:94 - starting GzipHandler@62b09715{STARTING,min=32,inflate=-1}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@4451f60c{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11299ms DeflaterPool@4451f60c{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11300ms GzipHandler@62b09715{STARTED,min=32,inflate=-1}
2022-02-14 10:55:39 DEBUG SparkContext:61 - Adding shutdown hook
2022-02-14 10:55:39 INFO  SharedState:57 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/spark-warehouse').
2022-02-14 10:55:39 INFO  SharedState:57 - Warehouse path is 'file:/C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/spark-warehouse'.
2022-02-14 10:55:39 DEBUG SharedState:61 - Applying initial SparkSession options to SparkConf/HadoopConf: spark.master -> local
2022-02-14 10:55:39 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@56a4abd0
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@5600a5da{/,null,STOPPED} added {ServletHandler@551be9f6{STOPPED},MANAGED}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ServletHandler@551be9f6{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-13250132==org.apache.spark.ui.JettyUtils$$anon$1@5ca66d33{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ServletHandler@551be9f6{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-13250132,POJO}
2022-02-14 10:55:39 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@7d3691e1
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@44bc2449{/,null,STOPPED} added {ServletHandler@3c28e5b6{STOPPED},MANAGED}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ServletHandler@3c28e5b6{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-3a296107==org.apache.spark.ui.JettyUtils$$anon$1@ae028485{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ServletHandler@3c28e5b6{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-3a296107,POJO}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ServletHandler@551be9f6{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-57151b3a==org.apache.spark.ui.HttpSecurityFilter@57151b3a{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ServletHandler@551be9f6{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-57151b3a,POJO}
2022-02-14 10:55:39 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:39 DEBUG GzipHandler:208 - GzipHandler@501957bf{STOPPED,min=32,inflate=-1} mime types IncludeExclude@5d1d9d73{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - GzipHandler@501957bf{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@5600a5da{/SQL,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@42fb8c87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@53b8afea{/,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@648d0e6d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2cc03cd1{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@75de6341{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3f628ce9{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@5922d3e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@639aba11{/api,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@10b1a751{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@45acdd11{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@32b0876c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@715d6168{/static,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@64aad809{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@62db0521{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@23f3da8b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@47d023b7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@36fc05ff{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@3291b443{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@54657dd2{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@6812fa3a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - SQL->[{GzipHandler@501957bf{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5600a5da{/SQL,null,STOPPED,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@52d6d273{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5bb51241{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@4b74b35{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7a0f244f{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@7f5b9db{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bfc6a5e{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@3c50ad4b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2a066689{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - metrics/json->[{GzipHandler@62b09715{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18dd5ed3{/metrics/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@4b4eced1{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3baf6936{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@501957bf{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@5600a5da{/SQL,null,STOPPED,@Spark}
2022-02-14 10:55:39 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@5600a5da{/SQL,null,STARTING,@Spark}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting ServletHandler@551be9f6{STOPPED}
2022-02-14 10:55:39 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-13250132[EMBEDDED:null]
2022-02-14 10:55:39 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-13250132==org.apache.spark.ui.JettyUtils$$anon$1@5ca66d33{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:39 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-57151b3a=org.apache.spark.ui.HttpSecurityFilter-57151b3a==org.apache.spark.ui.HttpSecurityFilter@57151b3a{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:39 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-57151b3a]
2022-02-14 10:55:39 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:39 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:39 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-13250132=org.apache.spark.ui.JettyUtils$$anon$1-13250132==org.apache.spark.ui.JettyUtils$$anon$1@5ca66d33{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:39 DEBUG AbstractHandler:94 - starting ServletHandler@551be9f6{STARTING}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11730ms ServletHandler@551be9f6{STARTED}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-57151b3a==org.apache.spark.ui.HttpSecurityFilter@57151b3a{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11730ms org.apache.spark.ui.HttpSecurityFilter-57151b3a==org.apache.spark.ui.HttpSecurityFilter@57151b3a{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:39 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@76c86567
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-13250132==org.apache.spark.ui.JettyUtils$$anon$1@5ca66d33{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11731ms org.apache.spark.ui.JettyUtils$$anon$1-13250132==org.apache.spark.ui.JettyUtils$$anon$1@5ca66d33{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:39 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-13250132
2022-02-14 10:55:39 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@5600a5da{/SQL,null,AVAILABLE,@Spark}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11731ms o.s.j.s.ServletContextHandler@5600a5da{/SQL,null,AVAILABLE,@Spark}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting GzipHandler@501957bf{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - GzipHandler@501957bf{STARTING,min=32,inflate=-1} added {DeflaterPool@1efac5b9{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:39 DEBUG AbstractHandler:94 - starting GzipHandler@501957bf{STARTING,min=32,inflate=-1}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@1efac5b9{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11732ms DeflaterPool@1efac5b9{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11733ms GzipHandler@501957bf{STARTED,min=32,inflate=-1}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ServletHandler@3c28e5b6{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-26c8b296==org.apache.spark.ui.HttpSecurityFilter@26c8b296{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ServletHandler@3c28e5b6{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-26c8b296,POJO}
2022-02-14 10:55:39 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:39 DEBUG GzipHandler:208 - GzipHandler@1c98b4eb{STOPPED,min=32,inflate=-1} mime types IncludeExclude@45801322{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - GzipHandler@1c98b4eb{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@44bc2449{/SQL/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@42fb8c87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@53b8afea{/,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@648d0e6d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2cc03cd1{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@75de6341{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3f628ce9{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@5922d3e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@639aba11{/api,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@10b1a751{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@45acdd11{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@32b0876c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@715d6168{/static,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@64aad809{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@62db0521{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@23f3da8b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@47d023b7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@36fc05ff{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@3291b443{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@54657dd2{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@6812fa3a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - SQL->[{GzipHandler@501957bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5600a5da{/SQL,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@52d6d273{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5bb51241{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@4b74b35{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7a0f244f{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@7f5b9db{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bfc6a5e{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - SQL/json->[{GzipHandler@1c98b4eb{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@44bc2449{/SQL/json,null,STOPPED,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@3c50ad4b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2a066689{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - metrics/json->[{GzipHandler@62b09715{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18dd5ed3{/metrics/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@4b4eced1{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3baf6936{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@1c98b4eb{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@44bc2449{/SQL/json,null,STOPPED,@Spark}
2022-02-14 10:55:39 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@44bc2449{/SQL/json,null,STARTING,@Spark}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting ServletHandler@3c28e5b6{STOPPED}
2022-02-14 10:55:39 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-3a296107[EMBEDDED:null]
2022-02-14 10:55:39 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-3a296107==org.apache.spark.ui.JettyUtils$$anon$1@ae028485{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:39 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-26c8b296=org.apache.spark.ui.HttpSecurityFilter-26c8b296==org.apache.spark.ui.HttpSecurityFilter@26c8b296{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:39 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-26c8b296]
2022-02-14 10:55:39 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:39 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:39 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-3a296107=org.apache.spark.ui.JettyUtils$$anon$1-3a296107==org.apache.spark.ui.JettyUtils$$anon$1@ae028485{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:39 DEBUG AbstractHandler:94 - starting ServletHandler@3c28e5b6{STARTING}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11746ms ServletHandler@3c28e5b6{STARTED}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-26c8b296==org.apache.spark.ui.HttpSecurityFilter@26c8b296{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11746ms org.apache.spark.ui.HttpSecurityFilter-26c8b296==org.apache.spark.ui.HttpSecurityFilter@26c8b296{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:39 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@5c4cc644
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-3a296107==org.apache.spark.ui.JettyUtils$$anon$1@ae028485{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11747ms org.apache.spark.ui.JettyUtils$$anon$1-3a296107==org.apache.spark.ui.JettyUtils$$anon$1@ae028485{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:39 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-3a296107
2022-02-14 10:55:39 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@44bc2449{/SQL/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11747ms o.s.j.s.ServletContextHandler@44bc2449{/SQL/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting GzipHandler@1c98b4eb{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - GzipHandler@1c98b4eb{STARTING,min=32,inflate=-1} added {DeflaterPool@3af2f846{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:39 DEBUG AbstractHandler:94 - starting GzipHandler@1c98b4eb{STARTING,min=32,inflate=-1}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@3af2f846{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11748ms DeflaterPool@3af2f846{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11748ms GzipHandler@1c98b4eb{STARTED,min=32,inflate=-1}
2022-02-14 10:55:39 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@284bdeed
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@482c351d{/,null,STOPPED} added {ServletHandler@75eaba95{STOPPED},MANAGED}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ServletHandler@75eaba95{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-435e416c==org.apache.spark.ui.JettyUtils$$anon$1@9c0eb7e7{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ServletHandler@75eaba95{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-435e416c,POJO}
2022-02-14 10:55:39 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@4c38cd16
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@f5bf288{/,null,STOPPED} added {ServletHandler@2c1d57bc{STOPPED},MANAGED}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ServletHandler@2c1d57bc{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-3e856100==org.apache.spark.ui.JettyUtils$$anon$1@8ba02738{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ServletHandler@2c1d57bc{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-3e856100,POJO}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ServletHandler@75eaba95{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-355ce6a6==org.apache.spark.ui.HttpSecurityFilter@355ce6a6{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ServletHandler@75eaba95{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-355ce6a6,POJO}
2022-02-14 10:55:39 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:39 DEBUG GzipHandler:208 - GzipHandler@4b9c411{STOPPED,min=32,inflate=-1} mime types IncludeExclude@41e9f86{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - GzipHandler@4b9c411{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@482c351d{/SQL/execution,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@42fb8c87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@53b8afea{/,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@648d0e6d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2cc03cd1{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@75de6341{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3f628ce9{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@5922d3e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@639aba11{/api,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@10b1a751{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@45acdd11{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@32b0876c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@715d6168{/static,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@64aad809{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@62db0521{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@23f3da8b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@47d023b7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@36fc05ff{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@3291b443{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@54657dd2{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@6812fa3a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - SQL->[{GzipHandler@501957bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5600a5da{/SQL,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@52d6d273{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5bb51241{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@4b74b35{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7a0f244f{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@7f5b9db{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bfc6a5e{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - SQL/json->[{GzipHandler@1c98b4eb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@44bc2449{/SQL/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@3c50ad4b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2a066689{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - metrics/json->[{GzipHandler@62b09715{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18dd5ed3{/metrics/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - SQL/execution->[{GzipHandler@4b9c411{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@482c351d{/SQL/execution,null,STOPPED,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@4b4eced1{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3baf6936{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@4b9c411{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@482c351d{/SQL/execution,null,STOPPED,@Spark}
2022-02-14 10:55:39 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@482c351d{/SQL/execution,null,STARTING,@Spark}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting ServletHandler@75eaba95{STOPPED}
2022-02-14 10:55:39 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-435e416c[EMBEDDED:null]
2022-02-14 10:55:39 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-435e416c==org.apache.spark.ui.JettyUtils$$anon$1@9c0eb7e7{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:39 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-355ce6a6=org.apache.spark.ui.HttpSecurityFilter-355ce6a6==org.apache.spark.ui.HttpSecurityFilter@355ce6a6{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:39 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-355ce6a6]
2022-02-14 10:55:39 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:39 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:39 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-435e416c=org.apache.spark.ui.JettyUtils$$anon$1-435e416c==org.apache.spark.ui.JettyUtils$$anon$1@9c0eb7e7{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:39 DEBUG AbstractHandler:94 - starting ServletHandler@75eaba95{STARTING}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11761ms ServletHandler@75eaba95{STARTED}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-355ce6a6==org.apache.spark.ui.HttpSecurityFilter@355ce6a6{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11762ms org.apache.spark.ui.HttpSecurityFilter-355ce6a6==org.apache.spark.ui.HttpSecurityFilter@355ce6a6{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:39 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@3d3c886f
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-435e416c==org.apache.spark.ui.JettyUtils$$anon$1@9c0eb7e7{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11762ms org.apache.spark.ui.JettyUtils$$anon$1-435e416c==org.apache.spark.ui.JettyUtils$$anon$1@9c0eb7e7{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:39 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-435e416c
2022-02-14 10:55:39 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@482c351d{/SQL/execution,null,AVAILABLE,@Spark}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11763ms o.s.j.s.ServletContextHandler@482c351d{/SQL/execution,null,AVAILABLE,@Spark}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting GzipHandler@4b9c411{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - GzipHandler@4b9c411{STARTING,min=32,inflate=-1} added {DeflaterPool@73a6cc79{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:39 DEBUG AbstractHandler:94 - starting GzipHandler@4b9c411{STARTING,min=32,inflate=-1}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@73a6cc79{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11764ms DeflaterPool@73a6cc79{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11764ms GzipHandler@4b9c411{STARTED,min=32,inflate=-1}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ServletHandler@2c1d57bc{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-67328bcb==org.apache.spark.ui.HttpSecurityFilter@67328bcb{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ServletHandler@2c1d57bc{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-67328bcb,POJO}
2022-02-14 10:55:39 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:39 DEBUG GzipHandler:208 - GzipHandler@1e40fbb3{STOPPED,min=32,inflate=-1} mime types IncludeExclude@1b560eb0{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - GzipHandler@1e40fbb3{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@f5bf288{/SQL/execution/json,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@42fb8c87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@53b8afea{/,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@648d0e6d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2cc03cd1{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@75de6341{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3f628ce9{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - SQL/execution/json->[{GzipHandler@1e40fbb3{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@f5bf288{/SQL/execution/json,null,STOPPED,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@5922d3e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@639aba11{/api,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@10b1a751{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@45acdd11{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@32b0876c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@715d6168{/static,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@64aad809{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@62db0521{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@23f3da8b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@47d023b7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@36fc05ff{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@3291b443{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@54657dd2{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@6812fa3a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - SQL->[{GzipHandler@501957bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5600a5da{/SQL,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@52d6d273{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5bb51241{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@4b74b35{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7a0f244f{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@7f5b9db{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bfc6a5e{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - SQL/json->[{GzipHandler@1c98b4eb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@44bc2449{/SQL/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@3c50ad4b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2a066689{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - metrics/json->[{GzipHandler@62b09715{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18dd5ed3{/metrics/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - SQL/execution->[{GzipHandler@4b9c411{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@482c351d{/SQL/execution,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@4b4eced1{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3baf6936{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@1e40fbb3{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@f5bf288{/SQL/execution/json,null,STOPPED,@Spark}
2022-02-14 10:55:39 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@f5bf288{/SQL/execution/json,null,STARTING,@Spark}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting ServletHandler@2c1d57bc{STOPPED}
2022-02-14 10:55:39 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-3e856100[EMBEDDED:null]
2022-02-14 10:55:39 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-3e856100==org.apache.spark.ui.JettyUtils$$anon$1@8ba02738{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:39 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-67328bcb=org.apache.spark.ui.HttpSecurityFilter-67328bcb==org.apache.spark.ui.HttpSecurityFilter@67328bcb{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:39 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-67328bcb]
2022-02-14 10:55:39 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:39 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:39 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-3e856100=org.apache.spark.ui.JettyUtils$$anon$1-3e856100==org.apache.spark.ui.JettyUtils$$anon$1@8ba02738{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:39 DEBUG AbstractHandler:94 - starting ServletHandler@2c1d57bc{STARTING}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11777ms ServletHandler@2c1d57bc{STARTED}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-67328bcb==org.apache.spark.ui.HttpSecurityFilter@67328bcb{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11777ms org.apache.spark.ui.HttpSecurityFilter-67328bcb==org.apache.spark.ui.HttpSecurityFilter@67328bcb{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:39 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@611d0763
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-3e856100==org.apache.spark.ui.JettyUtils$$anon$1@8ba02738{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11778ms org.apache.spark.ui.JettyUtils$$anon$1-3e856100==org.apache.spark.ui.JettyUtils$$anon$1@8ba02738{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:39 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-3e856100
2022-02-14 10:55:39 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@f5bf288{/SQL/execution/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11779ms o.s.j.s.ServletContextHandler@f5bf288{/SQL/execution/json,null,AVAILABLE,@Spark}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting GzipHandler@1e40fbb3{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - GzipHandler@1e40fbb3{STARTING,min=32,inflate=-1} added {DeflaterPool@48cd319d{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:39 DEBUG AbstractHandler:94 - starting GzipHandler@1e40fbb3{STARTING,min=32,inflate=-1}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@48cd319d{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11780ms DeflaterPool@48cd319d{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11780ms GzipHandler@1e40fbb3{STARTED,min=32,inflate=-1}
2022-02-14 10:55:39 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@b1b471
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@4f1afe8f{/,null,STOPPED} added {ServletHandler@492521c4{STOPPED},MANAGED}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ServletHandler@492521c4{STOPPED} added {org.sparkproject.jetty.servlet.DefaultServlet-6ddd1c51==org.sparkproject.jetty.servlet.DefaultServlet@17dc5ce4{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ServletHandler@492521c4{STOPPED} added {[/]=>org.sparkproject.jetty.servlet.DefaultServlet-6ddd1c51,POJO}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ServletHandler@492521c4{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-1fb2eec==org.apache.spark.ui.HttpSecurityFilter@1fb2eec{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ServletHandler@492521c4{STOPPED} added {[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-1fb2eec,POJO}
2022-02-14 10:55:39 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-14 10:55:39 DEBUG GzipHandler:208 - GzipHandler@6544899b{STOPPED,min=32,inflate=-1} mime types IncludeExclude@6da54910{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - GzipHandler@6544899b{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@4f1afe8f{/static/sql,null,STOPPED,@Spark},MANAGED}
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@42fb8c87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@53b8afea{/,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@648d0e6d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2cc03cd1{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@75de6341{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@69a2b3b6{/storage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@7b4a0aef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3f628ce9{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - SQL/execution/json->[{GzipHandler@1e40fbb3{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@f5bf288{/SQL/execution/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@5922d3e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@639aba11{/api,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@10b1a751{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5c73f672{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@45acdd11{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31d6f3fe{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@508a65bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2acbc859{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@32b0876c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@715d6168{/static,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@64aad809{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@62db0521{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@23f3da8b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7c2b58c0{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@47d023b7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@36fc05ff{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@3291b443{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@54657dd2{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@117525fe{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@12abdfb{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@33899f7a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@379ce046{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@c3edf4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@9d3c67{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@4a163575{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4088741b{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@6812fa3a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@782bf610{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - SQL->[{GzipHandler@501957bf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5600a5da{/SQL,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - static/sql->[{GzipHandler@6544899b{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4f1afe8f{/static/sql,null,STOPPED,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@52d6d273{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5bb51241{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@767a014e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@28f878a0{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@4b74b35{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7a0f244f{/environment,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@4d41ba0f{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@73437222{/stages,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@7f5b9db{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bfc6a5e{/executors,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - SQL/json->[{GzipHandler@1c98b4eb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@44bc2449{/SQL/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@3c50ad4b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2a066689{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - metrics/json->[{GzipHandler@62b09715{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18dd5ed3{/metrics/json,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - SQL/execution->[{GzipHandler@4b9c411{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@482c351d{/SQL/execution,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@4b4eced1{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3baf6936{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@7139bd31{STARTED} added {GzipHandler@6544899b{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@4f1afe8f{/static/sql,null,STOPPED,@Spark}
2022-02-14 10:55:39 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@4f1afe8f{/static/sql,null,STARTING,@Spark}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting ServletHandler@492521c4{STOPPED}
2022-02-14 10:55:39 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.sparkproject.jetty.servlet.DefaultServlet-6ddd1c51[EMBEDDED:null]
2022-02-14 10:55:39 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.sparkproject.jetty.servlet.DefaultServlet-6ddd1c51==org.sparkproject.jetty.servlet.DefaultServlet@17dc5ce4{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-14 10:55:39 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-1fb2eec=org.apache.spark.ui.HttpSecurityFilter-1fb2eec==org.apache.spark.ui.HttpSecurityFilter@1fb2eec{inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:39 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[ASYNC, REQUEST, ERROR, FORWARD, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-1fb2eec]
2022-02-14 10:55:39 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-02-14 10:55:39 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-14 10:55:39 DEBUG ServletHandler:1443 - servletNameMap={org.sparkproject.jetty.servlet.DefaultServlet-6ddd1c51=org.sparkproject.jetty.servlet.DefaultServlet-6ddd1c51==org.sparkproject.jetty.servlet.DefaultServlet@17dc5ce4{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-14 10:55:39 DEBUG AbstractHandler:94 - starting ServletHandler@492521c4{STARTING}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11792ms ServletHandler@492521c4{STARTED}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-1fb2eec==org.apache.spark.ui.HttpSecurityFilter@1fb2eec{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11792ms org.apache.spark.ui.HttpSecurityFilter-1fb2eec==org.apache.spark.ui.HttpSecurityFilter@1fb2eec{inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:39 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@14de1901
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting org.sparkproject.jetty.servlet.DefaultServlet-6ddd1c51==org.sparkproject.jetty.servlet.DefaultServlet@17dc5ce4{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11793ms org.sparkproject.jetty.servlet.DefaultServlet-6ddd1c51==org.sparkproject.jetty.servlet.DefaultServlet@17dc5ce4{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-14 10:55:39 DEBUG ServletHolder:621 - Servlet.init null for org.sparkproject.jetty.servlet.DefaultServlet-6ddd1c51
2022-02-14 10:55:39 DEBUG DefaultServlet:308 - resource base = jar:file:/C:/Users/Shridhar%20Ingale/.m2/repository/org/apache/spark/spark-sql_2.12/3.0.3/spark-sql_2.12-3.0.3.jar!/org/apache/spark/sql/execution/ui/static
2022-02-14 10:55:39 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@4f1afe8f{/static/sql,null,AVAILABLE,@Spark}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11817ms o.s.j.s.ServletContextHandler@4f1afe8f{/static/sql,null,AVAILABLE,@Spark}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting GzipHandler@6544899b{STOPPED,min=32,inflate=-1}
2022-02-14 10:55:39 DEBUG ContainerLifeCycle:412 - GzipHandler@6544899b{STARTING,min=32,inflate=-1} added {DeflaterPool@afde064{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-14 10:55:39 DEBUG AbstractHandler:94 - starting GzipHandler@6544899b{STARTING,min=32,inflate=-1}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@afde064{STOPPED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11818ms DeflaterPool@afde064{STARTED,size=0,capacity=UNLIMITED}
2022-02-14 10:55:39 DEBUG AbstractLifeCycle:191 - STARTED @11818ms GzipHandler@6544899b{STARTED,min=32,inflate=-1}
2022-02-14 10:55:40 DEBUG DataSource:61 - Some paths were ignored:
  
2022-02-14 10:55:40 INFO  InMemoryFileIndex:57 - It took 52 ms to list leaf files for 1 paths.
2022-02-14 10:55:40 INFO  InMemoryFileIndex:57 - It took 4 ms to list leaf files for 1 paths.
2022-02-14 10:55:42 DEBUG Analyzer$ResolveReferences:61 - Resolving 'value to value#0
2022-02-14 10:55:43 DEBUG Analyzer$ResolveReferences:61 - Resolving 'value to value#6
2022-02-14 10:55:43 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-02-14 10:55:43 INFO  FileSourceStrategy:57 - Post-Scan Filters: (length(trim(value#0, None)) > 0)
2022-02-14 10:55:43 INFO  FileSourceStrategy:57 - Output Data Schema: struct<value: string>
2022-02-14 10:55:44 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while ( inputadapter_input_0.hasNext()) {
/* 026 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 027 */
/* 028 */       do {
/* 029 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 030 */         UTF8String inputadapter_value_0 = inputadapter_isNull_0 ?
/* 031 */         null : (inputadapter_row_0.getUTF8String(0));
/* 032 */
/* 033 */         boolean filter_isNull_0 = true;
/* 034 */         boolean filter_value_0 = false;
/* 035 */         boolean filter_isNull_2 = false;
/* 036 */         UTF8String filter_value_2 = null;
/* 037 */         if (inputadapter_isNull_0) {
/* 038 */           filter_isNull_2 = true;
/* 039 */         } else {
/* 040 */           filter_value_2 = inputadapter_value_0.trim();
/* 041 */         }
/* 042 */         boolean filter_isNull_1 = filter_isNull_2;
/* 043 */         int filter_value_1 = -1;
/* 044 */
/* 045 */         if (!filter_isNull_2) {
/* 046 */           filter_value_1 = (filter_value_2).numChars();
/* 047 */         }
/* 048 */         if (!filter_isNull_1) {
/* 049 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 050 */           filter_value_0 = filter_value_1 > 0;
/* 051 */
/* 052 */         }
/* 053 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 054 */
/* 055 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 056 */
/* 057 */         filter_mutableStateArray_0[0].reset();
/* 058 */
/* 059 */         filter_mutableStateArray_0[0].zeroOutNullBytes();
/* 060 */
/* 061 */         if (inputadapter_isNull_0) {
/* 062 */           filter_mutableStateArray_0[0].setNullAt(0);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[0].write(0, inputadapter_value_0);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[0].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }

2022-02-14 10:55:44 DEBUG CodeGenerator:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while ( inputadapter_input_0.hasNext()) {
/* 026 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 027 */
/* 028 */       do {
/* 029 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 030 */         UTF8String inputadapter_value_0 = inputadapter_isNull_0 ?
/* 031 */         null : (inputadapter_row_0.getUTF8String(0));
/* 032 */
/* 033 */         boolean filter_isNull_0 = true;
/* 034 */         boolean filter_value_0 = false;
/* 035 */         boolean filter_isNull_2 = false;
/* 036 */         UTF8String filter_value_2 = null;
/* 037 */         if (inputadapter_isNull_0) {
/* 038 */           filter_isNull_2 = true;
/* 039 */         } else {
/* 040 */           filter_value_2 = inputadapter_value_0.trim();
/* 041 */         }
/* 042 */         boolean filter_isNull_1 = filter_isNull_2;
/* 043 */         int filter_value_1 = -1;
/* 044 */
/* 045 */         if (!filter_isNull_2) {
/* 046 */           filter_value_1 = (filter_value_2).numChars();
/* 047 */         }
/* 048 */         if (!filter_isNull_1) {
/* 049 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 050 */           filter_value_0 = filter_value_1 > 0;
/* 051 */
/* 052 */         }
/* 053 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 054 */
/* 055 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 056 */
/* 057 */         filter_mutableStateArray_0[0].reset();
/* 058 */
/* 059 */         filter_mutableStateArray_0[0].zeroOutNullBytes();
/* 060 */
/* 061 */         if (inputadapter_isNull_0) {
/* 062 */           filter_mutableStateArray_0[0].setNullAt(0);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[0].write(0, inputadapter_value_0);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[0].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }

2022-02-14 10:55:44 INFO  CodeGenerator:57 - Code generated in 325.142799 ms
2022-02-14 10:55:44 INFO  MemoryStore:57 - Block broadcast_0 stored as values in memory (estimated size 171.1 KiB, free 2.2 GiB)
2022-02-14 10:55:44 DEBUG BlockManager:61 - Put block broadcast_0 locally took 50 ms
2022-02-14 10:55:44 DEBUG BlockManager:61 - Putting block broadcast_0 without replication took 51 ms
2022-02-14 10:55:44 INFO  MemoryStore:57 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022-02-14 10:55:44 INFO  BlockManagerInfo:57 - Added broadcast_0_piece0 in memory on Clairvoyant-320:60340 (size: 24.0 KiB, free: 2.2 GiB)
2022-02-14 10:55:44 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_0_piece0
2022-02-14 10:55:44 DEBUG BlockManager:61 - Told master about block broadcast_0_piece0
2022-02-14 10:55:44 DEBUG BlockManager:61 - Put block broadcast_0_piece0 locally took 11 ms
2022-02-14 10:55:44 DEBUG BlockManager:61 - Putting block broadcast_0_piece0 without replication took 12 ms
2022-02-14 10:55:44 INFO  SparkContext:57 - Created broadcast 0 from load at UsedCase4.java:13
2022-02-14 10:55:44 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 7194299 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-14 10:55:44 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-02-14 10:55:44 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-02-14 10:55:44 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$executeTake$2
2022-02-14 10:55:44 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$executeTake$2) is now cleaned +++
2022-02-14 10:55:44 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$5
2022-02-14 10:55:44 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2022-02-14 10:55:44 INFO  SparkContext:57 - Starting job: load at UsedCase4.java:13
2022-02-14 10:55:44 INFO  DAGScheduler:57 - Got job 0 (load at UsedCase4.java:13) with 1 output partitions
2022-02-14 10:55:44 INFO  DAGScheduler:57 - Final stage: ResultStage 0 (load at UsedCase4.java:13)
2022-02-14 10:55:44 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-02-14 10:55:44 INFO  DAGScheduler:57 - Missing parents: List()
2022-02-14 10:55:44 DEBUG DAGScheduler:61 - submitStage(ResultStage 0 (name=load at UsedCase4.java:13;jobs=0))
2022-02-14 10:55:44 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:55:44 INFO  DAGScheduler:57 - Submitting ResultStage 0 (MapPartitionsRDD[3] at load at UsedCase4.java:13), which has no missing parents
2022-02-14 10:55:44 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 0)
2022-02-14 10:55:44 INFO  MemoryStore:57 - Block broadcast_1 stored as values in memory (estimated size 10.7 KiB, free 2.2 GiB)
2022-02-14 10:55:44 DEBUG BlockManager:61 - Put block broadcast_1 locally took 5 ms
2022-02-14 10:55:44 DEBUG BlockManager:61 - Putting block broadcast_1 without replication took 6 ms
2022-02-14 10:55:44 INFO  MemoryStore:57 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 2.2 GiB)
2022-02-14 10:55:44 INFO  BlockManagerInfo:57 - Added broadcast_1_piece0 in memory on Clairvoyant-320:60340 (size: 5.3 KiB, free: 2.2 GiB)
2022-02-14 10:55:44 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_1_piece0
2022-02-14 10:55:44 DEBUG BlockManager:61 - Told master about block broadcast_1_piece0
2022-02-14 10:55:44 DEBUG BlockManager:61 - Put block broadcast_1_piece0 locally took 2 ms
2022-02-14 10:55:44 DEBUG BlockManager:61 - Putting block broadcast_1_piece0 without replication took 2 ms
2022-02-14 10:55:44 INFO  SparkContext:57 - Created broadcast 1 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:55:44 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at UsedCase4.java:13) (first 15 tasks are for partitions Vector(0))
2022-02-14 10:55:44 INFO  TaskSchedulerImpl:57 - Adding task set 0.0 with 1 tasks
2022-02-14 10:55:44 DEBUG TaskSetManager:61 - Epoch for TaskSet 0.0: 0
2022-02-14 10:55:44 DEBUG TaskSetManager:61 - Adding pending tasks took 3 ms
2022-02-14 10:55:44 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 0.0: NO_PREF, ANY
2022-02-14 10:55:45 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_0.0, runningTasks: 0
2022-02-14 10:55:45 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 0.0: NO_PREF, ANY
2022-02-14 10:55:45 INFO  TaskSetManager:57 - Starting task 0.0 in stage 0.0 (TID 0, Clairvoyant-320, executor driver, partition 0, PROCESS_LOCAL, 7801 bytes)
2022-02-14 10:55:45 INFO  Executor:57 - Running task 0.0 in stage 0.0 (TID 0)
2022-02-14 10:55:45 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (0, 0) -> 1
2022-02-14 10:55:45 DEBUG BlockManager:61 - Getting local block broadcast_1
2022-02-14 10:55:45 DEBUG BlockManager:61 - Level for block broadcast_1 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:45 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/src/main/resources/retail_db/orders/part-00000, range: 0-2999995, partition values: [empty row]
2022-02-14 10:55:45 DEBUG GenerateUnsafeProjection:61 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-14 10:55:45 DEBUG CodeGenerator:61 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-14 10:55:45 INFO  CodeGenerator:57 - Code generated in 24.2739 ms
2022-02-14 10:55:45 DEBUG BlockManager:61 - Getting local block broadcast_0
2022-02-14 10:55:45 DEBUG BlockManager:61 - Level for block broadcast_0 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:45 INFO  Executor:57 - Finished task 0.0 in stage 0.0 (TID 0). 1600 bytes result sent to driver
2022-02-14 10:55:45 DEBUG ExecutorMetricsPoller:61 - removing (0, 0) from stageTCMP
2022-02-14 10:55:45 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_0.0, runningTasks: 0
2022-02-14 10:55:45 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-14 10:55:45 INFO  TaskSetManager:57 - Finished task 0.0 in stage 0.0 (TID 0) in 419 ms on Clairvoyant-320 (executor driver) (1/1)
2022-02-14 10:55:45 INFO  TaskSchedulerImpl:57 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-02-14 10:55:45 INFO  DAGScheduler:57 - ResultStage 0 (load at UsedCase4.java:13) finished in 0.591 s
2022-02-14 10:55:45 DEBUG DAGScheduler:61 - After removal of stage 0, remaining stages = 0
2022-02-14 10:55:45 INFO  DAGScheduler:57 - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2022-02-14 10:55:45 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 0: Stage finished
2022-02-14 10:55:45 INFO  DAGScheduler:57 - Job 0 finished: load at UsedCase4.java:13, took 0.654367 s
2022-02-14 10:55:45 DEBUG GenerateSafeProjection:61 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-02-14 10:55:45 DEBUG CodeGenerator:61 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-02-14 10:55:45 INFO  CodeGenerator:57 - Code generated in 17.943899 ms
2022-02-14 10:55:45 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-02-14 10:55:45 INFO  FileSourceStrategy:57 - Post-Scan Filters: 
2022-02-14 10:55:45 INFO  FileSourceStrategy:57 - Output Data Schema: struct<value: string>
2022-02-14 10:55:45 INFO  MemoryStore:57 - Block broadcast_2 stored as values in memory (estimated size 171.1 KiB, free 2.2 GiB)
2022-02-14 10:55:45 DEBUG BlockManager:61 - Put block broadcast_2 locally took 8 ms
2022-02-14 10:55:45 DEBUG BlockManager:61 - Putting block broadcast_2 without replication took 9 ms
2022-02-14 10:55:45 INFO  MemoryStore:57 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022-02-14 10:55:45 INFO  BlockManagerInfo:57 - Added broadcast_2_piece0 in memory on Clairvoyant-320:60340 (size: 24.0 KiB, free: 2.2 GiB)
2022-02-14 10:55:45 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_2_piece0
2022-02-14 10:55:45 DEBUG BlockManager:61 - Told master about block broadcast_2_piece0
2022-02-14 10:55:45 DEBUG BlockManager:61 - Put block broadcast_2_piece0 locally took 5 ms
2022-02-14 10:55:45 DEBUG BlockManager:61 - Putting block broadcast_2_piece0 without replication took 5 ms
2022-02-14 10:55:45 INFO  SparkContext:57 - Created broadcast 2 from load at UsedCase4.java:13
2022-02-14 10:55:45 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 7194299 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-14 10:55:45 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$rdd$1
2022-02-14 10:55:45 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$rdd$1) is now cleaned +++
2022-02-14 10:55:45 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$inferFromDataset$2
2022-02-14 10:55:45 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$inferFromDataset$2) is now cleaned +++
2022-02-14 10:55:45 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$infer$2
2022-02-14 10:55:45 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$infer$2) is now cleaned +++
2022-02-14 10:55:45 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$infer$3
2022-02-14 10:55:45 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$infer$3) is now cleaned +++
2022-02-14 10:55:45 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$6
2022-02-14 10:55:45 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$6) is now cleaned +++
2022-02-14 10:55:45 INFO  SparkContext:57 - Starting job: load at UsedCase4.java:13
2022-02-14 10:55:45 INFO  DAGScheduler:57 - Got job 1 (load at UsedCase4.java:13) with 1 output partitions
2022-02-14 10:55:45 INFO  DAGScheduler:57 - Final stage: ResultStage 1 (load at UsedCase4.java:13)
2022-02-14 10:55:45 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-02-14 10:55:45 INFO  DAGScheduler:57 - Missing parents: List()
2022-02-14 10:55:45 DEBUG DAGScheduler:61 - submitStage(ResultStage 1 (name=load at UsedCase4.java:13;jobs=1))
2022-02-14 10:55:45 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:55:45 INFO  DAGScheduler:57 - Submitting ResultStage 1 (MapPartitionsRDD[9] at load at UsedCase4.java:13), which has no missing parents
2022-02-14 10:55:45 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 1)
2022-02-14 10:55:45 INFO  MemoryStore:57 - Block broadcast_3 stored as values in memory (estimated size 15.1 KiB, free 2.2 GiB)
2022-02-14 10:55:45 DEBUG BlockManager:61 - Put block broadcast_3 locally took 5 ms
2022-02-14 10:55:45 DEBUG BlockManager:61 - Putting block broadcast_3 without replication took 5 ms
2022-02-14 10:55:45 INFO  MemoryStore:57 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 2.2 GiB)
2022-02-14 10:55:45 INFO  BlockManagerInfo:57 - Added broadcast_3_piece0 in memory on Clairvoyant-320:60340 (size: 7.6 KiB, free: 2.2 GiB)
2022-02-14 10:55:45 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_3_piece0
2022-02-14 10:55:45 DEBUG BlockManager:61 - Told master about block broadcast_3_piece0
2022-02-14 10:55:45 DEBUG BlockManager:61 - Put block broadcast_3_piece0 locally took 5 ms
2022-02-14 10:55:45 DEBUG BlockManager:61 - Putting block broadcast_3_piece0 without replication took 5 ms
2022-02-14 10:55:45 INFO  SparkContext:57 - Created broadcast 3 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:55:45 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at load at UsedCase4.java:13) (first 15 tasks are for partitions Vector(0))
2022-02-14 10:55:45 INFO  TaskSchedulerImpl:57 - Adding task set 1.0 with 1 tasks
2022-02-14 10:55:45 DEBUG TaskSetManager:61 - Epoch for TaskSet 1.0: 0
2022-02-14 10:55:45 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-02-14 10:55:45 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 1.0: NO_PREF, ANY
2022-02-14 10:55:45 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_1.0, runningTasks: 0
2022-02-14 10:55:45 INFO  TaskSetManager:57 - Starting task 0.0 in stage 1.0 (TID 1, Clairvoyant-320, executor driver, partition 0, PROCESS_LOCAL, 7801 bytes)
2022-02-14 10:55:45 INFO  Executor:57 - Running task 0.0 in stage 1.0 (TID 1)
2022-02-14 10:55:45 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (1, 0) -> 1
2022-02-14 10:55:45 DEBUG BlockManager:61 - Getting local block broadcast_3
2022-02-14 10:55:45 DEBUG BlockManager:61 - Level for block broadcast_3 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:45 DEBUG GenerateSafeProjection:61 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-02-14 10:55:45 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/src/main/resources/retail_db/orders/part-00000, range: 0-2999995, partition values: [empty row]
2022-02-14 10:55:45 DEBUG GenerateUnsafeProjection:61 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-14 10:55:45 DEBUG BlockManager:61 - Getting local block broadcast_2
2022-02-14 10:55:45 DEBUG BlockManager:61 - Level for block broadcast_2 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:46 INFO  Executor:57 - Finished task 0.0 in stage 1.0 (TID 1). 1566 bytes result sent to driver
2022-02-14 10:55:46 DEBUG ExecutorMetricsPoller:61 - removing (1, 0) from stageTCMP
2022-02-14 10:55:46 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_1.0, runningTasks: 0
2022-02-14 10:55:46 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-14 10:55:46 INFO  TaskSetManager:57 - Finished task 0.0 in stage 1.0 (TID 1) in 471 ms on Clairvoyant-320 (executor driver) (1/1)
2022-02-14 10:55:46 INFO  TaskSchedulerImpl:57 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-02-14 10:55:46 INFO  DAGScheduler:57 - ResultStage 1 (load at UsedCase4.java:13) finished in 0.541 s
2022-02-14 10:55:46 DEBUG DAGScheduler:61 - After removal of stage 1, remaining stages = 0
2022-02-14 10:55:46 INFO  DAGScheduler:57 - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2022-02-14 10:55:46 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 1: Stage finished
2022-02-14 10:55:46 INFO  DAGScheduler:57 - Job 1 finished: load at UsedCase4.java:13, took 0.553488 s
2022-02-14 10:55:46 DEBUG DataSource:61 - Some paths were ignored:
  
2022-02-14 10:55:46 INFO  InMemoryFileIndex:57 - It took 1 ms to list leaf files for 1 paths.
2022-02-14 10:55:46 INFO  InMemoryFileIndex:57 - It took 3 ms to list leaf files for 1 paths.
2022-02-14 10:55:46 DEBUG Analyzer$ResolveReferences:61 - Resolving 'value to value#24
2022-02-14 10:55:46 DEBUG Analyzer$ResolveReferences:61 - Resolving 'value to value#30
2022-02-14 10:55:46 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-02-14 10:55:46 INFO  FileSourceStrategy:57 - Post-Scan Filters: (length(trim(value#24, None)) > 0)
2022-02-14 10:55:46 INFO  FileSourceStrategy:57 - Output Data Schema: struct<value: string>
2022-02-14 10:55:46 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while ( inputadapter_input_0.hasNext()) {
/* 026 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 027 */
/* 028 */       do {
/* 029 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 030 */         UTF8String inputadapter_value_0 = inputadapter_isNull_0 ?
/* 031 */         null : (inputadapter_row_0.getUTF8String(0));
/* 032 */
/* 033 */         boolean filter_isNull_0 = true;
/* 034 */         boolean filter_value_0 = false;
/* 035 */         boolean filter_isNull_2 = false;
/* 036 */         UTF8String filter_value_2 = null;
/* 037 */         if (inputadapter_isNull_0) {
/* 038 */           filter_isNull_2 = true;
/* 039 */         } else {
/* 040 */           filter_value_2 = inputadapter_value_0.trim();
/* 041 */         }
/* 042 */         boolean filter_isNull_1 = filter_isNull_2;
/* 043 */         int filter_value_1 = -1;
/* 044 */
/* 045 */         if (!filter_isNull_2) {
/* 046 */           filter_value_1 = (filter_value_2).numChars();
/* 047 */         }
/* 048 */         if (!filter_isNull_1) {
/* 049 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 050 */           filter_value_0 = filter_value_1 > 0;
/* 051 */
/* 052 */         }
/* 053 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 054 */
/* 055 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 056 */
/* 057 */         filter_mutableStateArray_0[0].reset();
/* 058 */
/* 059 */         filter_mutableStateArray_0[0].zeroOutNullBytes();
/* 060 */
/* 061 */         if (inputadapter_isNull_0) {
/* 062 */           filter_mutableStateArray_0[0].setNullAt(0);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[0].write(0, inputadapter_value_0);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[0].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }

2022-02-14 10:55:46 INFO  MemoryStore:57 - Block broadcast_4 stored as values in memory (estimated size 171.1 KiB, free 2.2 GiB)
2022-02-14 10:55:46 DEBUG BlockManager:61 - Put block broadcast_4 locally took 6 ms
2022-02-14 10:55:46 DEBUG BlockManager:61 - Putting block broadcast_4 without replication took 7 ms
2022-02-14 10:55:46 INFO  MemoryStore:57 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022-02-14 10:55:46 INFO  BlockManagerInfo:57 - Added broadcast_4_piece0 in memory on Clairvoyant-320:60340 (size: 24.0 KiB, free: 2.2 GiB)
2022-02-14 10:55:46 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_4_piece0
2022-02-14 10:55:46 DEBUG BlockManager:61 - Told master about block broadcast_4_piece0
2022-02-14 10:55:46 DEBUG BlockManager:61 - Put block broadcast_4_piece0 locally took 6 ms
2022-02-14 10:55:46 DEBUG BlockManager:61 - Putting block broadcast_4_piece0 without replication took 8 ms
2022-02-14 10:55:46 INFO  SparkContext:57 - Created broadcast 4 from load at UsedCase4.java:16
2022-02-14 10:55:46 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 9603305 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-14 10:55:46 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-02-14 10:55:46 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-02-14 10:55:46 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$executeTake$2
2022-02-14 10:55:46 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$executeTake$2) is now cleaned +++
2022-02-14 10:55:46 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$5
2022-02-14 10:55:46 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2022-02-14 10:55:46 INFO  SparkContext:57 - Starting job: load at UsedCase4.java:16
2022-02-14 10:55:46 INFO  DAGScheduler:57 - Got job 2 (load at UsedCase4.java:16) with 1 output partitions
2022-02-14 10:55:46 INFO  DAGScheduler:57 - Final stage: ResultStage 2 (load at UsedCase4.java:16)
2022-02-14 10:55:46 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-02-14 10:55:46 INFO  DAGScheduler:57 - Missing parents: List()
2022-02-14 10:55:46 DEBUG DAGScheduler:61 - submitStage(ResultStage 2 (name=load at UsedCase4.java:16;jobs=2))
2022-02-14 10:55:46 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:55:46 INFO  DAGScheduler:57 - Submitting ResultStage 2 (MapPartitionsRDD[13] at load at UsedCase4.java:16), which has no missing parents
2022-02-14 10:55:46 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 2)
2022-02-14 10:55:46 INFO  MemoryStore:57 - Block broadcast_5 stored as values in memory (estimated size 10.7 KiB, free 2.2 GiB)
2022-02-14 10:55:46 DEBUG BlockManager:61 - Put block broadcast_5 locally took 9 ms
2022-02-14 10:55:46 DEBUG BlockManager:61 - Putting block broadcast_5 without replication took 10 ms
2022-02-14 10:55:46 INFO  MemoryStore:57 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 2.2 GiB)
2022-02-14 10:55:46 INFO  BlockManagerInfo:57 - Added broadcast_5_piece0 in memory on Clairvoyant-320:60340 (size: 5.3 KiB, free: 2.2 GiB)
2022-02-14 10:55:46 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_5_piece0
2022-02-14 10:55:46 DEBUG BlockManager:61 - Told master about block broadcast_5_piece0
2022-02-14 10:55:46 DEBUG BlockManager:61 - Put block broadcast_5_piece0 locally took 7 ms
2022-02-14 10:55:46 DEBUG BlockManager:61 - Putting block broadcast_5_piece0 without replication took 7 ms
2022-02-14 10:55:46 INFO  SparkContext:57 - Created broadcast 5 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:55:46 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at load at UsedCase4.java:16) (first 15 tasks are for partitions Vector(0))
2022-02-14 10:55:46 INFO  TaskSchedulerImpl:57 - Adding task set 2.0 with 1 tasks
2022-02-14 10:55:46 DEBUG TaskSetManager:61 - Epoch for TaskSet 2.0: 0
2022-02-14 10:55:46 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-02-14 10:55:46 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 2.0: NO_PREF, ANY
2022-02-14 10:55:46 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_2.0, runningTasks: 0
2022-02-14 10:55:46 INFO  TaskSetManager:57 - Starting task 0.0 in stage 2.0 (TID 2, Clairvoyant-320, executor driver, partition 0, PROCESS_LOCAL, 7806 bytes)
2022-02-14 10:55:46 INFO  Executor:57 - Running task 0.0 in stage 2.0 (TID 2)
2022-02-14 10:55:46 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (2, 0) -> 1
2022-02-14 10:55:46 DEBUG BlockManager:61 - Getting local block broadcast_5
2022-02-14 10:55:46 DEBUG BlockManager:61 - Level for block broadcast_5 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:46 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/src/main/resources/retail_db/order_items/part-00000, range: 0-5409001, partition values: [empty row]
2022-02-14 10:55:46 DEBUG GenerateUnsafeProjection:61 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-14 10:55:46 DEBUG BlockManager:61 - Getting local block broadcast_4
2022-02-14 10:55:46 DEBUG BlockManager:61 - Level for block broadcast_4 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:46 INFO  Executor:57 - Finished task 0.0 in stage 2.0 (TID 2). 1536 bytes result sent to driver
2022-02-14 10:55:46 DEBUG ExecutorMetricsPoller:61 - removing (2, 0) from stageTCMP
2022-02-14 10:55:46 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_2.0, runningTasks: 0
2022-02-14 10:55:46 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-14 10:55:46 INFO  TaskSetManager:57 - Finished task 0.0 in stage 2.0 (TID 2) in 32 ms on Clairvoyant-320 (executor driver) (1/1)
2022-02-14 10:55:46 INFO  TaskSchedulerImpl:57 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022-02-14 10:55:46 INFO  DAGScheduler:57 - ResultStage 2 (load at UsedCase4.java:16) finished in 0.060 s
2022-02-14 10:55:46 DEBUG DAGScheduler:61 - After removal of stage 2, remaining stages = 0
2022-02-14 10:55:46 INFO  DAGScheduler:57 - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2022-02-14 10:55:46 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 2: Stage finished
2022-02-14 10:55:46 INFO  DAGScheduler:57 - Job 2 finished: load at UsedCase4.java:16, took 0.066700 s
2022-02-14 10:55:46 DEBUG GenerateSafeProjection:61 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-02-14 10:55:46 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-02-14 10:55:46 INFO  FileSourceStrategy:57 - Post-Scan Filters: 
2022-02-14 10:55:46 INFO  FileSourceStrategy:57 - Output Data Schema: struct<value: string>
2022-02-14 10:55:46 INFO  MemoryStore:57 - Block broadcast_6 stored as values in memory (estimated size 171.1 KiB, free 2.2 GiB)
2022-02-14 10:55:46 DEBUG BlockManager:61 - Put block broadcast_6 locally took 5 ms
2022-02-14 10:55:46 DEBUG BlockManager:61 - Putting block broadcast_6 without replication took 5 ms
2022-02-14 10:55:46 INFO  MemoryStore:57 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022-02-14 10:55:46 INFO  BlockManagerInfo:57 - Added broadcast_6_piece0 in memory on Clairvoyant-320:60340 (size: 24.0 KiB, free: 2.2 GiB)
2022-02-14 10:55:46 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_6_piece0
2022-02-14 10:55:46 DEBUG BlockManager:61 - Told master about block broadcast_6_piece0
2022-02-14 10:55:46 DEBUG BlockManager:61 - Put block broadcast_6_piece0 locally took 5 ms
2022-02-14 10:55:46 DEBUG BlockManager:61 - Putting block broadcast_6_piece0 without replication took 5 ms
2022-02-14 10:55:46 INFO  SparkContext:57 - Created broadcast 6 from load at UsedCase4.java:16
2022-02-14 10:55:46 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 9603305 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-14 10:55:46 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$rdd$1
2022-02-14 10:55:46 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$rdd$1) is now cleaned +++
2022-02-14 10:55:46 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$inferFromDataset$2
2022-02-14 10:55:46 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$inferFromDataset$2) is now cleaned +++
2022-02-14 10:55:46 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$infer$2
2022-02-14 10:55:46 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$infer$2) is now cleaned +++
2022-02-14 10:55:46 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$infer$3
2022-02-14 10:55:46 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$infer$3) is now cleaned +++
2022-02-14 10:55:46 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$6
2022-02-14 10:55:46 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$6) is now cleaned +++
2022-02-14 10:55:46 INFO  SparkContext:57 - Starting job: load at UsedCase4.java:16
2022-02-14 10:55:46 INFO  DAGScheduler:57 - Got job 3 (load at UsedCase4.java:16) with 1 output partitions
2022-02-14 10:55:46 INFO  DAGScheduler:57 - Final stage: ResultStage 3 (load at UsedCase4.java:16)
2022-02-14 10:55:46 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-02-14 10:55:46 INFO  DAGScheduler:57 - Missing parents: List()
2022-02-14 10:55:46 DEBUG DAGScheduler:61 - submitStage(ResultStage 3 (name=load at UsedCase4.java:16;jobs=3))
2022-02-14 10:55:46 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:55:46 INFO  DAGScheduler:57 - Submitting ResultStage 3 (MapPartitionsRDD[19] at load at UsedCase4.java:16), which has no missing parents
2022-02-14 10:55:46 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 3)
2022-02-14 10:55:46 INFO  MemoryStore:57 - Block broadcast_7 stored as values in memory (estimated size 15.2 KiB, free 2.2 GiB)
2022-02-14 10:55:46 DEBUG BlockManager:61 - Put block broadcast_7 locally took 3 ms
2022-02-14 10:55:46 DEBUG BlockManager:61 - Putting block broadcast_7 without replication took 3 ms
2022-02-14 10:55:46 INFO  MemoryStore:57 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 2.2 GiB)
2022-02-14 10:55:46 INFO  BlockManagerInfo:57 - Added broadcast_7_piece0 in memory on Clairvoyant-320:60340 (size: 7.6 KiB, free: 2.2 GiB)
2022-02-14 10:55:46 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_7_piece0
2022-02-14 10:55:46 DEBUG BlockManager:61 - Told master about block broadcast_7_piece0
2022-02-14 10:55:46 DEBUG BlockManager:61 - Put block broadcast_7_piece0 locally took 4 ms
2022-02-14 10:55:46 DEBUG BlockManager:61 - Putting block broadcast_7_piece0 without replication took 4 ms
2022-02-14 10:55:46 INFO  SparkContext:57 - Created broadcast 7 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:55:46 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[19] at load at UsedCase4.java:16) (first 15 tasks are for partitions Vector(0))
2022-02-14 10:55:46 INFO  TaskSchedulerImpl:57 - Adding task set 3.0 with 1 tasks
2022-02-14 10:55:46 DEBUG TaskSetManager:61 - Epoch for TaskSet 3.0: 0
2022-02-14 10:55:46 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-02-14 10:55:46 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 3.0: NO_PREF, ANY
2022-02-14 10:55:46 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_3.0, runningTasks: 0
2022-02-14 10:55:46 INFO  TaskSetManager:57 - Starting task 0.0 in stage 3.0 (TID 3, Clairvoyant-320, executor driver, partition 0, PROCESS_LOCAL, 7806 bytes)
2022-02-14 10:55:46 INFO  Executor:57 - Running task 0.0 in stage 3.0 (TID 3)
2022-02-14 10:55:46 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (3, 0) -> 1
2022-02-14 10:55:46 DEBUG BlockManager:61 - Getting local block broadcast_7
2022-02-14 10:55:46 DEBUG BlockManager:61 - Level for block broadcast_7 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:46 DEBUG GenerateSafeProjection:61 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-02-14 10:55:46 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/src/main/resources/retail_db/order_items/part-00000, range: 0-5409001, partition values: [empty row]
2022-02-14 10:55:46 DEBUG GenerateUnsafeProjection:61 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-14 10:55:46 DEBUG BlockManager:61 - Getting local block broadcast_6
2022-02-14 10:55:46 DEBUG BlockManager:61 - Level for block broadcast_6 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(94)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 94
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 94
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(66)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 66
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 66
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(77)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 77
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 77
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(40)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 40
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 40
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(19)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 19
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 19
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(74)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 74
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 74
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(9)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 9
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 9
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(13)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 13
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 13
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(18)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 18
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 18
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(4)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 4
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 4
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(23)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 23
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 23
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(93)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 93
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 93
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(90)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 90
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 90
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(79)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 79
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 79
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(100)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 100
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 100
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(56)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 56
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 56
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(17)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 17
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 17
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(49)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 49
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 49
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(36)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 36
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 36
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(62)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 62
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 62
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(16)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 16
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 16
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(86)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 86
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 86
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(44)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 44
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 44
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(72)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 72
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 72
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(63)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 63
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 63
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(84)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 84
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 84
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(85)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 85
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 85
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(108)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 108
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 108
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(71)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 71
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 71
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(59)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 59
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 59
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(28)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 28
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 28
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(47)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 47
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 47
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(15)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 15
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 15
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(55)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 55
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 55
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(91)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 91
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 91
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 1
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 1
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(11)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 11
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 11
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(58)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 58
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 58
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(35)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 35
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 35
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(8)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 8
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 8
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(69)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 69
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 69
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(34)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 34
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 34
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(80)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 80
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 80
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(102)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 102
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 102
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(67)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 67
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 67
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(81)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 81
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 81
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(46)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 46
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 46
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(24)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 24
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 24
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(48)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 48
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 48
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(89)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 89
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 89
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(88)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 88
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 88
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(38)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 38
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 38
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(65)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 65
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 65
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(3)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning broadcast 3
2022-02-14 10:55:46 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 3
2022-02-14 10:55:46 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 3
2022-02-14 10:55:46 DEBUG BlockManager:61 - Removing broadcast 3
2022-02-14 10:55:46 DEBUG BlockManager:61 - Removing block broadcast_3_piece0
2022-02-14 10:55:46 DEBUG MemoryStore:61 - Block broadcast_3_piece0 of size 7746 dropped from memory (free 2347100763)
2022-02-14 10:55:46 INFO  BlockManagerInfo:57 - Removed broadcast_3_piece0 on Clairvoyant-320:60340 in memory (size: 7.6 KiB, free: 2.2 GiB)
2022-02-14 10:55:46 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_3_piece0
2022-02-14 10:55:46 DEBUG BlockManager:61 - Told master about block broadcast_3_piece0
2022-02-14 10:55:46 DEBUG BlockManager:61 - Removing block broadcast_3
2022-02-14 10:55:46 DEBUG MemoryStore:61 - Block broadcast_3 of size 15504 dropped from memory (free 2347116267)
2022-02-14 10:55:46 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 3, response is 0
2022-02-14 10:55:46 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60325
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned broadcast 3
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(31)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 31
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 31
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(73)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 73
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 73
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(25)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 25
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 25
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(103)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 103
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 103
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(41)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 41
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 41
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(57)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 57
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 57
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(6)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 6
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 6
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(107)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 107
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 107
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(29)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 29
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 29
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(0)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 0
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 0
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(92)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 92
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 92
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(64)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 64
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 64
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(14)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 14
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 14
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(110)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 110
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 110
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(87)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 87
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 87
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(97)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 97
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 97
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(98)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 98
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 98
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(82)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 82
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 82
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(0)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning broadcast 0
2022-02-14 10:55:46 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 0
2022-02-14 10:55:46 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 0
2022-02-14 10:55:46 DEBUG BlockManager:61 - Removing broadcast 0
2022-02-14 10:55:46 DEBUG BlockManager:61 - Removing block broadcast_0_piece0
2022-02-14 10:55:46 DEBUG MemoryStore:61 - Block broadcast_0_piece0 of size 24528 dropped from memory (free 2347140795)
2022-02-14 10:55:46 INFO  BlockManagerInfo:57 - Removed broadcast_0_piece0 on Clairvoyant-320:60340 in memory (size: 24.0 KiB, free: 2.2 GiB)
2022-02-14 10:55:46 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_0_piece0
2022-02-14 10:55:46 DEBUG BlockManager:61 - Told master about block broadcast_0_piece0
2022-02-14 10:55:46 DEBUG BlockManager:61 - Removing block broadcast_0
2022-02-14 10:55:46 DEBUG MemoryStore:61 - Block broadcast_0 of size 175184 dropped from memory (free 2347315979)
2022-02-14 10:55:46 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 0, response is 0
2022-02-14 10:55:46 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60325
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned broadcast 0
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(53)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 53
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 53
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(26)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 26
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 26
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(109)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 109
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 109
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(5)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning broadcast 5
2022-02-14 10:55:46 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 5
2022-02-14 10:55:46 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 5
2022-02-14 10:55:46 DEBUG BlockManager:61 - Removing broadcast 5
2022-02-14 10:55:46 DEBUG BlockManager:61 - Removing block broadcast_5
2022-02-14 10:55:46 DEBUG MemoryStore:61 - Block broadcast_5 of size 10992 dropped from memory (free 2347326971)
2022-02-14 10:55:46 DEBUG BlockManager:61 - Removing block broadcast_5_piece0
2022-02-14 10:55:46 DEBUG MemoryStore:61 - Block broadcast_5_piece0 of size 5457 dropped from memory (free 2347332428)
2022-02-14 10:55:46 INFO  BlockManagerInfo:57 - Removed broadcast_5_piece0 on Clairvoyant-320:60340 in memory (size: 5.3 KiB, free: 2.2 GiB)
2022-02-14 10:55:46 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_5_piece0
2022-02-14 10:55:46 DEBUG BlockManager:61 - Told master about block broadcast_5_piece0
2022-02-14 10:55:46 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 5, response is 0
2022-02-14 10:55:46 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60325
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned broadcast 5
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(5)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 5
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 5
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(70)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 70
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 70
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(32)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 32
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 32
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(76)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 76
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 76
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(43)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 43
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 43
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(75)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 75
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 75
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(27)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 27
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 27
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(61)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 61
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 61
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(96)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 96
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 96
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(3)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 3
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 3
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(52)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 52
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 52
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(2)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 2
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 2
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(51)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 51
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 51
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(60)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 60
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 60
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(4)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning broadcast 4
2022-02-14 10:55:46 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 4
2022-02-14 10:55:46 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 4
2022-02-14 10:55:46 DEBUG BlockManager:61 - Removing broadcast 4
2022-02-14 10:55:46 DEBUG BlockManager:61 - Removing block broadcast_4_piece0
2022-02-14 10:55:46 DEBUG MemoryStore:61 - Block broadcast_4_piece0 of size 24528 dropped from memory (free 2347356956)
2022-02-14 10:55:46 INFO  BlockManagerInfo:57 - Removed broadcast_4_piece0 on Clairvoyant-320:60340 in memory (size: 24.0 KiB, free: 2.2 GiB)
2022-02-14 10:55:46 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_4_piece0
2022-02-14 10:55:46 DEBUG BlockManager:61 - Told master about block broadcast_4_piece0
2022-02-14 10:55:46 DEBUG BlockManager:61 - Removing block broadcast_4
2022-02-14 10:55:46 DEBUG MemoryStore:61 - Block broadcast_4 of size 175184 dropped from memory (free 2347532140)
2022-02-14 10:55:46 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 4, response is 0
2022-02-14 10:55:46 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60325
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned broadcast 4
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(42)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 42
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 42
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(2)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning broadcast 2
2022-02-14 10:55:46 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 2
2022-02-14 10:55:46 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 2
2022-02-14 10:55:46 DEBUG BlockManager:61 - Removing broadcast 2
2022-02-14 10:55:46 DEBUG BlockManager:61 - Removing block broadcast_2
2022-02-14 10:55:46 DEBUG MemoryStore:61 - Block broadcast_2 of size 175184 dropped from memory (free 2347707324)
2022-02-14 10:55:46 DEBUG BlockManager:61 - Removing block broadcast_2_piece0
2022-02-14 10:55:46 DEBUG MemoryStore:61 - Block broadcast_2_piece0 of size 24528 dropped from memory (free 2347731852)
2022-02-14 10:55:46 INFO  BlockManagerInfo:57 - Removed broadcast_2_piece0 on Clairvoyant-320:60340 in memory (size: 24.0 KiB, free: 2.2 GiB)
2022-02-14 10:55:46 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_2_piece0
2022-02-14 10:55:46 DEBUG BlockManager:61 - Told master about block broadcast_2_piece0
2022-02-14 10:55:46 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 2, response is 0
2022-02-14 10:55:46 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60325
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned broadcast 2
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(33)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 33
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 33
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(83)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 83
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 83
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(30)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 30
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 30
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(10)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 10
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 10
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(39)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 39
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 39
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(1)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning broadcast 1
2022-02-14 10:55:46 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 1
2022-02-14 10:55:46 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 1
2022-02-14 10:55:46 DEBUG BlockManager:61 - Removing broadcast 1
2022-02-14 10:55:46 DEBUG BlockManager:61 - Removing block broadcast_1
2022-02-14 10:55:46 DEBUG MemoryStore:61 - Block broadcast_1 of size 10992 dropped from memory (free 2347742844)
2022-02-14 10:55:46 DEBUG BlockManager:61 - Removing block broadcast_1_piece0
2022-02-14 10:55:46 DEBUG MemoryStore:61 - Block broadcast_1_piece0 of size 5448 dropped from memory (free 2347748292)
2022-02-14 10:55:46 INFO  BlockManagerInfo:57 - Removed broadcast_1_piece0 on Clairvoyant-320:60340 in memory (size: 5.3 KiB, free: 2.2 GiB)
2022-02-14 10:55:46 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_1_piece0
2022-02-14 10:55:46 DEBUG BlockManager:61 - Told master about block broadcast_1_piece0
2022-02-14 10:55:46 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 1, response is 0
2022-02-14 10:55:46 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60325
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned broadcast 1
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(37)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 37
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 37
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(7)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 7
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 7
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(22)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 22
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 22
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(54)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 54
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 54
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(106)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 106
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 106
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(99)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 99
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 99
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(45)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 45
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 45
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(12)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 12
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 12
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(104)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 104
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 104
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(68)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 68
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 68
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(20)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 20
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 20
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(78)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 78
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 78
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(105)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 105
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 105
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(50)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 50
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 50
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(21)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 21
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 21
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(95)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 95
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 95
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(101)
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaning accumulator 101
2022-02-14 10:55:46 DEBUG ContextCleaner:61 - Cleaned accumulator 101
2022-02-14 10:55:47 INFO  Executor:57 - Finished task 0.0 in stage 3.0 (TID 3). 1662 bytes result sent to driver
2022-02-14 10:55:47 DEBUG ExecutorMetricsPoller:61 - removing (3, 0) from stageTCMP
2022-02-14 10:55:47 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_3.0, runningTasks: 0
2022-02-14 10:55:47 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-14 10:55:47 INFO  TaskSetManager:57 - Finished task 0.0 in stage 3.0 (TID 3) in 536 ms on Clairvoyant-320 (executor driver) (1/1)
2022-02-14 10:55:47 INFO  TaskSchedulerImpl:57 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2022-02-14 10:55:47 INFO  DAGScheduler:57 - ResultStage 3 (load at UsedCase4.java:16) finished in 0.557 s
2022-02-14 10:55:47 DEBUG DAGScheduler:61 - After removal of stage 3, remaining stages = 0
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2022-02-14 10:55:47 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 3: Stage finished
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Job 3 finished: load at UsedCase4.java:16, took 0.561399 s
2022-02-14 10:55:47 DEBUG DataSource:61 - Some paths were ignored:
  
2022-02-14 10:55:47 INFO  InMemoryFileIndex:57 - It took 2 ms to list leaf files for 1 paths.
2022-02-14 10:55:47 INFO  InMemoryFileIndex:57 - It took 1 ms to list leaf files for 1 paths.
2022-02-14 10:55:47 DEBUG Analyzer$ResolveReferences:61 - Resolving 'value to value#52
2022-02-14 10:55:47 DEBUG Analyzer$ResolveReferences:61 - Resolving 'value to value#58
2022-02-14 10:55:47 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-02-14 10:55:47 INFO  FileSourceStrategy:57 - Post-Scan Filters: (length(trim(value#52, None)) > 0)
2022-02-14 10:55:47 INFO  FileSourceStrategy:57 - Output Data Schema: struct<value: string>
2022-02-14 10:55:47 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while ( inputadapter_input_0.hasNext()) {
/* 026 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 027 */
/* 028 */       do {
/* 029 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 030 */         UTF8String inputadapter_value_0 = inputadapter_isNull_0 ?
/* 031 */         null : (inputadapter_row_0.getUTF8String(0));
/* 032 */
/* 033 */         boolean filter_isNull_0 = true;
/* 034 */         boolean filter_value_0 = false;
/* 035 */         boolean filter_isNull_2 = false;
/* 036 */         UTF8String filter_value_2 = null;
/* 037 */         if (inputadapter_isNull_0) {
/* 038 */           filter_isNull_2 = true;
/* 039 */         } else {
/* 040 */           filter_value_2 = inputadapter_value_0.trim();
/* 041 */         }
/* 042 */         boolean filter_isNull_1 = filter_isNull_2;
/* 043 */         int filter_value_1 = -1;
/* 044 */
/* 045 */         if (!filter_isNull_2) {
/* 046 */           filter_value_1 = (filter_value_2).numChars();
/* 047 */         }
/* 048 */         if (!filter_isNull_1) {
/* 049 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 050 */           filter_value_0 = filter_value_1 > 0;
/* 051 */
/* 052 */         }
/* 053 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 054 */
/* 055 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 056 */
/* 057 */         filter_mutableStateArray_0[0].reset();
/* 058 */
/* 059 */         filter_mutableStateArray_0[0].zeroOutNullBytes();
/* 060 */
/* 061 */         if (inputadapter_isNull_0) {
/* 062 */           filter_mutableStateArray_0[0].setNullAt(0);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[0].write(0, inputadapter_value_0);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[0].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }

2022-02-14 10:55:47 INFO  MemoryStore:57 - Block broadcast_8 stored as values in memory (estimated size 171.1 KiB, free 2.2 GiB)
2022-02-14 10:55:47 DEBUG BlockManager:61 - Put block broadcast_8 locally took 3 ms
2022-02-14 10:55:47 DEBUG BlockManager:61 - Putting block broadcast_8 without replication took 4 ms
2022-02-14 10:55:47 INFO  MemoryStore:57 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022-02-14 10:55:47 INFO  BlockManagerInfo:57 - Added broadcast_8_piece0 in memory on Clairvoyant-320:60340 (size: 24.0 KiB, free: 2.2 GiB)
2022-02-14 10:55:47 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_8_piece0
2022-02-14 10:55:47 DEBUG BlockManager:61 - Told master about block broadcast_8_piece0
2022-02-14 10:55:47 DEBUG BlockManager:61 - Put block broadcast_8_piece0 locally took 4 ms
2022-02-14 10:55:47 DEBUG BlockManager:61 - Putting block broadcast_8_piece0 without replication took 5 ms
2022-02-14 10:55:47 INFO  SparkContext:57 - Created broadcast 8 from load at UsedCase4.java:19
2022-02-14 10:55:47 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4368551 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$executeTake$2
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$executeTake$2) is now cleaned +++
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$5
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2022-02-14 10:55:47 INFO  SparkContext:57 - Starting job: load at UsedCase4.java:19
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Got job 4 (load at UsedCase4.java:19) with 1 output partitions
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Final stage: ResultStage 4 (load at UsedCase4.java:19)
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Missing parents: List()
2022-02-14 10:55:47 DEBUG DAGScheduler:61 - submitStage(ResultStage 4 (name=load at UsedCase4.java:19;jobs=4))
2022-02-14 10:55:47 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Submitting ResultStage 4 (MapPartitionsRDD[23] at load at UsedCase4.java:19), which has no missing parents
2022-02-14 10:55:47 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 4)
2022-02-14 10:55:47 INFO  MemoryStore:57 - Block broadcast_9 stored as values in memory (estimated size 10.7 KiB, free 2.2 GiB)
2022-02-14 10:55:47 DEBUG BlockManager:61 - Put block broadcast_9 locally took 2 ms
2022-02-14 10:55:47 DEBUG BlockManager:61 - Putting block broadcast_9 without replication took 2 ms
2022-02-14 10:55:47 INFO  MemoryStore:57 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 2.2 GiB)
2022-02-14 10:55:47 INFO  BlockManagerInfo:57 - Added broadcast_9_piece0 in memory on Clairvoyant-320:60340 (size: 5.3 KiB, free: 2.2 GiB)
2022-02-14 10:55:47 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_9_piece0
2022-02-14 10:55:47 DEBUG BlockManager:61 - Told master about block broadcast_9_piece0
2022-02-14 10:55:47 DEBUG BlockManager:61 - Put block broadcast_9_piece0 locally took 3 ms
2022-02-14 10:55:47 DEBUG BlockManager:61 - Putting block broadcast_9_piece0 without replication took 3 ms
2022-02-14 10:55:47 INFO  SparkContext:57 - Created broadcast 9 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at load at UsedCase4.java:19) (first 15 tasks are for partitions Vector(0))
2022-02-14 10:55:47 INFO  TaskSchedulerImpl:57 - Adding task set 4.0 with 1 tasks
2022-02-14 10:55:47 DEBUG TaskSetManager:61 - Epoch for TaskSet 4.0: 0
2022-02-14 10:55:47 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-02-14 10:55:47 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 4.0: NO_PREF, ANY
2022-02-14 10:55:47 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_4.0, runningTasks: 0
2022-02-14 10:55:47 INFO  TaskSetManager:57 - Starting task 0.0 in stage 4.0 (TID 4, Clairvoyant-320, executor driver, partition 0, PROCESS_LOCAL, 7803 bytes)
2022-02-14 10:55:47 INFO  Executor:57 - Running task 0.0 in stage 4.0 (TID 4)
2022-02-14 10:55:47 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (4, 0) -> 1
2022-02-14 10:55:47 DEBUG BlockManager:61 - Getting local block broadcast_9
2022-02-14 10:55:47 DEBUG BlockManager:61 - Level for block broadcast_9 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:47 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/src/main/resources/retail_db/products/part-00000, range: 0-174247, partition values: [empty row]
2022-02-14 10:55:47 DEBUG GenerateUnsafeProjection:61 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-14 10:55:47 DEBUG BlockManager:61 - Getting local block broadcast_8
2022-02-14 10:55:47 DEBUG BlockManager:61 - Level for block broadcast_8 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:47 INFO  Executor:57 - Finished task 0.0 in stage 4.0 (TID 4). 1577 bytes result sent to driver
2022-02-14 10:55:47 DEBUG ExecutorMetricsPoller:61 - removing (4, 0) from stageTCMP
2022-02-14 10:55:47 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_4.0, runningTasks: 0
2022-02-14 10:55:47 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-14 10:55:47 INFO  TaskSetManager:57 - Finished task 0.0 in stage 4.0 (TID 4) in 29 ms on Clairvoyant-320 (executor driver) (1/1)
2022-02-14 10:55:47 INFO  TaskSchedulerImpl:57 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2022-02-14 10:55:47 INFO  DAGScheduler:57 - ResultStage 4 (load at UsedCase4.java:19) finished in 0.040 s
2022-02-14 10:55:47 DEBUG DAGScheduler:61 - After removal of stage 4, remaining stages = 0
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2022-02-14 10:55:47 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 4: Stage finished
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Job 4 finished: load at UsedCase4.java:19, took 0.045562 s
2022-02-14 10:55:47 DEBUG GenerateSafeProjection:61 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-02-14 10:55:47 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-02-14 10:55:47 INFO  FileSourceStrategy:57 - Post-Scan Filters: 
2022-02-14 10:55:47 INFO  FileSourceStrategy:57 - Output Data Schema: struct<value: string>
2022-02-14 10:55:47 INFO  MemoryStore:57 - Block broadcast_10 stored as values in memory (estimated size 171.1 KiB, free 2.2 GiB)
2022-02-14 10:55:47 DEBUG BlockManager:61 - Put block broadcast_10 locally took 8 ms
2022-02-14 10:55:47 DEBUG BlockManager:61 - Putting block broadcast_10 without replication took 9 ms
2022-02-14 10:55:47 INFO  MemoryStore:57 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022-02-14 10:55:47 INFO  BlockManagerInfo:57 - Added broadcast_10_piece0 in memory on Clairvoyant-320:60340 (size: 24.0 KiB, free: 2.2 GiB)
2022-02-14 10:55:47 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_10_piece0
2022-02-14 10:55:47 DEBUG BlockManager:61 - Told master about block broadcast_10_piece0
2022-02-14 10:55:47 DEBUG BlockManager:61 - Put block broadcast_10_piece0 locally took 6 ms
2022-02-14 10:55:47 DEBUG BlockManager:61 - Putting block broadcast_10_piece0 without replication took 6 ms
2022-02-14 10:55:47 INFO  SparkContext:57 - Created broadcast 10 from load at UsedCase4.java:19
2022-02-14 10:55:47 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4368551 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$rdd$1
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$rdd$1) is now cleaned +++
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$inferFromDataset$2
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$inferFromDataset$2) is now cleaned +++
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$infer$2
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$infer$2) is now cleaned +++
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$infer$3
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$infer$3) is now cleaned +++
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$6
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$6) is now cleaned +++
2022-02-14 10:55:47 INFO  SparkContext:57 - Starting job: load at UsedCase4.java:19
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Got job 5 (load at UsedCase4.java:19) with 1 output partitions
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Final stage: ResultStage 5 (load at UsedCase4.java:19)
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Missing parents: List()
2022-02-14 10:55:47 DEBUG DAGScheduler:61 - submitStage(ResultStage 5 (name=load at UsedCase4.java:19;jobs=5))
2022-02-14 10:55:47 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Submitting ResultStage 5 (MapPartitionsRDD[29] at load at UsedCase4.java:19), which has no missing parents
2022-02-14 10:55:47 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 5)
2022-02-14 10:55:47 INFO  MemoryStore:57 - Block broadcast_11 stored as values in memory (estimated size 15.2 KiB, free 2.2 GiB)
2022-02-14 10:55:47 DEBUG BlockManager:61 - Put block broadcast_11 locally took 2 ms
2022-02-14 10:55:47 DEBUG BlockManager:61 - Putting block broadcast_11 without replication took 2 ms
2022-02-14 10:55:47 INFO  MemoryStore:57 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 2.2 GiB)
2022-02-14 10:55:47 INFO  BlockManagerInfo:57 - Added broadcast_11_piece0 in memory on Clairvoyant-320:60340 (size: 7.6 KiB, free: 2.2 GiB)
2022-02-14 10:55:47 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_11_piece0
2022-02-14 10:55:47 DEBUG BlockManager:61 - Told master about block broadcast_11_piece0
2022-02-14 10:55:47 DEBUG BlockManager:61 - Put block broadcast_11_piece0 locally took 7 ms
2022-02-14 10:55:47 DEBUG BlockManager:61 - Putting block broadcast_11_piece0 without replication took 8 ms
2022-02-14 10:55:47 INFO  SparkContext:57 - Created broadcast 11 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at load at UsedCase4.java:19) (first 15 tasks are for partitions Vector(0))
2022-02-14 10:55:47 INFO  TaskSchedulerImpl:57 - Adding task set 5.0 with 1 tasks
2022-02-14 10:55:47 DEBUG TaskSetManager:61 - Epoch for TaskSet 5.0: 0
2022-02-14 10:55:47 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-02-14 10:55:47 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 5.0: NO_PREF, ANY
2022-02-14 10:55:47 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_5.0, runningTasks: 0
2022-02-14 10:55:47 INFO  TaskSetManager:57 - Starting task 0.0 in stage 5.0 (TID 5, Clairvoyant-320, executor driver, partition 0, PROCESS_LOCAL, 7803 bytes)
2022-02-14 10:55:47 INFO  Executor:57 - Running task 0.0 in stage 5.0 (TID 5)
2022-02-14 10:55:47 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (5, 0) -> 1
2022-02-14 10:55:47 DEBUG BlockManager:61 - Getting local block broadcast_11
2022-02-14 10:55:47 DEBUG BlockManager:61 - Level for block broadcast_11 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:47 DEBUG GenerateSafeProjection:61 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-02-14 10:55:47 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/src/main/resources/retail_db/products/part-00000, range: 0-174247, partition values: [empty row]
2022-02-14 10:55:47 DEBUG GenerateUnsafeProjection:61 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-14 10:55:47 DEBUG BlockManager:61 - Getting local block broadcast_10
2022-02-14 10:55:47 DEBUG BlockManager:61 - Level for block broadcast_10 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:47 INFO  Executor:57 - Finished task 0.0 in stage 5.0 (TID 5). 1677 bytes result sent to driver
2022-02-14 10:55:47 DEBUG ExecutorMetricsPoller:61 - removing (5, 0) from stageTCMP
2022-02-14 10:55:47 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_5.0, runningTasks: 0
2022-02-14 10:55:47 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-14 10:55:47 INFO  TaskSetManager:57 - Finished task 0.0 in stage 5.0 (TID 5) in 56 ms on Clairvoyant-320 (executor driver) (1/1)
2022-02-14 10:55:47 INFO  TaskSchedulerImpl:57 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2022-02-14 10:55:47 INFO  DAGScheduler:57 - ResultStage 5 (load at UsedCase4.java:19) finished in 0.073 s
2022-02-14 10:55:47 DEBUG DAGScheduler:61 - After removal of stage 5, remaining stages = 0
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2022-02-14 10:55:47 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 5: Stage finished
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Job 5 finished: load at UsedCase4.java:19, took 0.082800 s
2022-02-14 10:55:47 DEBUG DataSource:61 - Some paths were ignored:
  
2022-02-14 10:55:47 INFO  InMemoryFileIndex:57 - It took 5 ms to list leaf files for 1 paths.
2022-02-14 10:55:47 INFO  InMemoryFileIndex:57 - It took 2 ms to list leaf files for 1 paths.
2022-02-14 10:55:47 DEBUG Analyzer$ResolveReferences:61 - Resolving 'value to value#80
2022-02-14 10:55:47 DEBUG Analyzer$ResolveReferences:61 - Resolving 'value to value#86
2022-02-14 10:55:47 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-02-14 10:55:47 INFO  FileSourceStrategy:57 - Post-Scan Filters: (length(trim(value#80, None)) > 0)
2022-02-14 10:55:47 INFO  FileSourceStrategy:57 - Output Data Schema: struct<value: string>
2022-02-14 10:55:47 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while ( inputadapter_input_0.hasNext()) {
/* 026 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 027 */
/* 028 */       do {
/* 029 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 030 */         UTF8String inputadapter_value_0 = inputadapter_isNull_0 ?
/* 031 */         null : (inputadapter_row_0.getUTF8String(0));
/* 032 */
/* 033 */         boolean filter_isNull_0 = true;
/* 034 */         boolean filter_value_0 = false;
/* 035 */         boolean filter_isNull_2 = false;
/* 036 */         UTF8String filter_value_2 = null;
/* 037 */         if (inputadapter_isNull_0) {
/* 038 */           filter_isNull_2 = true;
/* 039 */         } else {
/* 040 */           filter_value_2 = inputadapter_value_0.trim();
/* 041 */         }
/* 042 */         boolean filter_isNull_1 = filter_isNull_2;
/* 043 */         int filter_value_1 = -1;
/* 044 */
/* 045 */         if (!filter_isNull_2) {
/* 046 */           filter_value_1 = (filter_value_2).numChars();
/* 047 */         }
/* 048 */         if (!filter_isNull_1) {
/* 049 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 050 */           filter_value_0 = filter_value_1 > 0;
/* 051 */
/* 052 */         }
/* 053 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 054 */
/* 055 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 056 */
/* 057 */         filter_mutableStateArray_0[0].reset();
/* 058 */
/* 059 */         filter_mutableStateArray_0[0].zeroOutNullBytes();
/* 060 */
/* 061 */         if (inputadapter_isNull_0) {
/* 062 */           filter_mutableStateArray_0[0].setNullAt(0);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[0].write(0, inputadapter_value_0);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[0].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }

2022-02-14 10:55:47 INFO  MemoryStore:57 - Block broadcast_12 stored as values in memory (estimated size 171.1 KiB, free 2.2 GiB)
2022-02-14 10:55:47 DEBUG BlockManager:61 - Put block broadcast_12 locally took 5 ms
2022-02-14 10:55:47 DEBUG BlockManager:61 - Putting block broadcast_12 without replication took 5 ms
2022-02-14 10:55:47 INFO  MemoryStore:57 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022-02-14 10:55:47 INFO  BlockManagerInfo:57 - Added broadcast_12_piece0 in memory on Clairvoyant-320:60340 (size: 24.0 KiB, free: 2.2 GiB)
2022-02-14 10:55:47 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_12_piece0
2022-02-14 10:55:47 DEBUG BlockManager:61 - Told master about block broadcast_12_piece0
2022-02-14 10:55:47 DEBUG BlockManager:61 - Put block broadcast_12_piece0 locally took 4 ms
2022-02-14 10:55:47 DEBUG BlockManager:61 - Putting block broadcast_12_piece0 without replication took 5 ms
2022-02-14 10:55:47 INFO  SparkContext:57 - Created broadcast 12 from load at UsedCase4.java:22
2022-02-14 10:55:47 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4195382 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$executeTake$2
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$executeTake$2) is now cleaned +++
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$5
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2022-02-14 10:55:47 INFO  SparkContext:57 - Starting job: load at UsedCase4.java:22
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Got job 6 (load at UsedCase4.java:22) with 1 output partitions
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Final stage: ResultStage 6 (load at UsedCase4.java:22)
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Missing parents: List()
2022-02-14 10:55:47 DEBUG DAGScheduler:61 - submitStage(ResultStage 6 (name=load at UsedCase4.java:22;jobs=6))
2022-02-14 10:55:47 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Submitting ResultStage 6 (MapPartitionsRDD[33] at load at UsedCase4.java:22), which has no missing parents
2022-02-14 10:55:47 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 6)
2022-02-14 10:55:47 INFO  MemoryStore:57 - Block broadcast_13 stored as values in memory (estimated size 10.7 KiB, free 2.2 GiB)
2022-02-14 10:55:47 DEBUG BlockManager:61 - Put block broadcast_13 locally took 3 ms
2022-02-14 10:55:47 DEBUG BlockManager:61 - Putting block broadcast_13 without replication took 3 ms
2022-02-14 10:55:47 INFO  MemoryStore:57 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 2.2 GiB)
2022-02-14 10:55:47 INFO  BlockManagerInfo:57 - Added broadcast_13_piece0 in memory on Clairvoyant-320:60340 (size: 5.3 KiB, free: 2.2 GiB)
2022-02-14 10:55:47 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_13_piece0
2022-02-14 10:55:47 DEBUG BlockManager:61 - Told master about block broadcast_13_piece0
2022-02-14 10:55:47 DEBUG BlockManager:61 - Put block broadcast_13_piece0 locally took 6 ms
2022-02-14 10:55:47 DEBUG BlockManager:61 - Putting block broadcast_13_piece0 without replication took 6 ms
2022-02-14 10:55:47 INFO  SparkContext:57 - Created broadcast 13 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[33] at load at UsedCase4.java:22) (first 15 tasks are for partitions Vector(0))
2022-02-14 10:55:47 INFO  TaskSchedulerImpl:57 - Adding task set 6.0 with 1 tasks
2022-02-14 10:55:47 DEBUG TaskSetManager:61 - Epoch for TaskSet 6.0: 0
2022-02-14 10:55:47 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-02-14 10:55:47 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 6.0: NO_PREF, ANY
2022-02-14 10:55:47 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_6.0, runningTasks: 0
2022-02-14 10:55:47 INFO  TaskSetManager:57 - Starting task 0.0 in stage 6.0 (TID 6, Clairvoyant-320, executor driver, partition 0, PROCESS_LOCAL, 7805 bytes)
2022-02-14 10:55:47 INFO  Executor:57 - Running task 0.0 in stage 6.0 (TID 6)
2022-02-14 10:55:47 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (6, 0) -> 1
2022-02-14 10:55:47 DEBUG BlockManager:61 - Getting local block broadcast_13
2022-02-14 10:55:47 DEBUG BlockManager:61 - Level for block broadcast_13 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:47 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/src/main/resources/retail_db/categories/part-00000, range: 0-1078, partition values: [empty row]
2022-02-14 10:55:47 DEBUG GenerateUnsafeProjection:61 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-14 10:55:47 DEBUG BlockManager:61 - Getting local block broadcast_12
2022-02-14 10:55:47 DEBUG BlockManager:61 - Level for block broadcast_12 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:47 INFO  Executor:57 - Finished task 0.0 in stage 6.0 (TID 6). 1505 bytes result sent to driver
2022-02-14 10:55:47 DEBUG ExecutorMetricsPoller:61 - removing (6, 0) from stageTCMP
2022-02-14 10:55:47 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_6.0, runningTasks: 0
2022-02-14 10:55:47 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-14 10:55:47 INFO  TaskSetManager:57 - Finished task 0.0 in stage 6.0 (TID 6) in 21 ms on Clairvoyant-320 (executor driver) (1/1)
2022-02-14 10:55:47 INFO  TaskSchedulerImpl:57 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2022-02-14 10:55:47 INFO  DAGScheduler:57 - ResultStage 6 (load at UsedCase4.java:22) finished in 0.040 s
2022-02-14 10:55:47 DEBUG DAGScheduler:61 - After removal of stage 6, remaining stages = 0
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2022-02-14 10:55:47 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 6: Stage finished
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Job 6 finished: load at UsedCase4.java:22, took 0.042482 s
2022-02-14 10:55:47 DEBUG GenerateSafeProjection:61 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-02-14 10:55:47 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-02-14 10:55:47 INFO  FileSourceStrategy:57 - Post-Scan Filters: 
2022-02-14 10:55:47 INFO  FileSourceStrategy:57 - Output Data Schema: struct<value: string>
2022-02-14 10:55:47 INFO  MemoryStore:57 - Block broadcast_14 stored as values in memory (estimated size 171.1 KiB, free 2.2 GiB)
2022-02-14 10:55:47 DEBUG BlockManager:61 - Put block broadcast_14 locally took 5 ms
2022-02-14 10:55:47 DEBUG BlockManager:61 - Putting block broadcast_14 without replication took 6 ms
2022-02-14 10:55:47 INFO  MemoryStore:57 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022-02-14 10:55:47 INFO  BlockManagerInfo:57 - Added broadcast_14_piece0 in memory on Clairvoyant-320:60340 (size: 24.0 KiB, free: 2.2 GiB)
2022-02-14 10:55:47 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_14_piece0
2022-02-14 10:55:47 DEBUG BlockManager:61 - Told master about block broadcast_14_piece0
2022-02-14 10:55:47 DEBUG BlockManager:61 - Put block broadcast_14_piece0 locally took 3 ms
2022-02-14 10:55:47 DEBUG BlockManager:61 - Putting block broadcast_14_piece0 without replication took 3 ms
2022-02-14 10:55:47 INFO  SparkContext:57 - Created broadcast 14 from load at UsedCase4.java:22
2022-02-14 10:55:47 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4195382 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$rdd$1
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$rdd$1) is now cleaned +++
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$inferFromDataset$2
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$inferFromDataset$2) is now cleaned +++
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$infer$2
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$infer$2) is now cleaned +++
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$infer$3
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$infer$3) is now cleaned +++
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$6
2022-02-14 10:55:47 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$6) is now cleaned +++
2022-02-14 10:55:47 INFO  SparkContext:57 - Starting job: load at UsedCase4.java:22
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Got job 7 (load at UsedCase4.java:22) with 1 output partitions
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Final stage: ResultStage 7 (load at UsedCase4.java:22)
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Missing parents: List()
2022-02-14 10:55:47 DEBUG DAGScheduler:61 - submitStage(ResultStage 7 (name=load at UsedCase4.java:22;jobs=7))
2022-02-14 10:55:47 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Submitting ResultStage 7 (MapPartitionsRDD[39] at load at UsedCase4.java:22), which has no missing parents
2022-02-14 10:55:47 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 7)
2022-02-14 10:55:47 INFO  MemoryStore:57 - Block broadcast_15 stored as values in memory (estimated size 15.1 KiB, free 2.2 GiB)
2022-02-14 10:55:47 DEBUG BlockManager:61 - Put block broadcast_15 locally took 2 ms
2022-02-14 10:55:47 DEBUG BlockManager:61 - Putting block broadcast_15 without replication took 4 ms
2022-02-14 10:55:47 INFO  MemoryStore:57 - Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 2.2 GiB)
2022-02-14 10:55:47 INFO  BlockManagerInfo:57 - Added broadcast_15_piece0 in memory on Clairvoyant-320:60340 (size: 7.6 KiB, free: 2.2 GiB)
2022-02-14 10:55:47 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_15_piece0
2022-02-14 10:55:47 DEBUG BlockManager:61 - Told master about block broadcast_15_piece0
2022-02-14 10:55:47 DEBUG BlockManager:61 - Put block broadcast_15_piece0 locally took 2 ms
2022-02-14 10:55:47 DEBUG BlockManager:61 - Putting block broadcast_15_piece0 without replication took 2 ms
2022-02-14 10:55:47 INFO  SparkContext:57 - Created broadcast 15 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[39] at load at UsedCase4.java:22) (first 15 tasks are for partitions Vector(0))
2022-02-14 10:55:47 INFO  TaskSchedulerImpl:57 - Adding task set 7.0 with 1 tasks
2022-02-14 10:55:47 DEBUG TaskSetManager:61 - Epoch for TaskSet 7.0: 0
2022-02-14 10:55:47 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-02-14 10:55:47 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 7.0: NO_PREF, ANY
2022-02-14 10:55:47 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_7.0, runningTasks: 0
2022-02-14 10:55:47 INFO  TaskSetManager:57 - Starting task 0.0 in stage 7.0 (TID 7, Clairvoyant-320, executor driver, partition 0, PROCESS_LOCAL, 7805 bytes)
2022-02-14 10:55:47 INFO  Executor:57 - Running task 0.0 in stage 7.0 (TID 7)
2022-02-14 10:55:47 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (7, 0) -> 1
2022-02-14 10:55:47 DEBUG BlockManager:61 - Getting local block broadcast_15
2022-02-14 10:55:47 DEBUG BlockManager:61 - Level for block broadcast_15 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:47 DEBUG GenerateSafeProjection:61 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-02-14 10:55:47 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/src/main/resources/retail_db/categories/part-00000, range: 0-1078, partition values: [empty row]
2022-02-14 10:55:47 DEBUG GenerateUnsafeProjection:61 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-14 10:55:47 DEBUG BlockManager:61 - Getting local block broadcast_14
2022-02-14 10:55:47 DEBUG BlockManager:61 - Level for block broadcast_14 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:47 INFO  Executor:57 - Finished task 0.0 in stage 7.0 (TID 7). 1518 bytes result sent to driver
2022-02-14 10:55:47 DEBUG ExecutorMetricsPoller:61 - removing (7, 0) from stageTCMP
2022-02-14 10:55:47 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_7.0, runningTasks: 0
2022-02-14 10:55:47 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-14 10:55:47 INFO  TaskSetManager:57 - Finished task 0.0 in stage 7.0 (TID 7) in 31 ms on Clairvoyant-320 (executor driver) (1/1)
2022-02-14 10:55:47 INFO  TaskSchedulerImpl:57 - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2022-02-14 10:55:47 INFO  DAGScheduler:57 - ResultStage 7 (load at UsedCase4.java:22) finished in 0.048 s
2022-02-14 10:55:47 DEBUG DAGScheduler:61 - After removal of stage 7, remaining stages = 0
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2022-02-14 10:55:47 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 7: Stage finished
2022-02-14 10:55:47 INFO  DAGScheduler:57 - Job 7 finished: load at UsedCase4.java:22, took 0.053680 s
2022-02-14 10:55:47 DEBUG SparkSqlParser:61 - Parsing command: orders
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(206)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 206
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 206
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(201)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 201
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 201
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(255)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 255
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 255
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(224)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 224
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 224
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(205)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 205
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 205
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(134)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 134
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 134
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(212)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 212
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 212
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(7)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning broadcast 7
2022-02-14 10:55:48 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 7
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 7
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing broadcast 7
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing block broadcast_7
2022-02-14 10:55:48 DEBUG MemoryStore:61 - Block broadcast_7 of size 15584 dropped from memory (free 2346885569)
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing block broadcast_7_piece0
2022-02-14 10:55:48 DEBUG MemoryStore:61 - Block broadcast_7_piece0 of size 7791 dropped from memory (free 2346893360)
2022-02-14 10:55:48 INFO  BlockManagerInfo:57 - Removed broadcast_7_piece0 on Clairvoyant-320:60340 in memory (size: 7.6 KiB, free: 2.2 GiB)
2022-02-14 10:55:48 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_7_piece0
2022-02-14 10:55:48 DEBUG BlockManager:61 - Told master about block broadcast_7_piece0
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 7, response is 0
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60325
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned broadcast 7
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(247)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 247
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 247
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(202)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 202
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 202
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(218)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 218
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 218
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(118)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 118
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 118
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(129)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 129
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 129
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(188)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 188
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 188
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(124)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 124
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 124
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(222)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 222
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 222
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(259)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 259
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 259
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(275)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 275
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 275
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(152)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 152
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 152
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(166)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 166
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 166
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(225)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 225
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 225
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(119)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 119
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 119
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(135)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 135
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 135
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(258)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 258
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 258
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(198)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 198
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 198
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(114)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 114
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 114
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(196)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 196
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 196
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(262)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 262
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 262
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(126)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 126
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 126
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(139)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 139
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 139
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(140)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 140
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 140
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(265)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 265
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 265
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(15)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning broadcast 15
2022-02-14 10:55:48 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 15
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 15
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing broadcast 15
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing block broadcast_15
2022-02-14 10:55:48 DEBUG MemoryStore:61 - Block broadcast_15 of size 15496 dropped from memory (free 2346908856)
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing block broadcast_15_piece0
2022-02-14 10:55:48 DEBUG MemoryStore:61 - Block broadcast_15_piece0 of size 7740 dropped from memory (free 2346916596)
2022-02-14 10:55:48 INFO  BlockManagerInfo:57 - Removed broadcast_15_piece0 on Clairvoyant-320:60340 in memory (size: 7.6 KiB, free: 2.2 GiB)
2022-02-14 10:55:48 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_15_piece0
2022-02-14 10:55:48 DEBUG BlockManager:61 - Told master about block broadcast_15_piece0
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 15, response is 0
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60325
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned broadcast 15
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(11)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning broadcast 11
2022-02-14 10:55:48 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 11
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 11
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing broadcast 11
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing block broadcast_11
2022-02-14 10:55:48 DEBUG MemoryStore:61 - Block broadcast_11 of size 15552 dropped from memory (free 2346932148)
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing block broadcast_11_piece0
2022-02-14 10:55:48 DEBUG MemoryStore:61 - Block broadcast_11_piece0 of size 7772 dropped from memory (free 2346939920)
2022-02-14 10:55:48 INFO  BlockManagerInfo:57 - Removed broadcast_11_piece0 on Clairvoyant-320:60340 in memory (size: 7.6 KiB, free: 2.2 GiB)
2022-02-14 10:55:48 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_11_piece0
2022-02-14 10:55:48 DEBUG BlockManager:61 - Told master about block broadcast_11_piece0
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 11, response is 0
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60325
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned broadcast 11
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(146)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 146
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 146
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(115)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 115
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 115
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(143)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 143
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 143
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(137)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 137
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 137
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(274)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 274
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 274
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(268)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 268
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 268
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(235)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 235
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 235
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(272)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 272
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 272
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(132)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 132
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 132
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(133)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 133
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 133
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(182)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 182
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 182
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(14)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning broadcast 14
2022-02-14 10:55:48 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 14
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 14
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing broadcast 14
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing block broadcast_14
2022-02-14 10:55:48 DEBUG MemoryStore:61 - Block broadcast_14 of size 175184 dropped from memory (free 2347115104)
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing block broadcast_14_piece0
2022-02-14 10:55:48 DEBUG MemoryStore:61 - Block broadcast_14_piece0 of size 24528 dropped from memory (free 2347139632)
2022-02-14 10:55:48 INFO  BlockManagerInfo:57 - Removed broadcast_14_piece0 on Clairvoyant-320:60340 in memory (size: 24.0 KiB, free: 2.2 GiB)
2022-02-14 10:55:48 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_14_piece0
2022-02-14 10:55:48 DEBUG BlockManager:61 - Told master about block broadcast_14_piece0
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 14, response is 0
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60325
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned broadcast 14
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(257)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 257
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 257
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(8)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning broadcast 8
2022-02-14 10:55:48 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 8
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 8
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing broadcast 8
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing block broadcast_8
2022-02-14 10:55:48 DEBUG MemoryStore:61 - Block broadcast_8 of size 175184 dropped from memory (free 2347314816)
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing block broadcast_8_piece0
2022-02-14 10:55:48 DEBUG MemoryStore:61 - Block broadcast_8_piece0 of size 24528 dropped from memory (free 2347339344)
2022-02-14 10:55:48 INFO  BlockManagerInfo:57 - Removed broadcast_8_piece0 on Clairvoyant-320:60340 in memory (size: 24.0 KiB, free: 2.2 GiB)
2022-02-14 10:55:48 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_8_piece0
2022-02-14 10:55:48 DEBUG BlockManager:61 - Told master about block broadcast_8_piece0
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 8, response is 0
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60325
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned broadcast 8
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(261)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 261
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 261
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(170)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 170
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 170
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(160)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 160
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 160
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(123)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 123
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 123
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(197)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 197
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 197
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(176)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 176
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 176
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(173)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 173
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 173
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(244)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 244
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 244
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(194)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 194
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 194
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(13)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning broadcast 13
2022-02-14 10:55:48 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 13
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 13
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing broadcast 13
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing block broadcast_13_piece0
2022-02-14 10:55:48 DEBUG MemoryStore:61 - Block broadcast_13_piece0 of size 5457 dropped from memory (free 2347344801)
2022-02-14 10:55:48 INFO  BlockManagerInfo:57 - Removed broadcast_13_piece0 on Clairvoyant-320:60340 in memory (size: 5.3 KiB, free: 2.2 GiB)
2022-02-14 10:55:48 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_13_piece0
2022-02-14 10:55:48 DEBUG BlockManager:61 - Told master about block broadcast_13_piece0
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing block broadcast_13
2022-02-14 10:55:48 DEBUG MemoryStore:61 - Block broadcast_13 of size 10992 dropped from memory (free 2347355793)
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 13, response is 0
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60325
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned broadcast 13
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(242)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 242
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 242
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(144)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 144
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 144
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(125)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 125
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 125
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(131)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 131
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 131
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(159)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 159
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 159
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(220)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 220
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 220
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(162)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 162
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 162
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(221)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 221
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 221
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(260)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 260
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 260
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(122)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 122
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 122
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(130)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 130
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 130
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(181)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 181
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 181
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(251)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 251
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 251
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(219)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 219
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 219
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(168)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 168
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 168
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(186)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 186
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 186
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(252)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 252
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 252
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(215)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 215
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 215
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(169)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 169
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 169
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(167)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 167
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 167
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(211)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 211
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 211
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(245)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 245
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 245
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(116)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 116
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 116
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(141)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 141
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 141
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(161)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 161
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 161
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(172)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 172
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 172
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(200)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 200
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 200
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(209)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 209
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 209
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(10)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning broadcast 10
2022-02-14 10:55:48 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 10
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 10
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing broadcast 10
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing block broadcast_10
2022-02-14 10:55:48 DEBUG MemoryStore:61 - Block broadcast_10 of size 175184 dropped from memory (free 2347530977)
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing block broadcast_10_piece0
2022-02-14 10:55:48 DEBUG MemoryStore:61 - Block broadcast_10_piece0 of size 24528 dropped from memory (free 2347555505)
2022-02-14 10:55:48 INFO  BlockManagerInfo:57 - Removed broadcast_10_piece0 on Clairvoyant-320:60340 in memory (size: 24.0 KiB, free: 2.2 GiB)
2022-02-14 10:55:48 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_10_piece0
2022-02-14 10:55:48 DEBUG BlockManager:61 - Told master about block broadcast_10_piece0
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 10, response is 0
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60325
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned broadcast 10
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(227)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 227
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 227
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(233)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 233
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 233
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(151)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 151
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 151
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(204)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 204
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 204
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(250)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 250
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 250
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(210)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 210
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 210
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(223)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 223
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 223
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(253)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 253
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 253
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(248)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 248
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 248
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(193)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 193
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 193
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(12)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning broadcast 12
2022-02-14 10:55:48 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 12
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 12
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing broadcast 12
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing block broadcast_12_piece0
2022-02-14 10:55:48 DEBUG MemoryStore:61 - Block broadcast_12_piece0 of size 24528 dropped from memory (free 2347580033)
2022-02-14 10:55:48 INFO  BlockManagerInfo:57 - Removed broadcast_12_piece0 on Clairvoyant-320:60340 in memory (size: 24.0 KiB, free: 2.2 GiB)
2022-02-14 10:55:48 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_12_piece0
2022-02-14 10:55:48 DEBUG BlockManager:61 - Told master about block broadcast_12_piece0
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing block broadcast_12
2022-02-14 10:55:48 DEBUG MemoryStore:61 - Block broadcast_12 of size 175184 dropped from memory (free 2347755217)
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 12, response is 0
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60325
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned broadcast 12
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(199)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 199
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 199
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(6)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning broadcast 6
2022-02-14 10:55:48 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 6
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 6
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing broadcast 6
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing block broadcast_6_piece0
2022-02-14 10:55:48 DEBUG MemoryStore:61 - Block broadcast_6_piece0 of size 24528 dropped from memory (free 2347779745)
2022-02-14 10:55:48 INFO  BlockManagerInfo:57 - Removed broadcast_6_piece0 on Clairvoyant-320:60340 in memory (size: 24.0 KiB, free: 2.2 GiB)
2022-02-14 10:55:48 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_6_piece0
2022-02-14 10:55:48 DEBUG BlockManager:61 - Told master about block broadcast_6_piece0
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing block broadcast_6
2022-02-14 10:55:48 DEBUG MemoryStore:61 - Block broadcast_6 of size 175184 dropped from memory (free 2347954929)
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 6, response is 0
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60325
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned broadcast 6
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(231)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 231
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 231
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(263)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 263
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 263
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(142)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 142
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 142
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(184)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 184
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 184
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(117)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 117
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 117
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(273)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 273
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 273
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(214)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 214
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 214
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(226)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 226
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 226
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(234)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 234
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 234
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(149)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 149
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 149
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(136)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 136
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 136
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(164)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 164
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 164
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(190)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 190
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 190
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(175)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 175
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 175
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(185)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 185
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 185
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(278)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 278
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 278
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(165)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 165
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 165
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(232)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 232
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 232
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(239)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 239
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 239
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(256)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 256
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 256
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(112)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 112
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 112
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(229)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 229
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 229
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(155)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 155
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 155
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(217)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 217
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 217
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(238)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 238
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 238
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(157)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 157
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 157
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(113)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 113
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 113
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(178)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 178
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 178
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(147)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 147
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 147
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(145)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 145
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 145
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(279)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 279
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 279
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(183)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 183
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 183
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(174)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 174
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 174
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(277)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 277
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 277
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(240)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 240
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 240
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(177)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 177
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 177
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(128)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 128
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 128
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(156)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 156
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 156
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(264)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 264
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 264
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(276)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 276
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 276
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(266)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 266
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 266
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(270)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 270
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 270
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(158)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 158
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 158
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(192)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 192
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 192
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(216)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 216
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 216
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(271)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 271
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 271
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(241)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 241
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 241
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(246)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 246
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 246
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(127)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 127
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 127
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(179)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 179
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 179
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(187)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 187
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 187
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(208)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 208
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 208
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(267)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 267
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 267
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(153)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 153
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 153
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(207)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 207
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 207
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(111)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 111
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 111
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(120)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 120
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 120
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(163)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 163
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 163
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(203)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 203
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 203
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(138)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 138
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 138
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(228)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 228
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 228
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(150)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 150
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 150
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(148)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 148
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 148
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(230)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 230
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 230
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(243)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 243
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 243
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(237)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 237
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 237
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(171)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 171
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 171
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(9)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning broadcast 9
2022-02-14 10:55:48 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 9
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 9
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing broadcast 9
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing block broadcast_9_piece0
2022-02-14 10:55:48 DEBUG MemoryStore:61 - Block broadcast_9_piece0 of size 5458 dropped from memory (free 2347960387)
2022-02-14 10:55:48 INFO  BlockManagerInfo:57 - Removed broadcast_9_piece0 on Clairvoyant-320:60340 in memory (size: 5.3 KiB, free: 2.2 GiB)
2022-02-14 10:55:48 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_9_piece0
2022-02-14 10:55:48 DEBUG BlockManager:61 - Told master about block broadcast_9_piece0
2022-02-14 10:55:48 DEBUG BlockManager:61 - Removing block broadcast_9
2022-02-14 10:55:48 DEBUG MemoryStore:61 - Block broadcast_9 of size 10992 dropped from memory (free 2347971379)
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 9, response is 0
2022-02-14 10:55:48 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60325
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned broadcast 9
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(154)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 154
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 154
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(195)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 195
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 195
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(180)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 180
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 180
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(191)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 191
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 191
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(249)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 249
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 249
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(269)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 269
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 269
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(213)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 213
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 213
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(236)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 236
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 236
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(254)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 254
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 254
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(189)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 189
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 189
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(121)
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaning accumulator 121
2022-02-14 10:55:48 DEBUG ContextCleaner:61 - Cleaned accumulator 121
2022-02-14 10:55:48 DEBUG SparkSqlParser:61 - Parsing command: order_items
2022-02-14 10:55:48 DEBUG SparkSqlParser:61 - Parsing command: products
2022-02-14 10:55:48 DEBUG SparkSqlParser:61 - Parsing command: categories
2022-02-14 10:55:48 DEBUG SparkSqlParser:61 - Parsing command: SELECT c.*, round(sum(oi.order_item_subtotal), 2) as category_revenue
FROM orders o join order_items oi
     on o.order_id = oi.order_item_order_id
     join products p 
     on p.product_id = oi.order_item_product_id
     join categories c
     on c.category_id = p.product_category_id
WHERE date_format(o.order_date, 'yyyy-MM') LIKE '2014-01%' and o.order_status IN('COMPLETE','CLOSED')
group by c.category_id,c.category_department_id,c.category_name
order by c.category_id
2022-02-14 10:55:48 DEBUG Analyzer$ResolveReferences:61 - Resolving 'o.order_id to order_id#16
2022-02-14 10:55:48 DEBUG Analyzer$ResolveReferences:61 - Resolving 'oi.order_item_order_id to order_item_order_id#41
2022-02-14 10:55:48 DEBUG Analyzer$ResolveReferences:61 - Resolving 'p.product_id to product_id#68
2022-02-14 10:55:48 DEBUG Analyzer$ResolveReferences:61 - Resolving 'oi.order_item_product_id to order_item_product_id#42
2022-02-14 10:55:48 DEBUG Analyzer$ResolveReferences:61 - Resolving 'c.category_id to category_id#96
2022-02-14 10:55:48 DEBUG Analyzer$ResolveReferences:61 - Resolving 'p.product_category_id to product_category_id#69
2022-02-14 10:55:48 DEBUG Analyzer$ResolveReferences:61 - Resolving 'o.order_date to order_date#17
2022-02-14 10:55:48 DEBUG Analyzer$ResolveReferences:61 - Resolving 'o.order_status to order_status#19
2022-02-14 10:55:48 DEBUG Analyzer$ResolveReferences:61 - Resolving 'c.category_id to category_id#96
2022-02-14 10:55:48 DEBUG Analyzer$ResolveReferences:61 - Resolving 'c.category_department_id to category_department_id#97
2022-02-14 10:55:48 DEBUG Analyzer$ResolveReferences:61 - Resolving 'c.category_name to category_name#98
2022-02-14 10:55:48 DEBUG Analyzer$ResolveReferences:61 - Resolving 'oi.order_item_subtotal to order_item_subtotal#44
2022-02-14 10:55:48 DEBUG Analyzer$ResolveReferences:61 - Resolving 'c.category_id to category_id#96
2022-02-14 10:55:48 DEBUG ExtractEquiJoinKeys:61 - Considering join on: Some((category_id#96 = product_category_id#69))
2022-02-14 10:55:48 DEBUG ExtractEquiJoinKeys:61 - leftKeys:List(product_category_id#69) | rightKeys:List(category_id#96)
2022-02-14 10:55:48 DEBUG ExtractEquiJoinKeys:61 - Considering join on: Some((product_id#68 = order_item_product_id#42))
2022-02-14 10:55:48 DEBUG ExtractEquiJoinKeys:61 - leftKeys:List(order_item_product_id#42) | rightKeys:List(product_id#68)
2022-02-14 10:55:48 DEBUG ExtractEquiJoinKeys:61 - Considering join on: Some((order_id#16 = order_item_order_id#41))
2022-02-14 10:55:48 DEBUG ExtractEquiJoinKeys:61 - leftKeys:List(order_id#16) | rightKeys:List(order_item_order_id#41)
2022-02-14 10:55:48 DEBUG ExtractEquiJoinKeys:61 - Considering join on: Some((order_id#16 = order_item_order_id#41))
2022-02-14 10:55:48 DEBUG ExtractEquiJoinKeys:61 - leftKeys:List(order_id#16) | rightKeys:List(order_item_order_id#41)
2022-02-14 10:55:48 DEBUG ExtractEquiJoinKeys:61 - Considering join on: Some((product_id#68 = order_item_product_id#42))
2022-02-14 10:55:48 DEBUG ExtractEquiJoinKeys:61 - leftKeys:List(order_item_product_id#42) | rightKeys:List(product_id#68)
2022-02-14 10:55:48 DEBUG ExtractEquiJoinKeys:61 - Considering join on: Some((category_id#96 = product_category_id#69))
2022-02-14 10:55:48 DEBUG ExtractEquiJoinKeys:61 - leftKeys:List(product_category_id#69) | rightKeys:List(category_id#96)
2022-02-14 10:55:48 DEBUG ExtractEquiJoinKeys:61 - Considering join on: Some((category_id#96 = product_category_id#69))
2022-02-14 10:55:48 DEBUG ExtractEquiJoinKeys:61 - leftKeys:List(product_category_id#69) | rightKeys:List(category_id#96)
2022-02-14 10:55:48 DEBUG ExtractEquiJoinKeys:61 - Considering join on: Some((category_id#96 = product_category_id#69))
2022-02-14 10:55:48 DEBUG ExtractEquiJoinKeys:61 - leftKeys:List(product_category_id#69) | rightKeys:List(category_id#96)
2022-02-14 10:55:48 DEBUG ExtractEquiJoinKeys:61 - Considering join on: Some((product_id#68 = order_item_product_id#42))
2022-02-14 10:55:48 DEBUG ExtractEquiJoinKeys:61 - leftKeys:List(order_item_product_id#42) | rightKeys:List(product_id#68)
2022-02-14 10:55:48 DEBUG ExtractEquiJoinKeys:61 - Considering join on: Some((product_id#68 = order_item_product_id#42))
2022-02-14 10:55:48 DEBUG ExtractEquiJoinKeys:61 - leftKeys:List(order_item_product_id#42) | rightKeys:List(product_id#68)
2022-02-14 10:55:48 DEBUG ExtractEquiJoinKeys:61 - Considering join on: Some((order_id#16 = order_item_order_id#41))
2022-02-14 10:55:48 DEBUG ExtractEquiJoinKeys:61 - leftKeys:List(order_id#16) | rightKeys:List(order_item_order_id#41)
2022-02-14 10:55:48 DEBUG ExtractEquiJoinKeys:61 - Considering join on: Some((order_id#16 = order_item_order_id#41))
2022-02-14 10:55:48 DEBUG ExtractEquiJoinKeys:61 - leftKeys:List(order_id#16) | rightKeys:List(order_item_order_id#41)
2022-02-14 10:55:48 INFO  FileSourceStrategy:57 - Pushed Filters: In(order_status, [COMPLETE,CLOSED]),IsNotNull(order_id)
2022-02-14 10:55:48 INFO  FileSourceStrategy:57 - Post-Scan Filters: StartsWith(date_format(cast(order_date#17 as timestamp), yyyy-MM, Some(Asia/Calcutta)), 2014-01),order_status#19 IN (COMPLETE,CLOSED),isnotnull(order_id#16)
2022-02-14 10:55:48 INFO  FileSourceStrategy:57 - Output Data Schema: struct<order_id: int, order_date: string, order_status: string ... 1 more fields>
2022-02-14 10:55:48 INFO  FileSourceStrategy:57 - Pushed Filters: IsNotNull(order_item_order_id),IsNotNull(order_item_product_id)
2022-02-14 10:55:48 INFO  FileSourceStrategy:57 - Post-Scan Filters: isnotnull(order_item_order_id#41),isnotnull(order_item_product_id#42)
2022-02-14 10:55:48 INFO  FileSourceStrategy:57 - Output Data Schema: struct<order_item_order_id: int, order_item_product_id: int>
2022-02-14 10:55:48 INFO  FileSourceStrategy:57 - Pushed Filters: IsNotNull(product_id),IsNotNull(product_category_id)
2022-02-14 10:55:48 INFO  FileSourceStrategy:57 - Post-Scan Filters: isnotnull(product_id#68),isnotnull(product_category_id#69)
2022-02-14 10:55:48 INFO  FileSourceStrategy:57 - Output Data Schema: struct<product_id: int, product_category_id: int>
2022-02-14 10:55:48 INFO  FileSourceStrategy:57 - Pushed Filters: IsNotNull(category_id)
2022-02-14 10:55:48 INFO  FileSourceStrategy:57 - Post-Scan Filters: isnotnull(category_id#96)
2022-02-14 10:55:48 INFO  FileSourceStrategy:57 - Output Data Schema: struct<category_id: int, category_department_id: int, category_name: string ... 1 more fields>
2022-02-14 10:55:48 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage3(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=3
/* 006 */ final class GeneratedIteratorForCodegenStage3 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage3(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 021 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   protected void processNext() throws java.io.IOException {
/* 026 */     while ( inputadapter_input_0.hasNext()) {
/* 027 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 028 */
/* 029 */       do {
/* 030 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 031 */         int inputadapter_value_0 = inputadapter_isNull_0 ?
/* 032 */         -1 : (inputadapter_row_0.getInt(0));
/* 033 */
/* 034 */         boolean filter_value_2 = !inputadapter_isNull_0;
/* 035 */         if (!filter_value_2) continue;
/* 036 */
/* 037 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 038 */
/* 039 */         boolean inputadapter_isNull_1 = inputadapter_row_0.isNullAt(1);
/* 040 */         int inputadapter_value_1 = inputadapter_isNull_1 ?
/* 041 */         -1 : (inputadapter_row_0.getInt(1));
/* 042 */         boolean inputadapter_isNull_2 = inputadapter_row_0.isNullAt(2);
/* 043 */         UTF8String inputadapter_value_2 = inputadapter_isNull_2 ?
/* 044 */         null : (inputadapter_row_0.getUTF8String(2));
/* 045 */         filter_mutableStateArray_0[1].reset();
/* 046 */
/* 047 */         filter_mutableStateArray_0[1].zeroOutNullBytes();
/* 048 */
/* 049 */         if (false) {
/* 050 */           filter_mutableStateArray_0[1].setNullAt(0);
/* 051 */         } else {
/* 052 */           filter_mutableStateArray_0[1].write(0, inputadapter_value_0);
/* 053 */         }
/* 054 */
/* 055 */         if (inputadapter_isNull_1) {
/* 056 */           filter_mutableStateArray_0[1].setNullAt(1);
/* 057 */         } else {
/* 058 */           filter_mutableStateArray_0[1].write(1, inputadapter_value_1);
/* 059 */         }
/* 060 */
/* 061 */         if (inputadapter_isNull_2) {
/* 062 */           filter_mutableStateArray_0[1].setNullAt(2);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[1].write(2, inputadapter_value_2);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[1].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }

2022-02-14 10:55:48 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage2(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=2
/* 006 */ final class GeneratedIteratorForCodegenStage2 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage2(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 0);
/* 021 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 0);
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   protected void processNext() throws java.io.IOException {
/* 026 */     while ( inputadapter_input_0.hasNext()) {
/* 027 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 028 */
/* 029 */       do {
/* 030 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 031 */         int inputadapter_value_0 = inputadapter_isNull_0 ?
/* 032 */         -1 : (inputadapter_row_0.getInt(0));
/* 033 */
/* 034 */         boolean filter_value_2 = !inputadapter_isNull_0;
/* 035 */         if (!filter_value_2) continue;
/* 036 */
/* 037 */         boolean inputadapter_isNull_1 = inputadapter_row_0.isNullAt(1);
/* 038 */         int inputadapter_value_1 = inputadapter_isNull_1 ?
/* 039 */         -1 : (inputadapter_row_0.getInt(1));
/* 040 */
/* 041 */         boolean filter_value_5 = !inputadapter_isNull_1;
/* 042 */         if (!filter_value_5) continue;
/* 043 */
/* 044 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 045 */
/* 046 */         filter_mutableStateArray_0[1].reset();
/* 047 */
/* 048 */         if (false) {
/* 049 */           filter_mutableStateArray_0[1].setNullAt(0);
/* 050 */         } else {
/* 051 */           filter_mutableStateArray_0[1].write(0, inputadapter_value_0);
/* 052 */         }
/* 053 */
/* 054 */         if (false) {
/* 055 */           filter_mutableStateArray_0[1].setNullAt(1);
/* 056 */         } else {
/* 057 */           filter_mutableStateArray_0[1].write(1, inputadapter_value_1);
/* 058 */         }
/* 059 */         append((filter_mutableStateArray_0[1].getRow()));
/* 060 */
/* 061 */       } while(false);
/* 062 */       if (shouldStop()) return;
/* 063 */     }
/* 064 */   }
/* 065 */
/* 066 */ }

2022-02-14 10:55:48 DEBUG CodeGenerator:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage3(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=3
/* 006 */ final class GeneratedIteratorForCodegenStage3 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage3(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 021 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   protected void processNext() throws java.io.IOException {
/* 026 */     while ( inputadapter_input_0.hasNext()) {
/* 027 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 028 */
/* 029 */       do {
/* 030 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 031 */         int inputadapter_value_0 = inputadapter_isNull_0 ?
/* 032 */         -1 : (inputadapter_row_0.getInt(0));
/* 033 */
/* 034 */         boolean filter_value_2 = !inputadapter_isNull_0;
/* 035 */         if (!filter_value_2) continue;
/* 036 */
/* 037 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 038 */
/* 039 */         boolean inputadapter_isNull_1 = inputadapter_row_0.isNullAt(1);
/* 040 */         int inputadapter_value_1 = inputadapter_isNull_1 ?
/* 041 */         -1 : (inputadapter_row_0.getInt(1));
/* 042 */         boolean inputadapter_isNull_2 = inputadapter_row_0.isNullAt(2);
/* 043 */         UTF8String inputadapter_value_2 = inputadapter_isNull_2 ?
/* 044 */         null : (inputadapter_row_0.getUTF8String(2));
/* 045 */         filter_mutableStateArray_0[1].reset();
/* 046 */
/* 047 */         filter_mutableStateArray_0[1].zeroOutNullBytes();
/* 048 */
/* 049 */         if (false) {
/* 050 */           filter_mutableStateArray_0[1].setNullAt(0);
/* 051 */         } else {
/* 052 */           filter_mutableStateArray_0[1].write(0, inputadapter_value_0);
/* 053 */         }
/* 054 */
/* 055 */         if (inputadapter_isNull_1) {
/* 056 */           filter_mutableStateArray_0[1].setNullAt(1);
/* 057 */         } else {
/* 058 */           filter_mutableStateArray_0[1].write(1, inputadapter_value_1);
/* 059 */         }
/* 060 */
/* 061 */         if (inputadapter_isNull_2) {
/* 062 */           filter_mutableStateArray_0[1].setNullAt(2);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[1].write(2, inputadapter_value_2);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[1].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }

2022-02-14 10:55:48 DEBUG CodeGenerator:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage2(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=2
/* 006 */ final class GeneratedIteratorForCodegenStage2 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage2(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 0);
/* 021 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 0);
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   protected void processNext() throws java.io.IOException {
/* 026 */     while ( inputadapter_input_0.hasNext()) {
/* 027 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 028 */
/* 029 */       do {
/* 030 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 031 */         int inputadapter_value_0 = inputadapter_isNull_0 ?
/* 032 */         -1 : (inputadapter_row_0.getInt(0));
/* 033 */
/* 034 */         boolean filter_value_2 = !inputadapter_isNull_0;
/* 035 */         if (!filter_value_2) continue;
/* 036 */
/* 037 */         boolean inputadapter_isNull_1 = inputadapter_row_0.isNullAt(1);
/* 038 */         int inputadapter_value_1 = inputadapter_isNull_1 ?
/* 039 */         -1 : (inputadapter_row_0.getInt(1));
/* 040 */
/* 041 */         boolean filter_value_5 = !inputadapter_isNull_1;
/* 042 */         if (!filter_value_5) continue;
/* 043 */
/* 044 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 045 */
/* 046 */         filter_mutableStateArray_0[1].reset();
/* 047 */
/* 048 */         if (false) {
/* 049 */           filter_mutableStateArray_0[1].setNullAt(0);
/* 050 */         } else {
/* 051 */           filter_mutableStateArray_0[1].write(0, inputadapter_value_0);
/* 052 */         }
/* 053 */
/* 054 */         if (false) {
/* 055 */           filter_mutableStateArray_0[1].setNullAt(1);
/* 056 */         } else {
/* 057 */           filter_mutableStateArray_0[1].write(1, inputadapter_value_1);
/* 058 */         }
/* 059 */         append((filter_mutableStateArray_0[1].getRow()));
/* 060 */
/* 061 */       } while(false);
/* 062 */       if (shouldStop()) return;
/* 063 */     }
/* 064 */   }
/* 065 */
/* 066 */ }

2022-02-14 10:55:48 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 64);
/* 021 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   protected void processNext() throws java.io.IOException {
/* 026 */     while ( inputadapter_input_0.hasNext()) {
/* 027 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 028 */
/* 029 */       do {
/* 030 */         boolean inputadapter_isNull_1 = inputadapter_row_0.isNullAt(1);
/* 031 */         UTF8String inputadapter_value_1 = inputadapter_isNull_1 ?
/* 032 */         null : (inputadapter_row_0.getUTF8String(1));
/* 033 */
/* 034 */         boolean filter_isNull_0 = true;
/* 035 */         boolean filter_value_0 = false;
/* 036 */         boolean filter_isNull_1 = true;
/* 037 */         UTF8String filter_value_1 = null;
/* 038 */         boolean filter_isNull_2 = inputadapter_isNull_1;
/* 039 */         long filter_value_2 = -1L;
/* 040 */         if (!inputadapter_isNull_1) {
/* 041 */           scala.Option<Long> filter_longOpt_0 =
/* 042 */           org.apache.spark.sql.catalyst.util.DateTimeUtils.stringToTimestamp(inputadapter_value_1, ((java.time.ZoneId) references[2] /* zoneId */));
/* 043 */           if (filter_longOpt_0.isDefined()) {
/* 044 */             filter_value_2 = ((Long) filter_longOpt_0.get()).longValue();
/* 045 */           } else {
/* 046 */             filter_isNull_2 = true;
/* 047 */           }
/* 048 */         }
/* 049 */         if (!filter_isNull_2) {
/* 050 */           filter_isNull_1 = false; // resultCode could change nullability.
/* 051 */           filter_value_1 = UTF8String.fromString(((org.apache.spark.sql.catalyst.util.Iso8601TimestampFormatter) references[1] /* timestampFormatter */).format(filter_value_2));
/* 052 */
/* 053 */         }
/* 054 */         if (!filter_isNull_1) {
/* 055 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 056 */           filter_value_0 = (filter_value_1).startsWith(((UTF8String) references[4] /* literal */));
/* 057 */
/* 058 */         }
/* 059 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 060 */         boolean inputadapter_isNull_2 = inputadapter_row_0.isNullAt(2);
/* 061 */         UTF8String inputadapter_value_2 = inputadapter_isNull_2 ?
/* 062 */         null : (inputadapter_row_0.getUTF8String(2));
/* 063 */
/* 064 */         byte filter_inTmpResult_0 = -1;
/* 065 */         if (!inputadapter_isNull_2) {
/* 066 */           filter_inTmpResult_0 = 0;
/* 067 */           UTF8String filter_valueArg_0 = inputadapter_value_2;
/* 068 */           do {
/* 069 */             if (false) {
/* 070 */               filter_inTmpResult_0 = -1; // filter_isNull_6 = true;
/* 071 */             } else if (filter_valueArg_0.equals(((UTF8String) references[5] /* literal */))) {
/* 072 */               filter_inTmpResult_0 = 1; // filter_isNull_6 = false; filter_value_6 = true;
/* 073 */               continue;
/* 074 */             }
/* 075 */
/* 076 */             if (false) {
/* 077 */               filter_inTmpResult_0 = -1; // filter_isNull_6 = true;
/* 078 */             } else if (filter_valueArg_0.equals(((UTF8String) references[6] /* literal */))) {
/* 079 */               filter_inTmpResult_0 = 1; // filter_isNull_6 = false; filter_value_6 = true;
/* 080 */               continue;
/* 081 */             }
/* 082 */
/* 083 */           } while (false);
/* 084 */         }
/* 085 */         final boolean filter_isNull_6 = (filter_inTmpResult_0 == -1);
/* 086 */         final boolean filter_value_6 = (filter_inTmpResult_0 == 1);
/* 087 */         if (filter_isNull_6 || !filter_value_6) continue;
/* 088 */
/* 089 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 090 */         int inputadapter_value_0 = inputadapter_isNull_0 ?
/* 091 */         -1 : (inputadapter_row_0.getInt(0));
/* 092 */
/* 093 */         boolean filter_value_12 = !inputadapter_isNull_0;
/* 094 */         if (!filter_value_12) continue;
/* 095 */
/* 096 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 097 */
/* 098 */         filter_mutableStateArray_0[1].reset();
/* 099 */
/* 100 */         if (false) {
/* 101 */           filter_mutableStateArray_0[1].setNullAt(0);
/* 102 */         } else {
/* 103 */           filter_mutableStateArray_0[1].write(0, inputadapter_value_0);
/* 104 */         }
/* 105 */         append((filter_mutableStateArray_0[1].getRow()));
/* 106 */
/* 107 */       } while(false);
/* 108 */       if (shouldStop()) return;
/* 109 */     }
/* 110 */   }
/* 111 */
/* 112 */ }

2022-02-14 10:55:48 DEBUG CodeGenerator:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 64);
/* 021 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   protected void processNext() throws java.io.IOException {
/* 026 */     while ( inputadapter_input_0.hasNext()) {
/* 027 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 028 */
/* 029 */       do {
/* 030 */         boolean inputadapter_isNull_1 = inputadapter_row_0.isNullAt(1);
/* 031 */         UTF8String inputadapter_value_1 = inputadapter_isNull_1 ?
/* 032 */         null : (inputadapter_row_0.getUTF8String(1));
/* 033 */
/* 034 */         boolean filter_isNull_0 = true;
/* 035 */         boolean filter_value_0 = false;
/* 036 */         boolean filter_isNull_1 = true;
/* 037 */         UTF8String filter_value_1 = null;
/* 038 */         boolean filter_isNull_2 = inputadapter_isNull_1;
/* 039 */         long filter_value_2 = -1L;
/* 040 */         if (!inputadapter_isNull_1) {
/* 041 */           scala.Option<Long> filter_longOpt_0 =
/* 042 */           org.apache.spark.sql.catalyst.util.DateTimeUtils.stringToTimestamp(inputadapter_value_1, ((java.time.ZoneId) references[2] /* zoneId */));
/* 043 */           if (filter_longOpt_0.isDefined()) {
/* 044 */             filter_value_2 = ((Long) filter_longOpt_0.get()).longValue();
/* 045 */           } else {
/* 046 */             filter_isNull_2 = true;
/* 047 */           }
/* 048 */         }
/* 049 */         if (!filter_isNull_2) {
/* 050 */           filter_isNull_1 = false; // resultCode could change nullability.
/* 051 */           filter_value_1 = UTF8String.fromString(((org.apache.spark.sql.catalyst.util.Iso8601TimestampFormatter) references[1] /* timestampFormatter */).format(filter_value_2));
/* 052 */
/* 053 */         }
/* 054 */         if (!filter_isNull_1) {
/* 055 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 056 */           filter_value_0 = (filter_value_1).startsWith(((UTF8String) references[4] /* literal */));
/* 057 */
/* 058 */         }
/* 059 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 060 */         boolean inputadapter_isNull_2 = inputadapter_row_0.isNullAt(2);
/* 061 */         UTF8String inputadapter_value_2 = inputadapter_isNull_2 ?
/* 062 */         null : (inputadapter_row_0.getUTF8String(2));
/* 063 */
/* 064 */         byte filter_inTmpResult_0 = -1;
/* 065 */         if (!inputadapter_isNull_2) {
/* 066 */           filter_inTmpResult_0 = 0;
/* 067 */           UTF8String filter_valueArg_0 = inputadapter_value_2;
/* 068 */           do {
/* 069 */             if (false) {
/* 070 */               filter_inTmpResult_0 = -1; // filter_isNull_6 = true;
/* 071 */             } else if (filter_valueArg_0.equals(((UTF8String) references[5] /* literal */))) {
/* 072 */               filter_inTmpResult_0 = 1; // filter_isNull_6 = false; filter_value_6 = true;
/* 073 */               continue;
/* 074 */             }
/* 075 */
/* 076 */             if (false) {
/* 077 */               filter_inTmpResult_0 = -1; // filter_isNull_6 = true;
/* 078 */             } else if (filter_valueArg_0.equals(((UTF8String) references[6] /* literal */))) {
/* 079 */               filter_inTmpResult_0 = 1; // filter_isNull_6 = false; filter_value_6 = true;
/* 080 */               continue;
/* 081 */             }
/* 082 */
/* 083 */           } while (false);
/* 084 */         }
/* 085 */         final boolean filter_isNull_6 = (filter_inTmpResult_0 == -1);
/* 086 */         final boolean filter_value_6 = (filter_inTmpResult_0 == 1);
/* 087 */         if (filter_isNull_6 || !filter_value_6) continue;
/* 088 */
/* 089 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 090 */         int inputadapter_value_0 = inputadapter_isNull_0 ?
/* 091 */         -1 : (inputadapter_row_0.getInt(0));
/* 092 */
/* 093 */         boolean filter_value_12 = !inputadapter_isNull_0;
/* 094 */         if (!filter_value_12) continue;
/* 095 */
/* 096 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 097 */
/* 098 */         filter_mutableStateArray_0[1].reset();
/* 099 */
/* 100 */         if (false) {
/* 101 */           filter_mutableStateArray_0[1].setNullAt(0);
/* 102 */         } else {
/* 103 */           filter_mutableStateArray_0[1].write(0, inputadapter_value_0);
/* 104 */         }
/* 105 */         append((filter_mutableStateArray_0[1].getRow()));
/* 106 */
/* 107 */       } while(false);
/* 108 */       if (shouldStop()) return;
/* 109 */     }
/* 110 */   }
/* 111 */
/* 112 */ }

2022-02-14 10:55:48 INFO  CodeGenerator:57 - Code generated in 21.0933 ms
2022-02-14 10:55:49 INFO  MemoryStore:57 - Block broadcast_16 stored as values in memory (estimated size 170.9 KiB, free 2.2 GiB)
2022-02-14 10:55:49 DEBUG BlockManager:61 - Put block broadcast_16 locally took 5 ms
2022-02-14 10:55:49 DEBUG BlockManager:61 - Putting block broadcast_16 without replication took 6 ms
2022-02-14 10:55:49 INFO  CodeGenerator:57 - Code generated in 54.954899 ms
2022-02-14 10:55:49 INFO  MemoryStore:57 - Block broadcast_17 stored as values in memory (estimated size 170.9 KiB, free 2.2 GiB)
2022-02-14 10:55:49 DEBUG BlockManager:61 - Put block broadcast_17 locally took 4 ms
2022-02-14 10:55:49 DEBUG BlockManager:61 - Putting block broadcast_17 without replication took 4 ms
2022-02-14 10:55:49 INFO  CodeGenerator:57 - Code generated in 61.3643 ms
2022-02-14 10:55:49 INFO  MemoryStore:57 - Block broadcast_16_piece0 stored as bytes in memory (estimated size 23.9 KiB, free 2.2 GiB)
2022-02-14 10:55:49 INFO  MemoryStore:57 - Block broadcast_18 stored as values in memory (estimated size 170.9 KiB, free 2.2 GiB)
2022-02-14 10:55:49 INFO  BlockManagerInfo:57 - Added broadcast_16_piece0 in memory on Clairvoyant-320:60340 (size: 23.9 KiB, free: 2.2 GiB)
2022-02-14 10:55:49 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_16_piece0
2022-02-14 10:55:49 DEBUG BlockManager:61 - Told master about block broadcast_16_piece0
2022-02-14 10:55:49 DEBUG BlockManager:61 - Put block broadcast_16_piece0 locally took 3 ms
2022-02-14 10:55:49 DEBUG BlockManager:61 - Putting block broadcast_16_piece0 without replication took 4 ms
2022-02-14 10:55:49 INFO  SparkContext:57 - Created broadcast 16 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
2022-02-14 10:55:49 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage6(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=6
/* 006 */ final class GeneratedIteratorForCodegenStage6 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private boolean agg_bufIsNull_0;
/* 011 */   private long agg_bufValue_0;
/* 012 */   private scala.collection.Iterator inputadapter_input_0;
/* 013 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 014 */
/* 015 */   public GeneratedIteratorForCodegenStage6(Object[] references) {
/* 016 */     this.references = references;
/* 017 */   }
/* 018 */
/* 019 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 020 */     partitionIndex = index;
/* 021 */     this.inputs = inputs;
/* 022 */
/* 023 */     inputadapter_input_0 = inputs[0];
/* 024 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 025 */
/* 026 */   }
/* 027 */
/* 028 */   private void agg_doAggregateWithoutKey_0() throws java.io.IOException {
/* 029 */     // initialize aggregation buffer
/* 030 */     agg_bufIsNull_0 = false;
/* 031 */     agg_bufValue_0 = 0L;
/* 032 */
/* 033 */     while ( inputadapter_input_0.hasNext()) {
/* 034 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 035 */
/* 036 */       long inputadapter_value_0 = inputadapter_row_0.getLong(0);
/* 037 */
/* 038 */       agg_doConsume_0(inputadapter_row_0, inputadapter_value_0);
/* 039 */       // shouldStop check is eliminated
/* 040 */     }
/* 041 */
/* 042 */   }
/* 043 */
/* 044 */   private void agg_doConsume_0(InternalRow inputadapter_row_0, long agg_expr_0_0) throws java.io.IOException {
/* 045 */     // do aggregate
/* 046 */     // common sub-expressions
/* 047 */
/* 048 */     // evaluate aggregate functions and update aggregation buffers
/* 049 */
/* 050 */     long agg_value_3 = -1L;
/* 051 */
/* 052 */     agg_value_3 = agg_bufValue_0 + agg_expr_0_0;
/* 053 */
/* 054 */     agg_bufIsNull_0 = false;
/* 055 */     agg_bufValue_0 = agg_value_3;
/* 056 */
/* 057 */   }
/* 058 */
/* 059 */   protected void processNext() throws java.io.IOException {
/* 060 */     while (!agg_initAgg_0) {
/* 061 */       agg_initAgg_0 = true;
/* 062 */       long agg_beforeAgg_0 = System.nanoTime();
/* 063 */       agg_doAggregateWithoutKey_0();
/* 064 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_0) / 1000000);
/* 065 */
/* 066 */       // output the result
/* 067 */
/* 068 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 069 */       agg_mutableStateArray_0[0].reset();
/* 070 */
/* 071 */       agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 072 */
/* 073 */       agg_mutableStateArray_0[0].write(0, agg_bufValue_0);
/* 074 */       append((agg_mutableStateArray_0[0].getRow()));
/* 075 */     }
/* 076 */   }
/* 077 */
/* 078 */ }

2022-02-14 10:55:49 DEBUG BlockManager:61 - Put block broadcast_18 locally took 11 ms
2022-02-14 10:55:49 DEBUG BlockManager:61 - Putting block broadcast_18 without replication took 13 ms
2022-02-14 10:55:49 DEBUG CodeGenerator:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage6(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=6
/* 006 */ final class GeneratedIteratorForCodegenStage6 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private boolean agg_bufIsNull_0;
/* 011 */   private long agg_bufValue_0;
/* 012 */   private scala.collection.Iterator inputadapter_input_0;
/* 013 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 014 */
/* 015 */   public GeneratedIteratorForCodegenStage6(Object[] references) {
/* 016 */     this.references = references;
/* 017 */   }
/* 018 */
/* 019 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 020 */     partitionIndex = index;
/* 021 */     this.inputs = inputs;
/* 022 */
/* 023 */     inputadapter_input_0 = inputs[0];
/* 024 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 025 */
/* 026 */   }
/* 027 */
/* 028 */   private void agg_doAggregateWithoutKey_0() throws java.io.IOException {
/* 029 */     // initialize aggregation buffer
/* 030 */     agg_bufIsNull_0 = false;
/* 031 */     agg_bufValue_0 = 0L;
/* 032 */
/* 033 */     while ( inputadapter_input_0.hasNext()) {
/* 034 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 035 */
/* 036 */       long inputadapter_value_0 = inputadapter_row_0.getLong(0);
/* 037 */
/* 038 */       agg_doConsume_0(inputadapter_row_0, inputadapter_value_0);
/* 039 */       // shouldStop check is eliminated
/* 040 */     }
/* 041 */
/* 042 */   }
/* 043 */
/* 044 */   private void agg_doConsume_0(InternalRow inputadapter_row_0, long agg_expr_0_0) throws java.io.IOException {
/* 045 */     // do aggregate
/* 046 */     // common sub-expressions
/* 047 */
/* 048 */     // evaluate aggregate functions and update aggregation buffers
/* 049 */
/* 050 */     long agg_value_3 = -1L;
/* 051 */
/* 052 */     agg_value_3 = agg_bufValue_0 + agg_expr_0_0;
/* 053 */
/* 054 */     agg_bufIsNull_0 = false;
/* 055 */     agg_bufValue_0 = agg_value_3;
/* 056 */
/* 057 */   }
/* 058 */
/* 059 */   protected void processNext() throws java.io.IOException {
/* 060 */     while (!agg_initAgg_0) {
/* 061 */       agg_initAgg_0 = true;
/* 062 */       long agg_beforeAgg_0 = System.nanoTime();
/* 063 */       agg_doAggregateWithoutKey_0();
/* 064 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_0) / 1000000);
/* 065 */
/* 066 */       // output the result
/* 067 */
/* 068 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 069 */       agg_mutableStateArray_0[0].reset();
/* 070 */
/* 071 */       agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 072 */
/* 073 */       agg_mutableStateArray_0[0].write(0, agg_bufValue_0);
/* 074 */       append((agg_mutableStateArray_0[0].getRow()));
/* 075 */     }
/* 076 */   }
/* 077 */
/* 078 */ }

2022-02-14 10:55:49 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4368551 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-14 10:55:49 INFO  MemoryStore:57 - Block broadcast_17_piece0 stored as bytes in memory (estimated size 23.9 KiB, free 2.2 GiB)
2022-02-14 10:55:49 INFO  BlockManagerInfo:57 - Added broadcast_17_piece0 in memory on Clairvoyant-320:60340 (size: 23.9 KiB, free: 2.2 GiB)
2022-02-14 10:55:49 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_17_piece0
2022-02-14 10:55:49 DEBUG BlockManager:61 - Told master about block broadcast_17_piece0
2022-02-14 10:55:49 DEBUG BlockManager:61 - Put block broadcast_17_piece0 locally took 7 ms
2022-02-14 10:55:49 DEBUG BlockManager:61 - Putting block broadcast_17_piece0 without replication took 7 ms
2022-02-14 10:55:49 INFO  SparkContext:57 - Created broadcast 17 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
2022-02-14 10:55:49 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-02-14 10:55:49 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4195382 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-14 10:55:49 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-02-14 10:55:49 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-02-14 10:55:49 INFO  MemoryStore:57 - Block broadcast_18_piece0 stored as bytes in memory (estimated size 23.9 KiB, free 2.2 GiB)
2022-02-14 10:55:49 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$collect$2
2022-02-14 10:55:49 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-02-14 10:55:49 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$collect$2
2022-02-14 10:55:49 INFO  CodeGenerator:57 - Code generated in 35.542199 ms
2022-02-14 10:55:49 INFO  BlockManagerInfo:57 - Added broadcast_18_piece0 in memory on Clairvoyant-320:60340 (size: 23.9 KiB, free: 2.2 GiB)
2022-02-14 10:55:49 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_18_piece0
2022-02-14 10:55:49 DEBUG BlockManager:61 - Told master about block broadcast_18_piece0
2022-02-14 10:55:49 DEBUG BlockManager:61 - Put block broadcast_18_piece0 locally took 14 ms
2022-02-14 10:55:49 DEBUG BlockManager:61 - Putting block broadcast_18_piece0 without replication took 14 ms
2022-02-14 10:55:49 INFO  SparkContext:57 - Created broadcast 18 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
2022-02-14 10:55:49 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 7194299 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-14 10:55:49 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$collect$2) is now cleaned +++
2022-02-14 10:55:49 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-02-14 10:55:49 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-02-14 10:55:49 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$collect$2) is now cleaned +++
2022-02-14 10:55:49 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$5
2022-02-14 10:55:49 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$5
2022-02-14 10:55:49 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$collect$2
2022-02-14 10:55:49 INFO  HashAggregateExec:57 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2022-02-14 10:55:49 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2022-02-14 10:55:49 INFO  SparkContext:57 - Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
2022-02-14 10:55:49 INFO  DAGScheduler:57 - Got job 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
2022-02-14 10:55:49 INFO  DAGScheduler:57 - Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
2022-02-14 10:55:49 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-02-14 10:55:49 INFO  DAGScheduler:57 - Missing parents: List()
2022-02-14 10:55:49 DEBUG DAGScheduler:61 - submitStage(ResultStage 8 (name=$anonfun$withThreadLocalCaptured$1 at FutureTask.java:264;jobs=8))
2022-02-14 10:55:49 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:55:49 INFO  DAGScheduler:57 - Submitting ResultStage 8 (MapPartitionsRDD[45] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
2022-02-14 10:55:49 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 8)
2022-02-14 10:55:49 INFO  MemoryStore:57 - Block broadcast_19 stored as values in memory (estimated size 12.7 KiB, free 2.2 GiB)
2022-02-14 10:55:49 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2022-02-14 10:55:49 INFO  SparkContext:57 - Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
2022-02-14 10:55:49 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$collect$2) is now cleaned +++
2022-02-14 10:55:49 DEBUG BlockManager:61 - Put block broadcast_19 locally took 8 ms
2022-02-14 10:55:49 DEBUG BlockManager:61 - Putting block broadcast_19 without replication took 8 ms
2022-02-14 10:55:49 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage5(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=5
/* 006 */ final class GeneratedIteratorForCodegenStage5 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private boolean agg_bufIsNull_0;
/* 011 */   private long agg_bufValue_0;
/* 012 */   private boolean agg_initAgg_1;
/* 013 */   private org.apache.spark.unsafe.KVIterator agg_mapIter_0;
/* 014 */   private org.apache.spark.sql.execution.UnsafeFixedWidthAggregationMap agg_hashMap_0;
/* 015 */   private org.apache.spark.sql.execution.UnsafeKVExternalSorter agg_sorter_0;
/* 016 */   private scala.collection.Iterator inputadapter_input_0;
/* 017 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 018 */
/* 019 */   public GeneratedIteratorForCodegenStage5(Object[] references) {
/* 020 */     this.references = references;
/* 021 */   }
/* 022 */
/* 023 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 024 */     partitionIndex = index;
/* 025 */     this.inputs = inputs;
/* 026 */
/* 027 */     inputadapter_input_0 = inputs[0];
/* 028 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 029 */     agg_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 030 */
/* 031 */   }
/* 032 */
/* 033 */   private void agg_doAggregateWithoutKey_0() throws java.io.IOException {
/* 034 */     // initialize aggregation buffer
/* 035 */     agg_bufIsNull_0 = false;
/* 036 */     agg_bufValue_0 = 0L;
/* 037 */
/* 038 */     if (!agg_initAgg_1) {
/* 039 */       agg_initAgg_1 = true;
/* 040 */
/* 041 */       agg_hashMap_0 = ((org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0] /* plan */).createHashMap();
/* 042 */       long agg_beforeAgg_0 = System.nanoTime();
/* 043 */       agg_doAggregateWithKeys_0();
/* 044 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[5] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_0) / 1000000);
/* 045 */     }
/* 046 */     // output the result
/* 047 */
/* 048 */     while ( agg_mapIter_0.next()) {
/* 049 */       UnsafeRow agg_aggKey_0 = (UnsafeRow) agg_mapIter_0.getKey();
/* 050 */       UnsafeRow agg_aggBuffer_0 = (UnsafeRow) agg_mapIter_0.getValue();
/* 051 */       agg_doAggregateWithKeysOutput_0(agg_aggKey_0, agg_aggBuffer_0);
/* 052 */       if (shouldStop()) return;
/* 053 */     }
/* 054 */     agg_mapIter_0.close();
/* 055 */     if (agg_sorter_0 == null) {
/* 056 */       agg_hashMap_0.free();
/* 057 */     }
/* 058 */
/* 059 */   }
/* 060 */
/* 061 */   private void agg_doConsume_1() throws java.io.IOException {
/* 062 */     // do aggregate
/* 063 */     // common sub-expressions
/* 064 */
/* 065 */     // evaluate aggregate functions and update aggregation buffers
/* 066 */
/* 067 */     long agg_value_7 = -1L;
/* 068 */
/* 069 */     agg_value_7 = agg_bufValue_0 + 1L;
/* 070 */
/* 071 */     agg_bufIsNull_0 = false;
/* 072 */     agg_bufValue_0 = agg_value_7;
/* 073 */
/* 074 */   }
/* 075 */
/* 076 */   private void agg_doAggregateWithKeysOutput_0(UnsafeRow agg_keyTerm_0, UnsafeRow agg_bufferTerm_0)
/* 077 */   throws java.io.IOException {
/* 078 */     ((org.apache.spark.sql.execution.metric.SQLMetric) references[4] /* numOutputRows */).add(1);
/* 079 */
/* 080 */     agg_doConsume_1();
/* 081 */
/* 082 */   }
/* 083 */
/* 084 */   private void agg_doConsume_0(InternalRow inputadapter_row_0, int agg_expr_0_0, boolean agg_exprIsNull_0_0, int agg_expr_1_0, boolean agg_exprIsNull_1_0, UTF8String agg_expr_2_0, boolean agg_exprIsNull_2_0) throws java.io.IOException {
/* 085 */     UnsafeRow agg_unsafeRowAggBuffer_0 = null;
/* 086 */
/* 087 */     // generate grouping key
/* 088 */     agg_mutableStateArray_0[0].reset();
/* 089 */
/* 090 */     agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 091 */
/* 092 */     if (agg_exprIsNull_0_0) {
/* 093 */       agg_mutableStateArray_0[0].setNullAt(0);
/* 094 */     } else {
/* 095 */       agg_mutableStateArray_0[0].write(0, agg_expr_0_0);
/* 096 */     }
/* 097 */
/* 098 */     if (agg_exprIsNull_1_0) {
/* 099 */       agg_mutableStateArray_0[0].setNullAt(1);
/* 100 */     } else {
/* 101 */       agg_mutableStateArray_0[0].write(1, agg_expr_1_0);
/* 102 */     }
/* 103 */
/* 104 */     if (agg_exprIsNull_2_0) {
/* 105 */       agg_mutableStateArray_0[0].setNullAt(2);
/* 106 */     } else {
/* 107 */       agg_mutableStateArray_0[0].write(2, agg_expr_2_0);
/* 108 */     }
/* 109 */     int agg_unsafeRowKeyHash_0 = (agg_mutableStateArray_0[0].getRow()).hashCode();
/* 110 */     if (true) {
/* 111 */       // try to get the buffer from hash map
/* 112 */       agg_unsafeRowAggBuffer_0 =
/* 113 */       agg_hashMap_0.getAggregationBufferFromUnsafeRow((agg_mutableStateArray_0[0].getRow()), agg_unsafeRowKeyHash_0);
/* 114 */     }
/* 115 */     // Can't allocate buffer from the hash map. Spill the map and fallback to sort-based
/* 116 */     // aggregation after processing all input rows.
/* 117 */     if (agg_unsafeRowAggBuffer_0 == null) {
/* 118 */       if (agg_sorter_0 == null) {
/* 119 */         agg_sorter_0 = agg_hashMap_0.destructAndCreateExternalSorter();
/* 120 */       } else {
/* 121 */         agg_sorter_0.merge(agg_hashMap_0.destructAndCreateExternalSorter());
/* 122 */       }
/* 123 */
/* 124 */       // the hash map had be spilled, it should have enough memory now,
/* 125 */       // try to allocate buffer again.
/* 126 */       agg_unsafeRowAggBuffer_0 = agg_hashMap_0.getAggregationBufferFromUnsafeRow(
/* 127 */         (agg_mutableStateArray_0[0].getRow()), agg_unsafeRowKeyHash_0);
/* 128 */       if (agg_unsafeRowAggBuffer_0 == null) {
/* 129 */         // failed to allocate the first page
/* 130 */         throw new org.apache.spark.memory.SparkOutOfMemoryError("No enough memory for aggregation");
/* 131 */       }
/* 132 */     }
/* 133 */
/* 134 */     // common sub-expressions
/* 135 */
/* 136 */     // evaluate aggregate functions and update aggregation buffers
/* 137 */
/* 138 */   }
/* 139 */
/* 140 */   private void agg_doAggregateWithKeys_0() throws java.io.IOException {
/* 141 */     while ( inputadapter_input_0.hasNext()) {
/* 142 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 143 */
/* 144 */       boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 145 */       int inputadapter_value_0 = inputadapter_isNull_0 ?
/* 146 */       -1 : (inputadapter_row_0.getInt(0));
/* 147 */       boolean inputadapter_isNull_1 = inputadapter_row_0.isNullAt(1);
/* 148 */       int inputadapter_value_1 = inputadapter_isNull_1 ?
/* 149 */       -1 : (inputadapter_row_0.getInt(1));
/* 150 */       boolean inputadapter_isNull_2 = inputadapter_row_0.isNullAt(2);
/* 151 */       UTF8String inputadapter_value_2 = inputadapter_isNull_2 ?
/* 152 */       null : (inputadapter_row_0.getUTF8String(2));
/* 153 */
/* 154 */       agg_doConsume_0(inputadapter_row_0, inputadapter_value_0, inputadapter_isNull_0, inputadapter_value_1, inputadapter_isNull_1, inputadapter_value_2, inputadapter_isNull_2);
/* 155 */       // shouldStop check is eliminated
/* 156 */     }
/* 157 */
/* 158 */     agg_mapIter_0 = ((org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0] /* plan */).finishAggregate(agg_hashMap_0, agg_sorter_0, ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* peakMemory */), ((org.apache.spark.sql.execution.metric.SQLMetric) references[2] /* spillSize */), ((org.apache.spark.sql.execution.metric.SQLMetric) references[3] /* avgHashProbe */));
/* 159 */   }
/* 160 */
/* 161 */   protected void processNext() throws java.io.IOException {
/* 162 */     while (!agg_initAgg_0) {
/* 163 */       agg_initAgg_0 = true;
/* 164 */       long agg_beforeAgg_1 = System.nanoTime();
/* 165 */       agg_doAggregateWithoutKey_0();
/* 166 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[7] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_1) / 1000000);
/* 167 */
/* 168 */       // output the result
/* 169 */
/* 170 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[6] /* numOutputRows */).add(1);
/* 171 */       agg_mutableStateArray_0[1].reset();
/* 172 */
/* 173 */       agg_mutableStateArray_0[1].zeroOutNullBytes();
/* 174 */
/* 175 */       agg_mutableStateArray_0[1].write(0, agg_bufValue_0);
/* 176 */       append((agg_mutableStateArray_0[1].getRow()));
/* 177 */     }
/* 178 */   }
/* 179 */
/* 180 */ }

2022-02-14 10:55:49 INFO  MemoryStore:57 - Block broadcast_19_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 2.2 GiB)
2022-02-14 10:55:49 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$5
2022-02-14 10:55:49 DEBUG CodeGenerator:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage5(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=5
/* 006 */ final class GeneratedIteratorForCodegenStage5 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private boolean agg_bufIsNull_0;
/* 011 */   private long agg_bufValue_0;
/* 012 */   private boolean agg_initAgg_1;
/* 013 */   private org.apache.spark.unsafe.KVIterator agg_mapIter_0;
/* 014 */   private org.apache.spark.sql.execution.UnsafeFixedWidthAggregationMap agg_hashMap_0;
/* 015 */   private org.apache.spark.sql.execution.UnsafeKVExternalSorter agg_sorter_0;
/* 016 */   private scala.collection.Iterator inputadapter_input_0;
/* 017 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 018 */
/* 019 */   public GeneratedIteratorForCodegenStage5(Object[] references) {
/* 020 */     this.references = references;
/* 021 */   }
/* 022 */
/* 023 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 024 */     partitionIndex = index;
/* 025 */     this.inputs = inputs;
/* 026 */
/* 027 */     inputadapter_input_0 = inputs[0];
/* 028 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 029 */     agg_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 030 */
/* 031 */   }
/* 032 */
/* 033 */   private void agg_doAggregateWithoutKey_0() throws java.io.IOException {
/* 034 */     // initialize aggregation buffer
/* 035 */     agg_bufIsNull_0 = false;
/* 036 */     agg_bufValue_0 = 0L;
/* 037 */
/* 038 */     if (!agg_initAgg_1) {
/* 039 */       agg_initAgg_1 = true;
/* 040 */
/* 041 */       agg_hashMap_0 = ((org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0] /* plan */).createHashMap();
/* 042 */       long agg_beforeAgg_0 = System.nanoTime();
/* 043 */       agg_doAggregateWithKeys_0();
/* 044 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[5] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_0) / 1000000);
/* 045 */     }
/* 046 */     // output the result
/* 047 */
/* 048 */     while ( agg_mapIter_0.next()) {
/* 049 */       UnsafeRow agg_aggKey_0 = (UnsafeRow) agg_mapIter_0.getKey();
/* 050 */       UnsafeRow agg_aggBuffer_0 = (UnsafeRow) agg_mapIter_0.getValue();
/* 051 */       agg_doAggregateWithKeysOutput_0(agg_aggKey_0, agg_aggBuffer_0);
/* 052 */       if (shouldStop()) return;
/* 053 */     }
/* 054 */     agg_mapIter_0.close();
/* 055 */     if (agg_sorter_0 == null) {
/* 056 */       agg_hashMap_0.free();
/* 057 */     }
/* 058 */
/* 059 */   }
/* 060 */
/* 061 */   private void agg_doConsume_1() throws java.io.IOException {
/* 062 */     // do aggregate
/* 063 */     // common sub-expressions
/* 064 */
/* 065 */     // evaluate aggregate functions and update aggregation buffers
/* 066 */
/* 067 */     long agg_value_7 = -1L;
/* 068 */
/* 069 */     agg_value_7 = agg_bufValue_0 + 1L;
/* 070 */
/* 071 */     agg_bufIsNull_0 = false;
/* 072 */     agg_bufValue_0 = agg_value_7;
/* 073 */
/* 074 */   }
/* 075 */
/* 076 */   private void agg_doAggregateWithKeysOutput_0(UnsafeRow agg_keyTerm_0, UnsafeRow agg_bufferTerm_0)
/* 077 */   throws java.io.IOException {
/* 078 */     ((org.apache.spark.sql.execution.metric.SQLMetric) references[4] /* numOutputRows */).add(1);
/* 079 */
/* 080 */     agg_doConsume_1();
/* 081 */
/* 082 */   }
/* 083 */
/* 084 */   private void agg_doConsume_0(InternalRow inputadapter_row_0, int agg_expr_0_0, boolean agg_exprIsNull_0_0, int agg_expr_1_0, boolean agg_exprIsNull_1_0, UTF8String agg_expr_2_0, boolean agg_exprIsNull_2_0) throws java.io.IOException {
/* 085 */     UnsafeRow agg_unsafeRowAggBuffer_0 = null;
/* 086 */
/* 087 */     // generate grouping key
/* 088 */     agg_mutableStateArray_0[0].reset();
/* 089 */
/* 090 */     agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 091 */
/* 092 */     if (agg_exprIsNull_0_0) {
/* 093 */       agg_mutableStateArray_0[0].setNullAt(0);
/* 094 */     } else {
/* 095 */       agg_mutableStateArray_0[0].write(0, agg_expr_0_0);
/* 096 */     }
/* 097 */
/* 098 */     if (agg_exprIsNull_1_0) {
/* 099 */       agg_mutableStateArray_0[0].setNullAt(1);
/* 100 */     } else {
/* 101 */       agg_mutableStateArray_0[0].write(1, agg_expr_1_0);
/* 102 */     }
/* 103 */
/* 104 */     if (agg_exprIsNull_2_0) {
/* 105 */       agg_mutableStateArray_0[0].setNullAt(2);
/* 106 */     } else {
/* 107 */       agg_mutableStateArray_0[0].write(2, agg_expr_2_0);
/* 108 */     }
/* 109 */     int agg_unsafeRowKeyHash_0 = (agg_mutableStateArray_0[0].getRow()).hashCode();
/* 110 */     if (true) {
/* 111 */       // try to get the buffer from hash map
/* 112 */       agg_unsafeRowAggBuffer_0 =
/* 113 */       agg_hashMap_0.getAggregationBufferFromUnsafeRow((agg_mutableStateArray_0[0].getRow()), agg_unsafeRowKeyHash_0);
/* 114 */     }
/* 115 */     // Can't allocate buffer from the hash map. Spill the map and fallback to sort-based
/* 116 */     // aggregation after processing all input rows.
/* 117 */     if (agg_unsafeRowAggBuffer_0 == null) {
/* 118 */       if (agg_sorter_0 == null) {
/* 119 */         agg_sorter_0 = agg_hashMap_0.destructAndCreateExternalSorter();
/* 120 */       } else {
/* 121 */         agg_sorter_0.merge(agg_hashMap_0.destructAndCreateExternalSorter());
/* 122 */       }
/* 123 */
/* 124 */       // the hash map had be spilled, it should have enough memory now,
/* 125 */       // try to allocate buffer again.
/* 126 */       agg_unsafeRowAggBuffer_0 = agg_hashMap_0.getAggregationBufferFromUnsafeRow(
/* 127 */         (agg_mutableStateArray_0[0].getRow()), agg_unsafeRowKeyHash_0);
/* 128 */       if (agg_unsafeRowAggBuffer_0 == null) {
/* 129 */         // failed to allocate the first page
/* 130 */         throw new org.apache.spark.memory.SparkOutOfMemoryError("No enough memory for aggregation");
/* 131 */       }
/* 132 */     }
/* 133 */
/* 134 */     // common sub-expressions
/* 135 */
/* 136 */     // evaluate aggregate functions and update aggregation buffers
/* 137 */
/* 138 */   }
/* 139 */
/* 140 */   private void agg_doAggregateWithKeys_0() throws java.io.IOException {
/* 141 */     while ( inputadapter_input_0.hasNext()) {
/* 142 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 143 */
/* 144 */       boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 145 */       int inputadapter_value_0 = inputadapter_isNull_0 ?
/* 146 */       -1 : (inputadapter_row_0.getInt(0));
/* 147 */       boolean inputadapter_isNull_1 = inputadapter_row_0.isNullAt(1);
/* 148 */       int inputadapter_value_1 = inputadapter_isNull_1 ?
/* 149 */       -1 : (inputadapter_row_0.getInt(1));
/* 150 */       boolean inputadapter_isNull_2 = inputadapter_row_0.isNullAt(2);
/* 151 */       UTF8String inputadapter_value_2 = inputadapter_isNull_2 ?
/* 152 */       null : (inputadapter_row_0.getUTF8String(2));
/* 153 */
/* 154 */       agg_doConsume_0(inputadapter_row_0, inputadapter_value_0, inputadapter_isNull_0, inputadapter_value_1, inputadapter_isNull_1, inputadapter_value_2, inputadapter_isNull_2);
/* 155 */       // shouldStop check is eliminated
/* 156 */     }
/* 157 */
/* 158 */     agg_mapIter_0 = ((org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0] /* plan */).finishAggregate(agg_hashMap_0, agg_sorter_0, ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* peakMemory */), ((org.apache.spark.sql.execution.metric.SQLMetric) references[2] /* spillSize */), ((org.apache.spark.sql.execution.metric.SQLMetric) references[3] /* avgHashProbe */));
/* 159 */   }
/* 160 */
/* 161 */   protected void processNext() throws java.io.IOException {
/* 162 */     while (!agg_initAgg_0) {
/* 163 */       agg_initAgg_0 = true;
/* 164 */       long agg_beforeAgg_1 = System.nanoTime();
/* 165 */       agg_doAggregateWithoutKey_0();
/* 166 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[7] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_1) / 1000000);
/* 167 */
/* 168 */       // output the result
/* 169 */
/* 170 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[6] /* numOutputRows */).add(1);
/* 171 */       agg_mutableStateArray_0[1].reset();
/* 172 */
/* 173 */       agg_mutableStateArray_0[1].zeroOutNullBytes();
/* 174 */
/* 175 */       agg_mutableStateArray_0[1].write(0, agg_bufValue_0);
/* 176 */       append((agg_mutableStateArray_0[1].getRow()));
/* 177 */     }
/* 178 */   }
/* 179 */
/* 180 */ }

2022-02-14 10:55:49 INFO  BlockManagerInfo:57 - Added broadcast_19_piece0 in memory on Clairvoyant-320:60340 (size: 6.3 KiB, free: 2.2 GiB)
2022-02-14 10:55:49 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_19_piece0
2022-02-14 10:55:49 DEBUG BlockManager:61 - Told master about block broadcast_19_piece0
2022-02-14 10:55:49 DEBUG BlockManager:61 - Put block broadcast_19_piece0 locally took 6 ms
2022-02-14 10:55:49 DEBUG BlockManager:61 - Putting block broadcast_19_piece0 without replication took 6 ms
2022-02-14 10:55:49 INFO  SparkContext:57 - Created broadcast 19 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:55:49 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[45] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
2022-02-14 10:55:49 INFO  TaskSchedulerImpl:57 - Adding task set 8.0 with 1 tasks
2022-02-14 10:55:49 DEBUG TaskSetManager:61 - Epoch for TaskSet 8.0: 0
2022-02-14 10:55:49 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-02-14 10:55:49 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 8.0: NO_PREF, ANY
2022-02-14 10:55:49 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_8.0, runningTasks: 0
2022-02-14 10:55:49 INFO  TaskSetManager:57 - Starting task 0.0 in stage 8.0 (TID 8, Clairvoyant-320, executor driver, partition 0, PROCESS_LOCAL, 7803 bytes)
2022-02-14 10:55:49 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2022-02-14 10:55:49 INFO  DAGScheduler:57 - Got job 9 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
2022-02-14 10:55:49 INFO  DAGScheduler:57 - Final stage: ResultStage 9 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
2022-02-14 10:55:49 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-02-14 10:55:49 INFO  DAGScheduler:57 - Missing parents: List()
2022-02-14 10:55:49 INFO  SparkContext:57 - Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
2022-02-14 10:55:49 INFO  Executor:57 - Running task 0.0 in stage 8.0 (TID 8)
2022-02-14 10:55:49 DEBUG DAGScheduler:61 - submitStage(ResultStage 9 (name=$anonfun$withThreadLocalCaptured$1 at FutureTask.java:264;jobs=9))
2022-02-14 10:55:49 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:55:49 INFO  DAGScheduler:57 - Submitting ResultStage 9 (MapPartitionsRDD[47] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
2022-02-14 10:55:49 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 9)
2022-02-14 10:55:49 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (8, 0) -> 1
2022-02-14 10:55:49 DEBUG BlockManager:61 - Getting local block broadcast_19
2022-02-14 10:55:49 DEBUG BlockManager:61 - Level for block broadcast_19 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:49 INFO  MemoryStore:57 - Block broadcast_20 stored as values in memory (estimated size 12.9 KiB, free 2.2 GiB)
2022-02-14 10:55:49 DEBUG BlockManager:61 - Put block broadcast_20 locally took 4 ms
2022-02-14 10:55:49 DEBUG BlockManager:61 - Putting block broadcast_20 without replication took 4 ms
2022-02-14 10:55:49 INFO  MemoryStore:57 - Block broadcast_20_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 2.2 GiB)
2022-02-14 10:55:49 INFO  BlockManagerInfo:57 - Added broadcast_20_piece0 in memory on Clairvoyant-320:60340 (size: 6.4 KiB, free: 2.2 GiB)
2022-02-14 10:55:49 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_20_piece0
2022-02-14 10:55:49 DEBUG BlockManager:61 - Told master about block broadcast_20_piece0
2022-02-14 10:55:49 DEBUG BlockManager:61 - Put block broadcast_20_piece0 locally took 10 ms
2022-02-14 10:55:49 DEBUG BlockManager:61 - Putting block broadcast_20_piece0 without replication took 10 ms
2022-02-14 10:55:49 INFO  SparkContext:57 - Created broadcast 20 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:55:49 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[47] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
2022-02-14 10:55:49 INFO  TaskSchedulerImpl:57 - Adding task set 9.0 with 1 tasks
2022-02-14 10:55:49 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/src/main/resources/retail_db/products/part-00000, range: 0-174247, partition values: [empty row]
2022-02-14 10:55:49 DEBUG TaskSetManager:61 - Epoch for TaskSet 9.0: 0
2022-02-14 10:55:49 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-02-14 10:55:49 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 9.0: NO_PREF, ANY
2022-02-14 10:55:49 INFO  DAGScheduler:57 - Got job 10 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
2022-02-14 10:55:49 INFO  DAGScheduler:57 - Final stage: ResultStage 10 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
2022-02-14 10:55:49 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-02-14 10:55:49 INFO  DAGScheduler:57 - Missing parents: List()
2022-02-14 10:55:49 DEBUG DAGScheduler:61 - submitStage(ResultStage 10 (name=$anonfun$withThreadLocalCaptured$1 at FutureTask.java:264;jobs=10))
2022-02-14 10:55:49 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:55:49 INFO  DAGScheduler:57 - Submitting ResultStage 10 (MapPartitionsRDD[51] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
2022-02-14 10:55:49 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 10)
2022-02-14 10:55:49 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_8.0, runningTasks: 1
2022-02-14 10:55:49 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:55:49 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:55:49 DEBUG CodeGenerator:61 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:55:49 INFO  MemoryStore:57 - Block broadcast_21 stored as values in memory (estimated size 15.6 KiB, free 2.2 GiB)
2022-02-14 10:55:49 DEBUG BlockManager:61 - Put block broadcast_21 locally took 1 ms
2022-02-14 10:55:49 DEBUG BlockManager:61 - Putting block broadcast_21 without replication took 1 ms
2022-02-14 10:55:49 INFO  MemoryStore:57 - Block broadcast_21_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 2.2 GiB)
2022-02-14 10:55:49 INFO  BlockManagerInfo:57 - Added broadcast_21_piece0 in memory on Clairvoyant-320:60340 (size: 7.7 KiB, free: 2.2 GiB)
2022-02-14 10:55:49 INFO  CodeGenerator:57 - Code generated in 70.8163 ms
2022-02-14 10:55:49 INFO  HashAggregateExec:57 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2022-02-14 10:55:49 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_21_piece0
2022-02-14 10:55:49 DEBUG BlockManager:61 - Told master about block broadcast_21_piece0
2022-02-14 10:55:49 DEBUG BlockManager:61 - Put block broadcast_21_piece0 locally took 20 ms
2022-02-14 10:55:49 DEBUG BlockManager:61 - Putting block broadcast_21_piece0 without replication took 20 ms
2022-02-14 10:55:49 INFO  SparkContext:57 - Created broadcast 21 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:55:49 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[51] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
2022-02-14 10:55:49 INFO  TaskSchedulerImpl:57 - Adding task set 10.0 with 1 tasks
2022-02-14 10:55:49 DEBUG TaskSetManager:61 - Epoch for TaskSet 10.0: 0
2022-02-14 10:55:49 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-02-14 10:55:49 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 10.0: NO_PREF, ANY
2022-02-14 10:55:49 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_8.0, runningTasks: 1
2022-02-14 10:55:49 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:55:49 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_10.0, runningTasks: 0
2022-02-14 10:55:49 INFO  CodeGenerator:57 - Code generated in 55.87 ms
2022-02-14 10:55:49 DEBUG BlockManager:61 - Getting local block broadcast_16
2022-02-14 10:55:49 DEBUG BlockManager:61 - Level for block broadcast_16 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:49 DEBUG GeneratePredicate:61 - Generated predicate 'isnotnull(input[0, int, true])':
/* 001 */ public SpecificPredicate generate(Object[] references) {
/* 002 */   return new SpecificPredicate(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificPredicate extends org.apache.spark.sql.catalyst.expressions.BasePredicate {
/* 006 */   private final Object[] references;
/* 007 */
/* 008 */
/* 009 */   public SpecificPredicate(Object[] references) {
/* 010 */     this.references = references;
/* 011 */
/* 012 */   }
/* 013 */
/* 014 */   public void initialize(int partitionIndex) {
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public boolean eval(InternalRow i) {
/* 019 */     boolean isNull_1 = i.isNullAt(0);
/* 020 */     int value_1 = isNull_1 ?
/* 021 */     -1 : (i.getInt(0));
/* 022 */     boolean value_2 = !isNull_1;
/* 023 */     return !false && value_2;
/* 024 */   }
/* 025 */
/* 026 */
/* 027 */ }

2022-02-14 10:55:49 DEBUG CodeGenerator:61 - 
/* 001 */ public SpecificPredicate generate(Object[] references) {
/* 002 */   return new SpecificPredicate(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificPredicate extends org.apache.spark.sql.catalyst.expressions.BasePredicate {
/* 006 */   private final Object[] references;
/* 007 */
/* 008 */
/* 009 */   public SpecificPredicate(Object[] references) {
/* 010 */     this.references = references;
/* 011 */
/* 012 */   }
/* 013 */
/* 014 */   public void initialize(int partitionIndex) {
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public boolean eval(InternalRow i) {
/* 019 */     boolean isNull_1 = i.isNullAt(0);
/* 020 */     int value_1 = isNull_1 ?
/* 021 */     -1 : (i.getInt(0));
/* 022 */     boolean value_2 = !isNull_1;
/* 023 */     return !false && value_2;
/* 024 */   }
/* 025 */
/* 026 */
/* 027 */ }

2022-02-14 10:55:49 INFO  CodeGenerator:57 - Code generated in 8.193299 ms
2022-02-14 10:55:49 DEBUG GeneratePredicate:61 - Generated predicate 'isnotnull(input[1, int, true])':
/* 001 */ public SpecificPredicate generate(Object[] references) {
/* 002 */   return new SpecificPredicate(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificPredicate extends org.apache.spark.sql.catalyst.expressions.BasePredicate {
/* 006 */   private final Object[] references;
/* 007 */
/* 008 */
/* 009 */   public SpecificPredicate(Object[] references) {
/* 010 */     this.references = references;
/* 011 */
/* 012 */   }
/* 013 */
/* 014 */   public void initialize(int partitionIndex) {
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public boolean eval(InternalRow i) {
/* 019 */     boolean isNull_1 = i.isNullAt(1);
/* 020 */     int value_1 = isNull_1 ?
/* 021 */     -1 : (i.getInt(1));
/* 022 */     boolean value_2 = !isNull_1;
/* 023 */     return !false && value_2;
/* 024 */   }
/* 025 */
/* 026 */
/* 027 */ }

2022-02-14 10:55:49 DEBUG CodeGenerator:61 - 
/* 001 */ public SpecificPredicate generate(Object[] references) {
/* 002 */   return new SpecificPredicate(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificPredicate extends org.apache.spark.sql.catalyst.expressions.BasePredicate {
/* 006 */   private final Object[] references;
/* 007 */
/* 008 */
/* 009 */   public SpecificPredicate(Object[] references) {
/* 010 */     this.references = references;
/* 011 */
/* 012 */   }
/* 013 */
/* 014 */   public void initialize(int partitionIndex) {
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public boolean eval(InternalRow i) {
/* 019 */     boolean isNull_1 = i.isNullAt(1);
/* 020 */     int value_1 = isNull_1 ?
/* 021 */     -1 : (i.getInt(1));
/* 022 */     boolean value_2 = !isNull_1;
/* 023 */     return !false && value_2;
/* 024 */   }
/* 025 */
/* 026 */
/* 027 */ }

2022-02-14 10:55:49 INFO  CodeGenerator:57 - Code generated in 10.131399 ms
2022-02-14 10:55:49 INFO  Executor:57 - Finished task 0.0 in stage 8.0 (TID 8). 9392 bytes result sent to driver
2022-02-14 10:55:49 DEBUG ExecutorMetricsPoller:61 - removing (8, 0) from stageTCMP
2022-02-14 10:55:49 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_8.0, runningTasks: 0
2022-02-14 10:55:49 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:55:49 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_10.0, runningTasks: 0
2022-02-14 10:55:49 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-14 10:55:49 INFO  TaskSetManager:57 - Starting task 0.0 in stage 9.0 (TID 9, Clairvoyant-320, executor driver, partition 0, PROCESS_LOCAL, 7805 bytes)
2022-02-14 10:55:49 INFO  Executor:57 - Running task 0.0 in stage 9.0 (TID 9)
2022-02-14 10:55:49 INFO  TaskSetManager:57 - Finished task 0.0 in stage 8.0 (TID 8) in 238 ms on Clairvoyant-320 (executor driver) (1/1)
2022-02-14 10:55:49 INFO  TaskSchedulerImpl:57 - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2022-02-14 10:55:49 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-02-14 10:55:49 INFO  DAGScheduler:57 - ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.266 s
2022-02-14 10:55:49 DEBUG DAGScheduler:61 - After removal of stage 8, remaining stages = 2
2022-02-14 10:55:49 INFO  DAGScheduler:57 - Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
2022-02-14 10:55:49 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 8: Stage finished
2022-02-14 10:55:49 INFO  DAGScheduler:57 - Job 8 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.270120 s
2022-02-14 10:55:49 DEBUG BlockManager:61 - Getting local block broadcast_20
2022-02-14 10:55:49 DEBUG BlockManager:61 - Level for block broadcast_20 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:49 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/src/main/resources/retail_db/categories/part-00000, range: 0-1078, partition values: [empty row]
2022-02-14 10:55:49 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:49 DEBUG CodeGenerator:61 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:49 DEBUG TaskMemoryManager:228 - Task 0 acquired 1056.0 KiB for org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@4050dd3b
2022-02-14 10:55:49 INFO  CodeGenerator:57 - Code generated in 31.6047 ms
2022-02-14 10:55:49 DEBUG GenerateUnsafeProjection:61 - code for cast(input[0, int, true] as bigint):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     boolean isNull_0 = isNull_1;
/* 035 */     long value_0 = -1L;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-02-14 10:55:49 DEBUG CodeGenerator:61 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     boolean isNull_0 = isNull_1;
/* 035 */     long value_0 = -1L;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-02-14 10:55:49 DEBUG BlockManager:61 - Getting local block broadcast_17
2022-02-14 10:55:49 DEBUG BlockManager:61 - Level for block broadcast_17 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:49 DEBUG GeneratePredicate:61 - Generated predicate 'isnotnull(input[0, int, true])':
/* 001 */ public SpecificPredicate generate(Object[] references) {
/* 002 */   return new SpecificPredicate(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificPredicate extends org.apache.spark.sql.catalyst.expressions.BasePredicate {
/* 006 */   private final Object[] references;
/* 007 */
/* 008 */
/* 009 */   public SpecificPredicate(Object[] references) {
/* 010 */     this.references = references;
/* 011 */
/* 012 */   }
/* 013 */
/* 014 */   public void initialize(int partitionIndex) {
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public boolean eval(InternalRow i) {
/* 019 */     boolean isNull_1 = i.isNullAt(0);
/* 020 */     int value_1 = isNull_1 ?
/* 021 */     -1 : (i.getInt(0));
/* 022 */     boolean value_2 = !isNull_1;
/* 023 */     return !false && value_2;
/* 024 */   }
/* 025 */
/* 026 */
/* 027 */ }

2022-02-14 10:55:49 INFO  Executor:57 - Finished task 0.0 in stage 9.0 (TID 9). 2943 bytes result sent to driver
2022-02-14 10:55:49 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-02-14 10:55:49 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-14 10:55:49 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_10.0, runningTasks: 0
2022-02-14 10:55:49 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-14 10:55:49 INFO  TaskSetManager:57 - Starting task 0.0 in stage 10.0 (TID 10, Clairvoyant-320, executor driver, partition 0, PROCESS_LOCAL, 7801 bytes)
2022-02-14 10:55:49 INFO  TaskSetManager:57 - Finished task 0.0 in stage 9.0 (TID 9) in 87 ms on Clairvoyant-320 (executor driver) (1/1)
2022-02-14 10:55:49 INFO  Executor:57 - Running task 0.0 in stage 10.0 (TID 10)
2022-02-14 10:55:49 INFO  TaskSchedulerImpl:57 - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2022-02-14 10:55:49 INFO  CodeGenerator:57 - Code generated in 31.107199 ms
2022-02-14 10:55:49 INFO  DAGScheduler:57 - ResultStage 9 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.319 s
2022-02-14 10:55:49 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (10, 0) -> 1
2022-02-14 10:55:49 DEBUG DAGScheduler:61 - After removal of stage 9, remaining stages = 1
2022-02-14 10:55:49 INFO  DAGScheduler:57 - Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
2022-02-14 10:55:49 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 9: Stage finished
2022-02-14 10:55:49 INFO  DAGScheduler:57 - Job 9 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.342196 s
2022-02-14 10:55:49 DEBUG BlockManager:61 - Getting local block broadcast_21
2022-02-14 10:55:49 DEBUG BlockManager:61 - Level for block broadcast_21 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:49 DEBUG TaskMemoryManager:228 - Task 0 acquired 1025.0 KiB for org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@4511321c
2022-02-14 10:55:49 DEBUG GenerateUnsafeProjection:61 - code for cast(input[0, int, true] as bigint):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     boolean isNull_0 = isNull_1;
/* 035 */     long value_0 = -1L;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-02-14 10:55:49 DEBUG TaskMemoryManager:228 - Task 0 acquired 2.0 KiB for org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@4511321c
2022-02-14 10:55:49 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/src/main/resources/retail_db/orders/part-00000, range: 0-2999995, partition values: [empty row]
2022-02-14 10:55:49 DEBUG TaskMemoryManager:237 - Task 0 release 1024.0 B from org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@4511321c
2022-02-14 10:55:49 DEBUG TaskMemoryManager:228 - Task 0 acquired 64.0 KiB for org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@4050dd3b
2022-02-14 10:55:49 DEBUG TaskMemoryManager:228 - Task 0 acquired 464.0 B for org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@4511321c
2022-02-14 10:55:49 DEBUG TaskMemoryManager:237 - Task 0 release 2.0 KiB from org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@4511321c
2022-02-14 10:55:49 DEBUG TaskMemoryManager:237 - Task 0 release 32.0 KiB from org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@4050dd3b
2022-02-14 10:55:49 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, string, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 64);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:49 DEBUG TaskMemoryManager:228 - Task 0 acquired 10.5 KiB for org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@4050dd3b
2022-02-14 10:55:49 DEBUG TaskMemoryManager:237 - Task 0 release 64.0 KiB from org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@4050dd3b
2022-02-14 10:55:49 INFO  MemoryStore:57 - Block broadcast_23 stored as values in memory (estimated size 1034.5 KiB, free 2.2 GiB)
2022-02-14 10:55:49 DEBUG BlockManager:61 - Put block broadcast_23 locally took 2 ms
2022-02-14 10:55:49 DEBUG BlockManager:61 - Putting block broadcast_23 without replication took 3 ms
2022-02-14 10:55:49 INFO  MemoryStore:57 - Block broadcast_22 stored as values in memory (estimated size 1024.5 KiB, free 2.2 GiB)
2022-02-14 10:55:49 DEBUG CodeGenerator:61 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 64);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:49 DEBUG BlockManager:61 - Put block broadcast_22 locally took 13 ms
2022-02-14 10:55:49 DEBUG BlockManager:61 - Putting block broadcast_22 without replication took 13 ms
2022-02-14 10:55:49 INFO  MemoryStore:57 - Block broadcast_23_piece0 stored as bytes in memory (estimated size 14.4 KiB, free 2.2 GiB)
2022-02-14 10:55:49 INFO  MemoryStore:57 - Block broadcast_22_piece0 stored as bytes in memory (estimated size 1902.0 B, free 2.2 GiB)
2022-02-14 10:55:49 INFO  BlockManagerInfo:57 - Added broadcast_23_piece0 in memory on Clairvoyant-320:60340 (size: 14.4 KiB, free: 2.2 GiB)
2022-02-14 10:55:49 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_23_piece0
2022-02-14 10:55:49 DEBUG BlockManager:61 - Told master about block broadcast_23_piece0
2022-02-14 10:55:49 DEBUG BlockManager:61 - Put block broadcast_23_piece0 locally took 10 ms
2022-02-14 10:55:49 INFO  BlockManagerInfo:57 - Added broadcast_22_piece0 in memory on Clairvoyant-320:60340 (size: 1902.0 B, free: 2.2 GiB)
2022-02-14 10:55:49 DEBUG BlockManager:61 - Putting block broadcast_23_piece0 without replication took 10 ms
2022-02-14 10:55:49 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_22_piece0
2022-02-14 10:55:49 INFO  SparkContext:57 - Created broadcast 23 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
2022-02-14 10:55:49 DEBUG BlockManager:61 - Told master about block broadcast_22_piece0
2022-02-14 10:55:49 DEBUG BlockManager:61 - Put block broadcast_22_piece0 locally took 11 ms
2022-02-14 10:55:49 DEBUG BlockManager:61 - Putting block broadcast_22_piece0 without replication took 11 ms
2022-02-14 10:55:49 INFO  SparkContext:57 - Created broadcast 22 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
2022-02-14 10:55:49 INFO  CodeGenerator:57 - Code generated in 28.080301 ms
2022-02-14 10:55:49 DEBUG BlockManager:61 - Getting local block broadcast_18
2022-02-14 10:55:49 DEBUG BlockManager:61 - Level for block broadcast_18 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:49 DEBUG GeneratePredicate:61 - Generated predicate 'isnotnull(input[0, int, true])':
/* 001 */ public SpecificPredicate generate(Object[] references) {
/* 002 */   return new SpecificPredicate(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificPredicate extends org.apache.spark.sql.catalyst.expressions.BasePredicate {
/* 006 */   private final Object[] references;
/* 007 */
/* 008 */
/* 009 */   public SpecificPredicate(Object[] references) {
/* 010 */     this.references = references;
/* 011 */
/* 012 */   }
/* 013 */
/* 014 */   public void initialize(int partitionIndex) {
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public boolean eval(InternalRow i) {
/* 019 */     boolean isNull_1 = i.isNullAt(0);
/* 020 */     int value_1 = isNull_1 ?
/* 021 */     -1 : (i.getInt(0));
/* 022 */     boolean value_2 = !isNull_1;
/* 023 */     return !false && value_2;
/* 024 */   }
/* 025 */
/* 026 */
/* 027 */ }

2022-02-14 10:55:49 DEBUG GeneratePredicate:61 - Generated predicate 'input[2, string, true] IN (COMPLETE,CLOSED)':
/* 001 */ public SpecificPredicate generate(Object[] references) {
/* 002 */   return new SpecificPredicate(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificPredicate extends org.apache.spark.sql.catalyst.expressions.BasePredicate {
/* 006 */   private final Object[] references;
/* 007 */
/* 008 */
/* 009 */   public SpecificPredicate(Object[] references) {
/* 010 */     this.references = references;
/* 011 */
/* 012 */   }
/* 013 */
/* 014 */   public void initialize(int partitionIndex) {
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public boolean eval(InternalRow i) {
/* 019 */     boolean isNull_1 = i.isNullAt(2);
/* 020 */     UTF8String value_1 = isNull_1 ?
/* 021 */     null : (i.getUTF8String(2));
/* 022 */     byte inTmpResult_0 = -1;
/* 023 */     if (!isNull_1) {
/* 024 */       inTmpResult_0 = 0;
/* 025 */       UTF8String valueArg_0 = value_1;
/* 026 */       do {
/* 027 */
/* 028 */
/* 029 */         if (false) {
/* 030 */           inTmpResult_0 = -1; // isNull_0 = true;
/* 031 */         } else if (valueArg_0.equals(((UTF8String) references[0] /* literal */))) {
/* 032 */           inTmpResult_0 = 1; // isNull_0 = false; value_0 = true;
/* 033 */           continue;
/* 034 */         }
/* 035 */
/* 036 */
/* 037 */         if (false) {
/* 038 */           inTmpResult_0 = -1; // isNull_0 = true;
/* 039 */         } else if (valueArg_0.equals(((UTF8String) references[1] /* literal */))) {
/* 040 */           inTmpResult_0 = 1; // isNull_0 = false; value_0 = true;
/* 041 */           continue;
/* 042 */         }
/* 043 */
/* 044 */       } while (false);
/* 045 */     }
/* 046 */     final boolean isNull_0 = (inTmpResult_0 == -1);
/* 047 */     final boolean value_0 = (inTmpResult_0 == 1);
/* 048 */     return !isNull_0 && value_0;
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:55:49 DEBUG CodeGenerator:61 - 
/* 001 */ public SpecificPredicate generate(Object[] references) {
/* 002 */   return new SpecificPredicate(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificPredicate extends org.apache.spark.sql.catalyst.expressions.BasePredicate {
/* 006 */   private final Object[] references;
/* 007 */
/* 008 */
/* 009 */   public SpecificPredicate(Object[] references) {
/* 010 */     this.references = references;
/* 011 */
/* 012 */   }
/* 013 */
/* 014 */   public void initialize(int partitionIndex) {
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public boolean eval(InternalRow i) {
/* 019 */     boolean isNull_1 = i.isNullAt(2);
/* 020 */     UTF8String value_1 = isNull_1 ?
/* 021 */     null : (i.getUTF8String(2));
/* 022 */     byte inTmpResult_0 = -1;
/* 023 */     if (!isNull_1) {
/* 024 */       inTmpResult_0 = 0;
/* 025 */       UTF8String valueArg_0 = value_1;
/* 026 */       do {
/* 027 */
/* 028 */
/* 029 */         if (false) {
/* 030 */           inTmpResult_0 = -1; // isNull_0 = true;
/* 031 */         } else if (valueArg_0.equals(((UTF8String) references[0] /* literal */))) {
/* 032 */           inTmpResult_0 = 1; // isNull_0 = false; value_0 = true;
/* 033 */           continue;
/* 034 */         }
/* 035 */
/* 036 */
/* 037 */         if (false) {
/* 038 */           inTmpResult_0 = -1; // isNull_0 = true;
/* 039 */         } else if (valueArg_0.equals(((UTF8String) references[1] /* literal */))) {
/* 040 */           inTmpResult_0 = 1; // isNull_0 = false; value_0 = true;
/* 041 */           continue;
/* 042 */         }
/* 043 */
/* 044 */       } while (false);
/* 045 */     }
/* 046 */     final boolean isNull_0 = (inTmpResult_0 == -1);
/* 047 */     final boolean value_0 = (inTmpResult_0 == 1);
/* 048 */     return !isNull_0 && value_0;
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:55:49 INFO  CodeGenerator:57 - Code generated in 16.704599 ms
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(455)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 455
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 455
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(417)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 417
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 417
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(435)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 435
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 435
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(299)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 299
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 299
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(422)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 422
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 422
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(424)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 424
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 424
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(288)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 288
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 288
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(411)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 411
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 411
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(296)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 296
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 296
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(332)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 332
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 332
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(297)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 297
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 297
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(443)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 443
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 443
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(440)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 440
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 440
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(280)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 280
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 280
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(281)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 281
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 281
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(329)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 329
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 329
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(420)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 420
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 420
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(421)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 421
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 421
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(334)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 334
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 334
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(456)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 456
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 456
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(290)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 290
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 290
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(407)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 407
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 407
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(284)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 284
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 284
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(324)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 324
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 324
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(298)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 298
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 298
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(287)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 287
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 287
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(448)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 448
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 448
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(295)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 295
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 295
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(452)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 452
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 452
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(436)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 436
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 436
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(441)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 441
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 441
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(449)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 449
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 449
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(451)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 451
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 451
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(419)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 419
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 419
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(418)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 418
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 418
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(433)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 433
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 433
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(423)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 423
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 423
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(326)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 326
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 326
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(292)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 292
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 292
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(293)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 293
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 293
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(328)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 328
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 328
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(425)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 425
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 425
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(333)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 333
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 333
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(431)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 431
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 431
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(300)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 300
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 300
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(331)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 331
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 331
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(291)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 291
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 291
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(408)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 408
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 408
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(428)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 428
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 428
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(434)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 434
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 434
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(442)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 442
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 442
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(285)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 285
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 285
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(413)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 413
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 413
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(19)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning broadcast 19
2022-02-14 10:55:49 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 19
2022-02-14 10:55:49 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 19
2022-02-14 10:55:49 DEBUG BlockManager:61 - Removing broadcast 19
2022-02-14 10:55:49 DEBUG BlockManager:61 - Removing block broadcast_19_piece0
2022-02-14 10:55:49 DEBUG MemoryStore:61 - Block broadcast_19_piece0 of size 6488 dropped from memory (free 2345191247)
2022-02-14 10:55:49 INFO  BlockManagerInfo:57 - Removed broadcast_19_piece0 on Clairvoyant-320:60340 in memory (size: 6.3 KiB, free: 2.2 GiB)
2022-02-14 10:55:49 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_19_piece0
2022-02-14 10:55:49 DEBUG BlockManager:61 - Told master about block broadcast_19_piece0
2022-02-14 10:55:49 DEBUG BlockManager:61 - Removing block broadcast_19
2022-02-14 10:55:49 DEBUG MemoryStore:61 - Block broadcast_19 of size 12960 dropped from memory (free 2345204207)
2022-02-14 10:55:49 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 19, response is 0
2022-02-14 10:55:49 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60325
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned broadcast 19
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(325)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 325
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 325
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(282)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 282
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 282
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(427)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 427
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 427
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(429)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 429
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 429
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(283)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 283
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 283
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(446)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 446
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 446
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(432)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 432
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 432
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(20)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning broadcast 20
2022-02-14 10:55:49 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 20
2022-02-14 10:55:49 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 20
2022-02-14 10:55:49 DEBUG BlockManager:61 - Removing broadcast 20
2022-02-14 10:55:49 DEBUG BlockManager:61 - Removing block broadcast_20_piece0
2022-02-14 10:55:49 DEBUG MemoryStore:61 - Block broadcast_20_piece0 of size 6564 dropped from memory (free 2345210771)
2022-02-14 10:55:49 INFO  BlockManagerInfo:57 - Removed broadcast_20_piece0 on Clairvoyant-320:60340 in memory (size: 6.4 KiB, free: 2.2 GiB)
2022-02-14 10:55:49 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_20_piece0
2022-02-14 10:55:49 DEBUG BlockManager:61 - Told master about block broadcast_20_piece0
2022-02-14 10:55:49 DEBUG BlockManager:61 - Removing block broadcast_20
2022-02-14 10:55:49 DEBUG MemoryStore:61 - Block broadcast_20 of size 13160 dropped from memory (free 2345223931)
2022-02-14 10:55:49 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 20, response is 0
2022-02-14 10:55:49 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60325
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned broadcast 20
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(426)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 426
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 426
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(286)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 286
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 286
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(415)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 415
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 415
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(301)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 301
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 301
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(430)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 430
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 430
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(450)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 450
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 450
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(438)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 438
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 438
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(454)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 454
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 454
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(453)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 453
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 453
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(445)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 445
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 445
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(294)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 294
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 294
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(410)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 410
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 410
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(409)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 409
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 409
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(447)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 447
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 447
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(439)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 439
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 439
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(289)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 289
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 289
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(437)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 437
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 437
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(327)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 327
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 327
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(416)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 416
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 416
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(412)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 412
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 412
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(444)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 444
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 444
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(414)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 414
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 414
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(330)
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaning accumulator 330
2022-02-14 10:55:49 DEBUG ContextCleaner:61 - Cleaned accumulator 330
2022-02-14 10:55:50 INFO  Executor:57 - Finished task 0.0 in stage 10.0 (TID 10). 14526 bytes result sent to driver
2022-02-14 10:55:50 DEBUG ExecutorMetricsPoller:61 - removing (10, 0) from stageTCMP
2022-02-14 10:55:50 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_10.0, runningTasks: 0
2022-02-14 10:55:50 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-14 10:55:50 INFO  TaskSetManager:57 - Finished task 0.0 in stage 10.0 (TID 10) in 574 ms on Clairvoyant-320 (executor driver) (1/1)
2022-02-14 10:55:50 INFO  TaskSchedulerImpl:57 - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2022-02-14 10:55:50 INFO  DAGScheduler:57 - ResultStage 10 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.859 s
2022-02-14 10:55:50 DEBUG DAGScheduler:61 - After removal of stage 10, remaining stages = 0
2022-02-14 10:55:50 INFO  DAGScheduler:57 - Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
2022-02-14 10:55:50 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 10: Stage finished
2022-02-14 10:55:50 INFO  DAGScheduler:57 - Job 10 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.910905 s
2022-02-14 10:55:50 DEBUG TaskMemoryManager:228 - Task 0 acquired 1088.0 KiB for org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@56426f54
2022-02-14 10:55:50 DEBUG GenerateUnsafeProjection:61 - code for cast(input[0, int, true] as bigint):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     boolean isNull_0 = isNull_1;
/* 035 */     long value_0 = -1L;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-02-14 10:55:50 DEBUG TaskMemoryManager:228 - Task 0 acquired 128.0 KiB for org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@56426f54
2022-02-14 10:55:50 DEBUG TaskMemoryManager:237 - Task 0 release 64.0 KiB from org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@56426f54
2022-02-14 10:55:50 INFO  MemoryStore:57 - Block broadcast_24 stored as values in memory (estimated size 1152.0 KiB, free 2.2 GiB)
2022-02-14 10:55:50 DEBUG BlockManager:61 - Put block broadcast_24 locally took 5 ms
2022-02-14 10:55:50 DEBUG BlockManager:61 - Putting block broadcast_24 without replication took 6 ms
2022-02-14 10:55:50 INFO  MemoryStore:57 - Block broadcast_24_piece0 stored as bytes in memory (estimated size 39.4 KiB, free 2.2 GiB)
2022-02-14 10:55:50 INFO  BlockManagerInfo:57 - Added broadcast_24_piece0 in memory on Clairvoyant-320:60340 (size: 39.4 KiB, free: 2.2 GiB)
2022-02-14 10:55:50 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_24_piece0
2022-02-14 10:55:50 DEBUG BlockManager:61 - Told master about block broadcast_24_piece0
2022-02-14 10:55:50 DEBUG BlockManager:61 - Put block broadcast_24_piece0 locally took 7 ms
2022-02-14 10:55:50 DEBUG BlockManager:61 - Putting block broadcast_24_piece0 without replication took 7 ms
2022-02-14 10:55:50 INFO  SparkContext:57 - Created broadcast 24 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
2022-02-14 10:55:50 DEBUG BlockManager:61 - Getting local block broadcast_24
2022-02-14 10:55:50 DEBUG BlockManager:61 - Level for block broadcast_24 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:50 DEBUG BlockManager:61 - Getting local block broadcast_23
2022-02-14 10:55:50 DEBUG BlockManager:61 - Level for block broadcast_23 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:50 DEBUG BlockManager:61 - Getting local block broadcast_22
2022-02-14 10:55:50 DEBUG BlockManager:61 - Level for block broadcast_22 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:50 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage4(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=4
/* 006 */ final class GeneratedIteratorForCodegenStage4 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private org.apache.spark.unsafe.KVIterator agg_mapIter_0;
/* 011 */   private org.apache.spark.sql.execution.UnsafeFixedWidthAggregationMap agg_hashMap_0;
/* 012 */   private org.apache.spark.sql.execution.UnsafeKVExternalSorter agg_sorter_0;
/* 013 */   private scala.collection.Iterator inputadapter_input_0;
/* 014 */   private org.apache.spark.sql.execution.joins.LongHashedRelation bhj_relation_0;
/* 015 */   private org.apache.spark.sql.execution.joins.LongHashedRelation bhj_relation_1;
/* 016 */   private org.apache.spark.sql.execution.joins.LongHashedRelation bhj_relation_2;
/* 017 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[13];
/* 018 */
/* 019 */   public GeneratedIteratorForCodegenStage4(Object[] references) {
/* 020 */     this.references = references;
/* 021 */   }
/* 022 */
/* 023 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 024 */     partitionIndex = index;
/* 025 */     this.inputs = inputs;
/* 026 */     wholestagecodegen_init_0_0();
/* 027 */     wholestagecodegen_init_0_1();
/* 028 */
/* 029 */   }
/* 030 */
/* 031 */   private void bhj_doConsume_1(int bhj_expr_0_1, boolean bhj_exprIsNull_0_1) throws java.io.IOException {
/* 032 */     // generate join key for stream side
/* 033 */     boolean bhj_isNull_15 = bhj_exprIsNull_0_1;
/* 034 */     long bhj_value_15 = -1L;
/* 035 */     if (!bhj_exprIsNull_0_1) {
/* 036 */       bhj_value_15 = (long) bhj_expr_0_1;
/* 037 */     }
/* 038 */     // find matches from HashedRelation
/* 039 */     UnsafeRow bhj_matched_2 = bhj_isNull_15 ? null: (UnsafeRow)bhj_relation_2.getValue(bhj_value_15);
/* 040 */     if (bhj_matched_2 != null) {
/* 041 */       {
/* 042 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[10] /* numOutputRows */).add(1);
/* 043 */
/* 044 */         boolean bhj_isNull_17 = bhj_matched_2.isNullAt(0);
/* 045 */         int bhj_value_17 = bhj_isNull_17 ?
/* 046 */         -1 : (bhj_matched_2.getInt(0));
/* 047 */         boolean bhj_isNull_18 = bhj_matched_2.isNullAt(1);
/* 048 */         int bhj_value_18 = bhj_isNull_18 ?
/* 049 */         -1 : (bhj_matched_2.getInt(1));
/* 050 */         boolean bhj_isNull_19 = bhj_matched_2.isNullAt(2);
/* 051 */         UTF8String bhj_value_19 = bhj_isNull_19 ?
/* 052 */         null : (bhj_matched_2.getUTF8String(2));
/* 053 */
/* 054 */         agg_doConsume_0(bhj_value_17, bhj_isNull_17, bhj_value_18, bhj_isNull_18, bhj_value_19, bhj_isNull_19);
/* 055 */
/* 056 */       }
/* 057 */     }
/* 058 */
/* 059 */   }
/* 060 */
/* 061 */   private void agg_doAggregateWithKeysOutput_0(UnsafeRow agg_keyTerm_0, UnsafeRow agg_bufferTerm_0)
/* 062 */   throws java.io.IOException {
/* 063 */     ((org.apache.spark.sql.execution.metric.SQLMetric) references[11] /* numOutputRows */).add(1);
/* 064 */
/* 065 */     boolean agg_isNull_9 = agg_keyTerm_0.isNullAt(0);
/* 066 */     int agg_value_9 = agg_isNull_9 ?
/* 067 */     -1 : (agg_keyTerm_0.getInt(0));
/* 068 */     boolean agg_isNull_10 = agg_keyTerm_0.isNullAt(1);
/* 069 */     int agg_value_10 = agg_isNull_10 ?
/* 070 */     -1 : (agg_keyTerm_0.getInt(1));
/* 071 */     boolean agg_isNull_11 = agg_keyTerm_0.isNullAt(2);
/* 072 */     UTF8String agg_value_11 = agg_isNull_11 ?
/* 073 */     null : (agg_keyTerm_0.getUTF8String(2));
/* 074 */     filter_mutableStateArray_0[12].reset();
/* 075 */
/* 076 */     filter_mutableStateArray_0[12].zeroOutNullBytes();
/* 077 */
/* 078 */     if (agg_isNull_9) {
/* 079 */       filter_mutableStateArray_0[12].setNullAt(0);
/* 080 */     } else {
/* 081 */       filter_mutableStateArray_0[12].write(0, agg_value_9);
/* 082 */     }
/* 083 */
/* 084 */     if (agg_isNull_10) {
/* 085 */       filter_mutableStateArray_0[12].setNullAt(1);
/* 086 */     } else {
/* 087 */       filter_mutableStateArray_0[12].write(1, agg_value_10);
/* 088 */     }
/* 089 */
/* 090 */     if (agg_isNull_11) {
/* 091 */       filter_mutableStateArray_0[12].setNullAt(2);
/* 092 */     } else {
/* 093 */       filter_mutableStateArray_0[12].write(2, agg_value_11);
/* 094 */     }
/* 095 */     append((filter_mutableStateArray_0[12].getRow()));
/* 096 */
/* 097 */   }
/* 098 */
/* 099 */   private void wholestagecodegen_init_0_1() {
/* 100 */     filter_mutableStateArray_0[5] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 0);
/* 101 */     filter_mutableStateArray_0[6] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 102 */     filter_mutableStateArray_0[7] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 103 */
/* 104 */     bhj_relation_2 = ((org.apache.spark.sql.execution.joins.LongHashedRelation) ((org.apache.spark.broadcast.TorrentBroadcast) references[9] /* broadcast */).value()).asReadOnlyCopy();
/* 105 */     incPeakExecutionMemory(bhj_relation_2.estimatedSize());
/* 106 */
/* 107 */     filter_mutableStateArray_0[8] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 32);
/* 108 */     filter_mutableStateArray_0[9] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 109 */     filter_mutableStateArray_0[10] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 110 */     filter_mutableStateArray_0[11] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 111 */     filter_mutableStateArray_0[12] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 112 */
/* 113 */   }
/* 114 */
/* 115 */   private void agg_doConsume_0(int agg_expr_0_0, boolean agg_exprIsNull_0_0, int agg_expr_1_0, boolean agg_exprIsNull_1_0, UTF8String agg_expr_2_0, boolean agg_exprIsNull_2_0) throws java.io.IOException {
/* 116 */     UnsafeRow agg_unsafeRowAggBuffer_0 = null;
/* 117 */
/* 118 */     // generate grouping key
/* 119 */     filter_mutableStateArray_0[11].reset();
/* 120 */
/* 121 */     filter_mutableStateArray_0[11].zeroOutNullBytes();
/* 122 */
/* 123 */     if (agg_exprIsNull_0_0) {
/* 124 */       filter_mutableStateArray_0[11].setNullAt(0);
/* 125 */     } else {
/* 126 */       filter_mutableStateArray_0[11].write(0, agg_expr_0_0);
/* 127 */     }
/* 128 */
/* 129 */     if (agg_exprIsNull_1_0) {
/* 130 */       filter_mutableStateArray_0[11].setNullAt(1);
/* 131 */     } else {
/* 132 */       filter_mutableStateArray_0[11].write(1, agg_expr_1_0);
/* 133 */     }
/* 134 */
/* 135 */     if (agg_exprIsNull_2_0) {
/* 136 */       filter_mutableStateArray_0[11].setNullAt(2);
/* 137 */     } else {
/* 138 */       filter_mutableStateArray_0[11].write(2, agg_expr_2_0);
/* 139 */     }
/* 140 */     int agg_unsafeRowKeyHash_0 = (filter_mutableStateArray_0[11].getRow()).hashCode();
/* 141 */     if (true) {
/* 142 */       // try to get the buffer from hash map
/* 143 */       agg_unsafeRowAggBuffer_0 =
/* 144 */       agg_hashMap_0.getAggregationBufferFromUnsafeRow((filter_mutableStateArray_0[11].getRow()), agg_unsafeRowKeyHash_0);
/* 145 */     }
/* 146 */     // Can't allocate buffer from the hash map. Spill the map and fallback to sort-based
/* 147 */     // aggregation after processing all input rows.
/* 148 */     if (agg_unsafeRowAggBuffer_0 == null) {
/* 149 */       if (agg_sorter_0 == null) {
/* 150 */         agg_sorter_0 = agg_hashMap_0.destructAndCreateExternalSorter();
/* 151 */       } else {
/* 152 */         agg_sorter_0.merge(agg_hashMap_0.destructAndCreateExternalSorter());
/* 153 */       }
/* 154 */
/* 155 */       // the hash map had be spilled, it should have enough memory now,
/* 156 */       // try to allocate buffer again.
/* 157 */       agg_unsafeRowAggBuffer_0 = agg_hashMap_0.getAggregationBufferFromUnsafeRow(
/* 158 */         (filter_mutableStateArray_0[11].getRow()), agg_unsafeRowKeyHash_0);
/* 159 */       if (agg_unsafeRowAggBuffer_0 == null) {
/* 160 */         // failed to allocate the first page
/* 161 */         throw new org.apache.spark.memory.SparkOutOfMemoryError("No enough memory for aggregation");
/* 162 */       }
/* 163 */     }
/* 164 */
/* 165 */     // common sub-expressions
/* 166 */
/* 167 */     // evaluate aggregate functions and update aggregation buffers
/* 168 */
/* 169 */   }
/* 170 */
/* 171 */   private void bhj_doConsume_0(int bhj_expr_0_0, boolean bhj_exprIsNull_0_0) throws java.io.IOException {
/* 172 */     // generate join key for stream side
/* 173 */     boolean bhj_isNull_7 = bhj_exprIsNull_0_0;
/* 174 */     long bhj_value_7 = -1L;
/* 175 */     if (!bhj_exprIsNull_0_0) {
/* 176 */       bhj_value_7 = (long) bhj_expr_0_0;
/* 177 */     }
/* 178 */     // find matches from HashedRelation
/* 179 */     UnsafeRow bhj_matched_1 = bhj_isNull_7 ? null: (UnsafeRow)bhj_relation_1.getValue(bhj_value_7);
/* 180 */     if (bhj_matched_1 != null) {
/* 181 */       {
/* 182 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[8] /* numOutputRows */).add(1);
/* 183 */
/* 184 */         boolean bhj_isNull_10 = bhj_matched_1.isNullAt(1);
/* 185 */         int bhj_value_10 = bhj_isNull_10 ?
/* 186 */         -1 : (bhj_matched_1.getInt(1));
/* 187 */
/* 188 */         bhj_doConsume_1(bhj_value_10, bhj_isNull_10);
/* 189 */
/* 190 */       }
/* 191 */     }
/* 192 */
/* 193 */   }
/* 194 */
/* 195 */   private void agg_doAggregateWithKeys_0() throws java.io.IOException {
/* 196 */     while ( inputadapter_input_0.hasNext()) {
/* 197 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 198 */
/* 199 */       do {
/* 200 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 201 */         int inputadapter_value_0 = inputadapter_isNull_0 ?
/* 202 */         -1 : (inputadapter_row_0.getInt(0));
/* 203 */
/* 204 */         boolean filter_value_2 = !inputadapter_isNull_0;
/* 205 */         if (!filter_value_2) continue;
/* 206 */
/* 207 */         boolean inputadapter_isNull_1 = inputadapter_row_0.isNullAt(1);
/* 208 */         int inputadapter_value_1 = inputadapter_isNull_1 ?
/* 209 */         -1 : (inputadapter_row_0.getInt(1));
/* 210 */
/* 211 */         boolean filter_value_5 = !inputadapter_isNull_1;
/* 212 */         if (!filter_value_5) continue;
/* 213 */
/* 214 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[4] /* numOutputRows */).add(1);
/* 215 */
/* 216 */         // generate join key for stream side
/* 217 */         boolean bhj_isNull_0 = false;
/* 218 */         long bhj_value_0 = -1L;
/* 219 */         if (!false) {
/* 220 */           bhj_value_0 = (long) inputadapter_value_0;
/* 221 */         }
/* 222 */         // find matches from HashedRelation
/* 223 */         UnsafeRow bhj_matched_0 = bhj_isNull_0 ? null: (UnsafeRow)bhj_relation_0.getValue(bhj_value_0);
/* 224 */         if (bhj_matched_0 != null) {
/* 225 */           {
/* 226 */             ((org.apache.spark.sql.execution.metric.SQLMetric) references[6] /* numOutputRows */).add(1);
/* 227 */
/* 228 */             bhj_doConsume_0(inputadapter_value_1, false);
/* 229 */
/* 230 */           }
/* 231 */         }
/* 232 */
/* 233 */       } while(false);
/* 234 */       // shouldStop check is eliminated
/* 235 */     }
/* 236 */
/* 237 */     agg_mapIter_0 = ((org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0] /* plan */).finishAggregate(agg_hashMap_0, agg_sorter_0, ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* peakMemory */), ((org.apache.spark.sql.execution.metric.SQLMetric) references[2] /* spillSize */), ((org.apache.spark.sql.execution.metric.SQLMetric) references[3] /* avgHashProbe */));
/* 238 */   }
/* 239 */
/* 240 */   protected void processNext() throws java.io.IOException {
/* 241 */     if (!agg_initAgg_0) {
/* 242 */       agg_initAgg_0 = true;
/* 243 */
/* 244 */       agg_hashMap_0 = ((org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0] /* plan */).createHashMap();
/* 245 */       long wholestagecodegen_beforeAgg_0 = System.nanoTime();
/* 246 */       agg_doAggregateWithKeys_0();
/* 247 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[12] /* aggTime */).add((System.nanoTime() - wholestagecodegen_beforeAgg_0) / 1000000);
/* 248 */     }
/* 249 */     // output the result
/* 250 */
/* 251 */     while ( agg_mapIter_0.next()) {
/* 252 */       UnsafeRow agg_aggKey_0 = (UnsafeRow) agg_mapIter_0.getKey();
/* 253 */       UnsafeRow agg_aggBuffer_0 = (UnsafeRow) agg_mapIter_0.getValue();
/* 254 */       agg_doAggregateWithKeysOutput_0(agg_aggKey_0, agg_aggBuffer_0);
/* 255 */       if (shouldStop()) return;
/* 256 */     }
/* 257 */     agg_mapIter_0.close();
/* 258 */     if (agg_sorter_0 == null) {
/* 259 */       agg_hashMap_0.free();
/* 260 */     }
/* 261 */   }
/* 262 */
/* 263 */   private void wholestagecodegen_init_0_0() {
/* 264 */     inputadapter_input_0 = inputs[0];
/* 265 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 0);
/* 266 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 0);
/* 267 */
/* 268 */     bhj_relation_0 = ((org.apache.spark.sql.execution.joins.LongHashedRelation) ((org.apache.spark.broadcast.TorrentBroadcast) references[5] /* broadcast */).value()).asReadOnlyCopy();
/* 269 */     incPeakExecutionMemory(bhj_relation_0.estimatedSize());
/* 270 */
/* 271 */     filter_mutableStateArray_0[2] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 0);
/* 272 */     filter_mutableStateArray_0[3] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 273 */     filter_mutableStateArray_0[4] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 274 */
/* 275 */     bhj_relation_1 = ((org.apache.spark.sql.execution.joins.LongHashedRelation) ((org.apache.spark.broadcast.TorrentBroadcast) references[7] /* broadcast */).value()).asReadOnlyCopy();
/* 276 */     incPeakExecutionMemory(bhj_relation_1.estimatedSize());
/* 277 */
/* 278 */   }
/* 279 */
/* 280 */ }

2022-02-14 10:55:50 DEBUG CodeGenerator:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage4(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=4
/* 006 */ final class GeneratedIteratorForCodegenStage4 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private org.apache.spark.unsafe.KVIterator agg_mapIter_0;
/* 011 */   private org.apache.spark.sql.execution.UnsafeFixedWidthAggregationMap agg_hashMap_0;
/* 012 */   private org.apache.spark.sql.execution.UnsafeKVExternalSorter agg_sorter_0;
/* 013 */   private scala.collection.Iterator inputadapter_input_0;
/* 014 */   private org.apache.spark.sql.execution.joins.LongHashedRelation bhj_relation_0;
/* 015 */   private org.apache.spark.sql.execution.joins.LongHashedRelation bhj_relation_1;
/* 016 */   private org.apache.spark.sql.execution.joins.LongHashedRelation bhj_relation_2;
/* 017 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[13];
/* 018 */
/* 019 */   public GeneratedIteratorForCodegenStage4(Object[] references) {
/* 020 */     this.references = references;
/* 021 */   }
/* 022 */
/* 023 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 024 */     partitionIndex = index;
/* 025 */     this.inputs = inputs;
/* 026 */     wholestagecodegen_init_0_0();
/* 027 */     wholestagecodegen_init_0_1();
/* 028 */
/* 029 */   }
/* 030 */
/* 031 */   private void bhj_doConsume_1(int bhj_expr_0_1, boolean bhj_exprIsNull_0_1) throws java.io.IOException {
/* 032 */     // generate join key for stream side
/* 033 */     boolean bhj_isNull_15 = bhj_exprIsNull_0_1;
/* 034 */     long bhj_value_15 = -1L;
/* 035 */     if (!bhj_exprIsNull_0_1) {
/* 036 */       bhj_value_15 = (long) bhj_expr_0_1;
/* 037 */     }
/* 038 */     // find matches from HashedRelation
/* 039 */     UnsafeRow bhj_matched_2 = bhj_isNull_15 ? null: (UnsafeRow)bhj_relation_2.getValue(bhj_value_15);
/* 040 */     if (bhj_matched_2 != null) {
/* 041 */       {
/* 042 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[10] /* numOutputRows */).add(1);
/* 043 */
/* 044 */         boolean bhj_isNull_17 = bhj_matched_2.isNullAt(0);
/* 045 */         int bhj_value_17 = bhj_isNull_17 ?
/* 046 */         -1 : (bhj_matched_2.getInt(0));
/* 047 */         boolean bhj_isNull_18 = bhj_matched_2.isNullAt(1);
/* 048 */         int bhj_value_18 = bhj_isNull_18 ?
/* 049 */         -1 : (bhj_matched_2.getInt(1));
/* 050 */         boolean bhj_isNull_19 = bhj_matched_2.isNullAt(2);
/* 051 */         UTF8String bhj_value_19 = bhj_isNull_19 ?
/* 052 */         null : (bhj_matched_2.getUTF8String(2));
/* 053 */
/* 054 */         agg_doConsume_0(bhj_value_17, bhj_isNull_17, bhj_value_18, bhj_isNull_18, bhj_value_19, bhj_isNull_19);
/* 055 */
/* 056 */       }
/* 057 */     }
/* 058 */
/* 059 */   }
/* 060 */
/* 061 */   private void agg_doAggregateWithKeysOutput_0(UnsafeRow agg_keyTerm_0, UnsafeRow agg_bufferTerm_0)
/* 062 */   throws java.io.IOException {
/* 063 */     ((org.apache.spark.sql.execution.metric.SQLMetric) references[11] /* numOutputRows */).add(1);
/* 064 */
/* 065 */     boolean agg_isNull_9 = agg_keyTerm_0.isNullAt(0);
/* 066 */     int agg_value_9 = agg_isNull_9 ?
/* 067 */     -1 : (agg_keyTerm_0.getInt(0));
/* 068 */     boolean agg_isNull_10 = agg_keyTerm_0.isNullAt(1);
/* 069 */     int agg_value_10 = agg_isNull_10 ?
/* 070 */     -1 : (agg_keyTerm_0.getInt(1));
/* 071 */     boolean agg_isNull_11 = agg_keyTerm_0.isNullAt(2);
/* 072 */     UTF8String agg_value_11 = agg_isNull_11 ?
/* 073 */     null : (agg_keyTerm_0.getUTF8String(2));
/* 074 */     filter_mutableStateArray_0[12].reset();
/* 075 */
/* 076 */     filter_mutableStateArray_0[12].zeroOutNullBytes();
/* 077 */
/* 078 */     if (agg_isNull_9) {
/* 079 */       filter_mutableStateArray_0[12].setNullAt(0);
/* 080 */     } else {
/* 081 */       filter_mutableStateArray_0[12].write(0, agg_value_9);
/* 082 */     }
/* 083 */
/* 084 */     if (agg_isNull_10) {
/* 085 */       filter_mutableStateArray_0[12].setNullAt(1);
/* 086 */     } else {
/* 087 */       filter_mutableStateArray_0[12].write(1, agg_value_10);
/* 088 */     }
/* 089 */
/* 090 */     if (agg_isNull_11) {
/* 091 */       filter_mutableStateArray_0[12].setNullAt(2);
/* 092 */     } else {
/* 093 */       filter_mutableStateArray_0[12].write(2, agg_value_11);
/* 094 */     }
/* 095 */     append((filter_mutableStateArray_0[12].getRow()));
/* 096 */
/* 097 */   }
/* 098 */
/* 099 */   private void wholestagecodegen_init_0_1() {
/* 100 */     filter_mutableStateArray_0[5] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 0);
/* 101 */     filter_mutableStateArray_0[6] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 102 */     filter_mutableStateArray_0[7] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 103 */
/* 104 */     bhj_relation_2 = ((org.apache.spark.sql.execution.joins.LongHashedRelation) ((org.apache.spark.broadcast.TorrentBroadcast) references[9] /* broadcast */).value()).asReadOnlyCopy();
/* 105 */     incPeakExecutionMemory(bhj_relation_2.estimatedSize());
/* 106 */
/* 107 */     filter_mutableStateArray_0[8] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 32);
/* 108 */     filter_mutableStateArray_0[9] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 109 */     filter_mutableStateArray_0[10] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 110 */     filter_mutableStateArray_0[11] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 111 */     filter_mutableStateArray_0[12] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 112 */
/* 113 */   }
/* 114 */
/* 115 */   private void agg_doConsume_0(int agg_expr_0_0, boolean agg_exprIsNull_0_0, int agg_expr_1_0, boolean agg_exprIsNull_1_0, UTF8String agg_expr_2_0, boolean agg_exprIsNull_2_0) throws java.io.IOException {
/* 116 */     UnsafeRow agg_unsafeRowAggBuffer_0 = null;
/* 117 */
/* 118 */     // generate grouping key
/* 119 */     filter_mutableStateArray_0[11].reset();
/* 120 */
/* 121 */     filter_mutableStateArray_0[11].zeroOutNullBytes();
/* 122 */
/* 123 */     if (agg_exprIsNull_0_0) {
/* 124 */       filter_mutableStateArray_0[11].setNullAt(0);
/* 125 */     } else {
/* 126 */       filter_mutableStateArray_0[11].write(0, agg_expr_0_0);
/* 127 */     }
/* 128 */
/* 129 */     if (agg_exprIsNull_1_0) {
/* 130 */       filter_mutableStateArray_0[11].setNullAt(1);
/* 131 */     } else {
/* 132 */       filter_mutableStateArray_0[11].write(1, agg_expr_1_0);
/* 133 */     }
/* 134 */
/* 135 */     if (agg_exprIsNull_2_0) {
/* 136 */       filter_mutableStateArray_0[11].setNullAt(2);
/* 137 */     } else {
/* 138 */       filter_mutableStateArray_0[11].write(2, agg_expr_2_0);
/* 139 */     }
/* 140 */     int agg_unsafeRowKeyHash_0 = (filter_mutableStateArray_0[11].getRow()).hashCode();
/* 141 */     if (true) {
/* 142 */       // try to get the buffer from hash map
/* 143 */       agg_unsafeRowAggBuffer_0 =
/* 144 */       agg_hashMap_0.getAggregationBufferFromUnsafeRow((filter_mutableStateArray_0[11].getRow()), agg_unsafeRowKeyHash_0);
/* 145 */     }
/* 146 */     // Can't allocate buffer from the hash map. Spill the map and fallback to sort-based
/* 147 */     // aggregation after processing all input rows.
/* 148 */     if (agg_unsafeRowAggBuffer_0 == null) {
/* 149 */       if (agg_sorter_0 == null) {
/* 150 */         agg_sorter_0 = agg_hashMap_0.destructAndCreateExternalSorter();
/* 151 */       } else {
/* 152 */         agg_sorter_0.merge(agg_hashMap_0.destructAndCreateExternalSorter());
/* 153 */       }
/* 154 */
/* 155 */       // the hash map had be spilled, it should have enough memory now,
/* 156 */       // try to allocate buffer again.
/* 157 */       agg_unsafeRowAggBuffer_0 = agg_hashMap_0.getAggregationBufferFromUnsafeRow(
/* 158 */         (filter_mutableStateArray_0[11].getRow()), agg_unsafeRowKeyHash_0);
/* 159 */       if (agg_unsafeRowAggBuffer_0 == null) {
/* 160 */         // failed to allocate the first page
/* 161 */         throw new org.apache.spark.memory.SparkOutOfMemoryError("No enough memory for aggregation");
/* 162 */       }
/* 163 */     }
/* 164 */
/* 165 */     // common sub-expressions
/* 166 */
/* 167 */     // evaluate aggregate functions and update aggregation buffers
/* 168 */
/* 169 */   }
/* 170 */
/* 171 */   private void bhj_doConsume_0(int bhj_expr_0_0, boolean bhj_exprIsNull_0_0) throws java.io.IOException {
/* 172 */     // generate join key for stream side
/* 173 */     boolean bhj_isNull_7 = bhj_exprIsNull_0_0;
/* 174 */     long bhj_value_7 = -1L;
/* 175 */     if (!bhj_exprIsNull_0_0) {
/* 176 */       bhj_value_7 = (long) bhj_expr_0_0;
/* 177 */     }
/* 178 */     // find matches from HashedRelation
/* 179 */     UnsafeRow bhj_matched_1 = bhj_isNull_7 ? null: (UnsafeRow)bhj_relation_1.getValue(bhj_value_7);
/* 180 */     if (bhj_matched_1 != null) {
/* 181 */       {
/* 182 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[8] /* numOutputRows */).add(1);
/* 183 */
/* 184 */         boolean bhj_isNull_10 = bhj_matched_1.isNullAt(1);
/* 185 */         int bhj_value_10 = bhj_isNull_10 ?
/* 186 */         -1 : (bhj_matched_1.getInt(1));
/* 187 */
/* 188 */         bhj_doConsume_1(bhj_value_10, bhj_isNull_10);
/* 189 */
/* 190 */       }
/* 191 */     }
/* 192 */
/* 193 */   }
/* 194 */
/* 195 */   private void agg_doAggregateWithKeys_0() throws java.io.IOException {
/* 196 */     while ( inputadapter_input_0.hasNext()) {
/* 197 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 198 */
/* 199 */       do {
/* 200 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 201 */         int inputadapter_value_0 = inputadapter_isNull_0 ?
/* 202 */         -1 : (inputadapter_row_0.getInt(0));
/* 203 */
/* 204 */         boolean filter_value_2 = !inputadapter_isNull_0;
/* 205 */         if (!filter_value_2) continue;
/* 206 */
/* 207 */         boolean inputadapter_isNull_1 = inputadapter_row_0.isNullAt(1);
/* 208 */         int inputadapter_value_1 = inputadapter_isNull_1 ?
/* 209 */         -1 : (inputadapter_row_0.getInt(1));
/* 210 */
/* 211 */         boolean filter_value_5 = !inputadapter_isNull_1;
/* 212 */         if (!filter_value_5) continue;
/* 213 */
/* 214 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[4] /* numOutputRows */).add(1);
/* 215 */
/* 216 */         // generate join key for stream side
/* 217 */         boolean bhj_isNull_0 = false;
/* 218 */         long bhj_value_0 = -1L;
/* 219 */         if (!false) {
/* 220 */           bhj_value_0 = (long) inputadapter_value_0;
/* 221 */         }
/* 222 */         // find matches from HashedRelation
/* 223 */         UnsafeRow bhj_matched_0 = bhj_isNull_0 ? null: (UnsafeRow)bhj_relation_0.getValue(bhj_value_0);
/* 224 */         if (bhj_matched_0 != null) {
/* 225 */           {
/* 226 */             ((org.apache.spark.sql.execution.metric.SQLMetric) references[6] /* numOutputRows */).add(1);
/* 227 */
/* 228 */             bhj_doConsume_0(inputadapter_value_1, false);
/* 229 */
/* 230 */           }
/* 231 */         }
/* 232 */
/* 233 */       } while(false);
/* 234 */       // shouldStop check is eliminated
/* 235 */     }
/* 236 */
/* 237 */     agg_mapIter_0 = ((org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0] /* plan */).finishAggregate(agg_hashMap_0, agg_sorter_0, ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* peakMemory */), ((org.apache.spark.sql.execution.metric.SQLMetric) references[2] /* spillSize */), ((org.apache.spark.sql.execution.metric.SQLMetric) references[3] /* avgHashProbe */));
/* 238 */   }
/* 239 */
/* 240 */   protected void processNext() throws java.io.IOException {
/* 241 */     if (!agg_initAgg_0) {
/* 242 */       agg_initAgg_0 = true;
/* 243 */
/* 244 */       agg_hashMap_0 = ((org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0] /* plan */).createHashMap();
/* 245 */       long wholestagecodegen_beforeAgg_0 = System.nanoTime();
/* 246 */       agg_doAggregateWithKeys_0();
/* 247 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[12] /* aggTime */).add((System.nanoTime() - wholestagecodegen_beforeAgg_0) / 1000000);
/* 248 */     }
/* 249 */     // output the result
/* 250 */
/* 251 */     while ( agg_mapIter_0.next()) {
/* 252 */       UnsafeRow agg_aggKey_0 = (UnsafeRow) agg_mapIter_0.getKey();
/* 253 */       UnsafeRow agg_aggBuffer_0 = (UnsafeRow) agg_mapIter_0.getValue();
/* 254 */       agg_doAggregateWithKeysOutput_0(agg_aggKey_0, agg_aggBuffer_0);
/* 255 */       if (shouldStop()) return;
/* 256 */     }
/* 257 */     agg_mapIter_0.close();
/* 258 */     if (agg_sorter_0 == null) {
/* 259 */       agg_hashMap_0.free();
/* 260 */     }
/* 261 */   }
/* 262 */
/* 263 */   private void wholestagecodegen_init_0_0() {
/* 264 */     inputadapter_input_0 = inputs[0];
/* 265 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 0);
/* 266 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 0);
/* 267 */
/* 268 */     bhj_relation_0 = ((org.apache.spark.sql.execution.joins.LongHashedRelation) ((org.apache.spark.broadcast.TorrentBroadcast) references[5] /* broadcast */).value()).asReadOnlyCopy();
/* 269 */     incPeakExecutionMemory(bhj_relation_0.estimatedSize());
/* 270 */
/* 271 */     filter_mutableStateArray_0[2] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 0);
/* 272 */     filter_mutableStateArray_0[3] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 273 */     filter_mutableStateArray_0[4] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 274 */
/* 275 */     bhj_relation_1 = ((org.apache.spark.sql.execution.joins.LongHashedRelation) ((org.apache.spark.broadcast.TorrentBroadcast) references[7] /* broadcast */).value()).asReadOnlyCopy();
/* 276 */     incPeakExecutionMemory(bhj_relation_1.estimatedSize());
/* 277 */
/* 278 */   }
/* 279 */
/* 280 */ }

2022-02-14 10:55:50 INFO  CodeGenerator:57 - Code generated in 47.0232 ms
2022-02-14 10:55:50 INFO  MemoryStore:57 - Block broadcast_25 stored as values in memory (estimated size 170.9 KiB, free 2.2 GiB)
2022-02-14 10:55:50 DEBUG BlockManager:61 - Put block broadcast_25 locally took 3 ms
2022-02-14 10:55:50 DEBUG BlockManager:61 - Putting block broadcast_25 without replication took 4 ms
2022-02-14 10:55:50 INFO  MemoryStore:57 - Block broadcast_25_piece0 stored as bytes in memory (estimated size 23.9 KiB, free 2.2 GiB)
2022-02-14 10:55:50 INFO  BlockManagerInfo:57 - Added broadcast_25_piece0 in memory on Clairvoyant-320:60340 (size: 23.9 KiB, free: 2.2 GiB)
2022-02-14 10:55:50 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_25_piece0
2022-02-14 10:55:50 DEBUG BlockManager:61 - Told master about block broadcast_25_piece0
2022-02-14 10:55:50 DEBUG BlockManager:61 - Put block broadcast_25_piece0 locally took 2 ms
2022-02-14 10:55:50 DEBUG BlockManager:61 - Putting block broadcast_25_piece0 without replication took 3 ms
2022-02-14 10:55:50 INFO  SparkContext:57 - Created broadcast 25 from count at UsedCase4.java:37
2022-02-14 10:55:50 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 9603305 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-14 10:55:50 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-02-14 10:55:50 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-02-14 10:55:50 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-02-14 10:55:50 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-02-14 10:55:50 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-02-14 10:55:50 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-02-14 10:55:50 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$collect$2
2022-02-14 10:55:50 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$collect$2) is now cleaned +++
2022-02-14 10:55:50 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$5
2022-02-14 10:55:50 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2022-02-14 10:55:50 INFO  SparkContext:57 - Starting job: count at UsedCase4.java:37
2022-02-14 10:55:50 INFO  DAGScheduler:57 - Registering RDD 55 (count at UsedCase4.java:37) as input to shuffle 0
2022-02-14 10:55:50 INFO  DAGScheduler:57 - Registering RDD 58 (count at UsedCase4.java:37) as input to shuffle 1
2022-02-14 10:55:50 INFO  DAGScheduler:57 - Got job 11 (count at UsedCase4.java:37) with 1 output partitions
2022-02-14 10:55:50 INFO  DAGScheduler:57 - Final stage: ResultStage 13 (count at UsedCase4.java:37)
2022-02-14 10:55:50 INFO  DAGScheduler:57 - Parents of final stage: List(ShuffleMapStage 12)
2022-02-14 10:55:50 INFO  DAGScheduler:57 - Missing parents: List(ShuffleMapStage 12)
2022-02-14 10:55:50 DEBUG DAGScheduler:61 - submitStage(ResultStage 13 (name=count at UsedCase4.java:37;jobs=11))
2022-02-14 10:55:50 DEBUG DAGScheduler:61 - missing: List(ShuffleMapStage 12)
2022-02-14 10:55:50 DEBUG DAGScheduler:61 - submitStage(ShuffleMapStage 12 (name=count at UsedCase4.java:37;jobs=11))
2022-02-14 10:55:50 DEBUG DAGScheduler:61 - missing: List(ShuffleMapStage 11)
2022-02-14 10:55:50 DEBUG DAGScheduler:61 - submitStage(ShuffleMapStage 11 (name=count at UsedCase4.java:37;jobs=11))
2022-02-14 10:55:50 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:55:50 INFO  DAGScheduler:57 - Submitting ShuffleMapStage 11 (MapPartitionsRDD[55] at count at UsedCase4.java:37), which has no missing parents
2022-02-14 10:55:50 DEBUG DAGScheduler:61 - submitMissingTasks(ShuffleMapStage 11)
2022-02-14 10:55:50 INFO  MemoryStore:57 - Block broadcast_26 stored as values in memory (estimated size 40.6 KiB, free 2.2 GiB)
2022-02-14 10:55:50 DEBUG BlockManager:61 - Put block broadcast_26 locally took 1 ms
2022-02-14 10:55:50 DEBUG BlockManager:61 - Putting block broadcast_26 without replication took 2 ms
2022-02-14 10:55:50 INFO  MemoryStore:57 - Block broadcast_26_piece0 stored as bytes in memory (estimated size 18.0 KiB, free 2.2 GiB)
2022-02-14 10:55:50 INFO  BlockManagerInfo:57 - Added broadcast_26_piece0 in memory on Clairvoyant-320:60340 (size: 18.0 KiB, free: 2.2 GiB)
2022-02-14 10:55:50 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_26_piece0
2022-02-14 10:55:50 DEBUG BlockManager:61 - Told master about block broadcast_26_piece0
2022-02-14 10:55:50 DEBUG BlockManager:61 - Put block broadcast_26_piece0 locally took 2 ms
2022-02-14 10:55:50 DEBUG BlockManager:61 - Putting block broadcast_26_piece0 without replication took 2 ms
2022-02-14 10:55:50 INFO  SparkContext:57 - Created broadcast 26 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:55:50 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[55] at count at UsedCase4.java:37) (first 15 tasks are for partitions Vector(0))
2022-02-14 10:55:50 INFO  TaskSchedulerImpl:57 - Adding task set 11.0 with 1 tasks
2022-02-14 10:55:50 DEBUG TaskSetManager:61 - Epoch for TaskSet 11.0: 0
2022-02-14 10:55:50 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-02-14 10:55:50 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 11.0: NO_PREF, ANY
2022-02-14 10:55:50 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-14 10:55:50 INFO  TaskSetManager:57 - Starting task 0.0 in stage 11.0 (TID 11, Clairvoyant-320, executor driver, partition 0, PROCESS_LOCAL, 7795 bytes)
2022-02-14 10:55:50 INFO  Executor:57 - Running task 0.0 in stage 11.0 (TID 11)
2022-02-14 10:55:50 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (11, 0) -> 1
2022-02-14 10:55:50 DEBUG BlockManager:61 - Getting local block broadcast_26
2022-02-14 10:55:50 DEBUG BlockManager:61 - Level for block broadcast_26 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:50 DEBUG GenerateUnsafeProjection:61 - code for pmod(hash(input[0, int, true], input[1, int, true], input[2, string, true], 42), 200):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private boolean globalIsNull_0;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 010 */
/* 011 */   public SpecificUnsafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */
/* 014 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public void initialize(int partitionIndex) {
/* 019 */
/* 020 */   }
/* 021 */
/* 022 */   // Scala.Function1 need this
/* 023 */   public java.lang.Object apply(java.lang.Object row) {
/* 024 */     return apply((InternalRow) row);
/* 025 */   }
/* 026 */
/* 027 */   public UnsafeRow apply(InternalRow i) {
/* 028 */     mutableStateArray_0[0].reset();
/* 029 */
/* 030 */
/* 031 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 032 */
/* 033 */     int value_6 = Pmod_0(i);
/* 034 */     if (globalIsNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_6);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */   private int Pmod_0(InternalRow i) {
/* 044 */     boolean isNull_0 = false;
/* 045 */     int value_0 = -1;
/* 046 */     if (200 == 0) {
/* 047 */       isNull_0 = true;
/* 048 */     } else {
/* 049 */       int value_1 = 42;
/* 050 */       boolean isNull_2 = i.isNullAt(0);
/* 051 */       int value_2 = isNull_2 ?
/* 052 */       -1 : (i.getInt(0));
/* 053 */       if (!isNull_2) {
/* 054 */         value_1 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashInt(value_2, value_1);
/* 055 */       }
/* 056 */       boolean isNull_3 = i.isNullAt(1);
/* 057 */       int value_3 = isNull_3 ?
/* 058 */       -1 : (i.getInt(1));
/* 059 */       if (!isNull_3) {
/* 060 */         value_1 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashInt(value_3, value_1);
/* 061 */       }
/* 062 */       boolean isNull_4 = i.isNullAt(2);
/* 063 */       UTF8String value_4 = isNull_4 ?
/* 064 */       null : (i.getUTF8String(2));
/* 065 */       if (!isNull_4) {
/* 066 */         value_1 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashUnsafeBytes(value_4.getBaseObject(), value_4.getBaseOffset(), value_4.numBytes(), value_1);
/* 067 */       }
/* 068 */
/* 069 */       int remainder_0 = value_1 % 200;
/* 070 */       if (remainder_0 < 0) {
/* 071 */         value_0=(remainder_0 + 200) % 200;
/* 072 */       } else {
/* 073 */         value_0=remainder_0;
/* 074 */       }
/* 075 */
/* 076 */     }
/* 077 */     globalIsNull_0 = isNull_0;
/* 078 */     return value_0;
/* 079 */   }
/* 080 */
/* 081 */ }

2022-02-14 10:55:50 DEBUG CodeGenerator:61 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private boolean globalIsNull_0;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 010 */
/* 011 */   public SpecificUnsafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */
/* 014 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public void initialize(int partitionIndex) {
/* 019 */
/* 020 */   }
/* 021 */
/* 022 */   // Scala.Function1 need this
/* 023 */   public java.lang.Object apply(java.lang.Object row) {
/* 024 */     return apply((InternalRow) row);
/* 025 */   }
/* 026 */
/* 027 */   public UnsafeRow apply(InternalRow i) {
/* 028 */     mutableStateArray_0[0].reset();
/* 029 */
/* 030 */
/* 031 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 032 */
/* 033 */     int value_6 = Pmod_0(i);
/* 034 */     if (globalIsNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_6);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */   private int Pmod_0(InternalRow i) {
/* 044 */     boolean isNull_0 = false;
/* 045 */     int value_0 = -1;
/* 046 */     if (200 == 0) {
/* 047 */       isNull_0 = true;
/* 048 */     } else {
/* 049 */       int value_1 = 42;
/* 050 */       boolean isNull_2 = i.isNullAt(0);
/* 051 */       int value_2 = isNull_2 ?
/* 052 */       -1 : (i.getInt(0));
/* 053 */       if (!isNull_2) {
/* 054 */         value_1 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashInt(value_2, value_1);
/* 055 */       }
/* 056 */       boolean isNull_3 = i.isNullAt(1);
/* 057 */       int value_3 = isNull_3 ?
/* 058 */       -1 : (i.getInt(1));
/* 059 */       if (!isNull_3) {
/* 060 */         value_1 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashInt(value_3, value_1);
/* 061 */       }
/* 062 */       boolean isNull_4 = i.isNullAt(2);
/* 063 */       UTF8String value_4 = isNull_4 ?
/* 064 */       null : (i.getUTF8String(2));
/* 065 */       if (!isNull_4) {
/* 066 */         value_1 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashUnsafeBytes(value_4.getBaseObject(), value_4.getBaseOffset(), value_4.numBytes(), value_1);
/* 067 */       }
/* 068 */
/* 069 */       int remainder_0 = value_1 % 200;
/* 070 */       if (remainder_0 < 0) {
/* 071 */         value_0=(remainder_0 + 200) % 200;
/* 072 */       } else {
/* 073 */         value_0=remainder_0;
/* 074 */       }
/* 075 */
/* 076 */     }
/* 077 */     globalIsNull_0 = isNull_0;
/* 078 */     return value_0;
/* 079 */   }
/* 080 */
/* 081 */ }

2022-02-14 10:55:50 INFO  CodeGenerator:57 - Code generated in 23.3433 ms
2022-02-14 10:55:50 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:50 DEBUG CodeGenerator:61 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:50 INFO  CodeGenerator:57 - Code generated in 11.053401 ms
2022-02-14 10:55:50 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:50 DEBUG TaskMemoryManager:228 - Task 11 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@205c01b7
2022-02-14 10:55:50 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:50 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Shridhar%20Ingale/IdeaProjects/UseCases1/src/main/resources/retail_db/order_items/part-00000, range: 0-5409001, partition values: [empty row]
2022-02-14 10:55:50 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-14 10:55:50 DEBUG BlockManager:61 - Getting local block broadcast_25
2022-02-14 10:55:50 DEBUG BlockManager:61 - Level for block broadcast_25 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:50 DEBUG GeneratePredicate:61 - Generated predicate 'isnotnull(input[0, int, true])':
/* 001 */ public SpecificPredicate generate(Object[] references) {
/* 002 */   return new SpecificPredicate(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificPredicate extends org.apache.spark.sql.catalyst.expressions.BasePredicate {
/* 006 */   private final Object[] references;
/* 007 */
/* 008 */
/* 009 */   public SpecificPredicate(Object[] references) {
/* 010 */     this.references = references;
/* 011 */
/* 012 */   }
/* 013 */
/* 014 */   public void initialize(int partitionIndex) {
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public boolean eval(InternalRow i) {
/* 019 */     boolean isNull_1 = i.isNullAt(0);
/* 020 */     int value_1 = isNull_1 ?
/* 021 */     -1 : (i.getInt(0));
/* 022 */     boolean value_2 = !isNull_1;
/* 023 */     return !false && value_2;
/* 024 */   }
/* 025 */
/* 026 */
/* 027 */ }

2022-02-14 10:55:50 DEBUG GeneratePredicate:61 - Generated predicate 'isnotnull(input[1, int, true])':
/* 001 */ public SpecificPredicate generate(Object[] references) {
/* 002 */   return new SpecificPredicate(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificPredicate extends org.apache.spark.sql.catalyst.expressions.BasePredicate {
/* 006 */   private final Object[] references;
/* 007 */
/* 008 */
/* 009 */   public SpecificPredicate(Object[] references) {
/* 010 */     this.references = references;
/* 011 */
/* 012 */   }
/* 013 */
/* 014 */   public void initialize(int partitionIndex) {
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public boolean eval(InternalRow i) {
/* 019 */     boolean isNull_1 = i.isNullAt(1);
/* 020 */     int value_1 = isNull_1 ?
/* 021 */     -1 : (i.getInt(1));
/* 022 */     boolean value_2 = !isNull_1;
/* 023 */     return !false && value_2;
/* 024 */   }
/* 025 */
/* 026 */
/* 027 */ }

2022-02-14 10:55:50 DEBUG TaskMemoryManager:228 - Task 11 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@205c01b7
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(459)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 459
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 459
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(474)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 474
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 474
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(458)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 458
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 458
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(471)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 471
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 471
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(457)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 457
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 457
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(480)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 480
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 480
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(468)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 468
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 468
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(469)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 469
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 469
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(463)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 463
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 463
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(477)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 477
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 477
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(479)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 479
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 479
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(476)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 476
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 476
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(478)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 478
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 478
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(472)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 472
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 472
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(466)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 466
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 466
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(475)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 475
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 475
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(460)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 460
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 460
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(462)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 462
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 462
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(465)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 465
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 465
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(473)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 473
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 473
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(467)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 467
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 467
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(470)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 470
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 470
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(481)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 481
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 481
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(461)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 461
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 461
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(21)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning broadcast 21
2022-02-14 10:55:50 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 21
2022-02-14 10:55:50 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 21
2022-02-14 10:55:50 DEBUG BlockManager:61 - Removing broadcast 21
2022-02-14 10:55:50 DEBUG BlockManager:61 - Removing block broadcast_21_piece0
2022-02-14 10:55:50 DEBUG MemoryStore:61 - Block broadcast_21_piece0 of size 7879 dropped from memory (free 2276381254)
2022-02-14 10:55:50 INFO  BlockManagerInfo:57 - Removed broadcast_21_piece0 on Clairvoyant-320:60340 in memory (size: 7.7 KiB, free: 2.2 GiB)
2022-02-14 10:55:50 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_21_piece0
2022-02-14 10:55:50 DEBUG BlockManager:61 - Told master about block broadcast_21_piece0
2022-02-14 10:55:50 DEBUG BlockManager:61 - Removing block broadcast_21
2022-02-14 10:55:50 DEBUG MemoryStore:61 - Block broadcast_21 of size 16008 dropped from memory (free 2276397262)
2022-02-14 10:55:50 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 21, response is 0
2022-02-14 10:55:50 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60325
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned broadcast 21
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(464)
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaning accumulator 464
2022-02-14 10:55:50 DEBUG ContextCleaner:61 - Cleaned accumulator 464
2022-02-14 10:55:51 DEBUG TaskMemoryManager:237 - Task 11 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@205c01b7
2022-02-14 10:55:51 DEBUG TaskMemoryManager:237 - Task 11 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@205c01b7
2022-02-14 10:55:51 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 11 with length 200
2022-02-14 10:55:51 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 11: [0,0,0,0,0,0,0,84,0,0,0,0,0,0,0,0,0,84,0,84,0,0,0,0,0,0,0,0,0,124,0,92,0,0,0,76,0,0,76,0,0,0,76,84,0,0,0,0,83,0,0,0,84,0,0,0,0,0,0,0,0,0,0,92,0,0,0,0,0,0,0,0,0,84,80,0,0,0,0,0,0,0,0,0,0,0,84,0,0,92,84,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,84,0,0,0,0,0,0,84,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,84,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,92,0,0,0,71,0,92,0,0,84,0,0,0,0,0,0,76,0,0,72,0,0,0,121,0,0,0,0,0,0,84,84,0,83,0,0,0,0,0,91]
2022-02-14 10:55:51 INFO  Executor:57 - Finished task 0.0 in stage 11.0 (TID 11). 4872 bytes result sent to driver
2022-02-14 10:55:51 DEBUG ExecutorMetricsPoller:61 - removing (11, 0) from stageTCMP
2022-02-14 10:55:51 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-14 10:55:51 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-14 10:55:51 INFO  TaskSetManager:57 - Finished task 0.0 in stage 11.0 (TID 11) in 975 ms on Clairvoyant-320 (executor driver) (1/1)
2022-02-14 10:55:51 INFO  TaskSchedulerImpl:57 - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2022-02-14 10:55:51 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:51 INFO  DAGScheduler:57 - ShuffleMapStage 11 (count at UsedCase4.java:37) finished in 1.000 s
2022-02-14 10:55:51 INFO  DAGScheduler:57 - looking for newly runnable stages
2022-02-14 10:55:51 INFO  DAGScheduler:57 - running: Set()
2022-02-14 10:55:51 INFO  DAGScheduler:57 - waiting: Set(ShuffleMapStage 12, ResultStage 13)
2022-02-14 10:55:51 INFO  DAGScheduler:57 - failed: Set()
2022-02-14 10:55:51 DEBUG MapOutputTrackerMaster:61 - Increasing epoch to 1
2022-02-14 10:55:51 DEBUG DAGScheduler:61 - submitStage(ShuffleMapStage 12 (name=count at UsedCase4.java:37;jobs=11))
2022-02-14 10:55:51 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:55:51 INFO  DAGScheduler:57 - Submitting ShuffleMapStage 12 (MapPartitionsRDD[58] at count at UsedCase4.java:37), which has no missing parents
2022-02-14 10:55:51 DEBUG DAGScheduler:61 - submitMissingTasks(ShuffleMapStage 12)
2022-02-14 10:55:51 INFO  MemoryStore:57 - Block broadcast_27 stored as values in memory (estimated size 44.1 KiB, free 2.2 GiB)
2022-02-14 10:55:51 DEBUG BlockManager:61 - Put block broadcast_27 locally took 1 ms
2022-02-14 10:55:51 DEBUG BlockManager:61 - Putting block broadcast_27 without replication took 2 ms
2022-02-14 10:55:51 INFO  MemoryStore:57 - Block broadcast_27_piece0 stored as bytes in memory (estimated size 21.4 KiB, free 2.2 GiB)
2022-02-14 10:55:51 INFO  BlockManagerInfo:57 - Added broadcast_27_piece0 in memory on Clairvoyant-320:60340 (size: 21.4 KiB, free: 2.2 GiB)
2022-02-14 10:55:51 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_27_piece0
2022-02-14 10:55:51 DEBUG BlockManager:61 - Told master about block broadcast_27_piece0
2022-02-14 10:55:51 DEBUG BlockManager:61 - Put block broadcast_27_piece0 locally took 1 ms
2022-02-14 10:55:51 DEBUG BlockManager:61 - Putting block broadcast_27_piece0 without replication took 1 ms
2022-02-14 10:55:51 INFO  SparkContext:57 - Created broadcast 27 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:55:51 INFO  DAGScheduler:57 - Submitting 200 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[58] at count at UsedCase4.java:37) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2022-02-14 10:55:51 INFO  TaskSchedulerImpl:57 - Adding task set 12.0 with 200 tasks
2022-02-14 10:55:51 DEBUG TaskSetManager:61 - Epoch for TaskSet 12.0: 1
2022-02-14 10:55:51 DEBUG TaskSetManager:61 - Adding pending tasks took 2 ms
2022-02-14 10:55:51 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 12.0: NODE_LOCAL, NO_PREF, ANY
2022-02-14 10:55:51 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:51 INFO  TaskSetManager:57 - Starting task 7.0 in stage 12.0 (TID 12, Clairvoyant-320, executor driver, partition 7, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:51 INFO  Executor:57 - Running task 7.0 in stage 12.0 (TID 12)
2022-02-14 10:55:51 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:51 DEBUG BlockManager:61 - Getting local block broadcast_27
2022-02-14 10:55:51 DEBUG BlockManager:61 - Level for block broadcast_27 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:51 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 7-8
2022-02-14 10:55:51 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:51 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:51 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 8 ms
2022-02-14 10:55:51 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_7,0)
2022-02-14 10:55:51 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 16 ms
2022-02-14 10:55:51 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:51 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:51 DEBUG TaskMemoryManager:228 - Task 12 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5a0c520c
2022-02-14 10:55:51 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:51 DEBUG TaskMemoryManager:228 - Task 12 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@5a0c520c
2022-02-14 10:55:51 DEBUG TaskMemoryManager:237 - Task 12 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5a0c520c
2022-02-14 10:55:51 DEBUG TaskMemoryManager:237 - Task 12 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@5a0c520c
2022-02-14 10:55:51 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 12 with length 1
2022-02-14 10:55:51 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 12: [59]
2022-02-14 10:55:51 INFO  Executor:57 - Finished task 7.0 in stage 12.0 (TID 12). 6269 bytes result sent to driver
2022-02-14 10:55:51 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:51 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:51 INFO  TaskSetManager:57 - Starting task 17.0 in stage 12.0 (TID 13, Clairvoyant-320, executor driver, partition 17, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:51 INFO  Executor:57 - Running task 17.0 in stage 12.0 (TID 13)
2022-02-14 10:55:51 INFO  TaskSetManager:57 - Finished task 7.0 in stage 12.0 (TID 12) in 119 ms on Clairvoyant-320 (executor driver) (1/200)
2022-02-14 10:55:51 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:51 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:51 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 17-18
2022-02-14 10:55:51 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:51 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:51 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:51 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_17,0)
2022-02-14 10:55:51 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:51 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:51 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:51 DEBUG TaskMemoryManager:228 - Task 13 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@80bb3ff
2022-02-14 10:55:51 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:51 DEBUG TaskMemoryManager:228 - Task 13 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@80bb3ff
2022-02-14 10:55:51 DEBUG TaskMemoryManager:237 - Task 13 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@80bb3ff
2022-02-14 10:55:51 DEBUG TaskMemoryManager:237 - Task 13 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@80bb3ff
2022-02-14 10:55:51 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 13 with length 1
2022-02-14 10:55:51 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 13: [59]
2022-02-14 10:55:51 INFO  Executor:57 - Finished task 17.0 in stage 12.0 (TID 13). 6269 bytes result sent to driver
2022-02-14 10:55:51 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:51 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:51 INFO  TaskSetManager:57 - Starting task 19.0 in stage 12.0 (TID 14, Clairvoyant-320, executor driver, partition 19, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:51 INFO  Executor:57 - Running task 19.0 in stage 12.0 (TID 14)
2022-02-14 10:55:51 INFO  TaskSetManager:57 - Finished task 17.0 in stage 12.0 (TID 13) in 63 ms on Clairvoyant-320 (executor driver) (2/200)
2022-02-14 10:55:51 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:51 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:51 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 19-20
2022-02-14 10:55:51 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:51 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:51 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:51 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_19,0)
2022-02-14 10:55:51 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:51 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:51 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:51 DEBUG TaskMemoryManager:228 - Task 14 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@71e1db20
2022-02-14 10:55:51 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:51 DEBUG TaskMemoryManager:228 - Task 14 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@71e1db20
2022-02-14 10:55:51 DEBUG TaskMemoryManager:237 - Task 14 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@71e1db20
2022-02-14 10:55:51 DEBUG TaskMemoryManager:237 - Task 14 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@71e1db20
2022-02-14 10:55:51 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 14 with length 1
2022-02-14 10:55:51 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 14: [59]
2022-02-14 10:55:51 INFO  Executor:57 - Finished task 19.0 in stage 12.0 (TID 14). 6226 bytes result sent to driver
2022-02-14 10:55:51 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:51 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:51 INFO  TaskSetManager:57 - Starting task 29.0 in stage 12.0 (TID 15, Clairvoyant-320, executor driver, partition 29, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:51 INFO  Executor:57 - Running task 29.0 in stage 12.0 (TID 15)
2022-02-14 10:55:51 INFO  TaskSetManager:57 - Finished task 19.0 in stage 12.0 (TID 14) in 72 ms on Clairvoyant-320 (executor driver) (3/200)
2022-02-14 10:55:51 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:51 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:51 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 29-30
2022-02-14 10:55:51 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:51 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:51 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:55:51 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_29,0)
2022-02-14 10:55:51 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:51 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:51 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:51 DEBUG TaskMemoryManager:228 - Task 15 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@416e10a2
2022-02-14 10:55:51 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:51 DEBUG TaskMemoryManager:228 - Task 15 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@416e10a2
2022-02-14 10:55:51 DEBUG TaskMemoryManager:237 - Task 15 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@416e10a2
2022-02-14 10:55:51 DEBUG TaskMemoryManager:237 - Task 15 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@416e10a2
2022-02-14 10:55:51 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 15 with length 1
2022-02-14 10:55:51 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 15: [59]
2022-02-14 10:55:51 INFO  Executor:57 - Finished task 29.0 in stage 12.0 (TID 15). 6226 bytes result sent to driver
2022-02-14 10:55:51 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:51 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:51 INFO  TaskSetManager:57 - Starting task 31.0 in stage 12.0 (TID 16, Clairvoyant-320, executor driver, partition 31, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:51 INFO  Executor:57 - Running task 31.0 in stage 12.0 (TID 16)
2022-02-14 10:55:51 INFO  TaskSetManager:57 - Finished task 29.0 in stage 12.0 (TID 15) in 64 ms on Clairvoyant-320 (executor driver) (4/200)
2022-02-14 10:55:51 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:51 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:51 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 31-32
2022-02-14 10:55:51 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:51 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:51 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:51 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_31,0)
2022-02-14 10:55:51 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-02-14 10:55:51 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:51 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:51 DEBUG TaskMemoryManager:228 - Task 16 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@6e52c8f7
2022-02-14 10:55:51 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:51 DEBUG TaskMemoryManager:228 - Task 16 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@6e52c8f7
2022-02-14 10:55:51 DEBUG TaskMemoryManager:237 - Task 16 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@6e52c8f7
2022-02-14 10:55:51 DEBUG TaskMemoryManager:237 - Task 16 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@6e52c8f7
2022-02-14 10:55:51 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 16 with length 1
2022-02-14 10:55:51 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 16: [59]
2022-02-14 10:55:51 INFO  Executor:57 - Finished task 31.0 in stage 12.0 (TID 16). 6226 bytes result sent to driver
2022-02-14 10:55:51 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:51 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:51 INFO  TaskSetManager:57 - Starting task 35.0 in stage 12.0 (TID 17, Clairvoyant-320, executor driver, partition 35, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:51 INFO  TaskSetManager:57 - Finished task 31.0 in stage 12.0 (TID 16) in 62 ms on Clairvoyant-320 (executor driver) (5/200)
2022-02-14 10:55:51 INFO  Executor:57 - Running task 35.0 in stage 12.0 (TID 17)
2022-02-14 10:55:51 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:51 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:51 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 35-36
2022-02-14 10:55:51 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:51 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:51 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:51 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_35,0)
2022-02-14 10:55:51 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:51 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:51 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:51 DEBUG TaskMemoryManager:228 - Task 17 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4713e3c3
2022-02-14 10:55:51 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:51 DEBUG TaskMemoryManager:228 - Task 17 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@4713e3c3
2022-02-14 10:55:51 DEBUG TaskMemoryManager:237 - Task 17 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4713e3c3
2022-02-14 10:55:51 DEBUG TaskMemoryManager:237 - Task 17 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@4713e3c3
2022-02-14 10:55:51 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 17 with length 1
2022-02-14 10:55:51 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 17: [59]
2022-02-14 10:55:51 INFO  Executor:57 - Finished task 35.0 in stage 12.0 (TID 17). 6269 bytes result sent to driver
2022-02-14 10:55:51 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:51 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:51 INFO  TaskSetManager:57 - Starting task 38.0 in stage 12.0 (TID 18, Clairvoyant-320, executor driver, partition 38, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:51 INFO  TaskSetManager:57 - Finished task 35.0 in stage 12.0 (TID 17) in 71 ms on Clairvoyant-320 (executor driver) (6/200)
2022-02-14 10:55:51 INFO  Executor:57 - Running task 38.0 in stage 12.0 (TID 18)
2022-02-14 10:55:51 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:51 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:51 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 38-39
2022-02-14 10:55:51 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:51 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:51 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:51 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_38,0)
2022-02-14 10:55:51 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:51 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:51 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:51 DEBUG TaskMemoryManager:228 - Task 18 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@21c93657
2022-02-14 10:55:51 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:51 DEBUG TaskMemoryManager:228 - Task 18 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@21c93657
2022-02-14 10:55:51 DEBUG TaskMemoryManager:237 - Task 18 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@21c93657
2022-02-14 10:55:51 DEBUG TaskMemoryManager:237 - Task 18 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@21c93657
2022-02-14 10:55:51 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 18 with length 1
2022-02-14 10:55:51 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 18: [59]
2022-02-14 10:55:51 INFO  Executor:57 - Finished task 38.0 in stage 12.0 (TID 18). 6226 bytes result sent to driver
2022-02-14 10:55:51 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:51 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:51 INFO  TaskSetManager:57 - Starting task 42.0 in stage 12.0 (TID 19, Clairvoyant-320, executor driver, partition 42, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:51 INFO  Executor:57 - Running task 42.0 in stage 12.0 (TID 19)
2022-02-14 10:55:51 INFO  TaskSetManager:57 - Finished task 38.0 in stage 12.0 (TID 18) in 60 ms on Clairvoyant-320 (executor driver) (7/200)
2022-02-14 10:55:51 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:51 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:51 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 42-43
2022-02-14 10:55:51 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:51 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:51 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 3 ms
2022-02-14 10:55:51 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_42,0)
2022-02-14 10:55:51 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 3 ms
2022-02-14 10:55:51 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:51 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:51 DEBUG TaskMemoryManager:228 - Task 19 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@65e92ab4
2022-02-14 10:55:51 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:51 DEBUG TaskMemoryManager:228 - Task 19 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@65e92ab4
2022-02-14 10:55:51 DEBUG TaskMemoryManager:237 - Task 19 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@65e92ab4
2022-02-14 10:55:51 DEBUG TaskMemoryManager:237 - Task 19 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@65e92ab4
2022-02-14 10:55:51 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 19 with length 1
2022-02-14 10:55:51 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 19: [59]
2022-02-14 10:55:51 INFO  Executor:57 - Finished task 42.0 in stage 12.0 (TID 19). 6269 bytes result sent to driver
2022-02-14 10:55:51 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:51 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:51 INFO  TaskSetManager:57 - Starting task 43.0 in stage 12.0 (TID 20, Clairvoyant-320, executor driver, partition 43, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:51 INFO  Executor:57 - Running task 43.0 in stage 12.0 (TID 20)
2022-02-14 10:55:51 INFO  TaskSetManager:57 - Finished task 42.0 in stage 12.0 (TID 19) in 55 ms on Clairvoyant-320 (executor driver) (8/200)
2022-02-14 10:55:51 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:51 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:51 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 43-44
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_43,0)
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 20 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7d7d989
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 20 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@7d7d989
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 20 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7d7d989
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 20 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@7d7d989
2022-02-14 10:55:52 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 20 with length 1
2022-02-14 10:55:52 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 20: [59]
2022-02-14 10:55:52 INFO  Executor:57 - Finished task 43.0 in stage 12.0 (TID 20). 6269 bytes result sent to driver
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:52 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Starting task 48.0 in stage 12.0 (TID 21, Clairvoyant-320, executor driver, partition 48, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:52 INFO  Executor:57 - Running task 48.0 in stage 12.0 (TID 21)
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Finished task 43.0 in stage 12.0 (TID 20) in 56 ms on Clairvoyant-320 (executor driver) (9/200)
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:52 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:52 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 48-49
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_48,0)
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 21 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@9d7bc10
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 21 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@9d7bc10
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 21 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@9d7bc10
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 21 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@9d7bc10
2022-02-14 10:55:52 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 21 with length 1
2022-02-14 10:55:52 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 21: [59]
2022-02-14 10:55:52 INFO  Executor:57 - Finished task 48.0 in stage 12.0 (TID 21). 6269 bytes result sent to driver
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:52 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Starting task 52.0 in stage 12.0 (TID 22, Clairvoyant-320, executor driver, partition 52, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:52 INFO  Executor:57 - Running task 52.0 in stage 12.0 (TID 22)
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Finished task 48.0 in stage 12.0 (TID 21) in 67 ms on Clairvoyant-320 (executor driver) (10/200)
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:52 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:52 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 52-53
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_52,0)
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 22 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@a389bb1
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 22 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@a389bb1
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 22 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@a389bb1
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 22 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@a389bb1
2022-02-14 10:55:52 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 22 with length 1
2022-02-14 10:55:52 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 22: [59]
2022-02-14 10:55:52 INFO  Executor:57 - Finished task 52.0 in stage 12.0 (TID 22). 6269 bytes result sent to driver
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:52 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Starting task 63.0 in stage 12.0 (TID 23, Clairvoyant-320, executor driver, partition 63, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:52 INFO  Executor:57 - Running task 63.0 in stage 12.0 (TID 23)
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Finished task 52.0 in stage 12.0 (TID 22) in 54 ms on Clairvoyant-320 (executor driver) (11/200)
2022-02-14 10:55:52 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:52 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 63-64
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_63,0)
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 23 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@14f15791
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 23 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@14f15791
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 23 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@14f15791
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 23 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@14f15791
2022-02-14 10:55:52 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 23 with length 1
2022-02-14 10:55:52 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 23: [59]
2022-02-14 10:55:52 INFO  Executor:57 - Finished task 63.0 in stage 12.0 (TID 23). 6226 bytes result sent to driver
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:52 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Starting task 73.0 in stage 12.0 (TID 24, Clairvoyant-320, executor driver, partition 73, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:52 INFO  Executor:57 - Running task 73.0 in stage 12.0 (TID 24)
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Finished task 63.0 in stage 12.0 (TID 23) in 61 ms on Clairvoyant-320 (executor driver) (12/200)
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:52 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:52 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 73-74
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_73,0)
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 24 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@204c844f
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 24 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@204c844f
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 24 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@204c844f
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 24 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@204c844f
2022-02-14 10:55:52 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 24 with length 1
2022-02-14 10:55:52 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 24: [59]
2022-02-14 10:55:52 INFO  Executor:57 - Finished task 73.0 in stage 12.0 (TID 24). 6226 bytes result sent to driver
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:52 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Starting task 74.0 in stage 12.0 (TID 25, Clairvoyant-320, executor driver, partition 74, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:52 INFO  Executor:57 - Running task 74.0 in stage 12.0 (TID 25)
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Finished task 73.0 in stage 12.0 (TID 24) in 76 ms on Clairvoyant-320 (executor driver) (13/200)
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:52 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:52 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 74-75
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_74,0)
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 25 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2cb1363b
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 25 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@2cb1363b
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 25 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2cb1363b
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 25 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@2cb1363b
2022-02-14 10:55:52 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 25 with length 1
2022-02-14 10:55:52 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 25: [59]
2022-02-14 10:55:52 INFO  Executor:57 - Finished task 74.0 in stage 12.0 (TID 25). 6269 bytes result sent to driver
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:52 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Starting task 86.0 in stage 12.0 (TID 26, Clairvoyant-320, executor driver, partition 86, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:52 INFO  Executor:57 - Running task 86.0 in stage 12.0 (TID 26)
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Finished task 74.0 in stage 12.0 (TID 25) in 67 ms on Clairvoyant-320 (executor driver) (14/200)
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:52 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:52 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 86-87
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_86,0)
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 26 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4a2ff508
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 26 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@4a2ff508
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 26 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4a2ff508
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 26 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@4a2ff508
2022-02-14 10:55:52 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 26 with length 1
2022-02-14 10:55:52 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 26: [59]
2022-02-14 10:55:52 INFO  Executor:57 - Finished task 86.0 in stage 12.0 (TID 26). 6226 bytes result sent to driver
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:52 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Starting task 89.0 in stage 12.0 (TID 27, Clairvoyant-320, executor driver, partition 89, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:52 INFO  Executor:57 - Running task 89.0 in stage 12.0 (TID 27)
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Finished task 86.0 in stage 12.0 (TID 26) in 60 ms on Clairvoyant-320 (executor driver) (15/200)
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:52 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:52 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 89-90
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_89,0)
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 27 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@6db75f0
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 27 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@6db75f0
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 27 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@6db75f0
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 27 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@6db75f0
2022-02-14 10:55:52 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 27 with length 1
2022-02-14 10:55:52 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 27: [59]
2022-02-14 10:55:52 INFO  Executor:57 - Finished task 89.0 in stage 12.0 (TID 27). 6226 bytes result sent to driver
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:52 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Starting task 90.0 in stage 12.0 (TID 28, Clairvoyant-320, executor driver, partition 90, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:52 INFO  Executor:57 - Running task 90.0 in stage 12.0 (TID 28)
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Finished task 89.0 in stage 12.0 (TID 27) in 60 ms on Clairvoyant-320 (executor driver) (16/200)
2022-02-14 10:55:52 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:52 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 90-91
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_90,0)
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 28 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@bf79e32
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 28 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@bf79e32
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 28 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@bf79e32
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 28 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@bf79e32
2022-02-14 10:55:52 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 28 with length 1
2022-02-14 10:55:52 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 28: [59]
2022-02-14 10:55:52 INFO  Executor:57 - Finished task 90.0 in stage 12.0 (TID 28). 6269 bytes result sent to driver
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:52 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Starting task 108.0 in stage 12.0 (TID 29, Clairvoyant-320, executor driver, partition 108, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Finished task 90.0 in stage 12.0 (TID 28) in 61 ms on Clairvoyant-320 (executor driver) (17/200)
2022-02-14 10:55:52 INFO  Executor:57 - Running task 108.0 in stage 12.0 (TID 29)
2022-02-14 10:55:52 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:52 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 108-109
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 2 ms
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_108,0)
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 3 ms
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 29 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1ab6007e
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 29 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@1ab6007e
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 29 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1ab6007e
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 29 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@1ab6007e
2022-02-14 10:55:52 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 29 with length 1
2022-02-14 10:55:52 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 29: [59]
2022-02-14 10:55:52 INFO  Executor:57 - Finished task 108.0 in stage 12.0 (TID 29). 6269 bytes result sent to driver
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:52 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Starting task 115.0 in stage 12.0 (TID 30, Clairvoyant-320, executor driver, partition 115, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:52 INFO  Executor:57 - Running task 115.0 in stage 12.0 (TID 30)
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Finished task 108.0 in stage 12.0 (TID 29) in 55 ms on Clairvoyant-320 (executor driver) (18/200)
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:52 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:52 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 115-116
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_115,0)
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 30 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@152e1b30
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 30 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@152e1b30
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 30 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@152e1b30
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 30 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@152e1b30
2022-02-14 10:55:52 WARN  ProcfsMetricsGetter:69 - Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-02-14 10:55:52 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 30 with length 1
2022-02-14 10:55:52 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 30: [59]
2022-02-14 10:55:52 INFO  Executor:57 - Finished task 115.0 in stage 12.0 (TID 30). 6226 bytes result sent to driver
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:52 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Starting task 132.0 in stage 12.0 (TID 31, Clairvoyant-320, executor driver, partition 132, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:52 INFO  Executor:57 - Running task 132.0 in stage 12.0 (TID 31)
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Finished task 115.0 in stage 12.0 (TID 30) in 69 ms on Clairvoyant-320 (executor driver) (19/200)
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:52 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:52 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 132-133
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_132,0)
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 31 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5a732c4b
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 31 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@5a732c4b
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 31 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5a732c4b
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 31 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@5a732c4b
2022-02-14 10:55:52 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 31 with length 1
2022-02-14 10:55:52 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 31: [59]
2022-02-14 10:55:52 INFO  Executor:57 - Finished task 132.0 in stage 12.0 (TID 31). 6226 bytes result sent to driver
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:52 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Starting task 160.0 in stage 12.0 (TID 32, Clairvoyant-320, executor driver, partition 160, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:52 INFO  Executor:57 - Running task 160.0 in stage 12.0 (TID 32)
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Finished task 132.0 in stage 12.0 (TID 31) in 61 ms on Clairvoyant-320 (executor driver) (20/200)
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:52 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:52 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 160-161
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_160,0)
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 32 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3260d0a8
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 32 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@3260d0a8
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 32 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3260d0a8
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 32 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@3260d0a8
2022-02-14 10:55:52 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 32 with length 1
2022-02-14 10:55:52 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 32: [59]
2022-02-14 10:55:52 INFO  Executor:57 - Finished task 160.0 in stage 12.0 (TID 32). 6269 bytes result sent to driver
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:52 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Starting task 164.0 in stage 12.0 (TID 33, Clairvoyant-320, executor driver, partition 164, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:52 INFO  Executor:57 - Running task 164.0 in stage 12.0 (TID 33)
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Finished task 160.0 in stage 12.0 (TID 32) in 46 ms on Clairvoyant-320 (executor driver) (21/200)
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:52 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:52 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 164-165
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_164,0)
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 33 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@371615f0
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 33 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@371615f0
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 33 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@371615f0
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 33 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@371615f0
2022-02-14 10:55:52 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 33 with length 1
2022-02-14 10:55:52 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 33: [59]
2022-02-14 10:55:52 INFO  Executor:57 - Finished task 164.0 in stage 12.0 (TID 33). 6226 bytes result sent to driver
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:52 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Starting task 166.0 in stage 12.0 (TID 34, Clairvoyant-320, executor driver, partition 166, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Finished task 164.0 in stage 12.0 (TID 33) in 50 ms on Clairvoyant-320 (executor driver) (22/200)
2022-02-14 10:55:52 INFO  Executor:57 - Running task 166.0 in stage 12.0 (TID 34)
2022-02-14 10:55:52 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:52 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 166-167
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_166,0)
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 34 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@39c96377
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 34 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@39c96377
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 34 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@39c96377
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 34 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@39c96377
2022-02-14 10:55:52 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 34 with length 1
2022-02-14 10:55:52 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 34: [59]
2022-02-14 10:55:52 INFO  Executor:57 - Finished task 166.0 in stage 12.0 (TID 34). 6226 bytes result sent to driver
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:52 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Starting task 169.0 in stage 12.0 (TID 35, Clairvoyant-320, executor driver, partition 169, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:52 INFO  Executor:57 - Running task 169.0 in stage 12.0 (TID 35)
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Finished task 166.0 in stage 12.0 (TID 34) in 57 ms on Clairvoyant-320 (executor driver) (23/200)
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:52 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:52 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 169-170
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_169,0)
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 35 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@531e0b18
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 35 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@531e0b18
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 35 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@531e0b18
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 35 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@531e0b18
2022-02-14 10:55:52 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 35 with length 1
2022-02-14 10:55:52 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 35: [59]
2022-02-14 10:55:52 INFO  Executor:57 - Finished task 169.0 in stage 12.0 (TID 35). 6226 bytes result sent to driver
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:52 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Starting task 176.0 in stage 12.0 (TID 36, Clairvoyant-320, executor driver, partition 176, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:52 INFO  Executor:57 - Running task 176.0 in stage 12.0 (TID 36)
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Finished task 169.0 in stage 12.0 (TID 35) in 59 ms on Clairvoyant-320 (executor driver) (24/200)
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:52 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:52 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 176-177
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:52 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_176,0)
2022-02-14 10:55:52 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 36 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2edf4a25
2022-02-14 10:55:52 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:52 DEBUG TaskMemoryManager:228 - Task 36 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@2edf4a25
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 36 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2edf4a25
2022-02-14 10:55:52 DEBUG TaskMemoryManager:237 - Task 36 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@2edf4a25
2022-02-14 10:55:52 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 36 with length 1
2022-02-14 10:55:52 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 36: [59]
2022-02-14 10:55:52 INFO  Executor:57 - Finished task 176.0 in stage 12.0 (TID 36). 6226 bytes result sent to driver
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:52 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Starting task 179.0 in stage 12.0 (TID 37, Clairvoyant-320, executor driver, partition 179, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:52 INFO  Executor:57 - Running task 179.0 in stage 12.0 (TID 37)
2022-02-14 10:55:52 INFO  TaskSetManager:57 - Finished task 176.0 in stage 12.0 (TID 36) in 62 ms on Clairvoyant-320 (executor driver) (25/200)
2022-02-14 10:55:52 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:52 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:53 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 179-180
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_179,0)
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 37 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@79297e5b
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 37 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@79297e5b
2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 37 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@79297e5b
2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 37 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@79297e5b
2022-02-14 10:55:53 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 37 with length 1
2022-02-14 10:55:53 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 37: [59]
2022-02-14 10:55:53 INFO  Executor:57 - Finished task 179.0 in stage 12.0 (TID 37). 6226 bytes result sent to driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:53 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Starting task 183.0 in stage 12.0 (TID 38, Clairvoyant-320, executor driver, partition 183, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Finished task 179.0 in stage 12.0 (TID 37) in 51 ms on Clairvoyant-320 (executor driver) (26/200)
2022-02-14 10:55:53 INFO  Executor:57 - Running task 183.0 in stage 12.0 (TID 38)
2022-02-14 10:55:53 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:53 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 183-184
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_183,0)
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 38 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@57f7ece3
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 38 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@57f7ece3
2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 38 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@57f7ece3
2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 38 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@57f7ece3
2022-02-14 10:55:53 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 38 with length 1
2022-02-14 10:55:53 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 38: [59]
2022-02-14 10:55:53 INFO  Executor:57 - Finished task 183.0 in stage 12.0 (TID 38). 6226 bytes result sent to driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:53 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Starting task 190.0 in stage 12.0 (TID 39, Clairvoyant-320, executor driver, partition 190, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:53 INFO  Executor:57 - Running task 190.0 in stage 12.0 (TID 39)
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Finished task 183.0 in stage 12.0 (TID 38) in 60 ms on Clairvoyant-320 (executor driver) (27/200)
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:53 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:53 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 190-191
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_190,0)
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 39 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4566065
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 39 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@4566065
2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 39 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4566065
2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 39 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@4566065
2022-02-14 10:55:53 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 39 with length 1
2022-02-14 10:55:53 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 39: [59]
2022-02-14 10:55:53 INFO  Executor:57 - Finished task 190.0 in stage 12.0 (TID 39). 6269 bytes result sent to driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:53 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Starting task 191.0 in stage 12.0 (TID 40, Clairvoyant-320, executor driver, partition 191, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:53 INFO  Executor:57 - Running task 191.0 in stage 12.0 (TID 40)
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Finished task 190.0 in stage 12.0 (TID 39) in 55 ms on Clairvoyant-320 (executor driver) (28/200)
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:53 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:53 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 191-192
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_191,0)
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 40 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@ee20bbc
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 40 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@ee20bbc
2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 40 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@ee20bbc
2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 40 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@ee20bbc
2022-02-14 10:55:53 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 40 with length 1
2022-02-14 10:55:53 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 40: [59]
2022-02-14 10:55:53 INFO  Executor:57 - Finished task 191.0 in stage 12.0 (TID 40). 6226 bytes result sent to driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:53 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Starting task 193.0 in stage 12.0 (TID 41, Clairvoyant-320, executor driver, partition 193, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:53 INFO  Executor:57 - Running task 193.0 in stage 12.0 (TID 41)
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Finished task 191.0 in stage 12.0 (TID 40) in 58 ms on Clairvoyant-320 (executor driver) (29/200)
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:53 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:53 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 193-194
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_193,0)
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 41 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@47741adc
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 41 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@47741adc
2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 41 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@47741adc
2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 41 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@47741adc
2022-02-14 10:55:53 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 41 with length 1
2022-02-14 10:55:53 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 41: [59]
2022-02-14 10:55:53 INFO  Executor:57 - Finished task 193.0 in stage 12.0 (TID 41). 6226 bytes result sent to driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:53 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Starting task 199.0 in stage 12.0 (TID 42, Clairvoyant-320, executor driver, partition 199, NODE_LOCAL, 7314 bytes)
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Finished task 193.0 in stage 12.0 (TID 41) in 51 ms on Clairvoyant-320 (executor driver) (30/200)
2022-02-14 10:55:53 INFO  Executor:57 - Running task 199.0 in stage 12.0 (TID 42)
2022-02-14 10:55:53 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:53 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 199-200
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_11_199,0)
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 42 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@78a1c8f5
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 42 acquired 64.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@78a1c8f5
2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 42 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@78a1c8f5
2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 42 release 64.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@78a1c8f5
2022-02-14 10:55:53 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 42 with length 1
2022-02-14 10:55:53 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 42: [59]
2022-02-14 10:55:53 INFO  Executor:57 - Finished task 199.0 in stage 12.0 (TID 42). 6226 bytes result sent to driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:53 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:53 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-02-14 10:55:53 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Starting task 0.0 in stage 12.0 (TID 43, Clairvoyant-320, executor driver, partition 0, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:53 INFO  Executor:57 - Running task 0.0 in stage 12.0 (TID 43)
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Finished task 199.0 in stage 12.0 (TID 42) in 84 ms on Clairvoyant-320 (executor driver) (31/200)
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:53 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:53 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 0-1
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 43 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5f1dd9fe
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 43 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5f1dd9fe
2022-02-14 10:55:53 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 43 with length 1
2022-02-14 10:55:53 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 43: [56]
2022-02-14 10:55:53 INFO  Executor:57 - Finished task 0.0 in stage 12.0 (TID 43). 6269 bytes result sent to driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:53 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Starting task 1.0 in stage 12.0 (TID 44, Clairvoyant-320, executor driver, partition 1, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Finished task 0.0 in stage 12.0 (TID 43) in 66 ms on Clairvoyant-320 (executor driver) (32/200)
2022-02-14 10:55:53 INFO  Executor:57 - Running task 1.0 in stage 12.0 (TID 44)
2022-02-14 10:55:53 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:53 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 1-2
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 44 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2f279a76
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 44 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2f279a76
2022-02-14 10:55:53 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 44 with length 1
2022-02-14 10:55:53 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 44: [56]
2022-02-14 10:55:53 INFO  Executor:57 - Finished task 1.0 in stage 12.0 (TID 44). 6226 bytes result sent to driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:53 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Starting task 2.0 in stage 12.0 (TID 45, Clairvoyant-320, executor driver, partition 2, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Finished task 1.0 in stage 12.0 (TID 44) in 55 ms on Clairvoyant-320 (executor driver) (33/200)
2022-02-14 10:55:53 INFO  Executor:57 - Running task 2.0 in stage 12.0 (TID 45)
2022-02-14 10:55:53 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:53 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 2-3
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(26)
2022-02-14 10:55:53 DEBUG ContextCleaner:61 - Cleaning broadcast 26
2022-02-14 10:55:53 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 26
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:53 DEBUG BlockManagerSlaveEndpoint:61 - removing broadcast 26
2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 45 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@719b1d73
2022-02-14 10:55:53 DEBUG BlockManager:61 - Removing broadcast 26
2022-02-14 10:55:53 DEBUG BlockManager:61 - Removing block broadcast_26
2022-02-14 10:55:53 DEBUG MemoryStore:61 - Block broadcast_26 of size 41600 dropped from memory (free 2343480687)
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG BlockManager:61 - Removing block broadcast_26_piece0
2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 45 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@719b1d73
2022-02-14 10:55:53 DEBUG MemoryStore:61 - Block broadcast_26_piece0 of size 18427 dropped from memory (free 2343499114)
2022-02-14 10:55:53 INFO  BlockManagerInfo:57 - Removed broadcast_26_piece0 on Clairvoyant-320:60340 in memory (size: 18.0 KiB, free: 2.2 GiB)
2022-02-14 10:55:53 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_26_piece0
2022-02-14 10:55:53 DEBUG BlockManager:61 - Told master about block broadcast_26_piece0
2022-02-14 10:55:53 DEBUG BlockManagerSlaveEndpoint:61 - Done removing broadcast 26, response is 0
2022-02-14 10:55:53 DEBUG BlockManagerSlaveEndpoint:61 - Sent response: 0 to Clairvoyant-320:60325
2022-02-14 10:55:53 DEBUG ContextCleaner:61 - Cleaned broadcast 26
2022-02-14 10:55:53 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 45 with length 1
2022-02-14 10:55:53 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 45: [56]
2022-02-14 10:55:53 INFO  Executor:57 - Finished task 2.0 in stage 12.0 (TID 45). 6269 bytes result sent to driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:53 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Starting task 3.0 in stage 12.0 (TID 46, Clairvoyant-320, executor driver, partition 3, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:53 INFO  Executor:57 - Running task 3.0 in stage 12.0 (TID 46)
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Finished task 2.0 in stage 12.0 (TID 45) in 74 ms on Clairvoyant-320 (executor driver) (34/200)
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:53 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:53 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 3-4
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 46 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4bb877d
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 46 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4bb877d
2022-02-14 10:55:53 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 46 with length 1
2022-02-14 10:55:53 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 46: [56]
2022-02-14 10:55:53 INFO  Executor:57 - Finished task 3.0 in stage 12.0 (TID 46). 6269 bytes result sent to driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:53 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Starting task 4.0 in stage 12.0 (TID 47, Clairvoyant-320, executor driver, partition 4, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:53 INFO  Executor:57 - Running task 4.0 in stage 12.0 (TID 47)
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Finished task 3.0 in stage 12.0 (TID 46) in 43 ms on Clairvoyant-320 (executor driver) (35/200)
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:53 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:53 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 4-5
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 47 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@16118e8f
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 47 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@16118e8f
2022-02-14 10:55:53 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 47 with length 1
2022-02-14 10:55:53 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 47: [56]
2022-02-14 10:55:53 INFO  Executor:57 - Finished task 4.0 in stage 12.0 (TID 47). 6269 bytes result sent to driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:53 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Starting task 5.0 in stage 12.0 (TID 48, Clairvoyant-320, executor driver, partition 5, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:53 INFO  Executor:57 - Running task 5.0 in stage 12.0 (TID 48)
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Finished task 4.0 in stage 12.0 (TID 47) in 54 ms on Clairvoyant-320 (executor driver) (36/200)
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:53 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:53 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 5-6
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 48 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@177c2b8c
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 48 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@177c2b8c
2022-02-14 10:55:53 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 48 with length 1
2022-02-14 10:55:53 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 48: [56]
2022-02-14 10:55:53 INFO  Executor:57 - Finished task 5.0 in stage 12.0 (TID 48). 6226 bytes result sent to driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:53 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Starting task 6.0 in stage 12.0 (TID 49, Clairvoyant-320, executor driver, partition 6, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:53 INFO  Executor:57 - Running task 6.0 in stage 12.0 (TID 49)
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Finished task 5.0 in stage 12.0 (TID 48) in 40 ms on Clairvoyant-320 (executor driver) (37/200)
2022-02-14 10:55:53 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:53 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 6-7
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 49 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5df4a8c5
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 49 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5df4a8c5
2022-02-14 10:55:53 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 49 with length 1
2022-02-14 10:55:53 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 49: [56]
2022-02-14 10:55:53 INFO  Executor:57 - Finished task 6.0 in stage 12.0 (TID 49). 6226 bytes result sent to driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:53 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Starting task 8.0 in stage 12.0 (TID 50, Clairvoyant-320, executor driver, partition 8, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:53 INFO  Executor:57 - Running task 8.0 in stage 12.0 (TID 50)
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Finished task 6.0 in stage 12.0 (TID 49) in 41 ms on Clairvoyant-320 (executor driver) (38/200)
2022-02-14 10:55:53 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:53 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 8-9
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 50 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@23a547d1
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 50 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@23a547d1
2022-02-14 10:55:53 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 50 with length 1
2022-02-14 10:55:53 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 50: [56]
2022-02-14 10:55:53 INFO  Executor:57 - Finished task 8.0 in stage 12.0 (TID 50). 6226 bytes result sent to driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:53 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Starting task 9.0 in stage 12.0 (TID 51, Clairvoyant-320, executor driver, partition 9, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Finished task 8.0 in stage 12.0 (TID 50) in 58 ms on Clairvoyant-320 (executor driver) (39/200)
2022-02-14 10:55:53 INFO  Executor:57 - Running task 9.0 in stage 12.0 (TID 51)
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:53 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:53 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 9-10
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 51 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@6dc7b9d2
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 51 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@6dc7b9d2
2022-02-14 10:55:53 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 51 with length 1
2022-02-14 10:55:53 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 51: [56]
2022-02-14 10:55:53 INFO  Executor:57 - Finished task 9.0 in stage 12.0 (TID 51). 6226 bytes result sent to driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:53 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Starting task 10.0 in stage 12.0 (TID 52, Clairvoyant-320, executor driver, partition 10, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:53 INFO  Executor:57 - Running task 10.0 in stage 12.0 (TID 52)
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Finished task 9.0 in stage 12.0 (TID 51) in 38 ms on Clairvoyant-320 (executor driver) (40/200)
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:53 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:53 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 10-11
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 52 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@197ba164
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 52 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@197ba164
2022-02-14 10:55:53 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 52 with length 1
2022-02-14 10:55:53 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 52: [56]
2022-02-14 10:55:53 INFO  Executor:57 - Finished task 10.0 in stage 12.0 (TID 52). 6269 bytes result sent to driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:53 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Starting task 11.0 in stage 12.0 (TID 53, Clairvoyant-320, executor driver, partition 11, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:53 INFO  Executor:57 - Running task 11.0 in stage 12.0 (TID 53)
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Finished task 10.0 in stage 12.0 (TID 52) in 42 ms on Clairvoyant-320 (executor driver) (41/200)
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:53 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:53 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 11-12
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 53 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@b8c8f93
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 53 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@b8c8f93
2022-02-14 10:55:53 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 53 with length 1
2022-02-14 10:55:53 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 53: [56]
2022-02-14 10:55:53 INFO  Executor:57 - Finished task 11.0 in stage 12.0 (TID 53). 6226 bytes result sent to driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:53 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Starting task 12.0 in stage 12.0 (TID 54, Clairvoyant-320, executor driver, partition 12, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:53 INFO  Executor:57 - Running task 12.0 in stage 12.0 (TID 54)
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Finished task 11.0 in stage 12.0 (TID 53) in 30 ms on Clairvoyant-320 (executor driver) (42/200)
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:53 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:53 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 12-13
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 54 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@23970a42
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 54 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@23970a42
2022-02-14 10:55:53 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 54 with length 1
2022-02-14 10:55:53 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 54: [56]
2022-02-14 10:55:53 INFO  Executor:57 - Finished task 12.0 in stage 12.0 (TID 54). 6226 bytes result sent to driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:53 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Starting task 13.0 in stage 12.0 (TID 55, Clairvoyant-320, executor driver, partition 13, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Finished task 12.0 in stage 12.0 (TID 54) in 35 ms on Clairvoyant-320 (executor driver) (43/200)
2022-02-14 10:55:53 INFO  Executor:57 - Running task 13.0 in stage 12.0 (TID 55)
2022-02-14 10:55:53 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:53 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 13-14
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 55 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@177f213c
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 55 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@177f213c
2022-02-14 10:55:53 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 55 with length 1
2022-02-14 10:55:53 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 55: [56]
2022-02-14 10:55:53 INFO  Executor:57 - Finished task 13.0 in stage 12.0 (TID 55). 6226 bytes result sent to driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:53 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Starting task 14.0 in stage 12.0 (TID 56, Clairvoyant-320, executor driver, partition 14, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:53 INFO  Executor:57 - Running task 14.0 in stage 12.0 (TID 56)
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Finished task 13.0 in stage 12.0 (TID 55) in 35 ms on Clairvoyant-320 (executor driver) (44/200)
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:53 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:53 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 14-15
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 56 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1cf5dbd0
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 56 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1cf5dbd0
2022-02-14 10:55:53 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 56 with length 1
2022-02-14 10:55:53 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 56: [56]
2022-02-14 10:55:53 INFO  Executor:57 - Finished task 14.0 in stage 12.0 (TID 56). 6269 bytes result sent to driver
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:53 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Starting task 15.0 in stage 12.0 (TID 57, Clairvoyant-320, executor driver, partition 15, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:53 INFO  Executor:57 - Running task 15.0 in stage 12.0 (TID 57)
2022-02-14 10:55:53 INFO  TaskSetManager:57 - Finished task 14.0 in stage 12.0 (TID 56) in 34 ms on Clairvoyant-320 (executor driver) (45/200)
2022-02-14 10:55:53 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:53 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:53 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 15-16
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:53 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:53 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:228 - Task 57 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@692524f0
2022-02-14 10:55:53 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:53 DEBUG TaskMemoryManager:237 - Task 57 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@692524f0
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 57 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 57: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 15.0 in stage 12.0 (TID 57). 6269 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 16.0 in stage 12.0 (TID 58, Clairvoyant-320, executor driver, partition 16, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 15.0 in stage 12.0 (TID 57) in 36 ms on Clairvoyant-320 (executor driver) (46/200)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 16.0 in stage 12.0 (TID 58)
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 16-17
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 58 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@32213775
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 58 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@32213775
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 58 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 58: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 16.0 in stage 12.0 (TID 58). 6226 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 18.0 in stage 12.0 (TID 59, Clairvoyant-320, executor driver, partition 18, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 16.0 in stage 12.0 (TID 58) in 44 ms on Clairvoyant-320 (executor driver) (47/200)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 18.0 in stage 12.0 (TID 59)
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 18-19
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 59 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2cdd0403
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 59 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2cdd0403
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 59 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 59: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 18.0 in stage 12.0 (TID 59). 6226 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 20.0 in stage 12.0 (TID 60, Clairvoyant-320, executor driver, partition 20, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 20.0 in stage 12.0 (TID 60)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 18.0 in stage 12.0 (TID 59) in 33 ms on Clairvoyant-320 (executor driver) (48/200)
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 20-21
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 60 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@681790f6
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 60 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@681790f6
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 60 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 60: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 20.0 in stage 12.0 (TID 60). 6269 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 21.0 in stage 12.0 (TID 61, Clairvoyant-320, executor driver, partition 21, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 21.0 in stage 12.0 (TID 61)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 20.0 in stage 12.0 (TID 60) in 37 ms on Clairvoyant-320 (executor driver) (49/200)
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 21-22
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 61 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@18326953
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 61 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@18326953
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 61 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 61: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 21.0 in stage 12.0 (TID 61). 6226 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 22.0 in stage 12.0 (TID 62, Clairvoyant-320, executor driver, partition 22, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 22.0 in stage 12.0 (TID 62)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 21.0 in stage 12.0 (TID 61) in 32 ms on Clairvoyant-320 (executor driver) (50/200)
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 22-23
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 62 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@76f6e671
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 62 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@76f6e671
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 62 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 62: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 22.0 in stage 12.0 (TID 62). 6226 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 23.0 in stage 12.0 (TID 63, Clairvoyant-320, executor driver, partition 23, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 22.0 in stage 12.0 (TID 62) in 49 ms on Clairvoyant-320 (executor driver) (51/200)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 23.0 in stage 12.0 (TID 63)
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 23-24
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 63 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2c279654
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 63 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2c279654
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 63 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 63: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 23.0 in stage 12.0 (TID 63). 6226 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 24.0 in stage 12.0 (TID 64, Clairvoyant-320, executor driver, partition 24, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 24.0 in stage 12.0 (TID 64)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 23.0 in stage 12.0 (TID 63) in 39 ms on Clairvoyant-320 (executor driver) (52/200)
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 24-25
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 64 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@b5b9b2d
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 64 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@b5b9b2d
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 64 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 64: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 24.0 in stage 12.0 (TID 64). 6269 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 25.0 in stage 12.0 (TID 65, Clairvoyant-320, executor driver, partition 25, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 25.0 in stage 12.0 (TID 65)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 24.0 in stage 12.0 (TID 64) in 36 ms on Clairvoyant-320 (executor driver) (53/200)
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 25-26
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 65 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@59cb23b7
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 65 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@59cb23b7
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 65 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 65: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 25.0 in stage 12.0 (TID 65). 6269 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 26.0 in stage 12.0 (TID 66, Clairvoyant-320, executor driver, partition 26, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 26.0 in stage 12.0 (TID 66)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 25.0 in stage 12.0 (TID 65) in 35 ms on Clairvoyant-320 (executor driver) (54/200)
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 26-27
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 66 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@31059a38
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 66 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@31059a38
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 66 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 66: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 26.0 in stage 12.0 (TID 66). 6226 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 27.0 in stage 12.0 (TID 67, Clairvoyant-320, executor driver, partition 27, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 26.0 in stage 12.0 (TID 66) in 45 ms on Clairvoyant-320 (executor driver) (55/200)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 27.0 in stage 12.0 (TID 67)
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 27-28
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 67 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@d4832b0
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 67 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@d4832b0
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 67 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 67: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 27.0 in stage 12.0 (TID 67). 6226 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 28.0 in stage 12.0 (TID 68, Clairvoyant-320, executor driver, partition 28, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 28.0 in stage 12.0 (TID 68)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 27.0 in stage 12.0 (TID 67) in 40 ms on Clairvoyant-320 (executor driver) (56/200)
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 28-29
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 68 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@6969863d
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 68 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@6969863d
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 68 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 68: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 28.0 in stage 12.0 (TID 68). 6226 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 30.0 in stage 12.0 (TID 69, Clairvoyant-320, executor driver, partition 30, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 30.0 in stage 12.0 (TID 69)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 28.0 in stage 12.0 (TID 68) in 43 ms on Clairvoyant-320 (executor driver) (57/200)
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 30-31
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 69 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2b266cc
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 69 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2b266cc
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 69 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 69: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 30.0 in stage 12.0 (TID 69). 6226 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 32.0 in stage 12.0 (TID 70, Clairvoyant-320, executor driver, partition 32, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 32.0 in stage 12.0 (TID 70)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 30.0 in stage 12.0 (TID 69) in 38 ms on Clairvoyant-320 (executor driver) (58/200)
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 32-33
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 70 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@13d289fc
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 70 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@13d289fc
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 70 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 70: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 32.0 in stage 12.0 (TID 70). 6226 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 33.0 in stage 12.0 (TID 71, Clairvoyant-320, executor driver, partition 33, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 33.0 in stage 12.0 (TID 71)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 32.0 in stage 12.0 (TID 70) in 42 ms on Clairvoyant-320 (executor driver) (59/200)
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 33-34
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 71 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@56accfcb
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 71 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@56accfcb
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 71 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 71: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 33.0 in stage 12.0 (TID 71). 6226 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 34.0 in stage 12.0 (TID 72, Clairvoyant-320, executor driver, partition 34, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 34.0 in stage 12.0 (TID 72)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 33.0 in stage 12.0 (TID 71) in 35 ms on Clairvoyant-320 (executor driver) (60/200)
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 34-35
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 72 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@41e4ee44
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 72 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@41e4ee44
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 72 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 72: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 34.0 in stage 12.0 (TID 72). 6226 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 36.0 in stage 12.0 (TID 73, Clairvoyant-320, executor driver, partition 36, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 36.0 in stage 12.0 (TID 73)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 34.0 in stage 12.0 (TID 72) in 42 ms on Clairvoyant-320 (executor driver) (61/200)
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 36-37
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 73 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3042b9c5
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 73 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3042b9c5
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 73 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 73: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 36.0 in stage 12.0 (TID 73). 6226 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 37.0 in stage 12.0 (TID 74, Clairvoyant-320, executor driver, partition 37, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 37.0 in stage 12.0 (TID 74)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 36.0 in stage 12.0 (TID 73) in 31 ms on Clairvoyant-320 (executor driver) (62/200)
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 37-38
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 74 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2ead59b7
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 74 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2ead59b7
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 74 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 74: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 37.0 in stage 12.0 (TID 74). 6269 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 39.0 in stage 12.0 (TID 75, Clairvoyant-320, executor driver, partition 39, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 39.0 in stage 12.0 (TID 75)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 37.0 in stage 12.0 (TID 74) in 35 ms on Clairvoyant-320 (executor driver) (63/200)
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 39-40
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 75 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3b7574a5
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 75 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3b7574a5
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 75 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 75: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 39.0 in stage 12.0 (TID 75). 6269 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 40.0 in stage 12.0 (TID 76, Clairvoyant-320, executor driver, partition 40, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 40.0 in stage 12.0 (TID 76)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 39.0 in stage 12.0 (TID 75) in 48 ms on Clairvoyant-320 (executor driver) (64/200)
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 40-41
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 76 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2b4d71ca
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 76 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2b4d71ca
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 76 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 76: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 40.0 in stage 12.0 (TID 76). 6269 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 41.0 in stage 12.0 (TID 77, Clairvoyant-320, executor driver, partition 41, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 41.0 in stage 12.0 (TID 77)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 40.0 in stage 12.0 (TID 76) in 36 ms on Clairvoyant-320 (executor driver) (65/200)
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 41-42
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 77 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3e9e9db5
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 77 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3e9e9db5
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 77 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 77: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 41.0 in stage 12.0 (TID 77). 6269 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 44.0 in stage 12.0 (TID 78, Clairvoyant-320, executor driver, partition 44, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 41.0 in stage 12.0 (TID 77) in 36 ms on Clairvoyant-320 (executor driver) (66/200)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 44.0 in stage 12.0 (TID 78)
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 44-45
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 78 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@273d6e75
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 78 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@273d6e75
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 78 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 78: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 44.0 in stage 12.0 (TID 78). 6226 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 45.0 in stage 12.0 (TID 79, Clairvoyant-320, executor driver, partition 45, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 45.0 in stage 12.0 (TID 79)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 44.0 in stage 12.0 (TID 78) in 39 ms on Clairvoyant-320 (executor driver) (67/200)
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 45-46
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 79 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@701e9fd6
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 79 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@701e9fd6
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 79 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 79: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 45.0 in stage 12.0 (TID 79). 6269 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 46.0 in stage 12.0 (TID 80, Clairvoyant-320, executor driver, partition 46, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 45.0 in stage 12.0 (TID 79) in 37 ms on Clairvoyant-320 (executor driver) (68/200)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 46.0 in stage 12.0 (TID 80)
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 46-47
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 80 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@518b4742
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 80 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@518b4742
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 80 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 80: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 46.0 in stage 12.0 (TID 80). 6226 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 47.0 in stage 12.0 (TID 81, Clairvoyant-320, executor driver, partition 47, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 47.0 in stage 12.0 (TID 81)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 46.0 in stage 12.0 (TID 80) in 35 ms on Clairvoyant-320 (executor driver) (69/200)
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 47-48
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 81 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1511a57f
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 81 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1511a57f
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 81 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 81: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 47.0 in stage 12.0 (TID 81). 6226 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 49.0 in stage 12.0 (TID 82, Clairvoyant-320, executor driver, partition 49, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 49.0 in stage 12.0 (TID 82)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 47.0 in stage 12.0 (TID 81) in 37 ms on Clairvoyant-320 (executor driver) (70/200)
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 49-50
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 82 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@778c6cf6
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 82 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@778c6cf6
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 82 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 82: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 49.0 in stage 12.0 (TID 82). 6226 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 50.0 in stage 12.0 (TID 83, Clairvoyant-320, executor driver, partition 50, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 50.0 in stage 12.0 (TID 83)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 49.0 in stage 12.0 (TID 82) in 34 ms on Clairvoyant-320 (executor driver) (71/200)
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 50-51
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 83 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@523d2399
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 83 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@523d2399
2022-02-14 10:55:54 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 83 with length 1
2022-02-14 10:55:54 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 83: [56]
2022-02-14 10:55:54 INFO  Executor:57 - Finished task 50.0 in stage 12.0 (TID 83). 6269 bytes result sent to driver
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:54 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Starting task 51.0 in stage 12.0 (TID 84, Clairvoyant-320, executor driver, partition 51, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:54 INFO  Executor:57 - Running task 51.0 in stage 12.0 (TID 84)
2022-02-14 10:55:54 INFO  TaskSetManager:57 - Finished task 50.0 in stage 12.0 (TID 83) in 35 ms on Clairvoyant-320 (executor driver) (72/200)
2022-02-14 10:55:54 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:54 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:54 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 51-52
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:54 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:54 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:228 - Task 84 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@63d403ae
2022-02-14 10:55:54 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:54 DEBUG TaskMemoryManager:237 - Task 84 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@63d403ae
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 84 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 84: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 51.0 in stage 12.0 (TID 84). 6269 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 53.0 in stage 12.0 (TID 85, Clairvoyant-320, executor driver, partition 53, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 53.0 in stage 12.0 (TID 85)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 51.0 in stage 12.0 (TID 84) in 44 ms on Clairvoyant-320 (executor driver) (73/200)
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 53-54
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 85 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@64f245c0
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 85 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@64f245c0
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 85 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 85: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 53.0 in stage 12.0 (TID 85). 6226 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 54.0 in stage 12.0 (TID 86, Clairvoyant-320, executor driver, partition 54, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 54.0 in stage 12.0 (TID 86)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 53.0 in stage 12.0 (TID 85) in 30 ms on Clairvoyant-320 (executor driver) (74/200)
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 54-55
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 86 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5093883f
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 86 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5093883f
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 86 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 86: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 54.0 in stage 12.0 (TID 86). 6269 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 55.0 in stage 12.0 (TID 87, Clairvoyant-320, executor driver, partition 55, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 55.0 in stage 12.0 (TID 87)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 54.0 in stage 12.0 (TID 86) in 42 ms on Clairvoyant-320 (executor driver) (75/200)
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 55-56
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 87 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7c2631a9
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 87 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7c2631a9
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 87 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 87: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 55.0 in stage 12.0 (TID 87). 6226 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 56.0 in stage 12.0 (TID 88, Clairvoyant-320, executor driver, partition 56, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 55.0 in stage 12.0 (TID 87) in 34 ms on Clairvoyant-320 (executor driver) (76/200)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 56.0 in stage 12.0 (TID 88)
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 56-57
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 88 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@77562242
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 88 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@77562242
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 88 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 88: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 56.0 in stage 12.0 (TID 88). 6226 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 57.0 in stage 12.0 (TID 89, Clairvoyant-320, executor driver, partition 57, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 57.0 in stage 12.0 (TID 89)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 56.0 in stage 12.0 (TID 88) in 36 ms on Clairvoyant-320 (executor driver) (77/200)
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 57-58
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 89 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7d4c12d1
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 89 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7d4c12d1
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 89 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 89: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 57.0 in stage 12.0 (TID 89). 6269 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 58.0 in stage 12.0 (TID 90, Clairvoyant-320, executor driver, partition 58, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 57.0 in stage 12.0 (TID 89) in 32 ms on Clairvoyant-320 (executor driver) (78/200)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 58.0 in stage 12.0 (TID 90)
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 58-59
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 90 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@64f883a7
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 90 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@64f883a7
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 90 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 90: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 58.0 in stage 12.0 (TID 90). 6269 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 59.0 in stage 12.0 (TID 91, Clairvoyant-320, executor driver, partition 59, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 59.0 in stage 12.0 (TID 91)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 58.0 in stage 12.0 (TID 90) in 45 ms on Clairvoyant-320 (executor driver) (79/200)
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 59-60
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 91 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@50d02b2a
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 91 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@50d02b2a
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 91 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 91: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 59.0 in stage 12.0 (TID 91). 6269 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 60.0 in stage 12.0 (TID 92, Clairvoyant-320, executor driver, partition 60, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 59.0 in stage 12.0 (TID 91) in 32 ms on Clairvoyant-320 (executor driver) (80/200)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 60.0 in stage 12.0 (TID 92)
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 60-61
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 92 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3f3f27ab
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 92 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3f3f27ab
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 92 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 92: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 60.0 in stage 12.0 (TID 92). 6269 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 61.0 in stage 12.0 (TID 93, Clairvoyant-320, executor driver, partition 61, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 60.0 in stage 12.0 (TID 92) in 41 ms on Clairvoyant-320 (executor driver) (81/200)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 61.0 in stage 12.0 (TID 93)
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 61-62
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 93 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@450b3b33
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 93 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@450b3b33
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 93 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 93: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 61.0 in stage 12.0 (TID 93). 6269 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 62.0 in stage 12.0 (TID 94, Clairvoyant-320, executor driver, partition 62, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 61.0 in stage 12.0 (TID 93) in 45 ms on Clairvoyant-320 (executor driver) (82/200)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 62.0 in stage 12.0 (TID 94)
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 62-63
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 94 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@59840263
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 94 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@59840263
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 94 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 94: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 62.0 in stage 12.0 (TID 94). 6226 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 64.0 in stage 12.0 (TID 95, Clairvoyant-320, executor driver, partition 64, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 62.0 in stage 12.0 (TID 94) in 34 ms on Clairvoyant-320 (executor driver) (83/200)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 64.0 in stage 12.0 (TID 95)
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 64-65
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 95 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@481124cb
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 95 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@481124cb
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 95 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 95: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 64.0 in stage 12.0 (TID 95). 6269 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 65.0 in stage 12.0 (TID 96, Clairvoyant-320, executor driver, partition 65, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 65.0 in stage 12.0 (TID 96)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 64.0 in stage 12.0 (TID 95) in 42 ms on Clairvoyant-320 (executor driver) (84/200)
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 65-66
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 96 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7241f77c
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 96 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7241f77c
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 96 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 96: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 65.0 in stage 12.0 (TID 96). 6226 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 66.0 in stage 12.0 (TID 97, Clairvoyant-320, executor driver, partition 66, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 65.0 in stage 12.0 (TID 96) in 40 ms on Clairvoyant-320 (executor driver) (85/200)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 66.0 in stage 12.0 (TID 97)
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 66-67
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 97 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5700fac8
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 97 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5700fac8
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 97 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 97: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 66.0 in stage 12.0 (TID 97). 6226 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 67.0 in stage 12.0 (TID 98, Clairvoyant-320, executor driver, partition 67, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 66.0 in stage 12.0 (TID 97) in 33 ms on Clairvoyant-320 (executor driver) (86/200)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 67.0 in stage 12.0 (TID 98)
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 67-68
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 98 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@6addb97a
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 98 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@6addb97a
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 98 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 98: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 67.0 in stage 12.0 (TID 98). 6269 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 68.0 in stage 12.0 (TID 99, Clairvoyant-320, executor driver, partition 68, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 67.0 in stage 12.0 (TID 98) in 37 ms on Clairvoyant-320 (executor driver) (87/200)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 68.0 in stage 12.0 (TID 99)
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 68-69
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 99 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1918bd7
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 99 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1918bd7
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 99 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 99: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 68.0 in stage 12.0 (TID 99). 6269 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 69.0 in stage 12.0 (TID 100, Clairvoyant-320, executor driver, partition 69, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 69.0 in stage 12.0 (TID 100)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 68.0 in stage 12.0 (TID 99) in 33 ms on Clairvoyant-320 (executor driver) (88/200)
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 69-70
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 100 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@512474a5
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 100 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@512474a5
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 100 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 100: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 69.0 in stage 12.0 (TID 100). 6269 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 70.0 in stage 12.0 (TID 101, Clairvoyant-320, executor driver, partition 70, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 69.0 in stage 12.0 (TID 100) in 35 ms on Clairvoyant-320 (executor driver) (89/200)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 70.0 in stage 12.0 (TID 101)
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 70-71
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 101 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3778286b
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 101 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3778286b
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 101 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 101: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 70.0 in stage 12.0 (TID 101). 6226 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 71.0 in stage 12.0 (TID 102, Clairvoyant-320, executor driver, partition 71, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 71.0 in stage 12.0 (TID 102)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 70.0 in stage 12.0 (TID 101) in 30 ms on Clairvoyant-320 (executor driver) (90/200)
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 71-72
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 102 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3efecc0a
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 102 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3efecc0a
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 102 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 102: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 71.0 in stage 12.0 (TID 102). 6226 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 72.0 in stage 12.0 (TID 103, Clairvoyant-320, executor driver, partition 72, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 72.0 in stage 12.0 (TID 103)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 71.0 in stage 12.0 (TID 102) in 31 ms on Clairvoyant-320 (executor driver) (91/200)
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 72-73
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 103 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3d513489
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 103 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3d513489
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 103 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 103: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 72.0 in stage 12.0 (TID 103). 6226 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 75.0 in stage 12.0 (TID 104, Clairvoyant-320, executor driver, partition 75, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 72.0 in stage 12.0 (TID 103) in 42 ms on Clairvoyant-320 (executor driver) (92/200)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 75.0 in stage 12.0 (TID 104)
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 75-76
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 104 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@9a4a488
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 104 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@9a4a488
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 104 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 104: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 75.0 in stage 12.0 (TID 104). 6226 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 76.0 in stage 12.0 (TID 105, Clairvoyant-320, executor driver, partition 76, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 75.0 in stage 12.0 (TID 104) in 44 ms on Clairvoyant-320 (executor driver) (93/200)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 76.0 in stage 12.0 (TID 105)
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 76-77
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 105 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@afc1875
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 105 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@afc1875
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 105 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 105: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 76.0 in stage 12.0 (TID 105). 6226 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 77.0 in stage 12.0 (TID 106, Clairvoyant-320, executor driver, partition 77, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 76.0 in stage 12.0 (TID 105) in 27 ms on Clairvoyant-320 (executor driver) (94/200)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 77.0 in stage 12.0 (TID 106)
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 77-78
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 106 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@27bbca7e
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 106 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@27bbca7e
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 106 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 106: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 77.0 in stage 12.0 (TID 106). 6226 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 78.0 in stage 12.0 (TID 107, Clairvoyant-320, executor driver, partition 78, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 78.0 in stage 12.0 (TID 107)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 77.0 in stage 12.0 (TID 106) in 44 ms on Clairvoyant-320 (executor driver) (95/200)
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 78-79
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 107 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2ea620a9
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 107 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2ea620a9
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 107 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 107: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 78.0 in stage 12.0 (TID 107). 6226 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 79.0 in stage 12.0 (TID 108, Clairvoyant-320, executor driver, partition 79, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 79.0 in stage 12.0 (TID 108)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 78.0 in stage 12.0 (TID 107) in 39 ms on Clairvoyant-320 (executor driver) (96/200)
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 79-80
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 108 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3c8dc6b5
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 108 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3c8dc6b5
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 108 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 108: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 79.0 in stage 12.0 (TID 108). 6269 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 80.0 in stage 12.0 (TID 109, Clairvoyant-320, executor driver, partition 80, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 79.0 in stage 12.0 (TID 108) in 46 ms on Clairvoyant-320 (executor driver) (97/200)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 80.0 in stage 12.0 (TID 109)
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 80-81
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 109 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7594dd09
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 109 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7594dd09
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 109 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 109: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 80.0 in stage 12.0 (TID 109). 6226 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 81.0 in stage 12.0 (TID 110, Clairvoyant-320, executor driver, partition 81, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 80.0 in stage 12.0 (TID 109) in 34 ms on Clairvoyant-320 (executor driver) (98/200)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 81.0 in stage 12.0 (TID 110)
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 81-82
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 110 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@14c84a24
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 110 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@14c84a24
2022-02-14 10:55:55 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 110 with length 1
2022-02-14 10:55:55 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 110: [56]
2022-02-14 10:55:55 INFO  Executor:57 - Finished task 81.0 in stage 12.0 (TID 110). 6226 bytes result sent to driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Starting task 82.0 in stage 12.0 (TID 111, Clairvoyant-320, executor driver, partition 82, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:55 INFO  TaskSetManager:57 - Finished task 81.0 in stage 12.0 (TID 110) in 37 ms on Clairvoyant-320 (executor driver) (99/200)
2022-02-14 10:55:55 INFO  Executor:57 - Running task 82.0 in stage 12.0 (TID 111)
2022-02-14 10:55:55 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:55 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 82-83
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:55 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:55 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:228 - Task 111 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2363ca30
2022-02-14 10:55:55 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:55 DEBUG TaskMemoryManager:237 - Task 111 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2363ca30
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 111 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 111: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 82.0 in stage 12.0 (TID 111). 6269 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 83.0 in stage 12.0 (TID 112, Clairvoyant-320, executor driver, partition 83, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 82.0 in stage 12.0 (TID 111) in 45 ms on Clairvoyant-320 (executor driver) (100/200)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 83.0 in stage 12.0 (TID 112)
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 83-84
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 112 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@551d5e39
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 112 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@551d5e39
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 112 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 112: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 83.0 in stage 12.0 (TID 112). 6226 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 84.0 in stage 12.0 (TID 113, Clairvoyant-320, executor driver, partition 84, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 84.0 in stage 12.0 (TID 113)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 83.0 in stage 12.0 (TID 112) in 37 ms on Clairvoyant-320 (executor driver) (101/200)
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 84-85
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 113 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7e3ad049
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 113 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7e3ad049
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 113 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 113: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 84.0 in stage 12.0 (TID 113). 6226 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 85.0 in stage 12.0 (TID 114, Clairvoyant-320, executor driver, partition 85, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 84.0 in stage 12.0 (TID 113) in 34 ms on Clairvoyant-320 (executor driver) (102/200)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 85.0 in stage 12.0 (TID 114)
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 85-86
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 114 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@6bf17dc3
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 114 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@6bf17dc3
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 114 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 114: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 85.0 in stage 12.0 (TID 114). 6226 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 87.0 in stage 12.0 (TID 115, Clairvoyant-320, executor driver, partition 87, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 85.0 in stage 12.0 (TID 114) in 28 ms on Clairvoyant-320 (executor driver) (103/200)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 87.0 in stage 12.0 (TID 115)
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 87-88
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 115 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@212758ec
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 115 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@212758ec
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 115 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 115: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 87.0 in stage 12.0 (TID 115). 6226 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 88.0 in stage 12.0 (TID 116, Clairvoyant-320, executor driver, partition 88, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 87.0 in stage 12.0 (TID 115) in 31 ms on Clairvoyant-320 (executor driver) (104/200)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 88.0 in stage 12.0 (TID 116)
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 88-89
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 116 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4ae025b5
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 116 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4ae025b5
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 116 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 116: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 88.0 in stage 12.0 (TID 116). 6226 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 91.0 in stage 12.0 (TID 117, Clairvoyant-320, executor driver, partition 91, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 91.0 in stage 12.0 (TID 117)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 88.0 in stage 12.0 (TID 116) in 32 ms on Clairvoyant-320 (executor driver) (105/200)
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 91-92
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 117 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1970ce8b
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 117 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1970ce8b
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 117 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 117: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 91.0 in stage 12.0 (TID 117). 6226 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 92.0 in stage 12.0 (TID 118, Clairvoyant-320, executor driver, partition 92, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 91.0 in stage 12.0 (TID 117) in 29 ms on Clairvoyant-320 (executor driver) (106/200)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 92.0 in stage 12.0 (TID 118)
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 92-93
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 118 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@38dc2882
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 118 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@38dc2882
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 118 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 118: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 92.0 in stage 12.0 (TID 118). 6226 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 93.0 in stage 12.0 (TID 119, Clairvoyant-320, executor driver, partition 93, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 92.0 in stage 12.0 (TID 118) in 35 ms on Clairvoyant-320 (executor driver) (107/200)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 93.0 in stage 12.0 (TID 119)
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 93-94
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 119 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5c3b473a
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 119 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5c3b473a
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 119 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 119: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 93.0 in stage 12.0 (TID 119). 6226 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 94.0 in stage 12.0 (TID 120, Clairvoyant-320, executor driver, partition 94, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 94.0 in stage 12.0 (TID 120)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 93.0 in stage 12.0 (TID 119) in 33 ms on Clairvoyant-320 (executor driver) (108/200)
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 94-95
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 120 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@265a67df
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 120 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@265a67df
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 120 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 120: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 94.0 in stage 12.0 (TID 120). 6226 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 95.0 in stage 12.0 (TID 121, Clairvoyant-320, executor driver, partition 95, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 94.0 in stage 12.0 (TID 120) in 39 ms on Clairvoyant-320 (executor driver) (109/200)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 95.0 in stage 12.0 (TID 121)
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 95-96
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 121 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@18c2f7ed
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 121 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@18c2f7ed
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 121 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 121: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 95.0 in stage 12.0 (TID 121). 6269 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 96.0 in stage 12.0 (TID 122, Clairvoyant-320, executor driver, partition 96, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 96.0 in stage 12.0 (TID 122)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 95.0 in stage 12.0 (TID 121) in 40 ms on Clairvoyant-320 (executor driver) (110/200)
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 96-97
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 122 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2947b26c
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 122 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2947b26c
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 122 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 122: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 96.0 in stage 12.0 (TID 122). 6226 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 97.0 in stage 12.0 (TID 123, Clairvoyant-320, executor driver, partition 97, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 96.0 in stage 12.0 (TID 122) in 45 ms on Clairvoyant-320 (executor driver) (111/200)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 97.0 in stage 12.0 (TID 123)
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 97-98
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 123 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3a1e1289
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 123 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3a1e1289
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 123 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 123: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 97.0 in stage 12.0 (TID 123). 6226 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 98.0 in stage 12.0 (TID 124, Clairvoyant-320, executor driver, partition 98, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 97.0 in stage 12.0 (TID 123) in 39 ms on Clairvoyant-320 (executor driver) (112/200)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 98.0 in stage 12.0 (TID 124)
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 98-99
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 124 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3bbc053c
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 124 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3bbc053c
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 124 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 124: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 98.0 in stage 12.0 (TID 124). 6269 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 99.0 in stage 12.0 (TID 125, Clairvoyant-320, executor driver, partition 99, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 99.0 in stage 12.0 (TID 125)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 98.0 in stage 12.0 (TID 124) in 51 ms on Clairvoyant-320 (executor driver) (113/200)
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 99-100
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 125 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@719b0ac7
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 125 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@719b0ac7
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 125 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 125: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 99.0 in stage 12.0 (TID 125). 6269 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 100.0 in stage 12.0 (TID 126, Clairvoyant-320, executor driver, partition 100, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 99.0 in stage 12.0 (TID 125) in 35 ms on Clairvoyant-320 (executor driver) (114/200)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 100.0 in stage 12.0 (TID 126)
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 100-101
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 126 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@60a36a3d
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 126 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@60a36a3d
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 126 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 126: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 100.0 in stage 12.0 (TID 126). 6269 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 101.0 in stage 12.0 (TID 127, Clairvoyant-320, executor driver, partition 101, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 100.0 in stage 12.0 (TID 126) in 46 ms on Clairvoyant-320 (executor driver) (115/200)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 101.0 in stage 12.0 (TID 127)
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 101-102
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 127 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@662d10c5
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 127 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@662d10c5
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 127 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 127: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 101.0 in stage 12.0 (TID 127). 6269 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 102.0 in stage 12.0 (TID 128, Clairvoyant-320, executor driver, partition 102, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 102.0 in stage 12.0 (TID 128)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 101.0 in stage 12.0 (TID 127) in 35 ms on Clairvoyant-320 (executor driver) (116/200)
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 102-103
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 128 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7ae9abcb
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 128 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7ae9abcb
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 128 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 128: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 102.0 in stage 12.0 (TID 128). 6226 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 103.0 in stage 12.0 (TID 129, Clairvoyant-320, executor driver, partition 103, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 102.0 in stage 12.0 (TID 128) in 38 ms on Clairvoyant-320 (executor driver) (117/200)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 103.0 in stage 12.0 (TID 129)
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 103-104
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 129 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@518bbe6d
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 129 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@518bbe6d
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 129 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 129: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 103.0 in stage 12.0 (TID 129). 6226 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 104.0 in stage 12.0 (TID 130, Clairvoyant-320, executor driver, partition 104, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 103.0 in stage 12.0 (TID 129) in 33 ms on Clairvoyant-320 (executor driver) (118/200)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 104.0 in stage 12.0 (TID 130)
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 104-105
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 130 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@339a5ee
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 130 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@339a5ee
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 130 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 130: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 104.0 in stage 12.0 (TID 130). 6226 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 105.0 in stage 12.0 (TID 131, Clairvoyant-320, executor driver, partition 105, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 105.0 in stage 12.0 (TID 131)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 104.0 in stage 12.0 (TID 130) in 38 ms on Clairvoyant-320 (executor driver) (119/200)
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 105-106
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 131 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@796e128a
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 131 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@796e128a
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 131 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 131: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 105.0 in stage 12.0 (TID 131). 6226 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 106.0 in stage 12.0 (TID 132, Clairvoyant-320, executor driver, partition 106, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 105.0 in stage 12.0 (TID 131) in 36 ms on Clairvoyant-320 (executor driver) (120/200)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 106.0 in stage 12.0 (TID 132)
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 106-107
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 132 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@165dc557
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 132 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@165dc557
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 132 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 132: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 106.0 in stage 12.0 (TID 132). 6226 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 107.0 in stage 12.0 (TID 133, Clairvoyant-320, executor driver, partition 107, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 106.0 in stage 12.0 (TID 132) in 31 ms on Clairvoyant-320 (executor driver) (121/200)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 107.0 in stage 12.0 (TID 133)
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 107-108
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 133 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@6860ca35
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 133 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@6860ca35
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 133 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 133: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 107.0 in stage 12.0 (TID 133). 6226 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 109.0 in stage 12.0 (TID 134, Clairvoyant-320, executor driver, partition 109, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 109.0 in stage 12.0 (TID 134)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 107.0 in stage 12.0 (TID 133) in 38 ms on Clairvoyant-320 (executor driver) (122/200)
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 109-110
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 134 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@52214c1d
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 134 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@52214c1d
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 134 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 134: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 109.0 in stage 12.0 (TID 134). 6269 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 110.0 in stage 12.0 (TID 135, Clairvoyant-320, executor driver, partition 110, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 109.0 in stage 12.0 (TID 134) in 36 ms on Clairvoyant-320 (executor driver) (123/200)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 110.0 in stage 12.0 (TID 135)
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 110-111
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 135 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@10aeaeb2
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 135 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@10aeaeb2
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 135 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 135: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 110.0 in stage 12.0 (TID 135). 6226 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 111.0 in stage 12.0 (TID 136, Clairvoyant-320, executor driver, partition 111, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 110.0 in stage 12.0 (TID 135) in 34 ms on Clairvoyant-320 (executor driver) (124/200)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 111.0 in stage 12.0 (TID 136)
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 111-112
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 136 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3e599c4a
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 136 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3e599c4a
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 136 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 136: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 111.0 in stage 12.0 (TID 136). 6226 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 112.0 in stage 12.0 (TID 137, Clairvoyant-320, executor driver, partition 112, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 112.0 in stage 12.0 (TID 137)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 111.0 in stage 12.0 (TID 136) in 35 ms on Clairvoyant-320 (executor driver) (125/200)
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 112-113
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 137 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4b6f2ebb
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 137 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4b6f2ebb
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 137 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 137: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 112.0 in stage 12.0 (TID 137). 6226 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 113.0 in stage 12.0 (TID 138, Clairvoyant-320, executor driver, partition 113, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 113.0 in stage 12.0 (TID 138)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 112.0 in stage 12.0 (TID 137) in 44 ms on Clairvoyant-320 (executor driver) (126/200)
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 113-114
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 138 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@72e57cfc
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:237 - Task 138 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@72e57cfc
2022-02-14 10:55:56 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 138 with length 1
2022-02-14 10:55:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 138: [56]
2022-02-14 10:55:56 INFO  Executor:57 - Finished task 113.0 in stage 12.0 (TID 138). 6226 bytes result sent to driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Starting task 114.0 in stage 12.0 (TID 139, Clairvoyant-320, executor driver, partition 114, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:56 INFO  TaskSetManager:57 - Finished task 113.0 in stage 12.0 (TID 138) in 34 ms on Clairvoyant-320 (executor driver) (127/200)
2022-02-14 10:55:56 INFO  Executor:57 - Running task 114.0 in stage 12.0 (TID 139)
2022-02-14 10:55:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 114-115
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:56 DEBUG TaskMemoryManager:228 - Task 139 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@78fc136b
2022-02-14 10:55:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 139 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@78fc136b
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 139 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 139: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 114.0 in stage 12.0 (TID 139). 6226 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 116.0 in stage 12.0 (TID 140, Clairvoyant-320, executor driver, partition 116, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 116.0 in stage 12.0 (TID 140)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 114.0 in stage 12.0 (TID 139) in 36 ms on Clairvoyant-320 (executor driver) (128/200)
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 116-117
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 140 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@41217435
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 140 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@41217435
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 140 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 140: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 116.0 in stage 12.0 (TID 140). 6226 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 117.0 in stage 12.0 (TID 141, Clairvoyant-320, executor driver, partition 117, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 117.0 in stage 12.0 (TID 141)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 116.0 in stage 12.0 (TID 140) in 29 ms on Clairvoyant-320 (executor driver) (129/200)
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 117-118
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 141 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@437cbbf3
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 141 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@437cbbf3
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 141 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 141: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 117.0 in stage 12.0 (TID 141). 6226 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 118.0 in stage 12.0 (TID 142, Clairvoyant-320, executor driver, partition 118, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 118.0 in stage 12.0 (TID 142)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 117.0 in stage 12.0 (TID 141) in 38 ms on Clairvoyant-320 (executor driver) (130/200)
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 118-119
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 142 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@22e8a353
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 142 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@22e8a353
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 142 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 142: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 118.0 in stage 12.0 (TID 142). 6226 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 119.0 in stage 12.0 (TID 143, Clairvoyant-320, executor driver, partition 119, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 118.0 in stage 12.0 (TID 142) in 40 ms on Clairvoyant-320 (executor driver) (131/200)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 119.0 in stage 12.0 (TID 143)
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 119-120
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 143 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@c0cfc23
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 143 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@c0cfc23
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 143 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 143: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 119.0 in stage 12.0 (TID 143). 6183 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 120.0 in stage 12.0 (TID 144, Clairvoyant-320, executor driver, partition 120, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 119.0 in stage 12.0 (TID 143) in 43 ms on Clairvoyant-320 (executor driver) (132/200)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 120.0 in stage 12.0 (TID 144)
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 120-121
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 144 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@388688f8
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 144 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@388688f8
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 144 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 144: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 120.0 in stage 12.0 (TID 144). 6226 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 121.0 in stage 12.0 (TID 145, Clairvoyant-320, executor driver, partition 121, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 121.0 in stage 12.0 (TID 145)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 120.0 in stage 12.0 (TID 144) in 35 ms on Clairvoyant-320 (executor driver) (133/200)
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 121-122
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 145 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@35ee307c
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 145 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@35ee307c
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 145 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 145: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 121.0 in stage 12.0 (TID 145). 6226 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 122.0 in stage 12.0 (TID 146, Clairvoyant-320, executor driver, partition 122, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 121.0 in stage 12.0 (TID 145) in 30 ms on Clairvoyant-320 (executor driver) (134/200)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 122.0 in stage 12.0 (TID 146)
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 122-123
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 146 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@40a2aa47
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 146 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@40a2aa47
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 146 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 146: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 122.0 in stage 12.0 (TID 146). 6269 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 123.0 in stage 12.0 (TID 147, Clairvoyant-320, executor driver, partition 123, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 122.0 in stage 12.0 (TID 146) in 30 ms on Clairvoyant-320 (executor driver) (135/200)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 123.0 in stage 12.0 (TID 147)
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 123-124
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 147 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@249062ed
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 147 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@249062ed
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 147 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 147: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 123.0 in stage 12.0 (TID 147). 6269 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 124.0 in stage 12.0 (TID 148, Clairvoyant-320, executor driver, partition 124, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 124.0 in stage 12.0 (TID 148)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 123.0 in stage 12.0 (TID 147) in 36 ms on Clairvoyant-320 (executor driver) (136/200)
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 124-125
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 148 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7fc172ec
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 148 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7fc172ec
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 148 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 148: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 124.0 in stage 12.0 (TID 148). 6226 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 125.0 in stage 12.0 (TID 149, Clairvoyant-320, executor driver, partition 125, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 125.0 in stage 12.0 (TID 149)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 124.0 in stage 12.0 (TID 148) in 28 ms on Clairvoyant-320 (executor driver) (137/200)
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 125-126
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 149 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5ab85441
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 149 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5ab85441
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 149 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 149: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 125.0 in stage 12.0 (TID 149). 6269 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 126.0 in stage 12.0 (TID 150, Clairvoyant-320, executor driver, partition 126, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 126.0 in stage 12.0 (TID 150)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 125.0 in stage 12.0 (TID 149) in 42 ms on Clairvoyant-320 (executor driver) (138/200)
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 126-127
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 150 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1d24a1e9
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 150 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1d24a1e9
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 150 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 150: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 126.0 in stage 12.0 (TID 150). 6269 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 127.0 in stage 12.0 (TID 151, Clairvoyant-320, executor driver, partition 127, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 127.0 in stage 12.0 (TID 151)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 126.0 in stage 12.0 (TID 150) in 32 ms on Clairvoyant-320 (executor driver) (139/200)
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 127-128
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 151 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@60ac8c69
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 151 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@60ac8c69
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 151 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 151: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 127.0 in stage 12.0 (TID 151). 6226 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 128.0 in stage 12.0 (TID 152, Clairvoyant-320, executor driver, partition 128, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 127.0 in stage 12.0 (TID 151) in 45 ms on Clairvoyant-320 (executor driver) (140/200)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 128.0 in stage 12.0 (TID 152)
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 128-129
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 152 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@9c93427
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 152 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@9c93427
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 152 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 152: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 128.0 in stage 12.0 (TID 152). 6226 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 129.0 in stage 12.0 (TID 153, Clairvoyant-320, executor driver, partition 129, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 128.0 in stage 12.0 (TID 152) in 36 ms on Clairvoyant-320 (executor driver) (141/200)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 129.0 in stage 12.0 (TID 153)
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 129-130
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 153 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@23690df2
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 153 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@23690df2
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 153 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 153: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 129.0 in stage 12.0 (TID 153). 6269 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 130.0 in stage 12.0 (TID 154, Clairvoyant-320, executor driver, partition 130, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 130.0 in stage 12.0 (TID 154)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 129.0 in stage 12.0 (TID 153) in 31 ms on Clairvoyant-320 (executor driver) (142/200)
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 130-131
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 154 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@795cbd9b
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 154 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@795cbd9b
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 154 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 154: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 130.0 in stage 12.0 (TID 154). 6226 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 131.0 in stage 12.0 (TID 155, Clairvoyant-320, executor driver, partition 131, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 130.0 in stage 12.0 (TID 154) in 37 ms on Clairvoyant-320 (executor driver) (143/200)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 131.0 in stage 12.0 (TID 155)
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 131-132
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 155 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@b8af3e3
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 155 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@b8af3e3
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 155 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 155: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 131.0 in stage 12.0 (TID 155). 6226 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 133.0 in stage 12.0 (TID 156, Clairvoyant-320, executor driver, partition 133, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 133.0 in stage 12.0 (TID 156)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 131.0 in stage 12.0 (TID 155) in 40 ms on Clairvoyant-320 (executor driver) (144/200)
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 133-134
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 156 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@48a64dc4
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 156 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@48a64dc4
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 156 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 156: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 133.0 in stage 12.0 (TID 156). 6226 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 134.0 in stage 12.0 (TID 157, Clairvoyant-320, executor driver, partition 134, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 134.0 in stage 12.0 (TID 157)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 133.0 in stage 12.0 (TID 156) in 36 ms on Clairvoyant-320 (executor driver) (145/200)
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 134-135
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 157 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@40dc8c0a
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 157 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@40dc8c0a
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 157 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 157: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 134.0 in stage 12.0 (TID 157). 6226 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 135.0 in stage 12.0 (TID 158, Clairvoyant-320, executor driver, partition 135, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 134.0 in stage 12.0 (TID 157) in 33 ms on Clairvoyant-320 (executor driver) (146/200)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 135.0 in stage 12.0 (TID 158)
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 135-136
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 158 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1981c2cf
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 158 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1981c2cf
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 158 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 158: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 135.0 in stage 12.0 (TID 158). 6226 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 136.0 in stage 12.0 (TID 159, Clairvoyant-320, executor driver, partition 136, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 135.0 in stage 12.0 (TID 158) in 31 ms on Clairvoyant-320 (executor driver) (147/200)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 136.0 in stage 12.0 (TID 159)
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 136-137
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 159 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@213a422f
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 159 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@213a422f
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 159 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 159: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 136.0 in stage 12.0 (TID 159). 6226 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 137.0 in stage 12.0 (TID 160, Clairvoyant-320, executor driver, partition 137, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 136.0 in stage 12.0 (TID 159) in 36 ms on Clairvoyant-320 (executor driver) (148/200)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 137.0 in stage 12.0 (TID 160)
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 137-138
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 160 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@31fafe6d
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 160 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@31fafe6d
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 160 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 160: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 137.0 in stage 12.0 (TID 160). 6269 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 138.0 in stage 12.0 (TID 161, Clairvoyant-320, executor driver, partition 138, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 138.0 in stage 12.0 (TID 161)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 137.0 in stage 12.0 (TID 160) in 43 ms on Clairvoyant-320 (executor driver) (149/200)
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 138-139
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 161 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1c36bd02
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 161 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1c36bd02
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 161 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 161: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 138.0 in stage 12.0 (TID 161). 6226 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 139.0 in stage 12.0 (TID 162, Clairvoyant-320, executor driver, partition 139, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 139.0 in stage 12.0 (TID 162)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 138.0 in stage 12.0 (TID 161) in 35 ms on Clairvoyant-320 (executor driver) (150/200)
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 139-140
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 162 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@222367dd
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 162 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@222367dd
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 162 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 162: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 139.0 in stage 12.0 (TID 162). 6226 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 140.0 in stage 12.0 (TID 163, Clairvoyant-320, executor driver, partition 140, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 139.0 in stage 12.0 (TID 162) in 34 ms on Clairvoyant-320 (executor driver) (151/200)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 140.0 in stage 12.0 (TID 163)
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 140-141
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 163 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4bd94119
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 163 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4bd94119
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 163 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 163: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 140.0 in stage 12.0 (TID 163). 6269 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 141.0 in stage 12.0 (TID 164, Clairvoyant-320, executor driver, partition 141, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 141.0 in stage 12.0 (TID 164)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 140.0 in stage 12.0 (TID 163) in 33 ms on Clairvoyant-320 (executor driver) (152/200)
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 141-142
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 164 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@74abe03d
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 164 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@74abe03d
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 164 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 164: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 141.0 in stage 12.0 (TID 164). 6226 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 142.0 in stage 12.0 (TID 165, Clairvoyant-320, executor driver, partition 142, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 142.0 in stage 12.0 (TID 165)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 141.0 in stage 12.0 (TID 164) in 37 ms on Clairvoyant-320 (executor driver) (153/200)
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 142-143
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 165 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@67f9a9f6
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 165 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@67f9a9f6
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 165 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 165: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 142.0 in stage 12.0 (TID 165). 6226 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 143.0 in stage 12.0 (TID 166, Clairvoyant-320, executor driver, partition 143, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 143.0 in stage 12.0 (TID 166)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 142.0 in stage 12.0 (TID 165) in 40 ms on Clairvoyant-320 (executor driver) (154/200)
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 143-144
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 166 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@168efffb
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:237 - Task 166 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@168efffb
2022-02-14 10:55:57 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 166 with length 1
2022-02-14 10:55:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 166: [56]
2022-02-14 10:55:57 INFO  Executor:57 - Finished task 143.0 in stage 12.0 (TID 166). 6269 bytes result sent to driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Starting task 144.0 in stage 12.0 (TID 167, Clairvoyant-320, executor driver, partition 144, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:57 INFO  TaskSetManager:57 - Finished task 143.0 in stage 12.0 (TID 166) in 61 ms on Clairvoyant-320 (executor driver) (155/200)
2022-02-14 10:55:57 INFO  Executor:57 - Running task 144.0 in stage 12.0 (TID 167)
2022-02-14 10:55:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 144-145
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:57 DEBUG TaskMemoryManager:228 - Task 167 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@dcbea8d
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 167 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@dcbea8d
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 167 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 167: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 144.0 in stage 12.0 (TID 167). 6226 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 145.0 in stage 12.0 (TID 168, Clairvoyant-320, executor driver, partition 145, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 145.0 in stage 12.0 (TID 168)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 144.0 in stage 12.0 (TID 167) in 41 ms on Clairvoyant-320 (executor driver) (156/200)
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 145-146
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 168 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@54b55d35
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 168 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@54b55d35
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 168 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 168: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 145.0 in stage 12.0 (TID 168). 6226 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 146.0 in stage 12.0 (TID 169, Clairvoyant-320, executor driver, partition 146, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 145.0 in stage 12.0 (TID 168) in 44 ms on Clairvoyant-320 (executor driver) (157/200)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 146.0 in stage 12.0 (TID 169)
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 146-147
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 169 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3abc752b
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 169 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3abc752b
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 169 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 169: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 146.0 in stage 12.0 (TID 169). 6226 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 147.0 in stage 12.0 (TID 170, Clairvoyant-320, executor driver, partition 147, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 146.0 in stage 12.0 (TID 169) in 41 ms on Clairvoyant-320 (executor driver) (158/200)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 147.0 in stage 12.0 (TID 170)
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 147-148
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 170 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5480827e
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 170 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5480827e
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 170 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 170: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 147.0 in stage 12.0 (TID 170). 6269 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 148.0 in stage 12.0 (TID 171, Clairvoyant-320, executor driver, partition 148, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 148.0 in stage 12.0 (TID 171)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 147.0 in stage 12.0 (TID 170) in 39 ms on Clairvoyant-320 (executor driver) (159/200)
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 148-149
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 171 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@648edd77
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 171 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@648edd77
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 171 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 171: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 148.0 in stage 12.0 (TID 171). 6226 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 149.0 in stage 12.0 (TID 172, Clairvoyant-320, executor driver, partition 149, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 149.0 in stage 12.0 (TID 172)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 148.0 in stage 12.0 (TID 171) in 38 ms on Clairvoyant-320 (executor driver) (160/200)
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 149-150
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 172 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1d79042d
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 172 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1d79042d
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 172 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 172: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 149.0 in stage 12.0 (TID 172). 6269 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 150.0 in stage 12.0 (TID 173, Clairvoyant-320, executor driver, partition 150, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 149.0 in stage 12.0 (TID 172) in 33 ms on Clairvoyant-320 (executor driver) (161/200)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 150.0 in stage 12.0 (TID 173)
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 150-151
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 173 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@6c7f05ff
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 173 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@6c7f05ff
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 173 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 173: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 150.0 in stage 12.0 (TID 173). 6226 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 151.0 in stage 12.0 (TID 174, Clairvoyant-320, executor driver, partition 151, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 150.0 in stage 12.0 (TID 173) in 28 ms on Clairvoyant-320 (executor driver) (162/200)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 151.0 in stage 12.0 (TID 174)
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 151-152
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 174 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@35607a15
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 174 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@35607a15
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 174 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 174: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 151.0 in stage 12.0 (TID 174). 6226 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 152.0 in stage 12.0 (TID 175, Clairvoyant-320, executor driver, partition 152, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 152.0 in stage 12.0 (TID 175)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 151.0 in stage 12.0 (TID 174) in 42 ms on Clairvoyant-320 (executor driver) (163/200)
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 152-153
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 175 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@59d58a27
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 175 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@59d58a27
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 175 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 175: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 152.0 in stage 12.0 (TID 175). 6226 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 153.0 in stage 12.0 (TID 176, Clairvoyant-320, executor driver, partition 153, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 152.0 in stage 12.0 (TID 175) in 37 ms on Clairvoyant-320 (executor driver) (164/200)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 153.0 in stage 12.0 (TID 176)
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 153-154
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 176 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4f6cac62
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 176 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4f6cac62
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 176 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 176: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 153.0 in stage 12.0 (TID 176). 6226 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 154.0 in stage 12.0 (TID 177, Clairvoyant-320, executor driver, partition 154, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 153.0 in stage 12.0 (TID 176) in 40 ms on Clairvoyant-320 (executor driver) (165/200)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 154.0 in stage 12.0 (TID 177)
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 154-155
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 177 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@62dc2a6c
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 177 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@62dc2a6c
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 177 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 177: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 154.0 in stage 12.0 (TID 177). 6226 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 155.0 in stage 12.0 (TID 178, Clairvoyant-320, executor driver, partition 155, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 154.0 in stage 12.0 (TID 177) in 36 ms on Clairvoyant-320 (executor driver) (166/200)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 155.0 in stage 12.0 (TID 178)
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 155-156
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 178 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@24ece5bd
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 178 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@24ece5bd
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 178 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 178: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 155.0 in stage 12.0 (TID 178). 6226 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 156.0 in stage 12.0 (TID 179, Clairvoyant-320, executor driver, partition 156, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 155.0 in stage 12.0 (TID 178) in 35 ms on Clairvoyant-320 (executor driver) (167/200)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 156.0 in stage 12.0 (TID 179)
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 156-157
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 179 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@482dfbc3
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 179 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@482dfbc3
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 179 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 179: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 156.0 in stage 12.0 (TID 179). 6226 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 157.0 in stage 12.0 (TID 180, Clairvoyant-320, executor driver, partition 157, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 157.0 in stage 12.0 (TID 180)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 156.0 in stage 12.0 (TID 179) in 33 ms on Clairvoyant-320 (executor driver) (168/200)
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 157-158
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 180 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5974301e
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 180 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5974301e
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 180 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 180: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 157.0 in stage 12.0 (TID 180). 6226 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 158.0 in stage 12.0 (TID 181, Clairvoyant-320, executor driver, partition 158, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 157.0 in stage 12.0 (TID 180) in 30 ms on Clairvoyant-320 (executor driver) (169/200)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 158.0 in stage 12.0 (TID 181)
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 158-159
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 181 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2b746b8e
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 181 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2b746b8e
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 181 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 181: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 158.0 in stage 12.0 (TID 181). 6226 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 159.0 in stage 12.0 (TID 182, Clairvoyant-320, executor driver, partition 159, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 158.0 in stage 12.0 (TID 181) in 29 ms on Clairvoyant-320 (executor driver) (170/200)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 159.0 in stage 12.0 (TID 182)
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 159-160
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 182 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7750ada
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 182 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7750ada
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 182 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 182: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 159.0 in stage 12.0 (TID 182). 6226 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 161.0 in stage 12.0 (TID 183, Clairvoyant-320, executor driver, partition 161, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 159.0 in stage 12.0 (TID 182) in 33 ms on Clairvoyant-320 (executor driver) (171/200)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 161.0 in stage 12.0 (TID 183)
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 161-162
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 183 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@477cbe47
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 183 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@477cbe47
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 183 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 183: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 161.0 in stage 12.0 (TID 183). 6226 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 162.0 in stage 12.0 (TID 184, Clairvoyant-320, executor driver, partition 162, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 161.0 in stage 12.0 (TID 183) in 28 ms on Clairvoyant-320 (executor driver) (172/200)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 162.0 in stage 12.0 (TID 184)
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 162-163
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 184 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5dee43fc
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 184 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5dee43fc
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 184 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 184: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 162.0 in stage 12.0 (TID 184). 6226 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 163.0 in stage 12.0 (TID 185, Clairvoyant-320, executor driver, partition 163, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 162.0 in stage 12.0 (TID 184) in 40 ms on Clairvoyant-320 (executor driver) (173/200)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 163.0 in stage 12.0 (TID 185)
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 163-164
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 185 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@64619ffb
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 185 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@64619ffb
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 185 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 185: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 163.0 in stage 12.0 (TID 185). 6226 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 165.0 in stage 12.0 (TID 186, Clairvoyant-320, executor driver, partition 165, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 163.0 in stage 12.0 (TID 185) in 29 ms on Clairvoyant-320 (executor driver) (174/200)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 165.0 in stage 12.0 (TID 186)
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 165-166
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 186 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@65c0a756
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 186 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@65c0a756
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 186 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 186: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 165.0 in stage 12.0 (TID 186). 6226 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 167.0 in stage 12.0 (TID 187, Clairvoyant-320, executor driver, partition 167, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 167.0 in stage 12.0 (TID 187)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 165.0 in stage 12.0 (TID 186) in 33 ms on Clairvoyant-320 (executor driver) (175/200)
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 167-168
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 187 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3e8ce46f
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 187 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3e8ce46f
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 187 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 187: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 167.0 in stage 12.0 (TID 187). 6269 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 168.0 in stage 12.0 (TID 188, Clairvoyant-320, executor driver, partition 168, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 167.0 in stage 12.0 (TID 187) in 45 ms on Clairvoyant-320 (executor driver) (176/200)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 168.0 in stage 12.0 (TID 188)
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 168-169
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 188 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5e2d69f7
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 188 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5e2d69f7
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 188 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 188: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 168.0 in stage 12.0 (TID 188). 6226 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 170.0 in stage 12.0 (TID 189, Clairvoyant-320, executor driver, partition 170, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 170.0 in stage 12.0 (TID 189)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 168.0 in stage 12.0 (TID 188) in 24 ms on Clairvoyant-320 (executor driver) (177/200)
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 170-171
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 189 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@78c62926
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 189 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@78c62926
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 189 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 189: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 170.0 in stage 12.0 (TID 189). 6226 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 171.0 in stage 12.0 (TID 190, Clairvoyant-320, executor driver, partition 171, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 170.0 in stage 12.0 (TID 189) in 51 ms on Clairvoyant-320 (executor driver) (178/200)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 171.0 in stage 12.0 (TID 190)
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 171-172
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 190 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@65bc30f4
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 190 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@65bc30f4
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 190 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 190: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 171.0 in stage 12.0 (TID 190). 6269 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 172.0 in stage 12.0 (TID 191, Clairvoyant-320, executor driver, partition 172, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 172.0 in stage 12.0 (TID 191)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 171.0 in stage 12.0 (TID 190) in 51 ms on Clairvoyant-320 (executor driver) (179/200)
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 172-173
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 191 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@77a66252
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 191 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@77a66252
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 191 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 191: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 172.0 in stage 12.0 (TID 191). 6226 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 173.0 in stage 12.0 (TID 192, Clairvoyant-320, executor driver, partition 173, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 173.0 in stage 12.0 (TID 192)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 172.0 in stage 12.0 (TID 191) in 35 ms on Clairvoyant-320 (executor driver) (180/200)
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 173-174
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 192 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4e37e811
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 192 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4e37e811
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 192 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 192: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 173.0 in stage 12.0 (TID 192). 6269 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 174.0 in stage 12.0 (TID 193, Clairvoyant-320, executor driver, partition 174, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 173.0 in stage 12.0 (TID 192) in 43 ms on Clairvoyant-320 (executor driver) (181/200)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 174.0 in stage 12.0 (TID 193)
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 174-175
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 193 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7a436e98
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 193 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7a436e98
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 193 with length 1
2022-02-14 10:55:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 193: [56]
2022-02-14 10:55:58 INFO  Executor:57 - Finished task 174.0 in stage 12.0 (TID 193). 6226 bytes result sent to driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Starting task 175.0 in stage 12.0 (TID 194, Clairvoyant-320, executor driver, partition 175, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:58 INFO  TaskSetManager:57 - Finished task 174.0 in stage 12.0 (TID 193) in 34 ms on Clairvoyant-320 (executor driver) (182/200)
2022-02-14 10:55:58 INFO  Executor:57 - Running task 175.0 in stage 12.0 (TID 194)
2022-02-14 10:55:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 175-176
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:228 - Task 194 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7572aeb8
2022-02-14 10:55:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:58 DEBUG TaskMemoryManager:237 - Task 194 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7572aeb8
2022-02-14 10:55:58 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 194 with length 1
2022-02-14 10:55:59 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 194: [56]
2022-02-14 10:55:59 INFO  Executor:57 - Finished task 175.0 in stage 12.0 (TID 194). 6226 bytes result sent to driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:59 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Starting task 177.0 in stage 12.0 (TID 195, Clairvoyant-320, executor driver, partition 177, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:59 INFO  Executor:57 - Running task 177.0 in stage 12.0 (TID 195)
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Finished task 175.0 in stage 12.0 (TID 194) in 35 ms on Clairvoyant-320 (executor driver) (183/200)
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:59 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:59 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 177-178
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:228 - Task 195 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@558806bf
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:237 - Task 195 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@558806bf
2022-02-14 10:55:59 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 195 with length 1
2022-02-14 10:55:59 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 195: [56]
2022-02-14 10:55:59 INFO  Executor:57 - Finished task 177.0 in stage 12.0 (TID 195). 6226 bytes result sent to driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:59 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Starting task 178.0 in stage 12.0 (TID 196, Clairvoyant-320, executor driver, partition 178, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:59 INFO  Executor:57 - Running task 178.0 in stage 12.0 (TID 196)
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Finished task 177.0 in stage 12.0 (TID 195) in 27 ms on Clairvoyant-320 (executor driver) (184/200)
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:59 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:59 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 178-179
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:228 - Task 196 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2e89accf
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:237 - Task 196 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2e89accf
2022-02-14 10:55:59 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 196 with length 1
2022-02-14 10:55:59 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 196: [56]
2022-02-14 10:55:59 INFO  Executor:57 - Finished task 178.0 in stage 12.0 (TID 196). 6226 bytes result sent to driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:59 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Starting task 180.0 in stage 12.0 (TID 197, Clairvoyant-320, executor driver, partition 180, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Finished task 178.0 in stage 12.0 (TID 196) in 33 ms on Clairvoyant-320 (executor driver) (185/200)
2022-02-14 10:55:59 INFO  Executor:57 - Running task 180.0 in stage 12.0 (TID 197)
2022-02-14 10:55:59 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:59 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 180-181
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:228 - Task 197 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5db559ee
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:237 - Task 197 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5db559ee
2022-02-14 10:55:59 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 197 with length 1
2022-02-14 10:55:59 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 197: [56]
2022-02-14 10:55:59 INFO  Executor:57 - Finished task 180.0 in stage 12.0 (TID 197). 6226 bytes result sent to driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:59 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Starting task 181.0 in stage 12.0 (TID 198, Clairvoyant-320, executor driver, partition 181, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:59 INFO  Executor:57 - Running task 181.0 in stage 12.0 (TID 198)
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Finished task 180.0 in stage 12.0 (TID 197) in 31 ms on Clairvoyant-320 (executor driver) (186/200)
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:59 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:59 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 181-182
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:228 - Task 198 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7e9f2bca
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:237 - Task 198 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7e9f2bca
2022-02-14 10:55:59 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 198 with length 1
2022-02-14 10:55:59 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 198: [56]
2022-02-14 10:55:59 INFO  Executor:57 - Finished task 181.0 in stage 12.0 (TID 198). 6226 bytes result sent to driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:59 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Starting task 182.0 in stage 12.0 (TID 199, Clairvoyant-320, executor driver, partition 182, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:59 INFO  Executor:57 - Running task 182.0 in stage 12.0 (TID 199)
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Finished task 181.0 in stage 12.0 (TID 198) in 35 ms on Clairvoyant-320 (executor driver) (187/200)
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:59 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:59 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 182-183
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:228 - Task 199 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@34682c9f
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:237 - Task 199 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@34682c9f
2022-02-14 10:55:59 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 199 with length 1
2022-02-14 10:55:59 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 199: [56]
2022-02-14 10:55:59 INFO  Executor:57 - Finished task 182.0 in stage 12.0 (TID 199). 6226 bytes result sent to driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:59 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Starting task 184.0 in stage 12.0 (TID 200, Clairvoyant-320, executor driver, partition 184, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:59 INFO  Executor:57 - Running task 184.0 in stage 12.0 (TID 200)
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Finished task 182.0 in stage 12.0 (TID 199) in 34 ms on Clairvoyant-320 (executor driver) (188/200)
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:59 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:59 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 184-185
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:228 - Task 200 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4b36746f
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:237 - Task 200 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4b36746f
2022-02-14 10:55:59 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 200 with length 1
2022-02-14 10:55:59 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 200: [56]
2022-02-14 10:55:59 INFO  Executor:57 - Finished task 184.0 in stage 12.0 (TID 200). 6226 bytes result sent to driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:59 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Starting task 185.0 in stage 12.0 (TID 201, Clairvoyant-320, executor driver, partition 185, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Finished task 184.0 in stage 12.0 (TID 200) in 45 ms on Clairvoyant-320 (executor driver) (189/200)
2022-02-14 10:55:59 INFO  Executor:57 - Running task 185.0 in stage 12.0 (TID 201)
2022-02-14 10:55:59 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:59 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 185-186
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:228 - Task 201 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@55b0b59f
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:237 - Task 201 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@55b0b59f
2022-02-14 10:55:59 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 201 with length 1
2022-02-14 10:55:59 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 201: [56]
2022-02-14 10:55:59 INFO  Executor:57 - Finished task 185.0 in stage 12.0 (TID 201). 6226 bytes result sent to driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:59 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Starting task 186.0 in stage 12.0 (TID 202, Clairvoyant-320, executor driver, partition 186, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Finished task 185.0 in stage 12.0 (TID 201) in 36 ms on Clairvoyant-320 (executor driver) (190/200)
2022-02-14 10:55:59 INFO  Executor:57 - Running task 186.0 in stage 12.0 (TID 202)
2022-02-14 10:55:59 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:59 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 186-187
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:228 - Task 202 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@497732da
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:237 - Task 202 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@497732da
2022-02-14 10:55:59 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 202 with length 1
2022-02-14 10:55:59 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 202: [56]
2022-02-14 10:55:59 INFO  Executor:57 - Finished task 186.0 in stage 12.0 (TID 202). 6226 bytes result sent to driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:59 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Starting task 187.0 in stage 12.0 (TID 203, Clairvoyant-320, executor driver, partition 187, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:59 INFO  Executor:57 - Running task 187.0 in stage 12.0 (TID 203)
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Finished task 186.0 in stage 12.0 (TID 202) in 30 ms on Clairvoyant-320 (executor driver) (191/200)
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:59 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:59 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 187-188
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:228 - Task 203 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@9db4eaa
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:237 - Task 203 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@9db4eaa
2022-02-14 10:55:59 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 203 with length 1
2022-02-14 10:55:59 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 203: [56]
2022-02-14 10:55:59 INFO  Executor:57 - Finished task 187.0 in stage 12.0 (TID 203). 6226 bytes result sent to driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:59 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Starting task 188.0 in stage 12.0 (TID 204, Clairvoyant-320, executor driver, partition 188, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:59 INFO  Executor:57 - Running task 188.0 in stage 12.0 (TID 204)
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Finished task 187.0 in stage 12.0 (TID 203) in 38 ms on Clairvoyant-320 (executor driver) (192/200)
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:59 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:59 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 188-189
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:228 - Task 204 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2fcc28dd
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:237 - Task 204 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2fcc28dd
2022-02-14 10:55:59 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 204 with length 1
2022-02-14 10:55:59 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 204: [56]
2022-02-14 10:55:59 INFO  Executor:57 - Finished task 188.0 in stage 12.0 (TID 204). 6226 bytes result sent to driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:59 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Starting task 189.0 in stage 12.0 (TID 205, Clairvoyant-320, executor driver, partition 189, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:59 INFO  Executor:57 - Running task 189.0 in stage 12.0 (TID 205)
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Finished task 188.0 in stage 12.0 (TID 204) in 31 ms on Clairvoyant-320 (executor driver) (193/200)
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:59 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:59 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 189-190
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:228 - Task 205 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@341d0628
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:237 - Task 205 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@341d0628
2022-02-14 10:55:59 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 205 with length 1
2022-02-14 10:55:59 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 205: [56]
2022-02-14 10:55:59 INFO  Executor:57 - Finished task 189.0 in stage 12.0 (TID 205). 6226 bytes result sent to driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:59 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Starting task 192.0 in stage 12.0 (TID 206, Clairvoyant-320, executor driver, partition 192, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Finished task 189.0 in stage 12.0 (TID 205) in 34 ms on Clairvoyant-320 (executor driver) (194/200)
2022-02-14 10:55:59 INFO  Executor:57 - Running task 192.0 in stage 12.0 (TID 206)
2022-02-14 10:55:59 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:59 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 192-193
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:228 - Task 206 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@55a9c29b
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:237 - Task 206 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@55a9c29b
2022-02-14 10:55:59 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 206 with length 1
2022-02-14 10:55:59 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 206: [56]
2022-02-14 10:55:59 INFO  Executor:57 - Finished task 192.0 in stage 12.0 (TID 206). 6226 bytes result sent to driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:59 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Starting task 194.0 in stage 12.0 (TID 207, Clairvoyant-320, executor driver, partition 194, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:59 INFO  Executor:57 - Running task 194.0 in stage 12.0 (TID 207)
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Finished task 192.0 in stage 12.0 (TID 206) in 38 ms on Clairvoyant-320 (executor driver) (195/200)
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:59 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:59 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 194-195
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:228 - Task 207 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@56a6e6ba
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:237 - Task 207 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@56a6e6ba
2022-02-14 10:55:59 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 207 with length 1
2022-02-14 10:55:59 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 207: [56]
2022-02-14 10:55:59 INFO  Executor:57 - Finished task 194.0 in stage 12.0 (TID 207). 6226 bytes result sent to driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:59 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Starting task 195.0 in stage 12.0 (TID 208, Clairvoyant-320, executor driver, partition 195, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Finished task 194.0 in stage 12.0 (TID 207) in 32 ms on Clairvoyant-320 (executor driver) (196/200)
2022-02-14 10:55:59 INFO  Executor:57 - Running task 195.0 in stage 12.0 (TID 208)
2022-02-14 10:55:59 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:59 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 195-196
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:228 - Task 208 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2e667768
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:237 - Task 208 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2e667768
2022-02-14 10:55:59 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 208 with length 1
2022-02-14 10:55:59 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 208: [56]
2022-02-14 10:55:59 INFO  Executor:57 - Finished task 195.0 in stage 12.0 (TID 208). 6226 bytes result sent to driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:59 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Starting task 196.0 in stage 12.0 (TID 209, Clairvoyant-320, executor driver, partition 196, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:59 INFO  Executor:57 - Running task 196.0 in stage 12.0 (TID 209)
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Finished task 195.0 in stage 12.0 (TID 208) in 34 ms on Clairvoyant-320 (executor driver) (197/200)
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:59 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:59 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 196-197
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:228 - Task 209 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@246fca5d
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:237 - Task 209 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@246fca5d
2022-02-14 10:55:59 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 209 with length 1
2022-02-14 10:55:59 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 209: [56]
2022-02-14 10:55:59 INFO  Executor:57 - Finished task 196.0 in stage 12.0 (TID 209). 6226 bytes result sent to driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:59 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Starting task 197.0 in stage 12.0 (TID 210, Clairvoyant-320, executor driver, partition 197, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Finished task 196.0 in stage 12.0 (TID 209) in 39 ms on Clairvoyant-320 (executor driver) (198/200)
2022-02-14 10:55:59 INFO  Executor:57 - Running task 197.0 in stage 12.0 (TID 210)
2022-02-14 10:55:59 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:59 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 197-198
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:228 - Task 210 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7fc2d9e6
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:237 - Task 210 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7fc2d9e6
2022-02-14 10:55:59 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 210 with length 1
2022-02-14 10:55:59 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 210: [56]
2022-02-14 10:55:59 INFO  Executor:57 - Finished task 197.0 in stage 12.0 (TID 210). 6269 bytes result sent to driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:59 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Starting task 198.0 in stage 12.0 (TID 211, Clairvoyant-320, executor driver, partition 198, PROCESS_LOCAL, 7314 bytes)
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Finished task 197.0 in stage 12.0 (TID 210) in 29 ms on Clairvoyant-320 (executor driver) (199/200)
2022-02-14 10:55:59 INFO  Executor:57 - Running task 198.0 in stage 12.0 (TID 211)
2022-02-14 10:55:59 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-02-14 10:55:59 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0, partitions 198-199
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:228 - Task 211 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@57a6ba83
2022-02-14 10:55:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-14 10:55:59 DEBUG TaskMemoryManager:237 - Task 211 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@57a6ba83
2022-02-14 10:55:59 DEBUG LocalDiskShuffleMapOutputWriter:115 - Writing shuffle index file for mapId 211 with length 1
2022-02-14 10:55:59 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 211: [56]
2022-02-14 10:55:59 INFO  Executor:57 - Finished task 198.0 in stage 12.0 (TID 211). 6269 bytes result sent to driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-02-14 10:55:59 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Finished task 198.0 in stage 12.0 (TID 211) in 41 ms on Clairvoyant-320 (executor driver) (200/200)
2022-02-14 10:55:59 INFO  TaskSchedulerImpl:57 - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2022-02-14 10:55:59 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-02-14 10:55:59 INFO  DAGScheduler:57 - ShuffleMapStage 12 (count at UsedCase4.java:37) finished in 8.151 s
2022-02-14 10:55:59 INFO  DAGScheduler:57 - looking for newly runnable stages
2022-02-14 10:55:59 INFO  DAGScheduler:57 - running: Set()
2022-02-14 10:55:59 INFO  DAGScheduler:57 - waiting: Set(ResultStage 13)
2022-02-14 10:55:59 INFO  DAGScheduler:57 - failed: Set()
2022-02-14 10:55:59 DEBUG MapOutputTrackerMaster:61 - Increasing epoch to 2
2022-02-14 10:55:59 DEBUG DAGScheduler:61 - submitStage(ResultStage 13 (name=count at UsedCase4.java:37;jobs=11))
2022-02-14 10:55:59 DEBUG DAGScheduler:61 - missing: List()
2022-02-14 10:55:59 INFO  DAGScheduler:57 - Submitting ResultStage 13 (MapPartitionsRDD[61] at count at UsedCase4.java:37), which has no missing parents
2022-02-14 10:55:59 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 13)
2022-02-14 10:55:59 INFO  MemoryStore:57 - Block broadcast_28 stored as values in memory (estimated size 10.1 KiB, free 2.2 GiB)
2022-02-14 10:55:59 DEBUG BlockManager:61 - Put block broadcast_28 locally took 1 ms
2022-02-14 10:55:59 DEBUG BlockManager:61 - Putting block broadcast_28 without replication took 1 ms
2022-02-14 10:55:59 INFO  MemoryStore:57 - Block broadcast_28_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 2.2 GiB)
2022-02-14 10:55:59 INFO  BlockManagerInfo:57 - Added broadcast_28_piece0 in memory on Clairvoyant-320:60340 (size: 5.0 KiB, free: 2.2 GiB)
2022-02-14 10:55:59 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_28_piece0
2022-02-14 10:55:59 DEBUG BlockManager:61 - Told master about block broadcast_28_piece0
2022-02-14 10:55:59 DEBUG BlockManager:61 - Put block broadcast_28_piece0 locally took 2 ms
2022-02-14 10:55:59 DEBUG BlockManager:61 - Putting block broadcast_28_piece0 without replication took 2 ms
2022-02-14 10:55:59 INFO  SparkContext:57 - Created broadcast 28 from broadcast at DAGScheduler.scala:1223
2022-02-14 10:55:59 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[61] at count at UsedCase4.java:37) (first 15 tasks are for partitions Vector(0))
2022-02-14 10:55:59 INFO  TaskSchedulerImpl:57 - Adding task set 13.0 with 1 tasks
2022-02-14 10:55:59 DEBUG TaskSetManager:61 - Epoch for TaskSet 13.0: 2
2022-02-14 10:55:59 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-02-14 10:55:59 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 13.0: NODE_LOCAL, ANY
2022-02-14 10:55:59 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_13.0, runningTasks: 0
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Starting task 0.0 in stage 13.0 (TID 212, Clairvoyant-320, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
2022-02-14 10:55:59 INFO  Executor:57 - Running task 0.0 in stage 13.0 (TID 212)
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (13, 0) -> 1
2022-02-14 10:55:59 DEBUG BlockManager:61 - Getting local block broadcast_28
2022-02-14 10:55:59 DEBUG BlockManager:61 - Level for block broadcast_28 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-14 10:55:59 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 1, partitions 0-1
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Getting 200 (11.7 KiB) non-empty blocks including 200 (11.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-02-14 10:55:59 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_1_43_0,0), (shuffle_1_44_0,1), (shuffle_1_45_0,2), (shuffle_1_46_0,3), (shuffle_1_47_0,4), (shuffle_1_48_0,5), (shuffle_1_49_0,6), (shuffle_1_12_0,7), (shuffle_1_50_0,8), (shuffle_1_51_0,9), (shuffle_1_52_0,10), (shuffle_1_53_0,11), (shuffle_1_54_0,12), (shuffle_1_55_0,13), (shuffle_1_56_0,14), (shuffle_1_57_0,15), (shuffle_1_58_0,16), (shuffle_1_13_0,17), (shuffle_1_59_0,18), (shuffle_1_14_0,19), (shuffle_1_60_0,20), (shuffle_1_61_0,21), (shuffle_1_62_0,22), (shuffle_1_63_0,23), (shuffle_1_64_0,24), (shuffle_1_65_0,25), (shuffle_1_66_0,26), (shuffle_1_67_0,27), (shuffle_1_68_0,28), (shuffle_1_15_0,29), (shuffle_1_69_0,30), (shuffle_1_16_0,31), (shuffle_1_70_0,32), (shuffle_1_71_0,33), (shuffle_1_72_0,34), (shuffle_1_17_0,35), (shuffle_1_73_0,36), (shuffle_1_74_0,37), (shuffle_1_18_0,38), (shuffle_1_75_0,39), (shuffle_1_76_0,40), (shuffle_1_77_0,41), (shuffle_1_19_0,42), (shuffle_1_20_0,43), (shuffle_1_78_0,44), (shuffle_1_79_0,45), (shuffle_1_80_0,46), (shuffle_1_81_0,47), (shuffle_1_21_0,48), (shuffle_1_82_0,49), (shuffle_1_83_0,50), (shuffle_1_84_0,51), (shuffle_1_22_0,52), (shuffle_1_85_0,53), (shuffle_1_86_0,54), (shuffle_1_87_0,55), (shuffle_1_88_0,56), (shuffle_1_89_0,57), (shuffle_1_90_0,58), (shuffle_1_91_0,59), (shuffle_1_92_0,60), (shuffle_1_93_0,61), (shuffle_1_94_0,62), (shuffle_1_23_0,63), (shuffle_1_95_0,64), (shuffle_1_96_0,65), (shuffle_1_97_0,66), (shuffle_1_98_0,67), (shuffle_1_99_0,68), (shuffle_1_100_0,69), (shuffle_1_101_0,70), (shuffle_1_102_0,71), (shuffle_1_103_0,72), (shuffle_1_24_0,73), (shuffle_1_25_0,74), (shuffle_1_104_0,75), (shuffle_1_105_0,76), (shuffle_1_106_0,77), (shuffle_1_107_0,78), (shuffle_1_108_0,79), (shuffle_1_109_0,80), (shuffle_1_110_0,81), (shuffle_1_111_0,82), (shuffle_1_112_0,83), (shuffle_1_113_0,84), (shuffle_1_114_0,85), (shuffle_1_26_0,86), (shuffle_1_115_0,87), (shuffle_1_116_0,88), (shuffle_1_27_0,89), (shuffle_1_28_0,90), (shuffle_1_117_0,91), (shuffle_1_118_0,92), (shuffle_1_119_0,93), (shuffle_1_120_0,94), (shuffle_1_121_0,95), (shuffle_1_122_0,96), (shuffle_1_123_0,97), (shuffle_1_124_0,98), (shuffle_1_125_0,99), (shuffle_1_126_0,100), (shuffle_1_127_0,101), (shuffle_1_128_0,102), (shuffle_1_129_0,103), (shuffle_1_130_0,104), (shuffle_1_131_0,105), (shuffle_1_132_0,106), (shuffle_1_133_0,107), (shuffle_1_29_0,108), (shuffle_1_134_0,109), (shuffle_1_135_0,110), (shuffle_1_136_0,111), (shuffle_1_137_0,112), (shuffle_1_138_0,113), (shuffle_1_139_0,114), (shuffle_1_30_0,115), (shuffle_1_140_0,116), (shuffle_1_141_0,117), (shuffle_1_142_0,118), (shuffle_1_143_0,119), (shuffle_1_144_0,120), (shuffle_1_145_0,121), (shuffle_1_146_0,122), (shuffle_1_147_0,123), (shuffle_1_148_0,124), (shuffle_1_149_0,125), (shuffle_1_150_0,126), (shuffle_1_151_0,127), (shuffle_1_152_0,128), (shuffle_1_153_0,129), (shuffle_1_154_0,130), (shuffle_1_155_0,131), (shuffle_1_31_0,132), (shuffle_1_156_0,133), (shuffle_1_157_0,134), (shuffle_1_158_0,135), (shuffle_1_159_0,136), (shuffle_1_160_0,137), (shuffle_1_161_0,138), (shuffle_1_162_0,139), (shuffle_1_163_0,140), (shuffle_1_164_0,141), (shuffle_1_165_0,142), (shuffle_1_166_0,143), (shuffle_1_167_0,144), (shuffle_1_168_0,145), (shuffle_1_169_0,146), (shuffle_1_170_0,147), (shuffle_1_171_0,148), (shuffle_1_172_0,149), (shuffle_1_173_0,150), (shuffle_1_174_0,151), (shuffle_1_175_0,152), (shuffle_1_176_0,153), (shuffle_1_177_0,154), (shuffle_1_178_0,155), (shuffle_1_179_0,156), (shuffle_1_180_0,157), (shuffle_1_181_0,158), (shuffle_1_182_0,159), (shuffle_1_32_0,160), (shuffle_1_183_0,161), (shuffle_1_184_0,162), (shuffle_1_185_0,163), (shuffle_1_33_0,164), (shuffle_1_186_0,165), (shuffle_1_34_0,166), (shuffle_1_187_0,167), (shuffle_1_188_0,168), (shuffle_1_35_0,169), (shuffle_1_189_0,170), (shuffle_1_190_0,171), (shuffle_1_191_0,172), (shuffle_1_192_0,173), (shuffle_1_193_0,174), (shuffle_1_194_0,175), (shuffle_1_36_0,176), (shuffle_1_195_0,177), (shuffle_1_196_0,178), (shuffle_1_37_0,179), (shuffle_1_197_0,180), (shuffle_1_198_0,181), (shuffle_1_199_0,182), (shuffle_1_38_0,183), (shuffle_1_200_0,184), (shuffle_1_201_0,185), (shuffle_1_202_0,186), (shuffle_1_203_0,187), (shuffle_1_204_0,188), (shuffle_1_205_0,189), (shuffle_1_39_0,190), (shuffle_1_40_0,191), (shuffle_1_206_0,192), (shuffle_1_41_0,193), (shuffle_1_207_0,194), (shuffle_1_208_0,195), (shuffle_1_209_0,196), (shuffle_1_210_0,197), (shuffle_1_211_0,198), (shuffle_1_42_0,199)
2022-02-14 10:55:59 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 37 ms
2022-02-14 10:55:59 INFO  Executor:57 - Finished task 0.0 in stage 13.0 (TID 212). 2605 bytes result sent to driver
2022-02-14 10:55:59 DEBUG ExecutorMetricsPoller:61 - removing (13, 0) from stageTCMP
2022-02-14 10:55:59 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_13.0, runningTasks: 0
2022-02-14 10:55:59 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
2022-02-14 10:55:59 INFO  TaskSetManager:57 - Finished task 0.0 in stage 13.0 (TID 212) in 72 ms on Clairvoyant-320 (executor driver) (1/1)
2022-02-14 10:55:59 INFO  TaskSchedulerImpl:57 - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2022-02-14 10:55:59 INFO  DAGScheduler:57 - ResultStage 13 (count at UsedCase4.java:37) finished in 0.081 s
2022-02-14 10:55:59 DEBUG DAGScheduler:61 - After removal of stage 11, remaining stages = 2
2022-02-14 10:55:59 DEBUG DAGScheduler:61 - After removal of stage 13, remaining stages = 1
2022-02-14 10:55:59 DEBUG DAGScheduler:61 - After removal of stage 12, remaining stages = 0
2022-02-14 10:55:59 INFO  DAGScheduler:57 - Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
2022-02-14 10:55:59 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 13: Stage finished
2022-02-14 10:55:59 INFO  DAGScheduler:57 - Job 11 finished: count at UsedCase4.java:37, took 9.287596 s
2022-02-14 10:55:59 INFO  SparkContext:57 - Invoking stop() from shutdown hook
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:212 - stopping Server@59901c4d{STARTED}[9.4.40.v20210413]
2022-02-14 10:55:59 DEBUG Server:433 - doStop Server@59901c4d{STOPPING}[9.4.40.v20210413]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1038 - ran SparkUI-36-acceptor-0@4edef76c-ServerConnector@42b6d0cc{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} in QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=3,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}]
2022-02-14 10:55:59 DEBUG AbstractHandlerContainer:167 - Graceful shutdown Server@59901c4d{STOPPING}[9.4.40.v20210413] by 
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:212 - stopping Spark@42b6d0cc{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:212 - stopping SelectorManager@Spark@42b6d0cc{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:212 - stopping ManagedSelector@4207609e{STARTED} id=3 keys=0 selected=0 updates=0
2022-02-14 10:55:59 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$CloseConnections@64166e54 on ManagedSelector@4207609e{STOPPING} id=3 keys=0 selected=0 updates=0
2022-02-14 10:55:59 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@4207609e{STOPPING} id=3 keys=0 selected=0 updates=1
2022-02-14 10:55:59 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@396675eb woken with none selected
2022-02-14 10:55:59 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@396675eb woken up from select, 0/0/0 selected
2022-02-14 10:55:59 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@396675eb processing 0 keys, 1 updates
2022-02-14 10:55:59 DEBUG ManagedSelector:558 - updateable 1
2022-02-14 10:55:59 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$CloseConnections@64166e54
2022-02-14 10:55:59 DEBUG ManagedSelector:996 - Closing 0 connections on ManagedSelector@4207609e{STOPPING} id=3 keys=0 selected=0 updates=0
2022-02-14 10:55:59 DEBUG ManagedSelector:587 - updates 0
2022-02-14 10:55:59 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@396675eb waiting with 0 keys
2022-02-14 10:55:59 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$StopSelector@20f633d on ManagedSelector@4207609e{STOPPING} id=3 keys=0 selected=0 updates=0
2022-02-14 10:55:59 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@4207609e{STOPPING} id=3 keys=0 selected=0 updates=1
2022-02-14 10:55:59 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@396675eb woken with none selected
2022-02-14 10:55:59 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@396675eb woken up from select, 0/0/0 selected
2022-02-14 10:55:59 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@396675eb processing 0 keys, 1 updates
2022-02-14 10:55:59 DEBUG ManagedSelector:558 - updateable 1
2022-02-14 10:55:59 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$StopSelector@20f633d
2022-02-14 10:55:59 DEBUG ManagedSelector:587 - updates 0
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:212 - stopping EatWhatYouKill@17690e14/SelectorProducer@6850b758/PRODUCING/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:59.6978591+05:30
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.io.ManagedSelector$$Lambda$447/0x000000080052ac40@7d04529c in QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}]
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:224 - STOPPED EatWhatYouKill@17690e14/SelectorProducer@6850b758/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:59.6978591+05:30
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:224 - STOPPED ManagedSelector@4207609e{STOPPED} id=3 keys=-1 selected=-1 updates=0
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:212 - stopping ManagedSelector@1fac1d5c{STARTED} id=2 keys=0 selected=0 updates=0
2022-02-14 10:55:59 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$CloseConnections@3afe3505 on ManagedSelector@1fac1d5c{STOPPING} id=2 keys=0 selected=0 updates=0
2022-02-14 10:55:59 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@1fac1d5c{STOPPING} id=2 keys=0 selected=0 updates=1
2022-02-14 10:55:59 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@6c74b96a woken with none selected
2022-02-14 10:55:59 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@6c74b96a woken up from select, 0/0/0 selected
2022-02-14 10:55:59 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@6c74b96a processing 0 keys, 1 updates
2022-02-14 10:55:59 DEBUG ManagedSelector:558 - updateable 1
2022-02-14 10:55:59 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$CloseConnections@3afe3505
2022-02-14 10:55:59 DEBUG ManagedSelector:996 - Closing 0 connections on ManagedSelector@1fac1d5c{STOPPING} id=2 keys=0 selected=0 updates=0
2022-02-14 10:55:59 DEBUG ManagedSelector:587 - updates 0
2022-02-14 10:55:59 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$StopSelector@1d7942b9 on ManagedSelector@1fac1d5c{STOPPING} id=2 keys=0 selected=0 updates=0
2022-02-14 10:55:59 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@6c74b96a waiting with 0 keys
2022-02-14 10:55:59 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@1fac1d5c{STOPPING} id=2 keys=0 selected=0 updates=1
2022-02-14 10:55:59 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@6c74b96a woken with none selected
2022-02-14 10:55:59 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@6c74b96a woken up from select, 0/0/0 selected
2022-02-14 10:55:59 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@6c74b96a processing 0 keys, 1 updates
2022-02-14 10:55:59 DEBUG ManagedSelector:558 - updateable 1
2022-02-14 10:55:59 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$StopSelector@1d7942b9
2022-02-14 10:55:59 DEBUG ManagedSelector:587 - updates 0
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:212 - stopping EatWhatYouKill@65d57e4e/SelectorProducer@6daf7d37/PRODUCING/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:59.6978591+05:30
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.io.ManagedSelector$$Lambda$447/0x000000080052ac40@59ed3e6c in QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}]
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:224 - STOPPED EatWhatYouKill@65d57e4e/SelectorProducer@6daf7d37/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:59.6978591+05:30
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:224 - STOPPED ManagedSelector@1fac1d5c{STOPPED} id=2 keys=-1 selected=-1 updates=0
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:212 - stopping ManagedSelector@741f8dbe{STARTED} id=1 keys=0 selected=0 updates=0
2022-02-14 10:55:59 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$CloseConnections@39ffb95c on ManagedSelector@741f8dbe{STOPPING} id=1 keys=0 selected=0 updates=0
2022-02-14 10:55:59 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@741f8dbe{STOPPING} id=1 keys=0 selected=0 updates=1
2022-02-14 10:55:59 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@7be3e310 woken with none selected
2022-02-14 10:55:59 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@7be3e310 woken up from select, 0/0/0 selected
2022-02-14 10:55:59 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@7be3e310 processing 0 keys, 1 updates
2022-02-14 10:55:59 DEBUG ManagedSelector:558 - updateable 1
2022-02-14 10:55:59 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$CloseConnections@39ffb95c
2022-02-14 10:55:59 DEBUG ManagedSelector:996 - Closing 0 connections on ManagedSelector@741f8dbe{STOPPING} id=1 keys=0 selected=0 updates=0
2022-02-14 10:55:59 DEBUG ManagedSelector:587 - updates 0
2022-02-14 10:55:59 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$StopSelector@20cdcb35 on ManagedSelector@741f8dbe{STOPPING} id=1 keys=0 selected=0 updates=0
2022-02-14 10:55:59 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@7be3e310 waiting with 0 keys
2022-02-14 10:55:59 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@741f8dbe{STOPPING} id=1 keys=0 selected=0 updates=1
2022-02-14 10:55:59 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@7be3e310 woken with none selected
2022-02-14 10:55:59 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@7be3e310 woken up from select, 0/0/0 selected
2022-02-14 10:55:59 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@7be3e310 processing 0 keys, 1 updates
2022-02-14 10:55:59 DEBUG ManagedSelector:558 - updateable 1
2022-02-14 10:55:59 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$StopSelector@20cdcb35
2022-02-14 10:55:59 DEBUG ManagedSelector:587 - updates 0
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:212 - stopping EatWhatYouKill@17d32e9b/SelectorProducer@66f0548d/PRODUCING/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:59.6978591+05:30
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.io.ManagedSelector$$Lambda$447/0x000000080052ac40@6c931d35 in QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}]
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:224 - STOPPED EatWhatYouKill@17d32e9b/SelectorProducer@66f0548d/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:59.7030132+05:30
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:224 - STOPPED ManagedSelector@741f8dbe{STOPPED} id=1 keys=-1 selected=-1 updates=0
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:212 - stopping ManagedSelector@51841ac6{STARTED} id=0 keys=0 selected=0 updates=0
2022-02-14 10:55:59 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$CloseConnections@51d2f64a on ManagedSelector@51841ac6{STOPPING} id=0 keys=0 selected=0 updates=0
2022-02-14 10:55:59 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@51841ac6{STOPPING} id=0 keys=0 selected=0 updates=1
2022-02-14 10:55:59 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@18fd92dc woken with none selected
2022-02-14 10:55:59 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@18fd92dc woken up from select, 0/0/0 selected
2022-02-14 10:55:59 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@18fd92dc processing 0 keys, 1 updates
2022-02-14 10:55:59 DEBUG ManagedSelector:558 - updateable 1
2022-02-14 10:55:59 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$CloseConnections@51d2f64a
2022-02-14 10:55:59 DEBUG ManagedSelector:996 - Closing 0 connections on ManagedSelector@51841ac6{STOPPING} id=0 keys=0 selected=0 updates=0
2022-02-14 10:55:59 DEBUG ManagedSelector:587 - updates 0
2022-02-14 10:55:59 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@18fd92dc waiting with 0 keys
2022-02-14 10:55:59 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$StopSelector@2b3969c on ManagedSelector@51841ac6{STOPPING} id=0 keys=0 selected=0 updates=0
2022-02-14 10:55:59 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@51841ac6{STOPPING} id=0 keys=0 selected=0 updates=1
2022-02-14 10:55:59 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@18fd92dc woken with none selected
2022-02-14 10:55:59 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@18fd92dc woken up from select, 0/0/0 selected
2022-02-14 10:55:59 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@18fd92dc processing 0 keys, 1 updates
2022-02-14 10:55:59 DEBUG ManagedSelector:558 - updateable 1
2022-02-14 10:55:59 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$StopSelector@2b3969c
2022-02-14 10:55:59 DEBUG ManagedSelector:587 - updates 0
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:212 - stopping EatWhatYouKill@67efd2c2/SelectorProducer@10fda3d0/PRODUCING/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:59.7080618+05:30
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.io.ManagedSelector$$Lambda$447/0x000000080052ac40@3bddc676 in QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}]
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:224 - STOPPED EatWhatYouKill@67efd2c2/SelectorProducer@10fda3d0/IDLE/p=false/QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-14T10:55:59.708562+05:30
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:224 - STOPPED ManagedSelector@51841ac6{STOPPED} id=0 keys=-1 selected=-1 updates=0
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:224 - STOPPED SelectorManager@Spark@42b6d0cc{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:212 - stopping HttpConnectionFactory@74d3b638[HTTP/1.1]
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:224 - STOPPED HttpConnectionFactory@74d3b638[HTTP/1.1]
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:212 - stopping ScheduledExecutorScheduler@14b7786{STARTED}
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:224 - STOPPED ScheduledExecutorScheduler@14b7786{STOPPED}
2022-02-14 10:55:59 INFO  AbstractConnector:381 - Stopped Spark@42b6d0cc{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:224 - STOPPED Spark@42b6d0cc{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-14 10:55:59 DEBUG AbstractHandler:107 - stopping Server@59901c4d{STOPPING}[9.4.40.v20210413]
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:212 - stopping ContextHandlerCollection@7139bd31{STARTED}
2022-02-14 10:55:59 DEBUG AbstractHandler:107 - stopping ContextHandlerCollection@7139bd31{STOPPING}
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:224 - STOPPED ContextHandlerCollection@7139bd31{STOPPED}
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:212 - stopping ErrorHandler@47af099e{STARTED}
2022-02-14 10:55:59 DEBUG AbstractHandler:107 - stopping ErrorHandler@47af099e{STOPPING}
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:224 - STOPPED ErrorHandler@47af099e{STOPPED}
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:212 - stopping QueuedThreadPool[SparkUI]@3e1a3801{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:224 - Stopping QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@18acfe88{s=0/8,p=0}]
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:212 - stopping ReservedThreadExecutor@18acfe88{s=0/8,p=0}
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:224 - STOPPED ReservedThreadExecutor@18acfe88{s=-1/8,p=0}
2022-02-14 10:55:59 DEBUG QueuedThreadPool:317 - Waiting for Thread[SparkUI-31,5,main] for 14999
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@5a090f9a in QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@5a090f9a in QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@5a090f9a in QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@5a090f9a in QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@5a090f9a in QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@5a090f9a in QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@5a090f9a in QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@5a090f9a in QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@5a090f9a in QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@5a090f9a in QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@5a090f9a in QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@5a090f9a in QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@5a090f9a in QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@5a090f9a in QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@5a090f9a in QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-31,5,main] exited for QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-35,5,main] exited for QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-37,5,main] exited for QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-36,5,main] exited for QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-33,5,main] exited for QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-34,5,main] exited for QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$437/0x0000000800528c40@5a090f9a in QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-38,5,main] exited for QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:317 - Waiting for Thread[SparkUI-33,5,main] for 14998
2022-02-14 10:55:59 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-32,5,main] exited for QueuedThreadPool[SparkUI]@3e1a3801{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG QueuedThreadPool:317 - Waiting for Thread[SparkUI-38,5,] for 14996
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:224 - STOPPED QueuedThreadPool[SparkUI]@3e1a3801{STOPPED,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-14 10:55:59 DEBUG AbstractLifeCycle:224 - STOPPED Server@59901c4d{STOPPED}[9.4.40.v20210413]
2022-02-14 10:55:59 INFO  SparkUI:57 - Stopped Spark web UI at http://Clairvoyant-320:4040
2022-02-14 10:55:59 INFO  MapOutputTrackerMasterEndpoint:57 - MapOutputTrackerMasterEndpoint stopped!
2022-02-14 10:56:01 INFO  MemoryStore:57 - MemoryStore cleared
2022-02-14 10:56:01 INFO  BlockManager:57 - BlockManager stopped
2022-02-14 10:56:01 INFO  BlockManagerMaster:57 - BlockManagerMaster stopped
2022-02-14 10:56:01 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:57 - OutputCommitCoordinator stopped!
2022-02-14 10:56:01 INFO  SparkContext:57 - Successfully stopped SparkContext
2022-02-14 10:56:01 INFO  ShutdownHookManager:57 - Shutdown hook called
2022-02-14 10:56:01 INFO  ShutdownHookManager:57 - Deleting directory C:\Users\Shridhar Ingale\AppData\Local\Temp\spark-2cebba06-97ac-4158-84e6-88f5ed845c51
